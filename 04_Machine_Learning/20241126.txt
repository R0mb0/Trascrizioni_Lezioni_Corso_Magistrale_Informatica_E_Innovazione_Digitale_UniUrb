benissimo allora eccoci qua intanto buongiorno a tutti oggi proseguiamo ovviamente con la lezione di ieri che abbiamo interrotto in un punto abbastanza cruciale abbastanza interessante a proposito dei problemi della generalizzazione overfitting, underfitting quindi continuiamo questo tipo di su questo argomento ecco andremo un po' avanti vedremo un po' altre cose facciamo un breve riepilogo delle ultimissime cose che stavamo dicendo giusto per riallacciarci proprio all'argomento abbiamo visto che quando noi cominciamo a fare il training di modelli sempre più complessi nel caso di dati perfetti ovviamente questo implica che noi riusciamo in maniera sempre più precisa ad approssimare o la funzione di regressione che vogliamo andare a rappresentare oppure un confine decisionale che può essere quello di un classificatore quindi anche lì riusciamo ad approssimare una funzione in maniera arbitrariamente precisa i problemi nascono nel momento in cui abbiamo dei dati reali quindi dei dati che sono finiti, discreti e affetti da rumore in quel caso quello che si vede è che aumentando la complessità del modello quindi per esempio la sua capacità intesa come numero di unità che quel dato approssimatore universale è in grado di supportare quello che succede è che cos'è? vediamo che mentre il training set sul training set il modello chiaramente ha un errore sempre decrescente quindi fino ad avere delle performance praticamente ideali, perfette quindi non sbagliando nessun punto ad esempio nel caso del problema della classificazione o andando perfettamente ad adattarsi nel caso della regressione ai punti del training set il problema nasce nel momento in cui andiamo a provare su punti che lui non ha mai visto il nostro modello provare su punti che lui non ha mai visto significa testarne la capacità di generalizzare e se noi abbiamo schiacciato il modello troppo sul cioè abbiamo costruito un modello troppo complesso quindi abbiamo in qualche modo schiacciato l'acceleratore diciamo sulla parte del training su quei dati significa appunto schiacciare il modello verso i dati di training quindi anche verso il rumore e schiacciare sul rumore significa appiattire il modello in una direzione che non è quella corretta vogliamo mantenere la capacità di generalizzare e non di andare a riprodurre qualunque variazione potenzialmente rumorosa o diciamo fare in modo che vada a interpolare perfettamente dei punti in cui in mezzo non sappiamo effettivamente che cosa c'è e allora è meglio mantenere un modello meno complesso che però quando viene calato in una realtà che è quella poi in cui dovrà operare riesce però a cavarsela meglio essere più robusto rispetto a un modello che è stato molto preciso in fase di generalizzazione scusatemi di addestramento ma non lo è in fase di generalizzazione e qui avevamo visto un po' di esempi ecco questo per il caso della classificazione ne avevamo visti altrettanti per i problemi di regressione e qui la cosa con cui ci eravamo lasciati nell'ultima lezione era proprio la considerazione del fatto che l'errore di classificazione o comunque la funzione di perdita o l'errore quadratico medio se stiamo parlando per esempio di un problema di regressione sul training set non è uno strumento che ci aiuta a capire quando siamo in regione di underfitting o di overfitting come facciamo ad andare a capire quando invece siamo in questo caso? beh la strategia è abbastanza semplice quello che poi vi anticipavo già proprio alla fine della lezione di ieri quello che si fa è si prende il nostro training set e si suddivide non più in il nostro dataset scusatemi prendiamo non lo suddividiamo più solo in training set e test set ma lo suddividiamo in training set validation set e test set validation set quindi un'ulteriore porzione che viene destinata a fare che cosa? a fare la validazione del modello cioè a cercare di capire quale perché qui dobbiamo capire tra questi modelli questo è un modello questo è un altro modello questo è un altro modello e noi dobbiamo capire tra questi ad esempio in questo caso ho tre alternative ma chiaramente ne posso avere molto di più qual è quello migliore da un punto di vista della generalizzazione della capacità di generalizzare e non abbiamo a disposizione questo perché abbiamo detto che questa non ci dà alcuna informazione se io però comincio a ragionare lasciando una porzione del mio dataset alla validazione a quel punto faccio il training dei miei modelli comincio a vedere sul dataset di validazione quali sono le prestazioni e quello agisce come se fosse un qualcosa che di fatto simula una situazione di testing ok? quindi lì che cosa ci accorgiamo? ci accorgiamo della capacità o meno di generalizzare per cui se il modello è troppo complesso ed è stato addestrato in maniera rispetto appunto al dataset di addestramento in maniera troppo troppo avanzata rispetto a quello che è il dataset me ne accorgo quando vado sull'insieme di validazione ok? e a quel punto adesso poi questo si capirà meglio nelle slide successive però intanto ve lo anticipo a quel punto noi possiamo selezionare il modello migliore e quello sarà quello che poi andiamo a testare sul dataset di testi ok? e qui c'è un po' una slide di riassunto di tutte le cose che abbiamo detto ieri e che vi ho appunto poco fa ripreso nel momento in cui abbiamo dati di tipo perfetto aumentare la capacità del modello significa arrivare a una rappresentazione migliore qui abbiamo un dato di tipo perfetto supponiamo di addestrare ogni singolo modello vedete la leva del disco dell'ottimizzazione la manopola è girata tutta verso destra quindi ottimizzazione al meglio che possiamo di ogni singolo modello quindi tutte le epoche che ci servono tutte le iterazioni che ci servono per portare ad esempio un metodo di discesa del gradiente a convergenza e qui gradualmente abbiamo la leva della capacità il che significa che parto da poche unità per esempio del nostro approssimitore universale poi comincio a costruire un modello più con maggiore capacità lungo delle unità e quindi piano piano raggiungo una rappresentazione per questo che è perfetta del mio dataset qui ho un problema di regressione ma potrebbe essere di classificazione allo stesso modo io potrei partire subito con un modello di capacità molto alta il massimo che mi posso permettere ad esempio e lavorare sull'ottimizzazione questi sono due modi due leve la capacità e l'ottimizzazione che concorrono entrambe alla complessità del modello perché io posso partire con un modello che ha elevatissima capacità quindi scelgo un modello con tante unità di reti neurali, di alberi, quello che volete un modello molto grande sparo i parametri a caso cioè non otimizzo niente e chiaramente il risultato è una cosa di questo tipo creo un modello che ovviamente non assomiglia per niente alla funzione di cui ad esempio voglio farla regressione piano piano comincio a ottimizzare quel modello significa che comincio a far eseguire per esempio un metodo di ottimizzazione come appunto il cesare il radiente quello che volete e posso andare avanti e man mano che vado avanti piano piano quel modello comincerà a rappresentare sempre meglio il dataset fino ad arrivare alla rappresentazione perfetta questo se il dataset è perfetto se il dataset quindi due cose prima cosa dataset perfetto e dataset reale seconda cosa capacità più ottimizzazione come possibilità di agire per costruire per aumentare la complessità di un modello voi potete partire da un modello ad ampia capacità e ragionare sull'ottimizzazione o viceversa partire dal presupposto di ottimizzare sempre e lavorare su un modello di capacità diversa questo perché essendo due leve distinte rimane più comodo tenerne una fissa e lavorare sull'altra piuttosto che lavorare su tutte e due anche se ovviamente poi nella realtà quello che si fa è trovare, tentare combinazioni diverse se il dataset è reale quello che succede l'abbiamo visto ieri andando da da sinistra verso destra andiamo qui in una regione di overfitting qui siamo in underfitting e questa è invece la situazione reale nella quale vogliamo cercare di trovarci ecco quindi come facciamo? il problema è cosa succede? qui abbiamo il nostro esempio di regressione con un dataset reale da cui siamo partiti ieri qui abbiamo un esempio di classificazione in particolare giusto per dirvi di cosa si tratta qui abbiamo nella rega sopra un modello di regressione il primo è chiaramente un modello di regressione lineare lo vedete da qui qui abbiamo un modello polinomiale con grado 20 e qui abbiamo un modello polinomiale con grado pari a 3 qui abbiamo sempre un esempio con le l'approssimatore universale basato su unità polinomiale stessa cosa abbiamo visto se avessi preso delle reti neurali o degli alberi qui giusto per curiosità qui abbiamo un modello lineare un modello lineare molto semplice che tra l'altro classifica tutto come appartenente alla classe blu e la classe 1 qui abbiamo un modello polinomiale di grado 20 e qui abbiamo un modello polinomiale in cui il grado è pari a 2 ok questo è un problema di classificazione allora ovviamente come abbiamo detto prima se spingo troppo la leva della capacità della complessità diciamo meglio della complessità perché la posso ottenere sia tramite capacità che tramite ottimizzazione vado decisamente in overfitting qui qualunque punto io vada a prendere per fare regressione o classificazione decisamente che lui non ha mai visto molto probabilmente mi condurrà a degli errori come faccio a selezionare il livello di complessità giusta che è chiaramente quella di destra viceversa l'underfitting è chiaro che mi porta a sbagliare comunque tramite appunto quel processo che vi dicevo si chiama che sfrutta l'introduzione di un insieme di validazione è un processo che viene chiamato validazione incrociata in inglese cross validation cos'è la cross validation cross la cross validation è proprio quel processo che vi permette di tenere sotto controllo la complessità di un modello andandone a verificare le prestazioni su un insieme di dati che lui non ha mai visto che voi avete lasciato da parte il che significa come vi anticipavo ieri che noi dobbiamo sacrificare un'ulteriore fetta del nostro dataset per fare questo tipo di analisi però è necessario perché altrimenti rischiamo di ritrovarci in questi problemi e questo rende ancora più importante ovviamente il fatto di avere dei dataset che siano abbastanza che contengono abbastanza dati per poter addestrare un modello ma anche per poterlo validare e poi rimane il problema del testing perché una volta che l'abbiamo validato l'insieme di validazione serve per dire quale tra queste tre colonne è la migliore poi una volta che l'abbiamo scelta dobbiamo andare a vedere anche cosa succede in generale nel dataset di testing perché la correttità vuole questo che io vado a vedere cosa succede nel dataset di testing ulteriormente quello che si fa sì sì sì la domanda era come facciamo quindi a identificare il punto a partire dal quale avviene l'overfitting è proprio quello che vi andiamo a vedere adesso quindi come facciamo a selezionare il punto giusto della complessità l'errore di training non ci aiuta dobbiamo stimare l'accuratezza del dato che riceveremo in futuro ma ovviamente noi non lo sappiamo qual è il dato che riceveremo in futuro come facciamo? lo simuliamo lo simuliamo suddividendo il dataset in training e validation poi magari ce ne lasciamo una parte fuori per il test per fare le cose fatte per bene una volta che abbiamo scelto il modello diciamo ok questo è il test però intanto training e validation è quello che si fa e training e validation solitamente anche qui si va secondo regole empiriche diciamo si va da una frazione un decimo fino a un terzo il validation set a seconda di quanti dati abbiamo se ne abbiamo pochi un decimo se ne abbiamo un dataset più corposo si può arrivare fino a un terzo da assegnare al validation set queste solitamente sono delle regole empiriche che si danno e come vi dicevo il processo attraverso il quale diversi modelli che hanno diverse complessità vengono confrontati viene chiamato validazione incrociata ok allora ci sono diversi modi diverse metodologie per fare validazione incrociata ne vedremo alcune non ne vedremo chiaramente tutte intanto per capire che cosa è e come funziona vi definisco il modo più immediato intuibile che viene chiamato anche metodo di validazione incrociata cosiddetto in grino ok che funziona funziona ha delle limitazioni che discuteremo tra poco ma insomma in linea di principio è assolutamente un metodo molto pulito e diciamo è opportuno introdurlo se non altro perché appunto ci aiuta a capire come funziona tutta la tutto quello che c'è dietro questo meccanismo allora quello che si fa è semplicemente andare a valutare i modelli che hanno diversa capacità sul validation set quindi io a destra ho tanti modelli sul training set quanti ne voglio e poi ognuno di quelli lo vado a valutare sul validation set e vado a selezionare quello che ha l'errore di validazione scusatemi di validazione più bassa che cosa succede supponiamo di ragionare no nel caso in cui abbiamo detto per semplicità queste due leve no agiamo solo su una quindi l'ottimizzazione la facciamo meglio che possiamo e quindi andiamo a variare la leva della capacità che significa che partiamo da un modello che ha ad esempio un'unità poi ne aggiungiamo un'altra due tre quattro fino a un valore massimo bene quindi costruiamo una rete neurale con tante unità di questo tipo un albero con tante unità di questo tipo un approssimatore polinomiale con tante unità di questo tipo quante m grande o m a ognuno di questi corrisponde un differente modello cioè io posso andare a scrivere una cosa di questo genere quello che posso scrivere è che hanno in generale un modello in cui il primo modello chiamiamo modello 1 che è una funzione di x e dell'insieme dei parametri teta teta 1 sarà u0 più f1 di x per u2 ok poi avrò model 2 di x funzionando l'insieme dei parametri teta 2 sarà che cosa w0 più f1 di x w1 più f2 scusatemi per questo più f2 di x per w2 e così via fino ad arrivare al modello m sempre funziona di x avrà il suo insieme di parametri teta m che come sempre è questi parametri w0 w1 w2 più tutti i parametri interni vi ricordate ieri abbiamo visto tutte le funzioni che si portano dietro quelle per esempio le reti neurali o gli alberi una serie di parametri interni che sarà w0 più f1 di x per w1 più e c'è con m di x per wm ok quindi io mi costruisco quanti? 1 2 m maiuscolo modelli quindi ognuno di quei modelli viene addestrato viene fatto il training di unione di quei modelli al massimo delle possibilità di ottimizzazione e ognuno di quelli rappresenta una possibile alterna a questo punto io che cosa faccio? vedo una cosa vedo che per ognuno di questi ho una curva e lo vedete qui e posso costruire una curva che è una curva in cui vado a mettere l'errore e qui vado a mettere la complessità cosa intendo? beh l'errore può essere se è un classificatore il numero di di errore di classificazione che fa se è un problema di regressione l'errore quadratico medio ok? la complessità semplicemente è un indice che va da 1 a m grande i modelli va bene? complessità minima 2 3 5 ok? allora cosa succede? che io mi comincio ad accorgere che guardiamo la curva la curva blu la curva blu mi dice che cosa? che crescendo la complessità aumentando la complessità del modello l'errore diminuisce giusto? è quello che abbiamo visto in tutti gli esempi dell'ultima lezione che abbiamo ripilogato stamattina se io aumento la complessità del modello l'errore di training diminuisce fino a diventare potenzialmente zero non sbaglio più nessun punto ad esempio in un problema di classificazione o il problema di regressione riduco proprio a zero perché vado a fare un fitting perfetto di quei punti ok? però io non mi accorgo abbiamo detto guardando solo l'errore di training del fatto che sono andato in overfitting come me ne accorgo? introducendo l'errore di validazione cioè ho messo da parte dei dati che il mio modello non ha mai visto e siccome non li ha mai visti simulano di fatto quei dati che lui potrebbe vedere in futuro e a quel punto su quei dati lui comincerà a sbagliare perché saranno quei dati che si portano dietro quelle informazioni no? e se siamo nella regressione in un punto che va a finire in alto molto in basso oppure in quei punti che finiscono nei problemi di classificazione in quelle aree che vengono coperte perché magari c'è un errore e allora il classificatore comincia a costruire una piccola area intorno a quel punto d'errore per dire qui ci sono dei punti potenzialmente appartenenti all'altra classe ecco in questo modo che cosa succede? che io mi comincio ad accorgere all'aumentare della complessità vado a costruire questa curva gialla e questa curva gialla ha tipicamente un andamento a 1 cioè comincia a scendere all'inizio aumentando la complessità io parto da una zona che chiaramente è di underfitting quando ho la complessità minima solitamente a meno che non sono partito già con un modello che è troppo elevato per identificare l'underfitting ma se parto dai modelli proprio a minima complessità sono per definizione in underfitting comincia a scendere le prestazioni cioè comincia a fare meno errori aumentando la complessità è giusto questo arriverò a un valore minimo però a partire dal quale io comincio a risalire perché comincio a risalire perché entro in quel regime in cui piano piano aggiungo della complessità che va a scapito della capacità di generalizzare e allora arrivo a un punto in cui comincia la zona cosiddetta di overfitting quanto sono grandi queste due zone per rispondere alla domanda che mi faceva lui prima dipende ovviamente non è che possiamo dare delle regole assolute però quello che possiamo vedere non possiamo essere certi che l'overfitting comincia esattamente qui o magari lì qua ok però quello che possiamo dire sicuramente è che il punto migliore in cui collocarci è questo questo è un punto in cui noi sappiamo che lo evitiamo l'overfitting quindi andiamo a scegliere tra tutti i vari modelli quello che ha l'errore di validazione più basso ci siamo? avete capito? quindi dove inizia l'overfitting l'overfitting inizia dove il modello comincia l'errore di validazione dei modelli comincia a crescere nel momento in cui ha toccato il minimo già il punto successivo è un punto in cui cominciamo ad andare verso l'overfitting ma poi ci andiamo in maniera sempre più marcata esattamente la curva blu è l'errore sul training 7 e quella gialla sul test 7 lo scrivo qua questo è validation questo è training sì la domanda è dobbiamo tenere sotto controllo se non ho capito male quello che è il nostro dataset e il margine dell'errore che fa la risposta è sì la risposta è sì quello che si fa tipicamente adesso poi se non sbaglio c'è un'altra slide vi faccio vedere altri esempi si fa il training e durante l'addestramento si tiene sotto controllo l'errore di validazione so during training you have to keep under control the validation error when the validation error starts to increase you can stop yes and you decide to stop this is the way usually you you can go allora questo è l'approccio più generale alla validazione incrociata ci sono un paio di controindicazioni nel senso che funziona molto bene in linea di principio questo qui è noto in letteratura anche come diciamo la contrapposizione tra underfitting overfitting viene chiamato anche bias variance tra i due cioè il compromesso tra quello che è la varianza la variabilità e il bias cioè quando io lavoro in underfitting sto lavorando in una zona che si dice a bias elevato quando lavoro in overfitting a varianza elevata il compromesso tra queste due è la zona giusta dove ci si deve collocare va bene questo è giusto per darmi qualche volta lo trovate se magari vi capita in un testo in letteratura in inglese allora vi dicevo questo funziona però c'è un problema ci sono due categorie di problemi per cui in realtà la validazione di solito la validazione incrociata non si fa in questo modo perché ci sono due categorie di problemi il primo è legato alla complessità computazionale io devo addestrare m modelli m modelli per poter tener conto per potermi accorgere che cosa succede e allora quello che si fa è quello che dicevo a lui prima cioè in realtà quello che si fa durante l'addestramento adesso ve lo dirò meglio ci sono varie tecniche ma ci si ferma e quando ci si accorge che l'errore di validazione ricomincia a crescere perché io in questo modo invece ho addestramento di ogni modello al completo all'ottimizzazione massima questo significa che io devo addestrare m grande dove m è un numero arbitrario modelli e questo può essere costoso da un punto di vista computazionale primo problema della validazione incrociata quella di base naif standard secondo problema nel momento in cui io passo da 1 a 2 a 3 a 4 giungo delle unità può essere anche che io faccia un salto di capacità eccessivamente elevato e quindi magari mi perda qualcosa in mezzo che è ancora migliore questo dipende anche dall'architettura del sistema su cui stiamo lavorando molto dipendente dal tipo di di modello di machine learning su cui stiamo lavorando però anche qui potrebbe essere nel passare da model 1 model 2 a model 3 model 4 può essere che in mezzo ci sia un model 1.5 che è più adatto a risolvere il problema allora come si fa a risolvere queste due tipologie di problemi cioè non addestrare 100 modelli diversi per accorgermi che sto andando sulla curva in overfitting come lavorare e posizionarci in posizioni intermedie lavorare quindi su una grana un po' più fine per trovare modelli ancora migliori ci sono diverse tecniche fin qui ci siamo questo ok questo direi abbastanza semplice ok qui vi fa rivedere semplicemente una cosa che prima di andare a vedere come si fa vediamo questo esempio che è un esempio appunto della come si fa a ovviare i problemi della naive cross validation vediamo l'esempio di regressione su che cosa succede quando i nostri dati che erano quelli che avevamo visto nell'esempio della lezione scorsa e abbiamo tre modelli uno di underfitting uno di overfitting scusate questo è l'otto overfitting e il quattro è il giusto la giusta complessità in particolare qui abbiamo sono stati addestrati m polinomi con scusatemi m modelli con m che varia tra uno e otto sono dei polinomi quindi sono delle unità di polinomiale e sono stati addestrati su questo problema di regressione sono 21 punti dato e lo split è stato due terzi e un terzo quindi due terzi per il training e un terzo per la validazione e quindi il modello questo è un problema unidimensionale quindi giusto per dirvi il modello m era così fatto 0 più w1 per x più wm per x alla m va bene? modello di tipo polinomiale ora faccio la cross validazione come abbiamo detto la curva di training qui non si vede bene ma piano piano scende scende di poco ma scende la curva di validazione fa invece questa bella u vedete così è quella che dicevamo e quindi cosa vado a scegliere? vado a scegliere il modello migliore che è quello con m uguale a 4 questo stessa cosa con la classificazione binare qui il train split è stato fatto con una frazione 4 quinti e un quinto ok? quindi 4 quinti riservati al training un quinto riservato alla validation m sono sempre unità di tipo polinomiale con m che varia però questa volta tra 1 e 7 e il modello un modello costruito in questo modo w0 più la sommatoria quando i più j è maggiore di 0 ed è minore uguale di m vi ricordo che la somma degli indici i e j qui è un modello bidimensionale quindi qui abbiamo che cosa? x1 che è la prima feature alla i per x2 che è la seconda feature alla j per w i j che è il peso la somma di i più j deve essere uguale al massimo al grado del polinomio vi ricordate? l'avevamo detto quando abbiamo definito le unità di tipo polinomiale e la metrica in questo caso vedete vedere che è il numero di errori quindi si parte da un numero di errori che è 12 sul modello a complessità minima che è questo cioè lui li sbaglia tutti di fatto quelli del premium set e anche quelli del validation set direi e un po' 3 6 9 10 11 esatto fa 11 errori e poi vedete come la curva di addestramento decresce sempre lui qui arriva a un punto in cui fa zero errori quando voi prendete il modello 4 e andate a vedere questo caso qui lui riesce correttamente a classificare tutti i punti del dataset di addestramento o quasi invece sul dataset di validazione vedete c'è un andamento oscillatorio non è che la curva è a U in generale ovviamente ci possono essere delle oscillazioni ma se voi andate a scegliere questo punto prendete il punto a complessità migliore quindi l'errore di validazione vi guida nella scelta della complessità del modello come vi dicevo prima questo metodo di validazione incrociata può essere particolarmente dispendioso da un punto di vista computazionale perché si tratta di addestrare un numero potenzialmente elevato di modelli da zero fino alla all'ottimizzazione massima l'altro punto è che la differenza in capacità tra modelli diversi quando io mi muovo di un'attacca in quel disco della capacità aggiungendo per esempio un'unità può essere abbastanza ampia e quindi la capacità diciamo non è detta che io riesca a selezionarla in maniera così fine da andare a pescare un modello di capacità giusta e quindi ci sono altre soluzioni che permettono di ovviare a questa problematica queste soluzioni agiscono sull'altra leva che è la leva dell'ottimizzazione ok nella naive cross validation abbiamo ipotizzato di avere la leva dell'ottimizzazione tutta verso destra quindi di ottimizzare al massimo delle nostre capacità ci sono altre tecniche che lavorano molto sull'ottimizzazione e vi permettono di raggiungere gli scopi di avere un controllo più fine sulla capacità tra i diversi modelli che andate a testare e anche di avere diciamo un minor dispendio computazionale qui ne menziono un paio sono la validazione incrociata tramite boosting che non vedremo non abbiamo modo di vederlo anche se sarebbe molto interessante per tanti motivi per esempio molti alberi funzionano con questo principio del boosting ma ripeto ci porterebbe via molto tempo per cui ve lo segnalo solo come nome e quella che vedremo invece è l'approccio tramite regolarizzazione lo vedremo perché è abbastanza semplice da capire concettualmente si ricollega appunto al concetto di regolarizzazione che abbiamo già incontrato in altri punti del nostro percorso durante il corso di machine learning l'abbiamo visto se vi ricordate a proposito dell'SVM quando abbiamo regolarizzato la SVM per trasformarla da una formulazione hard margin a soft margin ma l'abbiamo anche visto quando abbiamo parlato di feature selection di selezione delle feature adesso oggi lo vediamo a proposito delle valorizzazioni incrociate e devono modificare la funzione di costo significa fondamentalmente poi qui dentro nel termine di regolarizzazione in realtà vedremo anche un'altra tecnica che è basata sull'early stopping che può rientrare in qualche modo nella famiglia delle regolarizzazioni e queste sono le due varianti di cui vi parlavo appunto early stopping che significa uscita prematura e quella basata proprio su un vero e proprio regolarizzatore che è la modifica della funzione di costo queste sono le due varianti dei metodi di validazione incrociata cosiddetti basati su regolarizzazione e che cosa che cosa significa ma significa che qui abbiamo il nostro solito dataset ok giusto per dirvi come funziona la lettura di questo grafico abbiamo il nostro dataset abbiamo il nostro dataset con il fitting e il fitting può essere frutto di un modello troppo complesso o di un modello giusto allora se noi andiamo a ottimizzare la funzione di costo al massimo quindi abbiamo fissato la complessità del modello quindi fissiamo in questo caso ripeto si va a scegliere un modello di complessità sufficientemente elevata e si agisce sulla leva invece dell'ottimizzazione quindi voi scegliete la complessità di un modello abbastanza elevata un modello abbastanza corposo abbastanza con parecchie unità e cominciate a lavorare sull'ottimizzazione supponiamo che la funzione di costo sia questa ok che questa sia la vostra funzione di costo se voi la ottimizzate al meglio che potete dovreste riuscire ad arrivare in questo punto che è questo cerchietto blu giusto al quale corrisponde questo valore sulla funzione di costo che è questa croce ok questo è il modello che a questo punto una capacità elevata e che è stato ottimizzato al massimo probabilmente siete andati in overfitting giusto e quindi vi ritrovate in una situazione che cosa succede se anziché arrivare qui vi fermate prima nel processo di ottimizzazione cioè anziché arrivare a manopola tutta a destra la mettete a metà vi fermate qui questo punto giallo a cui corrisponde un valore che è questa croce gialla e non avete ottimizzato il modello ma significa che il modello quindi ha una capacità inferiore una complessità scusatemi inferiore ok e quindi probabilmente se siete stati abbastanza fortunati o bravi vi siete fermati in un punto che corrisponde al vostro al vostro scopo come fate ad accorgervene beh durante il questa è la tecnica che si chiama early stopping voi prendete il vostro modello tenete sotto controllo l'errore sul training set e l'errore sul validation set vi avete tutti e due e cominciate ad addestrarlo cominciate a fare una serie di iterazioni ad esempio del metodo di discesa del gradiente per ogni punto delle iterazioni voi avete training set e test set il training set tenderà sempre a diminuire il test set scusatemi il validation set l'errore sul validation set tenderà a diminuire fino a un punto in cui comincia a risalire nel momento in cui vedo e mi accorgo che comincia a risalire mi fermo se ho impostato 500 epoche dell'addestramento e sono arrivato a 150 mi fermo non arriverò a 500 non giro quella manopola tutta a destra questo come funziona l'early stopping che è una tecnica molto utilizzata per esempio per addestrare le reti neurali se voi prendete un framework di quelli che lavorano sulle reti neurali ci sono dentro degli algoritmi di addestramento per esempio algoritmi basati su tecniche del primo ordine e tra i vari parametri che vi potete passare è il parametro basato su early stopping gli potete anche dire alcune cose ulteriormente per esempio sono estremamente sofisticati ad oggi come stato dell'arte perché potete dire controlla l'errore di validazione e se ad esempio vedi che per un certo numero di epoche di addestramento quell'errore di validazione continua a crescere ti fermo quindi non è detta che il primo punto in cui vedo che risale ci può essere qualche fluttuazione mi fermo ma se per un certo numero di iterazioni vedo che continua a salire mi fermo e prendo il migliore torno indietro perché magari permette di memorizzarli e vado a prendere quello che aveva l'errore di validazione più basso questa è la tecnica dell'errore stopping ok ci siamo e vi faccio notare che qui quello che facciamo è addestrare un solo modello che è un modello a più alta capacità però non parto da quelli a bassissima capacità e poi ne aggiungo tanto e ho la possibilità anche di essere molto fine nel nel selezionare un modello a giusta capacità perché vado ad agire proprio sulla leva dell'ottimizzazione quindi di solito quello che si fa è si parte da un modello abbastanza pesante da un punto di vista della capacità e si lavora sull'ottimizzazione questo è quello che si fa nella pratica ci siamo? avete capito come funziona? c'è un'altra categoria di metodi cross validation che rientrano in qualche modo in senso ampio nelle tecniche di regolarizzazione sono quelli proprio veramente basati su regolarizzatori e funzionano così qui abbiamo sulla sinistra l'esempio di che cosa succede se abbiamo la nostra funzione di costo man mano che nel cammino di ottimizzazione io parto da un valore iniziale e poi via via scendo nella mia loss function in cerca del minimo per ricavare i parametri ottimali del mio costo e questo è il classico classica rappresentazione qui ho idealmente rappresentato i pesi qui è il cammino del mio ottimizzatore cioè a questo punto corrisponde un insieme di pesi a questo un altro a questo un altro a questo un altro ancora questo è l'insieme di pesi ottimale che corrisponde al minimo della mia funzione di costo ok qui niente di nuovo quello che noi facciamo è questa è la nostra funzione f scusate lo scrivo qua f che è una funzione dei nostri parametri teta quello che noi facciamo è costruire scusate questa la chiamiamo g per essere coerenti con tutta la notazione che abbiamo usato fino a dove quello che facciamo è costruire una nuova funzione a partire da g in questo modo ci aggiungiamo un termine che chiamiamo h di teta che viene moltiplicato per un parametro lambda che è il parametro di regolarizzazione questo è quello che abbiamo fatto quando abbiamo fatto la selezione delle feature se vi ricordate l'abbiamo fatto anche quando abbiamo trasformato anche l'SWM aggiungevamo alla funzione di costo originale alla loss function un termine che abbiamo detto sempre essere il termine di regolarizzazione che è questo qua moltiplicato per un parametro lambda che è il parametro di regolarizzazione allora questo che cosa fa questo modifica la nostra funzione di costo se la mia funzione di costo prima aveva quell'andamento nel momento in cui allora dipende ovviamente da come la costruisco questa però in generale nel momento in cui aggiungo un termine di questo genere ottengo una funzione differente ad esempio una funzione che può essere questa con un certo valore fissato h può essere questa se io aumento lambda che cosa succede che questo termine andrà a pesare di più nella f quindi il mio minimizzatore comincerà a diciamo trascurare di più la minimizzazione del termine g e andare più a cercare dei parametri che soddisfino la minimizzazione del secondo addendo di questa somma e quindi andrà magari verso qui oppure verso qui oppure verso qua quindi spostandoci in questo modo man mano che aumenta lambda andiamo a dare sempre più importanza a h che magari è questa se io g diventa trascurabile rispetto alla lambda h è come se io minimizzasse solamente h quindi solo questa con dei valori via via di lambda più bassi fino a lambda zero questo è il valore che ritrovo con lambda uguale a zero nel modello quando dunque i pesi in realtà sono un insieme quindi non possiamo dire che crescono tutti o diminuiscono tutti i pesi sono i pesi del modello per cui potrebbero avere qualunque valore che noi diciamo lambda invece è un qualcosa che mi permette di pesare più questo termine di dare più importanza a questo termine e quindi lui non va a minimizzare il mio termine originario ma in maniera crescente dà più importanza a questo il che significa però che io mi vado a spostare vedete qui sulla curva il minimo di questa rosa è qui il minimo di questa gialla è qui il minimo di questa altra rosa è qui allora se mi sposto significa che vado a prendere un altro valore che non è il minimo della mia funzione originale quindi di nuovo ricapito in una situazione in cui non vado a ottimizzare al massimo ma vado a ottimizzare un'altra funzione che mi sposta il mio mass il mio scusatemi il minimo rispetto alla funzione di costo al minimo che troverei ottimizzando tutto a destra la leva dell'ottimizzazione quindi è un è un artificio che ci sposta e quindi vado adesso cerco di rispondere la sua domanda a cercare un altro insieme di pesi a ognuno di questi punti corrisponde un insieme di pesi che descrive il mio modello ok questo è quello che mi dà il minimo ma io lo voglio evitare perché sennò va di overfitting qualunque altro insieme di pesi è un insieme di pesi che non corrisponde al minimo diciamo meglio qui abbiamo vediamo che c'è un un unico minimo ok potrei avere più minimi locali e quindi a quel punto non è detta che io spostandomi evitando un minimo locale che troverei magari ottimizzando in un certo modo non vado a trovare qualcosa che è anche più in basso adesso questi sono casi che possono capitare ma che ovviamente insomma particolari lasciamo un attimo da parte perché poi posso comunque ricominciare da punti diversi il processo di ottimizzazione e vedere che succede sempre molto empirico è il processo di addestramento è sempre una componente dovete cercare il più possibile di avere sotto controllo cosa state facendo però queste sono delle tecniche che vi permettono di giostrare su questo e al solito cosa può cioè la domanda è quale tipo di funzione di regolarizzazione potete utilizzare al solito potete utilizzare per esempio la norma di tipo L1 o di tipo L2 dei pesi e quindi in questo senso se io minimizzo quello minimizzo la norma della somma dei valori dei pesi allora in quel senso sì se uso questo tipo di termini di regolarizzazione e quindi dei pesi più piccoli ok quindi riassumendo sia che voi utilizzate early stopping o che utilizzate la tecnica basata su regolarizzazione vera e propria quello che fate vi posizionate a un certo valore di capacità massimo massimo rispetto ai vostri requisiti computazionali ad esempio il mio sistema può gestire tot memoria mi posso permettere tot capacità tot tempo di addestramento e va bene scelgo un modello di sufficiente capacità abbastanza grande e poi cominciate a partire da qui ad esempio se lavorate sull'early stopping fate un certo numero di passi poi aumentate aumentate aumentate fino a fare parecchie epoche di addestramento e quello che vedete qui sovrapposta è la curva gialla dell'errore di validazione vedete che all'inizio è alto poi pian piano scende scende e poi risale e questa curva u ideale noi la teniamo sotto controllo per fermarci nella posizione giusta del selettore questo con l'early stopping la stessa cosa se non avessi l'early stopping ma avessi la regolarizzazione qui che cosa mi permetterebbe di passare da un'attacca all'altra l'aumento cosa sarebbe della variabile lambda aumentando lambda equivalentemente mi sposto o meglio qui parto da lambda alto quindi il diminuire di lambda mi fa spostare verso destra perché quando lambda è a zero idealmente sono a massima capacità e massima ottimizzazione allora quindi la validazione incrociata tramite regolarizzazione e early stopping ha ovviamente queste caratteristiche sono caratteristiche generali ha però anche chiaramente dietro dei dettagli di tipo implementativo di ingegnerizzazione cosa voglio dire abbiamo detto prima supponiamo di utilizzare un certo ottimizzatore e di lavorare fino al massimo della sua della sua capacità quindi per esempio di scesa del gradiente cosa succede se anziché di scesa del gradiente io utilizzo un metodo di newton del secondo ordine chiaramente cambiano le cose però solitamente anche se avete modelli ottimizzati in maniera diversa da un punto di vista dell'identificazione del del del del modello a complessità giusta quindi quello che non va né in overfitting né in underfitting l'impatto della tipologia dell'ottimizzatore c'è ma non è così elevato tipicamente quindi diciamo è un qualcosa che ci possiamo permettere in un'analisi in una prima analisi diciamo di del primordine di trascurare qual è il il livello di capacità no? abbiamo detto supponiamo di girare a destra tutta la la manopola della capacità cosa vuol dire che giriamo a destra la manopola della capacità quante unità devo mettere? beh abbastanza da andare in overfitting quando è totalmente ottimizzato quindi quello potete fare una prova e dire provo a fare un addestramento vedete se no? solitamente quello che si fa anziché fare una prova si parte con un modello abbastanza grande per dire sono abbastanza fiducioso che se lo ottimizzo tutto vado in overfitting ecco il problema vedete la differenza per esempio tra un metodo come il metodo di Newton e un metodo di scesa del gradiente è che il metodo di Newton se vi ricordate quando l'abbiamo spiegato che cosa abbiamo detto che fa dei passi molto grandi verso la convergenza ognuno dei quali implica insomma che deve fare un certo numero di operazioni l'inversione di una matrice eccetera eccetera però il singolo passo nel processo di minimizzazione è bello grande dopodiché potete anche qui introdurre il learning rate se volete però in generale rispetto ai metodi del primordine se volete ottenere una risoluzione molto fine cioè controllare la complessità del modello a dei piccoli passi è meglio che usate un metodo del primordine come il metodo di gradient descent di scesa del gradiente l'errore di validazione può oscillare come faccio a decidere quando mi fermo? beh quello che si fa si fa tutta questa bella curva U e poi si va si risale al punto di minimo della curva U gialla di solito oppure come vi dicevo prima si aspetta che siano trascorso un certo numero di epoche e poi si va a scegliere si torna indietro e si sceglie il valore del minimo questi sono alcuni dettagli che sono più ripeto implementativi o di ingegnerizzazione del sistema però il sistema fondamentalmente è tutto qui ecco va bene? ci siamo? ok va bene qui riassume questa slide cose che abbiamo già detto cioè le funzioni di regolarizzazione vengono aggiunte a modelli ad alta capacità alterano la forma della funzione di costo e permettono di muovere il minimo globale il minimo che può essere globale in realtà potrebbe essere anche locale lì a quel punto come vi dicevo prima non è detto che stiamo facendo una mossa necessariamente nella direzione giusta ma si muove comunque dalla posizione originale valori ampi di lambda vi portano in underfitting valori piccoli in overfitting e mettiamo un po' perché non la vediamo un po' ricaricata eh si è bloccata leggermente vediamo un attimo metto su questa slide che si era bloccata e va bene niente questa è l'ultima slide che riguarda vedete quello che vi dicevo prima avete esattamente la stessa figura però andando da sinistra verso destra andate a diminuire il valore di lambda passate dalla regione di underfitting a quella di overfitting e in mezzo avete la regione giusta che vi permette di selezionare la complessità del modello ok anche qui su questo tecniche di validazione incrociata secondo me ci sono delle possibilità per esempio per esplorare alcune caratteristiche di insomma di alcuni aspetti di un di un problema che si prestano bene per esempio potenzialmente a un progetto se uno vuole esplorare anche queste cose quindi avete anche qui ampio margine per poter provare a testare queste tecniche vedere insomma fissate dei modelli provate a vedere è ovvio che dovete andare sul non lineare quindi addestrare qualcosa e non abbiamo visto ancora come si fa lo vedremo nell'ultima esercitazione però insomma chi vuole può anche cimentarsi con questo ma indipendentemente da questo queste sono le tecniche diciamo più utilizzate come vi dicevo prima per quanto riguarda lambda per quanto riguarda lambda eccoci qua scusate non lambda ma h ovviamente è il termine che viene moltiplicato poi per lambda avete diverse opzioni a vostra a vostra scelta questa è una delle più utilizzate è la norma di tipo L1 del vettore dei pesi che produce vi ricordate un vettore dei pesi abbastanza sparso la maggior sparsità la produce la norma L0 questo l'abbiamo utilizzato quando abbiamo fatto feature selection la selezione delle feature vi ricordate per evidenziare alcune feature a scapito di altre e un'altra opzione è quella di utilizzare invece la norma di tipo L2 sono le due più utilizzate come un'altra bene allora questo diciamo per quanto riguarda le slide di questo blocco è tutto ripeto ci sarebbe molto altro da dire anche sulla validazione incrociata magari cercheremo di dire qualcosa nell'ultima parte del corso se abbiamo modo di richiamare qualche ulteriore concetto ma veramente anche qui c'è un mondo dietro che non abbiamo come abbiamo detto più volte modo di approfondire tutto quello che vi farei vedere a questo punto è invece proprio perché fino adesso abbiamo lavorato sulla teoria sulle slide vi farei vedere una cosa al volo su un notebook con un po' di codice che vi fa vedere proprio toccare con mano alcune delle cose che abbiamo visto su un problema di regressione quindi farei questa condivisione di questo di questo codice e vediamo questi aspetti direttamente su un problema che comincia ad essere più reale ecco allora eccoci qui di nuovo dunque quello che vi volevo prevedere era appunto un esempio di un notebook in cui viene implementata la regressione lineare con la trasformazione polinomiale delle feature cioè qui vediamo due cose vedremo in azione uno quei meccanismi di ingegnerizzazione delle feature quindi di iniezione della non linearità di cui vi parlavo a suo tempo ok e poi vi faccio vedere anche come quindi iniettare della non linearità che decidiamo noi nel modello e poi vi faccio vedere anche come questo poi conduce a dei modelli non lineari che possono andare in overfitting rispetto al nostro problema lo vediamo il tutto su un su un modello di regressione ok quindi utilizziamo una regressione lineare su cui facciamo trasformazioni non lineari vi ricordate vi ho detto è uno dei modi per ottenere la non linearità prima di affrontare tutti i discorsi del feature learning quindi di dire utilizziamo gli approssimatori universali eccetera va bene allora qui diciamo ci sono un po' di codice adesso l'obiettivo non è andare nel dettaglio di tutto poi se vi interessa ve lo posso anche lasciare quindi non è problema ve lo guardate con calma ma le cose principali sono va bene le librerie che importiamo che sono NumPy Matplotlib Seaborn se volete sempre per i grafici poi da Scikit-learn dal dal modulo preprocessing importiamo queste polynomial feature che sono le classi appunto per fare delle trasformazioni di tipo polinomiale quindi quelle che abbiamo visto xx quadro eccetera in una sola variabile ma lo fa anche in più variabili poi importiamo il modello di regressione lineare questo l'abbiamo visto già quando abbiamo fatto le nostre esercitazioni dedicate a quello e dalle metriche importiamo quel modulo min squared error che serve per calcolare l'errore quadratico medio ci siamo qui ok poi definiamo una nostra funzione che abbiamo chiamato true funnel una true function sarebbe quindi sta per funzione vera la funzione il processo che genera il nostro dataset che noi non conosciamo chiaramente perché lo vogliamo ricostruire a partire dai dati in realtà non ricostruiremo questa funzione chiaramente ma ricostruiamo i punti che questa funzione esprime ed è una funzione tipo sinusoidale un coseno di 1,5 per pi greco per x dove x è il nostro vettore di input va bene dopodiché quello che viene fatto in questa cella qui inizializzato il generatore di numeri pseudo casuali fissato il numero di campioni 30 campioni poi vedete c'è un array un vettore di 6 componenti che sono i gradi del polinomio che andremo perché andremo a lavorare su iniettando delle non linearità cioè il primo sarà in realtà un modello lineare polinomio di grado 1 poi vediamo cosa succede con polinomio di grado 4 6 10 12 13 cioè andiamo a trasformare il nostro input secondo una trasformazione polinomiale con quel grado poi quello che facciamo qui prendo un attimo quello che facciamo qui è vediamo un attimo se riesco allora vi dicevo quello che facciamo qui è generare il dataset di addestramento al dataset di addestramento x e y qui lavoriamo in una dimensione quindi un valore della x e un valore della y allora come viene come viene generato prendiamo un numero di campioni in questo caso 30 e li generiamo a caso e poi li ordiniamo sull'asse dell'x ok quindi generano una serie di numeri a caso questi numeri sono generati tra 0 e 1 ecco lo funzionamento ok dopodiché i valori della y come li ricaviamo invochiamo la funzione true function a partire da x train lui mi calcola il coseno di ognuno di quei valori 30 valori che ho generato a caso cioè lo moltiplica per pi greco ci aggiunge lo moltiplica per 1,5 scusate quindi 1,5 pi greco per x e calcola così ok poi però tanto per aggiungere un po' di rumore a cosa facciamo ci aggiungiamo un po' di rumore questo randenne è un rumore di tipo normale quindi una gaussiana centrata nello 0 nel genero e nei campioni e ha una varianza 0.1 lo moltiplico per 0.1 agendo su questo riuscite a dire quanto sono più sparpagliati questi valori cioè aumentiamo il rumore se aumentiamo quel valore dopodiché andiamo a fare un bel plot di x e y e gli facciamo anche stampare la shape di degree vabbè degree è un vettore di 6 elementi giusto così vedere che cos'è e viene fuori questa roba qua vedi è un andamento dietro c'è questo questo cosino noi abbiamo generato questi punti questo è il nostro dataset dopodiché facciamo una cosa abbastanza semplice allora generiamo il test set e il test set come lo generiamo prendiamo come x 100 punti tra 0 e 1 equispaziati e questi li generiamo con il comando lì in space con la funzione in space poi y test e x test a cui applico la funzione true giusto dopodiché semplicemente qui aggiungo una dimensione in più perché vi ricordate il discorso non pai no ammette o dei vettori che hanno 100 virgola come dimensione o qui la trasformiamo in 100 virgola 1 ok gli facciamo stampare la shape infatti se andate a vedere la shape è 30 virgola 1 nel caso del del cosa che ho fatto stampare arrivo a vedere extreme che hanno 30 punti x test saranno 100 ok vado a stampare il numero di gradi vado a inizializzare a un vettore di tutti 0 mse train e mse test qui dentro che cos'è quel vettore un vettore che ha tanti elementi quanti sono specificati da n ed x n ed x è una variabile in cui sono andata a mettere il numero di gradi del polinomio io ne testerò 6 in questo caso lui ha preso quel vettore di gris che vi ricordate specificava i gradi del polinomio erano 6 vuol dire 6 modelli diversi a ognuno di quei modelli associerò un errore di training e un errore che qui viene chiamato test ma che in realtà sarebbe di validazione sarebbe più corretto dire ok qualche volta c'è confusione tra validation in realtà per fare le cose fatte ben bene ripeto training validation e test in questo caso il test vero lo lasciamo da parte e in questo notebook viene chiamato test ma sarebbe più corretto chiamarlo validation quindi magari poi lo correggiamo insomma ok quindi però intendetemi è un errore di validazione questo ok stiamo valutando l'ordine oppure più semplicemente prendetelo come test ma vi accorgete poi quando andiamo a vedere che c'è l'overfitting insomma va bene se volete fare controllo della validazione è un errore di validazione se volete semplicemente vedere si tratta di cosa vuol dire l'overfitting va bene anche chiamarlo abbiamo fatto solamente training e test quindi siamo ritornati nella situazione prima di dire facciamo cross validazione ma di fatto vedrete che ci accorgeremo in questo allora poi che cosa facciamo va bene definiamo una figura con una certa dimensione e facciamo partire un ciclo for ok quante interazioni fa questo ciclo for allora degrees è un vettore di sei elementi la lunghetta quindi di quel vettore è sei i in range da quindi sei vuol dire zero uno due tre quattro cinque facciamo sei iterazioni ok cosa facciamo ognuna di queste sei iterazioni definiamo un subplot questo subplot è una riga e poi sei colonne allora e a ogni iterazione andiamo a lavorare sul primo sul secondo sul terzo sul quarto sul quinto grafico ci siamo ok qui va bene settiamo i tic ok tutto quello che vogliamo del grafico quello che ci interessa è qua qui abbiamo la classe polynomial feature a cui voi potete specificare il grado e lui vi restituisce un qualcosa che è un oggetto poly feature quell'oggetto è quello che potete utilizzare per costruire le non linearità introduciamo il modello di regressione lineare poi che cosa facciamo trasformiamo il nostro dataset di training invocando il metodo fit su questo oggetto polyfeatures e poi subito dopo anche il metodo transform che cosa fanno questi due metodi in cascata prendono il vostro dataset di addestramento e ci iniettano dentro una trasformazione non lineare di grado 1 poi cosa ci avevamo messo 2 4 6 ad ogni interazione creano tutte quelle feature che abbiamo visto quindi se gli dico grado 1 x non fa niente cioè è una trasformazione ovviamente che non produce nulla è un modello lineare rimane lineare se gli dico grado 2 e lui comincia a trasformare ogni input del mio dataset mettendoci x al quadrato il termine quadratico e così via e questo lo producono queste due queste due istruzioni dopodiché io prendo il mio modello di regressione lineare e gli metto dentro guardate non più x train ma x train poly che cos'è x train poly è il mio dataset di training che ho trasformato con quelle trasformazioni polinomiari che alla prima iterazione saranno lineari non faccio niente di fatto cioè costruisco il modello lineare alla seconda iterazione quadratico poi 4 non mi ricordo che grado di odato tutte quelle combinazioni che abbiamo visto ci siamo? riuscite a seguire il filo del discorso? cosa facciamo a questo punto? facciamo il fit del modello e a quel punto una volta che abbiamo addestrato il modello possiamo anche fare la predizione invochiamo il metodo predict gli passiamo il nostro x train trasformato e lui mi dice qual è il il risultato poi posso fare la stessa cosa sul dataset di test faccio la trasformazione delle feature e ricavo le y con il metodo predict quindi io trasformo e poi passo al mio modello lineare vi ricordate quando l'abbiamo spiegato a lezione no? inietto della non linearità e a destro con un modello lineare nel mondo trasformato la relazione è lineare nel mondo delle x non è più lineare e poi in queste due istruzioni invochiamo la funzione min square error che fa il calcolo dell'errore quadratico medio tra la nostra predizione e il valore vero della y sia per il training set che per il test set mi calcolo l'errore quadratico medio ci siamo fin qui? poi quello che facciamo è fare il plot in questo nel plot andiamo a sovrapporre tre curve per ognuna di quelle sei che vi ricordo cambiano con il grado del polinomio allora la prima curva è x test y test e questo è il nostro modello cioè come va la valutazione che fa il nostro modello sul dataset di test poi ci andiamo a mettere x test e la true function cioè quello che è il vero che dovremmo ottenere quindi la curva che chiamiamo la curva che chiamiamo model è quella del nostro modello la curva che chiamiamo true function è quella che vorremmo ottenere e poi abbiamo lo scatter con tutti i punti blu che è quello che abbiamo generato sopra che lo rimettiamo lì sopra per far vedere i nostri punti di addestramento dove stanno poi mettiamo le label x e y il limite massimo e il limite minimo per la x e per la y per inquadrare bene la porzione del grafico che noi vogliamo ottenere quindi 0 e 1 per la x e meno 2 e 2 per la y la leggenda la leggenda diciamo mettila dove vuoi tu dove ti sembra che stia meglio best e la leggenda è semplicemente diciamo vai a plottare la leggenda per cui model true function e samples e poi c'è un titolo in cui andiamo a mettere il grado e ms test e il risultato sono questi sei grafici questi sei grafici vedete abbiamo il grado e mill square error esatto e qui vediamo l'underfitting vedete il grado gli abbiamo dato un vettore che aveva 1 4 6 10 12 e 13 allora che cosa succede noi abbiamo fatto addestramento in cui trasformiamo le feature di ingresso secondo un polinomio di grado 1 cioè non le trasformiamo e il modello è un modello lineare qui sotto in blu ci sono i pallini dei nostri punti e in arancione la true function e noi gli abbiamo dato 100 punti qui in questo intervallo e lui ha calcolato per ognuno di quei punti la funzione vera e questi 100 punti sono quelli secondo il nostro modello e lui li ha plottati così se comincio a dargli un grado 4 guardate che l'errore questo che gli ho fatto stampare qui è il min square error del del test di quello che sarebbe il validation se facessimo validazione che vedete va sempre a diminuire 10 alla meno 1 10 alla meno 3 10 alla meno 3 10 alla meno 2 è sempre più 1,93 1,21 questo in realtà è un pochino più alto però piano piano diventa in realtà allora vediamo un attimo perché è diminuito perché questo è sul test scusatemi chiaramente non sul training questo qui è sul test che cosa succede? vedete la cosa interessante è che se io vado ad alzare il grado del polinomio se voi andate a vedere l'errore di training diminuisce sempre adesso questo non glielo ho fatto stampare quello di test che cosa fa? da qui a qua scende da qui a qua ricomincia a salire poi vedete 2,27 3,79 10 alla meno 2 10 alla meno 1 risale quindi da qui quello che potremmo dire è che il migliore è lui controllando questo valore e ce ne accorgiamo perché visivamente in questo caso ce ne accorgiamo vedete che questa è la curva migliore guardate vedete come andando avanti comincia quella blu a fare delle cose strane che non hanno niente a che vedere con il problema ok che cosa abbiamo fatto fare qui? ok gli ho fatto stampare l'errore di training ecco quello che vi dicevo nel training 7 nel test 7 vedete che il training guardate è sempre decrescente vedete che tende a 0 ma sul test o quello che sarebbe il validation se stessimo facendo la validazione ci accorgiamo che questo è il minimo e dopo ricomincia a salire quindi la differenza è questa e se voi fate il plot di questa roba qua ve ne accorgete il plot di quei due vettori l'ho fatto qui in questa cella e avete questo andamento in funzione del grado vi accorgete la curva rossa è quella relativa al test o validazione ripeto quella blu è training il training anche se di poco va sempre calando questo invece vedete questa curva U quando vi dicevo una curva U è sperimentalmente così e poi potete anche provare cosa succede se dunque c'era se facciamo una cosa del genere anziché qui cosa cambia anziché 13 l'ultimo grado è 14 andiamo a vedere cosa succede per curiosità sempre gli stessi punti guardate l'ultimo vedete come comincia a oscillare in maniera del tutto del tutto incongrua rispetto a quello che è il processo che ha generato questi punti ok e chiaramente ovviamente se andate a vedere gli errori vedete guardate cosa comincia a fare su quest'ultimo punto come errore quello è l'errore che farebbe su punti che lui non ha mai visto ecco l'importanza di tenere sotto controllo il fenomeno dell'overfitting ok va bene io questo mi sembrava significativo mi sembrava abbastanza interessante da farvi vedere questa cosa perché mette insieme un po' delle cose che abbiamo visto nelle ultime lezioni nelle ultime settimane iniettare della non linearità in questo caso manuale non è il problema della non linearità che abbiamo visto proprio quando adesso abbiamo incominciato a parlare di overfitting e underfitting che è un modello di approssimatore universale però il problema dell'underfitting e dell'overfitting c'è comunque e quindi su questo vedere come iniettare manualmente diciamo della non linearità e come però aumentare di troppo la complessità del modello significa portarlo in overfitting ok va bene allora non so ci sono domande avete domande su questo allora qui in realtà sì se vogliamo se stiamo facendo cross validation è di quella di quella nike sì cioè io addestro quattro modelli al massimo delle mie capacità e fondamentalmente sto facendo quelli sì perché io faccio inietto della non linearità poi risolvo un dove il modello poi in realtà un modello lineare quindi con le equazioni normali viene risolto comunque con il disceso del gradient è una funzione quella al minimo quadrati che è convessa quindi vado sempre a beccare il minimo quindi al massimo dell'ottimizzazione quindi manopola dell'ottimizzazione tutta a destra tante manopole sei in questo caso che mi invariano la complessità del modello quindi stiamo controllando lo secondo il metodo di crossvalidazione diciamo ingenua può procedere anche il modello di tipo di lineare in realtà no di solito no cioè tu ce l'hai quando c'hai dei modelli non lineari l'overfitting perché la complessità dei modelli lineari cioè più più semplice di un modello lineare non c'è niente quindi il modello lineare può darti luogo a underfitting ma non a overfitting perché comunque sia ti riesci a catturare cioè se tu pensi a una regressione il modello lineare è la cosa più semplice che ti può venire in mente cioè non ci sono altri andamenti anche un andamento costante un modello lineare per dire quindi da questo punto di vista i modelli lineari non presentano problemi di overfitting semmai hanno problemi di underfitting però ecco quindi va bene allora qui direi che possiamo intanto bloccare la registrazione per la lezione di oggi direi che è tutto e ci vediamo la prossima volta un attimo un attimo un attimo un attimo un attimo un attimo