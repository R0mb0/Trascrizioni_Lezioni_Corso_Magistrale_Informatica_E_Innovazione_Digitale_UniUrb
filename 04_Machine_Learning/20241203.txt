allora benissimo ieri abbiamo introdotto concetti di base riguardanti le reti neurali e in particolare le reti neurali cosiddette totalmente connesse o dense queste che vi sto descrivendo che abbiamo iniziato a descrivere ieri hanno diversi nomi un ulteriore nome con cui potete trovarle diciamo nell'ampia letteratura scientifica ma anche nel quando andate a cercare appunto informazioni ad esempio rete è multilayer perceptron quindi lo scrivo qua il multilayer perceptron è un altro dei modi con cui viene ok i multilayer perceptron sono un ulteriore ripeto nome che con il quale sono note le reti fully connected totalmente connesse abbiamo visto come costruire ieri un delle unità di primo livello quindi unità che hanno direttamente si interfacciano all'input quindi ognuna di queste riceve tutti gli input e ognuna di queste effettua due cose che sono la combinazione lineare dell'input e la funzione di attivazione non lineare adesso oggi andiamo avanti su questo schema perché abbiamo visto che oramai come funziona questo schema e questo schema è uno schema che può essere riutilizzato per costruire delle unità di secondo livello quindi quelle che qui vengono chiamate unità di two hidden layer cosa significa? significa che ci domandiamo come andare a costruire un neurone quando questo neurone non è collegato direttamente all'input ma è collegato a riceve come input il risultato delle elaborazioni del primo strato nascosto quindi abbiamo input primo strato nascosto e qui stiamo costruendo un secondo strato nascosto come funzionano le unità di questo secondo strato nascosto? in maniera del tutto analoga a quelle che abbiamo visto ieri per il primo quello che cambia è che non ricevono direttamente l'input ma ricevono l'elaborazione del primo strato nascosto in particolare se andate a vedere in questa formula abbiamo che cosa? che la funzione che definisce questa singola unità quindi questo è un singolo neurone e qui ci riferiamo al 2 per identificare il fatto che stiamo parlando di neuroni di un secondo strato nascosto ok? quindi abbiamo già definito il primo può essere descritta la funzione che implementa un singolo neurone di questo tipo in questo modo si prende un termine di bias W0 ovviamente anche qui l'indice 2 si riferisce al fatto che stiamo parlando del secondo strato nascosto e a questo si va a sommare questo termine qua questo che cos'è? se lo guardate di nuovo è una combinazione lineare combinazione lineare in cui avete una serie di termini ognuno dei quali ha un fattore di peso peso relativo a questa singola unità del secondo strato nascosto che va a moltiplicare che cosa? fi di 1 di x cioè noi abbiamo in questo singolo neurone convergono una serie di input quanti sono questi input? 1, 2, fino a u con 1 dove u con 1 è il numero di neuroni del primo strato nascosto quindi in ogni neurone del secondo strato arrivano convergono tutti gli output del primo strato ci siamo? ecco perché abbiamo questa sommatoria quindi di questi termini qui dentro avviene sempre lo stesso meccanismo che abbiamo visto ieri che abbiamo scomposto diciamo in due sotto funzioni la prima è la combinazione lineare che è questa che abbiamo appena evidenziato non mi ricordo se i colori erano esattamente questi ma ovviamente poco importa la prima è questa e la seconda è questa la seconda corrisponde all'attivazione non lineare e la prima corrisponde alla combinazione di input bene? quindi volendo dare una definizione del tutto analoga a quella che abbiamo dato ieri e che ci permette in maniera ricorsiva di definire il comportamento il funzionamento di questo neurone di questa unità ok si seleziona una funzione di attivazione a funzione di attivazione che può essere di nuovo ReLU quindi il max oppure può essere la sigmoide può essere la tangente iperbolica quello che volete e poi si costruiscono ovviamente un certo numero di unità di primo livello perché chiaramente da quello devo partire e questo l'abbiamo già fatto ieri e a partire da questa unità di primo livello quindi data la funzione di attivazione lineare costruiamo U1 unità di primo livello ok e con queste U1 unità di primo livello andiamo a calcolare questa combinazione lineare otteniamo uno scalare che chiamiamo U e da questo qua facciamo l'attivazione non lineare il meccanismo vedete è sempre lo stesso quello che cambia quello che cambia è semplicemente che l'input queste unità non sono collegate direttamente all'input ok a questo punto se fate un gioco come abbiamo fatto ieri di provare a costruire quattro unità con dei parametri generati casualmente ieri abbiamo visto che nella torno un attimo indietro no? avevamo questo tipo di grafico vi ho detto se generate prendete chiaramente un caso unidimensionale generate dei parametri in questo caso sono due parametri W0 e W1 e li generate a caso avete quattro possibili coppie questa sopra era una tangente iperbolica come funzione di attivazione questa sotto era una ReLU ottenevate questi grafici se adesso rifate la stessa cosa ma tenendo conto del fatto che in realtà avete incascata un neurone di primo livello che è quello che avete generato nell'esempio di ieri e poi un neurone di secondo livello che è questo con dei parametri generati a caso quindi in questo caso abbiamo due parametri generati a caso per il neurone di primo livello e due parametri generati a caso per il neurone di secondo livello giusto? ok? quindi abbiamo una situazione di questo tipo in cui abbiamo l'input che è la nostra X abbiamo un neurone di primo livello e abbiamo un neurone di secondo livello ok? e qui andiamo a vedere che cosa succede va bene? primo layer secondo layer quindi è una rete molto molto semplificata perché ha un solo neurone per ogni livello ok? se voi generate a caso i primi due parametri questi sono W0 di 1 e W1 di 1 poi qui avete W0 di 2 e W1 di 2 giusto? poi prendete X tra meno 5 e 5 una griglia di valori abbastanza fini tra meno 5 e 5 generate una quaterna di valori casuali e cominciate a mettere qui la funzione di attivazione e la tangente iperbolica ok? di X qui è uguale a RELU generate una prima quaterna casuale una seconda una terza una quarta la stessa cosa non fate cambiando la funzione di attivazione ottenete ad esempio ovviamente non otterrete queste stesse però delle varietà di questo tipo la cosa che salta subito all'occhio è che se voi queste le andate a confrontare con torno indietro le stesse figure che avevamo visto ieri nella lezione precedente sul lo stesso comportamento di un neurone del primo strato nascosto se andate scusate mi sto andando indietro devo andare indietro non si chiama andare avanti vedete le forme sono molto diverse cioè qui l'andamento è questo guardate qui già come diventa vedete come cominciano ad avere degli andamenti che sono una varietà maggiore vi ricordate quando abbiamo parlato della varietà anche delle singole unità come qualcosa che aggiunge capacità a un modello ecco componendo due soli neuroni riuscite a costruire delle funzioni dei profili di funzioni che hanno già una varietà maggiore rispetto a uno solo un solo strato ecco questo vi rende conto del fatto che andando in profondità riuscite ad avere un qualcosa che aumenta la capacità del nostro modello a questo punto una volta ci siamo fin qua allora adesso il gioco è direi abbastanza evidente nel senso che una volta che abbiamo scritto questo qui possiamo andare a riprendere questa espressione e fare lo stesso attuare lo stesso meccanismo che abbiamo visto per i neuroni di primo livello cioè andare a compattare quella notazione tramite prodotti matrici vettori cioè la domanda a cui partiamo è cosa succede se voglio io vi ho fatto quello era un singolo neurone giusto di secondo livello la domanda che non si può fare è dire ok se anziché avere un singolo neurone costruisco un modello in cui ne ho b di queste unità b che diventa u2 cioè il b era quel nostro b quando mettiamo insieme tanti termini di unità elementari in questo caso ne ho u1 per il primo strato nascosto e u2 per il secondo strato nascosto dove u1 e u2 sono chiaramente dei valori arbitrali allora il nostro modello in questo caso come diventa diventa questo guardate è questa espressione qua è un modello che dipende chiaramente dall'input e dipende da un insieme di parametri questo insieme di parametri è costituito da che cosa tutti i parametri interni a ogni neurone e tutti i parametri esterni i parametri esterni sono questi io sto combinando secondo questi parametri esterni un certo numero di neuroni di secondo livello ognuno con la sua brava funzione ognuno col suo pezzo ma ognuna di queste funzioni siccome è una funzione di secondo livello dipende da tutto quello che c'era a monte cioè dipende da che cosa dai neuroni di primo livello e lo vedete da questa scrittura cioè se io prendo il geesimo di questi termini ok è esattamente che cosa la scrittura che abbiamo visto nella slide precedente in cui abbiamo aggiunto semplicemente l'indice j per dire sto prendendo il geesimo di quei termini cioè ho una combinazione lineare più un termine di bias di che cosa di quello che gli arriva in input da tutti gli 1 neuroni del livello precedente che viene poi fatta passare attraverso una funzione di attivazione non lineare quindi siccome l'abbiamo visto ieri l'uscita del primo strato nascosto la posso scrivere così adesso andiamo a vedere se riusciamo a replicare lo stesso meccanismo qua e capite bene che lo riusciamo a fare perché seguiamo lo stesso percorso e lo stesso percorso è dire ok tutti questi pesi li vado a organizzare in una matrice che chiamo w2 per indicare che è la matrice relativa al secondo strato nascosto in questa matrice vedete abbiamo tutti indici 2 per dire che stiamo ragionando sul secondo livello e se andate su andate a vedere per esempio la prima colonna avete proprio questi pesi w0 w1 fino a w1 che sono questi con l'indice j vedete 1 1 1 poi avete l'indice 2 2 2 eccetera li abbiamo organizzati in colonna a questo punto l'output del secondo strato nascosto lo possiamo analogamente a quanto abbiamo scritto ieri poi costruiamo un vettore in cui andiamo a prendere quello che si fa è si va a moltiplicare questa trasposta per il suo input ok ma il suo input è chiaramente l'output del primo strato nascosto e vi ricordo che con a con sopra il cerchietto andiamo a indicare che cosa il vettore in cui il primo elemento è 1 e tutti gli altri sono l'applicazione della funzione non lineare a qualunque cosa che gli passiamo come argomento a qualunque a ogni componente di un vettore che gli passiamo come argomento se noi scriviamo così otteniamo come output del secondo layer vedete che cosa un qualcosa che è molto analogo a quello che abbiamo visto ieri se voi andate a prendere questa scrittura questa è la scrittura matriciale che vi dice qual è l'output è del tutto analoga al diciamo a quella a cui arrivereste sviluppando no questa qui da cui siamo partiti però è molto più compatta e qui si vede bene che cosa facciamo facciamo prendiamo l'input che è questo questo è l'input ok lo andiamo a moltiplicare questo input lo andiamo a moltiplicare per questa matrice v1 significa che facciamo la combinazione lineare e lo facciamo passare attraverso la funzione di attivazione e otteniamo l'output del primo strato nascosto dopodiché qui facciamo la combinazione lineare dell'output del primo strato nascosto ok e a sua volta questo risultato lo facciamo passare attraverso una funzione di attivazione non lineare che cosa rimane da fare rimane semplicemente da combinare questo è il risultato del singolo diciamo sarebbe quello che avviene a livello del singolo neurone che dobbiamo andare a combinare secondo questa notazione qua e quindi dobbiamo costruire un ultimo vettore che contiene tutti questi pesi W1 W2 fino a W di U2 e andarlo a moltiplicare per quello che avevamo ottenuto come output del secondo strato nascosto e li andiamo a combinare tutti insieme e questo è l'output del nostro modello se è un modello con un singolo valore di uscita ok se ne abbiamo di più ovviamente ognuno ci avrà lo stesso tipo di combinazione quindi stiamo costruendo esattamente secondo lo stesso meccanismo quelli che sono gli output di una rete in cui abbiamo inserito un primo e poi un secondo strato nascosto ok e vi faccio notare che in questo modo il modello vedete l'avete ottenuto così questo è del tutto equivalente a questo si tratta sempre dello stesso modello però questa è una notazione compatta che fa uso di matrici e vettori e questo tra l'altro vi fa toccare con mano qualcosa che sia a livello di notazione ma anche poi a livello di implementazione ha un suo impatto cioè quello che vi serve per implementare una rete neurale che deve fare un'inferenza una volta che avete fatto l'addestramento è semplicemente il vettore di input e poi delle matrici dei pesi e le funzioni di attivazione non lineare quindi prodotto matrici per vettore matrici per vettore tutto quello che fa una rete neurale e anche quando fate l'addestramento questa operazione elementare ha chiaramente un peso non indifferente e il successo delle GPU nelle applicazioni del deep learning deriva dal fatto che voi sfruttate un hardware che è quello che nasce in ambito rendering grafico per fare rendering grafico ma che di fatto ha un elevatissimo livello di parallelismo per poche operazioni specializzate e tra queste poche operazioni specializzate ci sono i prodotti matrici per vettore ecco perché riusciamo a parallelizzare così bene i task legati per esempio all'addestramento delle reti neurali ecco perché c'è stata l'esplosione ovviamente delle GPU come hardware associato al training del machine learning e anche poi all'inferenza se vogliamo l'inferenza intendo la tradizione cioè il fatto che voi avete un input e volete sapere l'output corrispondente se riuscite a parallelizzare riuscite a farlo con minore latenza bene domande? abbiamo domande? no? andiamo avanti allora allora qui avete un quadro riassuntivo di quello che abbiamo appena fatto che è la rappresentazione diciamo qui nella parte sinistra è una rappresentazione espansa di una rete con due strati nascosti poi qui abbiamo una rappresentazione un pochino più compatta e questa è la più compatta possibile da livello grafico allora partiamo da quella espansa che cosa ci dice questa rappresentazione? ci dice che noi abbiamo il nostro input tutti i nostri input quindi le nostre feature da 1 a n poi abbiamo un termine 1 perché questo sarebbe il nostro vettore x con sopra il cerchietto e questo input arriva a ognuna delle U1 unità del primo strato quindi viene replicato per ognuno di questi cioè tutti gli input vanno in ogni neurone del primo strato nascosto questo l'abbiamo visto io dove avviene che cosa? avviene una combinazione lineare con la relativa attivazione non lineare in ogni neurone dopodiché l'output di ognuno di questi viene combinato e vedete che qui siamo già sull'indice 2 per andare verso il primo elemento del secondo strato nascosto vedete che qui comincia hidden layer numero 2 mentre qui eravamo su hidden layer numero 1 qui comincia il secondo strato nascosto e vedete che ognuna di queste unità che sono 1, 2 fino a quante decidiamo di metterne? 2 fa che cosa di nuovo? prende tutti vedete gli input che riceve provengono dal primo strato nascosto cioè a questa unità prendiamo la prima gli arrivano gli output di tutti i neuroni del primo strato nascosto alla seconda unità questa prende tutti gli output del primo strato nascosto quest'ultima unità prende tutti gli output del primo strato nascosto sono reti dense totalmente connesse perché tutti gli output di uno strato vanno verso tutti gli input dell'altro strato successivo ok se lo volessimo vedere quindi finiamo di vedere intanto questo questo diciamo questa esplosione questo espanso diciamo del grafico e chiaramente una volta che ho i risultati qui dentro che cosa avviene? combinazione lineare con questi pesi e attivazione non lineare vedete che qui c'è un peso che è W02 W12 W22 qui c'è un peso che ha indice 1 qui c'è un peso che ha indice massimo questo è riferito al fatto che qui stiamo trattando il primo neurone il secondo e l'ultimo neurone del secondo strato nascosto quindi gli indici vi devono e i pedici vi dicono proprio questo che state parlando del secondo strato nascosto e state parlando del peso U1 esimo del secondo neurone dello strato nascosto e questi sono tutti i parametri che la rete dovrà imparare poi diciamo qualcosa come fa a impararlo però intanto descriviamo l'addestramento e qui vediamo che abbiamo appunto l'input layer lo strato nascosto numero 1 e lo strato nascosto numero 2 qui è dove avviene una trasformazione dell'effetto cioè l'input viene trasformato secondo questi due strati nascosti la rete elabora una trasformazione delle feature e da sola durante l'addestramento impara che cosa le serve tirare fuori come deve trasformare quell'input per produrre un determinato output che sia conforme all'addestramento e quindi quello che deve imparare a fare e l'output sta qua ok questo grafico scusatemi questo è questo qui è una versione un po' più compatta in cui anzi che andare a replicare un certo numero di volte l'input abbiamo l'input una sola volta e l'input viene passato a ognuno dei neuroni del primo strato qui si vede anche meglio vedete che ognuno di questi punta e va verso ogni neurone del primo strato qui c'è la matrice dei pesi che definisce la combinazione lineare degli input rispetto al primo strato a quella segue la funzione di attivazione non lineare dopodiché l'output di ogni neurone di primo livello confluisce in un neurone di secondo livello dove di nuovo c'è una combinazione lineare secondo questa matrice dei pesi attivazione non lineare e poi si va in uscita dove facciamo solo la combinazione lineare due cose vi volevo dire una la dicevo ieri credo non so non mi ricordo se durante la lezione o al termine però quello che solitamente si fa è in linea di principio potrei cambiare attivazione per ogni neurone o cambiare attivazione da strato a strato di solito quello che si fa è invece procedere con una stessa funzione non lineare per tutti i neuroni per motivi di comodità e questa è una prima cosa che vi volevo dire un'altra cosa che vi volevo dire è che ritrovate qui la scansione in layer di input nascosto 1 nascosto 2 trasformazione delle feature output e questo è il risultato del vostro modello la seconda cosa che vi volevo dire è che tipicamente anche qui in linea di principio potrei applicare un'ulteriore trasformazione non lineare ma tipicamente non si fa non serve questo grafico è un'ulteriore versione compattata dei primi due rappresenta sempre lo stesso in cui rappresentiamo il nostro input come un vettore un vettore in cui abbiamo il cerchietto sopra ecco una cosa torno un attimo alla figura sopra è quella precedente vedete qui ci sono degli 1 chiaramente quelli sono i pesi relativi poi le connessioni che escono da questo 1 sono quelle relative scusatemi ai termini di bias ok quindi i termini di bias sono quelli che poi confluiscono qui ci metto l'1 in cima proprio perché quando vado a moltiplicare w1t per x il primo termine viene moltiplicato per 1 ed è il termine di bias non tocca le picture il risultato è un'attivazione non linea il risultato viene mandato scusatemi in input a un'attivazione non lineare e poi di nuovo moltiplicato per un vettore dei pesi attivazione non lineare e un'ultima moltiplicazione per un vettore che è l'ultima combinazione scusatemi lineare va bene? quindi qui questi sono tre rappresentazioni di un modello di rete neurale che ha u1 neuroni di primo livello e u2 neuroni di secondo livello a questo punto il gioco è fatto perché io posso continuare in questo modo e aggiungerne quanti ne voglio per cui come lo schema è uno schema di tipo ricorsivo ormai lo abbiamo capito se io vado a costruire una generica unità se io voglio costruire diciamo meglio una generica unità di livello L dove L significa che ho fatto il primo ho fatto il secondo ho fatto il terzo sono a L uguale a 5 supponiamo come procedo di nuovo cosa faccio prendo un termine di bias e faccio una combinazione lineare di che cosa di tutti gli input che mi arrivano dal livello precedente che è il livello 4 se L vale 5 ok e quindi di nuovo ogni singolo neurone al livello L dell'IRL sarà definito in questo modo si fissa una funzione di attivazione si costruiscono un certo numero di unità di livello L-1 queste hanno una certa funzione di elaborazione vengono combinate linearmente e poi il risultato viene fatto passare attraverso una una funzione di attivazione non lineare se voi fate lo stesso la stessa piccola simulazione che abbiamo visto prima con neuroni di livello 1 uno strato nascosto due strati nascosti e questo è il risultato che ottenete invece se applicate un terzo livello di neuroni di tre strati nascosti vedete che comincia anche qui generando a caso sempre delle copie di parametri e le altre che poi danno l'input al secondo neurone con altre due copie di parametri che da l'input a un altro neurone con altre due copie di parametri generati casualmente cominciate a ottenere con due funzioni diverse di attivazione non lineare che sono rispettivamente la tangente iperbolica e la relu ottenete questa varietà di possibili funzioni vedete di nuovo come andando in profondità aumenta la capacità del sistema qui riassumendo anche qui anzi prima di riassumere andiamo avanti qui siamo di nuovo al generico la generico strato L ok quindi stiamo costruendo le unità di livello L di nuovo io posso scrivere il modello come una combinazione lineare di un certo numero che fisso un grande con L di unità di quello di quello strato perché ogni strato può avere un numero diverso di neuroni io posso mettere 5 neuroni nel primo strato 25 nel secondo 30 nel terzo 8 nel quarto per lo meno in linea di principio il nostro modello è quindi questo di nuovo la singola unità la esprimo come abbiamo visto prima come termine di bias più combinazione lineare di quello che gli arriva dallo strato precedente questa generalizza quelle che abbiamo scritto per i neuroni di secondo livello e di primo di primo c'era direttamente la x chiaramente l'output di un generico di un generico neurone dello strato di livello L lo possiamo scrivere quindi come una composizione di vedete qui un'altra cosa che ricorre che è evidente che è una composizione di funzioni ho l'input che viene dato in input appunto al sistema che viene composto tramite funzione lineare poi attivazione lineare viene dato come il suo output come input alla seconda livello che effettua la composizione relativa fino ad arrivare questo è il vettore che vi permette di costruire il il risultato finale e questa è la scrittura più generica a cui possiamo arrivare che è esattamente quella che abbiamo visto prima per il neurone di livello 2 generalizzata appunto a un livello L siamo ecco adesso per riassumere abbiamo lo schema di una di una di una rete neurale densa in cui abbiamo quanti livelli 2 fino a L-1 e poi abbiamo l'ultimo L-esimo quindi abbiamo L strati nascosti quindi una rete deep profonda in cui ogni input subisce la trasformazione che abbiamo detto secondo la matrice W1 al primo livello che fornisce la combinazione lineare attivazione non lineare combinazione lineare attivazione non lineare fino ad arrivare allo strato WL-1 scusate uno strato con indice L-1 combinazione lineare secondo questa matrice di pesi attivazione lineare ultima cosa arriviamo a livello L il risultato viene poi combinato linearmente per determinare il risultato vedete qui abbiamo un layer di input un layer nascosto di livello 1 di livello 2 fino ad arrivare al livello L la trasformazione avviene progressivamente in tutti questi strati del feature di input e l'output è null'altro che la combinazione lineare secondo questi pesi di quello che arriva qui ora la domanda è dato un oggetto di questo genere come facciamo ad addestrarlo perché un oggetto di questo genere ha una serie di parametri che sono questi che sono i parametri in qualche modo visibili alla fine la combinazione lineare di questi output e quindi sono W0 W1 W2 fino a W1 L e in più ci sono tutti i parametri interni che ognuno di questi ognuna di queste matrici definisce che rendono conto di ognuno di questi collegamenti e il peso di ognuno di quei collegamenti giusto? quindi ognuna di queste matrici si porta dietro il peso di quei collegamenti ecco come facciamo ad addestrare magari questo si vede bene un po' meglio anche qua in cui abbiamo sono le due versioni quella un po' più compatta quella super compatta che abbiamo visto anche prima ecco qui si vede bene quali sono i pesi che dobbiamo i parametri che la rete deve imparare sono questi ma che sono anche tutti i parametri che stanno qua dentro e i parametri che stanno qua dentro sono i pesi associati a queste connessioni ognuno di quelle connessioni è associato a un peso e la rete deve imparare tutti quei pesi come facciamo andiamo a vedere l'output lo confrontiamo nel nostro dataset di addestramento con l'output che vogliamo ottenere supponiamo che questo per semplicità sia un problema di regressione abbiamo un solo output se fosse un problema di classificazione in realtà qui avrei più output tanti quante sono le classi come facciamo costruiamo una funzione di costo giusto e poi confrontiamo in base a quella funzione di costo il risultato che ci dà la nostra rete ad esempio inizializzando tutti quell'insieme di pesi di parametri in maniera casuale e confrontiamo il risultato e vediamo quanto vale la nostra funzione di costo cosa ci rispondisce dopodiché abbiamo il problema di dover calcolare che cosa il gradiente della funzione di costo rispetto a questo insieme di pesi di parametri se io riesco a calcolarlo ho una direzione valida di discesa cioè posso avanzare verso un punto che è quello a costo più basso e poi di nuovo verso un punto a costo più basso verso un punto a costo più basso e qui chiudiamo un po' il cerchio con tutte le cose che abbiamo detto a partire dall'inizio le tecniche di ottimizzazione l'ottimizzazione di questi oggetti qui come vi dicevo avviene principalmente per tramite algoritmi del primo ordine algoritmi di discesa del gradiente che funzionano abbastanza bene per fortuna su questo tipo di architetture di rete ok tutto questo è allora come vi dicevo le reti torno un attimo indietro le reti dense sono un primo modello che nasce vedremo tra poco a partire diciamo dai primi modelli di neurone degli anni 50 quindi l'approccio cosiddetto connessionista quello che dà poi alle reti neurali il via nasce con questa tipologia di reti poi negli anni più recenti direi negli ultimi 15 anni si è andato un po' a specializzare come vi dicevo nell'ultima lezione se voi provate ad applicare una rete densa oggigiorno a problemi ad altra dimensionalità come appunto il riconoscimento di immagini cominciate ad avere subito un'esplosione dei parametri e quindi diciamo lì si sono sviluppate le prime per quel motivo ma anche per cercare di sfruttare meglio per esempio le caratteristiche cioè il fatto che un'immagine ha una regolarità spaziale di un certo tipo si sono sviluppate delle architetture particolari ma il meccanismo rimane sempre lo stesso cioè ho delle unità neuronali che funzionano in questo modo combinazione lineare dei suoi input e attivazione non lineare nelle reti convoluzionali semplicemente non tutti sono collegati a tutti e vengono fatte altre operazioni che sono appunto degli operatori vengono applicati gli operatori di convoluzione per effettuare un certo tipo di trasformazione che corrisponde bene a una logica che è quella del cercare di capire di catturare cosa avviene all'interno dell'immagine però di fatto lo schema generale rimane valido ho tante unità che fanno questa cosa fondamentalmente combinano linearmente e utilizzano funzioni di attivazione non lineare e poi in queste reti diciamo tra virgolette moderne quello che si fa è mescolare ci sono degli strati tipo convoluzionale che fanno appunto delle operazioni che sono quelle che vi ho appena accennato poi non abbiamo tempo di entrarci dentro e alternano queste magari degli strati di tipo denso quindi le reti densi rimangono comunque una base importante di partenza e anche qualcosa che viene tuttora utilizzato poi ci sono altre architetture ci sono le architetture ricorrenti in cui abbiamo dei meccanismi di feedback si torna indietro fino ad arrivare ai giorni nostri c'è un mondo insomma ovviamente che è quello del deep learning parte da qui che vediamo un tanto un'introduzione che abbiamo chiaramente la pretesa come già vi dicevo di entrare troppo in dettaglio su questo e tutto questo nasce in realtà da un qualcosa che una serie di studi che hanno provato a inquadrare il tema ampio dell'intelligenza artificiale con un approccio che è quello cosiddetto appunto vi dicevo connessionista che cerca di riprodurre a grandi linee i meccanismi di funzionamento del cervello degli organismi evoluti e allora i primi studi diciamo delle neuroscienze che intorno agli anni 40-50 hanno influenzato questo tipo di approccio avevano permesso di cominciare a capire qualcosa di più di come funzionava una cellula del sistema nervoso la cellula del sistema nervoso ha grosso modo uno schema di questo tipo ci sono dei dendriti che sono dei collegamenti delle terminazioni nervose che arrivano alla cellula da altre cellule dello stesso tipo ad esempio e attraverso queste terminazioni questi dendriti si propaga un segnale che è un segnale elettrico che proviene da appunto dalle altre cellule qui c'è appunto il corpo cellulare e qui c'è un collegamento di uscita che viene chiamato assone ovviamente ipersemplificando quello che è una realtà biologica che è ovviamente anche più complessa poi si è imparato nel corso degli anni però a quel punto quando è cominciato a venire fuori un punto degli studi in cui si capiva qualcosa di più di come era fatta una singola cellula del sistema nervoso subito il primo tentativo è stato quello di cercare di modellizzare il comportamento di questa cellula e la modellizzazione significa scrivere un modello matematico che descriva il funzionamento di una singola cellula e un primo modello che è stato proposto tra gli anni 40 e 50 in parte di due studi americani è stato proprio un modello di questo tipo che era dire ok perché cosa succede che alla cellula arrivano in input una serie di stimoli nervosi se questi input sono superiore a una certa soglia il neurone diciamo si accende e propaga in uscita a sua volta un segnale elettrico e allora tutto questo è stato modellizzato in questo modo in prima battuta ho una serie di input x1 fino a xn che arrivano secondo delle connessioni dendritiche in input alla mia cellula la mia cellula è costituita da un'unità di somma e un'unità di attivazione dove l'unità relativa alla somma fa una combinazione lineare e l'unità di attivazione effettua un'attivazione di tipo non lineare guardate un po' questo modello esattamente quello che noi abbiamo sfruttato per descrivere le reti neurali totalmente connesse di cui abbiamo parlato fino a poco fa ed è effettivamente il primo modello di neurone biologico che è stato proposto ripeto a partire dagli anni 50 del secolo scorso ora nel corso dei 50 anni successivi direi dei 70 anni che ci hanno portato fino ad oggi questo modello è stato messo chiaramente in discussione cioè se voi lo proponete a un neuroscienziato ogni giorno vi dice che questo modello non è assolutamente un modello plausibile per quel tipo di funzionamento cioè vi dice guarda che ci sono alcune cose che avvengono all'interno di questa cellula che questo modello non riesce a catturare e questo ovviamente rende conto diciamo c'è un probabilmente l'avrete anche sentito c'è un un detto che una citazione che è abbastanza famosa che credo sia attribuibile a uno statistico forse inglese non mi ricordo di dove fosse un inglese americano che all models are useful scusatemi all models are wrong but some are useful cioè tutti i modelli sono sbagliati perché sono delle rappresentazioni astratte della realtà ma qualcuno è utile ora questo modello probabilmente non è utile per descrivere per un biologo esattamente che cosa succede all'interno di un di un di un neurone o meglio qualche biologo avrebbe da obiettare che è un modello oggigiorno un po' grossolano però è un modello che comunque funziona per costruire un sistema artificiale che fa delle cose comunque egregie come per esempio riconoscere che in una foto di questo tavolo in questo tavolo c'è un monitor di un computer una tastiera una bottiglia e un foglio di carta quindi diciamo la plausibilità delle reti neurali è un qualcosa che è stata messa ben presto un po' in dubbio però il fatto che non siano cioè poi alla fine l'intento qual è costruire dei sistemi che funzionino per gli scopi che noi vogliamo certo siamo un po' lontani con questi sistemi a emulare strettamente il comportamento di un del cervello di un organismo intelligente ma i risultati in realtà a cui si arriva è o meglio siamo lontani non tanto all'emulazione al fatto di replicare esattamente ma non vogliamo costruire diciamo su silicio esattamente la stessa cosa vogliamo costruire qualcosa che emuli quel comportamento lo simuli in maniera plausibile e diciamo su questo sono stati fatti dei grandi passi avanti e si continua ovviamente a modificare cercando anche di trarre ispirazione da modelli biologici più realistici quindi provando a dire cosa succede se io metto un altro tipo di modello di neurone e comincio a combinare questi modelli tra di loro collegandoli eccetera vengono fuori delle cose più interessanti oppure no siamo in grado di costruire sistemi tra virgolette più intelligenti oppure no per esempio ve ne dico una su tutte è una cosa che è strabiliante del cervello umano e che riesce a fare tutte le cose che fa quindi frazione di secondo riesce a fare un rendering visivo tramite la corteccia visiva di quelle che sono le immagini che vediamo attraverso i nostri occhi attraverso la retina riesce appunto a quando attraversate la strada a fare la valutazione di quella che è la velocità di arrivo della macchina e di quando la macchina arriverà e quindi se fate a tempo ad attraversare la strada sulle strisce pedonali oppure no oppure se siete in macchina a valutare che cosa succede rispetto all'ambiente circostante tutto questo lo fa in una frazione di secondo ed è già di per sé sbalorditivo ma la cosa che dal mio punto di vista è ancora più sbalorditiva è che lo fa con un consumo energetico che è assolutamente strabiliante perché gli studi ci dicono che il nostro cervello ha un consumo di potenza in grosso modo intorno ai 3,10 e ai 20 watt quindi poco più di una lampadina di quelle a incandescenza con cui riuscivate a illuminare fino a un po' di tempo fa in maniera fiocca una stanza e ora se cercate di replicare un qualcosa del genere ancora non ci siamo riusciti per tante cose ma se pensiamo agli studi sui sistemi a guida autonoma eccetera hanno bisogno appunto di GPU che in continuazione macinano dati prima vengono addestrate su questi ma poi li macinano in continuazione prendendo immagine dalle telecamere o dai lidar o da qualunque sensore di arrivi in input e lo fanno con consumo di potenza voi prendete una GPU consuma 200 300 500 watt ora dove sta lo scarto tra questi sistemi sta probabilmente nel fatto che appunto qui dentro c'è qualcosa di diverso però insomma questo gli studi vanno avanti è un'area anche questa estremamente affascinante di ricerca va bene due cose così ampassant di delle tantissime aree di ricerca che ci sono in questo ambito che vanno in tante direzioni diverse per cui c'è sì per esempio il fatto di raggiungere livelli di accuratezza per esempio sempre più alti quando parliamo di sistemi di riconoscimento di classificazione ma c'è un problema anche di farlo con sistemi che siano energeticamente efficienti allora il modello del percettrone era giusto per tornare un attimo indietro questo è il modello del percettrone del primo neurone artificiale del 1957 mi ho detto prima tra gli anni 40 e 50 gli anni 40 cominciano i primi studi e questo modello è stato proposto nel 57 è giusto per darvi ancora qualche numero il cervello umano ci sono circa 10 alla 11 neuroni iniziamo parlando di qualcosa come 100 miliardi di neuroni e per un totale di qui sono delle stime ovviamente 10 alla 14 circa sinapsi le sinapsi sono questi collegamenti no? quindi sono i pesi in qualche modo che il nostro cervello deve il nostro cervello non sono plasticità questi pesi vengono modificati perché l'attività neuronale modifica i pesi rafforza alcuni pesi altri vengono invece depotenziati a seconda di quello che è poi l'attività del cervello per esempio alcune stime delle neuroscienze ci dicono che tra i 10 alla 5 e i 10 alla 6 di questi sinapsi scusate di questi neuroni e corrispondenti sinapsi sono coinvolte per esempio nella corteccia visiva quando si fa il rendering di un'immagine cioè riceviamo un'immagine sulla retina il nostro cellulare e la rapora quindi i dendriti di fatto sono appunto questi ricevitori il corpo cellulare è quello che qui viene chiamato soma e il trasmettitore è la sola queste sono le tre componenti di questo sistema volendolo vedere come un sistema diciamo ingegnerizzato ok questo diciamo è una slide in qualche modo dovuta nel momento in cui si parla di reti neurali perché sono sistema artificiale che è stato costruito fin dall'inizio cercando di trarre ispirazione da un modello biologico anche se poi le differenze sono molte tra il sistema artificiale e il sistema biologico come vi dicevo prima però nonostante queste differenze questi sistemi funzionano abbastanza bene quindi è un modello probabilmente sbagliato da un punto di vista delle neuroscienze ma utile per fare certe cose sbagliato diciamo più che altro limitato non sbagliato ok allora qui un semplice esempio di un torniamo invece ai nostri semplici reti dense qui abbiamo un primo esempio a sinistra in cui scusatemi non a sinistra ma nella parte superiore questa è la vista di regressione lo vedete meglio qui forse nella vista di percetrone un problema di classificazione binaria ok quindi classe rossa e classe blu input a due dimensioni e su cui è stata addestrata una rete neurale di tipo totalmente connesso a quattro strati dieci unità per ogni strato quindi tutti i quattro strati hanno dieci neuroni ma anche qui non c'è scritto da nessuna parte potreste provare a variare e vedere cosa succede funzione di attivazione tangente iperbolica qui è stata costruita una funzione di loss binaria di tipo softmax l'abbiamo vista a suo tempo che cos'era addestrata la rete con discesa del gradiente confini decisionali sono questi due tracciati in vino vedete che fa un ottimo lavoro la rete per riuscire a costruire in tutta in autonomia cioè qui vi faccio notare la differenza tra quando abbiamo fatto noi feature engineering per dire mi ricordate c'erano quelle ellissi abbiamo riconosciuto che c'è un ellissi allora andiamo a costruire a iniettare della non linearità di un certo tipo quadratico eccetera qui non gli diciamo nulla di tutto ciò la rete prende questo input quei pallini con le loro brave coordinate e da sola costruisce fa feature learning cioè apprendimento delle feature come fa a farlo? a tutti gli esempi qui in cui partiamo da dei vettori di input e abbiamo dei pesi generati a caso ma con tutti gli esempi di apprendimento supervisionato aggiusta quei pesi in modo da soddisfare questi questi vincoli e andare il più possibile ad abbassare la funzione di costo e a trovare quei confini decisionari nel secondo esempio abbiamo una cosa del tutto analoga solo che il problema questa volta è un problema di tre diciamo con tre possibili classi quindi qui siamo nel caso in cui abbiamo delle reti in cui l'uscita a differenza delle figure che vi ho fatto precedentemente che erano queste qui abbiamo nello strato di uscita un solo un solo neurone qui ne avremo tanti quante sono le classi quindi due se abbiamo due classi tre se abbiamo tre classi e così via e ognuno di questi è collegato a tutti i neuroni dello strato precedente quindi in questo caso abbiamo costruito una rete è stata costruita una rete neurale che ha tre neuroni in uscita e ha due strati nascosti quindi sono bastati due il primo ha 12 neuroni il secondo ha 5 neuroni la funzione di attivazione è sempre la tangente iperbolica funzione di costo è la softmax multiclasse addestrato con discesa del gradiente il risultato è una cosa di questo genere e con queste strutture si possono fare tantissime cose abbiamo parlato dell'apprendimento con supervisione quindi abbiamo visto il la classificazione si può fare anche regressione ma si possono fare anche risolvere problemi di tipo non supervisionale vi ricordate il discorso dell'autoencoder lineare in cui andiamo a cercare uno sottospazio lineare per fare riduzione della dimensionalità poi possiamo anche tornare nello spazio originale perdendo informazione eccetera eccetera qui possiamo fare la stessa cosa costruire lo stesso meccanismo in cui anziché andare ad apprendere una trasformazione lineare andiamo ad apprendere a partire dai dati senza etichette la miglior trasformazione non lineare e quindi fare delle cose di questo tipo diventano abbastanza complicate ma fanno una cosa di questo tipo allora qui abbiamo una rete neurale di tipo multistrato come abbiamo visto il multistrato appunto vi ho detto sono sinonimo di reti dense a tre strati in particolare con dieci unità per ogni layer quindi una rete con 30 30 neuroni tutto funziona di attivazione tangente peribolica e qui viene utilizzata una funzione di costo ai minimi quadrati e viene addestrata a partire da questo dataset il dataset di partenza è questo è una serie di punti che vivono in uno spazio bidimensionale x1 x2 sono le due allora quello che fa questa questa questa questa questa rete è costruire quel quella combinazione che noi abbiamo detto più volte no vogliamo costruire un un encoder che prende ogni singolo punto e poi vogliamo costruire e lo trasforma e vogliamo costruire anche un decoder che applicato a questo risultato mi restituisce qualcosa che è il più possibile simile al punto da cui sono partito ok questo era se vi ricordate l'obiettivo degli autoencoder come li avevamo impostati solo che fd ed fe nel caso dell'autoencoder lineare che abbiamo visto erano delle trasformazioni lineare qui in questo caso quello che succede è che un sistema di questo genere basato su rete neurale riesce ad aggiustare i pesi della trasformazione in modo che apprende come c'è scritto qua quello che i matematici chiamano una varietà cioè apprende il fatto che questi punti stanno tutti su questa curva ok mentre se noi avessimo fatto per esempio l'analisi dei componenti principali e l'avremmo proiettato su una retta chiaramente su una direzione su uno spazio lineare o su un piano su un interpiano lui riesce a capire che i punti stanno su questa curva questa è la curva che riesce ad apprendere e quindi quando facciamo questo è l'encoding qui c'è l'encoding e quando facciamo prendiamo i punti codificati quindi l'encoding che cosa fa prende un punto in dimensione due e lo trasforma in un punto che ha dimensione uno ok dimensione uno significa su questa superficie che in realtà è una curva ok e poi da qui se lo ritrasformiamo in dimensione due lui lo riproietta qua in forma così gli autoencoder sono appunto una realizzazione dell'autoencoder non lineare cioè si differiscono da quelli che abbiamo visto a suo tempo che fanno la riduzione della dimensionalità con trasformazioni lineari proprio per il fatto che riescono a proiettare i dati su una qualunque superficie a più bassa dimensione di tipo non lineare quindi si fanno cose arbitrariamente complicate anche qui si aprirebbe un mondo ma lo fanno guardando solamente i dati qui non c'è l'etichetta è tutto non supervisionato anche qui dietro c'è tantissimo ci sarebbe tantissimo da dire ma non basterebbero probabilmente due corsi e vi dico un paio di cose poi ancora poi ci fermiamo quando si comincia a studiare la una rete neurale e a progettarla la domanda che si fa e qualcuno già me la faceva nella lezione della volta scorsa è ma come possiamo scegliere il numero di layer come possiamo scegliere quanti ne dobbiamo mettere e quante quali sono le dimensioni questi sono degli iperparametri quindi ci sono anche degli strumenti automatizzati per cercare di esplorare questo spazio di parametri che però è uno spazio di parametri enorme anche qui e e quindi come ci si muove ci si muove o in maniera un po' empirica oppure cercando di testare diverse alternative vedendo quale funziona meglio ci sono però anche delle regole generali che vengono date e e adesso cerchiamo di di dirne qualcuna allora tipicamente quello che si può riscontrare ed è un qualcosa di intuitivo è che nel momento in cui aumentiamo il numero di layer aumenta la capacità del modello stessa cosa se aumentiamo anche il numero di neuroni per ogni layer aumenta la capacità del modello e qui abbiamo un esempio di nuovo di una classificazione binaria quindi punti verdi o rossi appartengono a una classe oppure a un'altra classe e abbiamo una rete con un solo strato nascosto e vedete cosa succede nel momento in cui andiamo a aumentare per esempio il numero di neuroni qui sono 3 qui sono 6 qui sono 20 allora quello che succede vedete che veramente qui c'è un fenomeno che vediamo che è un fenomeno tipico l'abbiamo già incontrato di overpitting ok e quindi qui che cosa si fa beh si può notare anche qui tenendo sotto controllo una curva di validazione si può controllare questo fenomeno ci si può collocare e scegliere un modello che ad esempio può essere questo intermedio oppure anche questo più semplice probabilmente in questo caso generalmente il consiglio qual è che si dà partire da un modello abbastanza diciamo potente abbastanza capace quindi ad esempio questo da 20 neuroni e poi agire tramite la regolarizzazione quindi utilizzare per esempio una funzione di regolarizzazione oppure un altro modo nelle reti neurali che oggigiorno viene utilizzato nella pratica per un'altra modalità diciamo equivalente alla regolarizzazione è quello del cosiddetto drop out drop out è un meccanismo in cui voi durante l'addestramento andate a spegnere selettivamente dei neuroni selezionati a caso questo si dimostra che è equivalente a una forma di regolarizzazione e vi permette di evitare che la rete vada troppo facilmente in overfitting quindi in questo modo riuscite a partire da una rete abbastanza capace un modello abbastanza complesso a tenere sotto controllo l'overfitting e a trovare magari già in partenza un buon buon compromesso oppure vedete la classica cross validation e come abbiamo visto è un modo per cercare di tenere sotto controllo questo tipo di fenomeno e controllare il numero di layer il numero di neuroni per layer e vedere tra diverse alternative qual è la migliore però non è mai un'attività semplice lo è finché siamo su architetture piccole quando cominciano a diventare architetture grandi sono abbastanza problemi perché significa tante risorse computazionali oggigiorno addestrare delle reti neurali significa disporre di tanti dati potenzialmente essenzialmente sono reti neurali di un certo tipo e che raggiungono certe prestazioni risporre di tanti dati e tante risorse computazionali reti neurali piccole no ovviamente è chiaro che qui a sinistra la generalizzazione è migliore rispetto a quelle della figura del centro di reti ok e qui c'è quello che vi dicevo cioè potete usare potete prendere la rete neurale con 20 unità e utilizzare la regolarizzazione per controllare l'overfitting qui avete che cosa succede quando utilizzate vi ricordate la regolarizzazione aggiungiamo alla nostra loss function un termine che è lambda per ad esempio la norma dei pesi la norma L1 dei pesi se utilizzate questo meccanismo con lambda per esempio pari a 10 alla meno 3 ottenete questa figura se lambda lo fate diventare 10 volte tanto vedete già come comincia a diventare questa e poi guardate con lambda 0 1 diventa 0 1 diventa lambda è parte di loss function right yes it is I'll translate and then I answer to you la domanda è se lambda è parte della funzione di loss e la risposta chiaramente è sì è quella parte della funzione di loss che viene modificata cioè è il multiplicatore della funzione di loss modificata yes the answer is yes we have our original loss function which is a function of our parameter let's call it w ok and then we modify from this we build another function which we may call f ok which is built as g plus lambda times let's say h which is another function which may be just to give an idea it may be the norm of the weight vector ok norm for instance norm l1 norm ok so lambda is the multiplier that controls how much this is the weight of regularization so if we have a very little value it is it means that f is almost the same as g yes we are adding noise of course but we this noise allow us to prevent overfitting and it also introduces some loss in terms of accuracy potentially in terms of training accuracy but it better generalizes so the test accuracy is better va bene ci siamo avete domande ok direi che questo rimangono poche cose che vediamo la prossima volta più con calma se mi aspettate un attimo allora adesso farei una cosa vi condividerei una cosa abbastanza simpatica potete provare ad andare a vedere a curiosare che è stata sviluppata da google per costruire per diciamo neanche costruire perché in realtà come potete giocare un pochino con un po' di alternative che loro hanno proposto su delle reti rurali dico giocare che si chiama proprio playground ed è una cosa vi faccio vedere il link vi faccio vedere come funziona e poi magari ci guardate con calma a casa provate un attimo visto che la prossima volta faremo un'esercitazione direttamente proprio per costruire in maniera invece diciamo le reti di questo tipo dense in maniera diciamo più sicuramente sistematica però intanto potete guardare questo esempio perché è una cosa abbastanza abbastanza secondo me carina e vale la pena ok allora questo è un esempio che vi voglio far vedere di appunto su questo sito che è un sito gestito appunto da da google che ha sviluppato questo strumento che si chiama tensorflow serve appunto lo vedremo nella prossima esercitazione del laboratorio per costruire e addestrare le reti neurali e qui avete un simpatico è un sito molto secondo me molto carino perché vi permette di appunto di giocare con un po' di esempi vi permette di costruire delle reti con un certo numero al massimo 8 neuroni per ogni strato un certo numero di layer nascosti e vi permette di avete a disposizione diversi tipi di dato vedete per esempio questo che è una distribuzione di dati che poi ritrovate anche qui a destra che sono queste due nuvole di punti l'avevamo utilizzate anche noi a suo tempo quando abbiamo fatto l'esercitazione del laboratorio ma potete anche cambiare avete questo avete questo in quest'altra opzione di questa spirale ok di punto poi con ognuno di questi potete andare a costruire vedete qui parte di default con una sola coppia questo è un dato bidimensionale quindi avete due neuroni di input x1 e x2 ma potete eventualmente aggiungere anche delle feature trasformate se volete e vedrete cosa succede poi potete impostare il numero di neuroni del primo stato nascosto qui sono 4 ma potete aumentare metterne 5 o anche di meno e potete eventualmente inserire anche altri strati nascosti ok e poi avete i due strati di uscita che rappresentano le due classi quello che potete poi fare è andare a gestire se andate a vedere il learning rate potete impostare tra più alternative potete impostare la funzione di attivazione scegliere tra relut tangente iperbolica sigmoide o lineare che significa che non fate trasformazione lineare e il parametro di regolarizzazione quindi l1 o l2 quindi la norma l1 dei pesi o la norma l2 e il rate di regolarizzazione che è quel fattore lambda di cui parlavamo prima e poi il problema il tipo di problema è un problema di classificazione o eventualmente di regressione perché potete fare anche regressione andiamo a vedere su questo poi mandate in esecuzione ok qui vi da un po' di spiegazioni quindi volendo potete andarle a leggere è abbastanza interessante quindi diciamo vi invito un semplice esercizio per giocare con queste cose che è abbastanza interessante secondo me e qui vi potete far partire vedete qui ci sono le epoche del training e qui sulla destra vi da le curve della loss sul dataset di test perché poi quello che non vi ho detto qui potete specificare anche il ratio del training data che in questo caso è il 50% rispetto al test data potete aggiungere del rumore e potete dirgli qual è la dimensione dei batch che lui utilizza per fare l'addestramento e guardate qui già cosa è arrivato a fare e qui potete fare lo posso bloccare posso anche aumentare l'erring rate e vedere che cosa succede se lo rifaccio partire con un learning rate diverso e guardate come aumentare il learning rate va molto più rapidamente a convergenza però all'inizio è un po' rumoroso rimbalza cioè anche qui vedete un po' di cose che già abbiamo visto in teoria quando abbiamo parlato degli algoritmi di ottimizzazione e l'altra cosa che potete fare è portando questo qua vedete cosa succede se cambio la funzione non lineare quindi se per esempio metto una una relu trova quest'altro tipo di profilo e se io mettessi possiamo anche farlo a prova di andare a vedere cosa succede se metto un'attivazione lineare guardate che cosa succede questo risponde alla domanda che se non sbaglio qualcuno di voi mi aveva fatto ieri cosa succede se utilizziamo se non mettiamo la non linearità e lui non trova niente vedete questo è estremamente secondo me significativo quindi diciamo il mio invito è un po' provare a giocare poi potete per esempio aumentare anche il rumore quindi introdurre del rumore nel dataset e vedere che cosa succede se c'è rumore mi fa un po' di fatica però riesce comunque a trovare un buon compromesso potreste dunque vediamo un po' chi riesce devo farvi vedere anche quando vai in overfitting potreste anche provare a vedere se aumentate il numero di strati e vedere se aumentando questo per esempio se vai in overfitting quindi magari mettete anche un po' abbassiamo questo vediamo un po' cosa succede e qui non riesce a trovare niente vedete quindi probabilmente siamo andati un po' in overfitting quindi magari possiamo fare una cosa leggera andare un po' più di là vediamo cosa succede vedete qui fa un po' fatica a trovare qui è in overfitting la rete vedete come la test loss è stata elevata piano piano scende ma ancora non riesce a trovare niente se introduciamo forse un termine di regolarizzazione forse un pochino ci può aiutare e quindi uno fa un po' di prove comincia a vedere cosa succede anche qui si pianta un po' quindi anche qui c'è un po' di problemi probabilmente la rete è un po' troppo grande rispetto a quei dati potete fare un po' di prove poi anche con gli altri dati diventa molto interessante perché vediamo qui aspettate la rimetto un po' di rumore perché oggettivamente era molto alto vediamo questo c'è ok ok qui ancora sta lavorando vedete che ancora non ha trovato bene possiamo fare aumentare un attimo magari di lineare di grade perché mi sembra che vada un po' piano partiamo dal piano se riesce a trovare e questo non è facile vediamo la regolarizzazione e vediamo cosa succede non è facile non è facile vedete che qui non lo riesce a trovare ancora però se provate un po' la combinazione giusta dovreste riuscire a ad arrivarci vediamo un po' veloce vediamo se qui la riesce a trovare no qui decisamente è partito molto male ma beh insomma qui è andato subito ma non distingue nulla no decisamente prossimo dovrebbe riuscire con la relu a trovare un qualcosa di ragionevole però probabilmente c'è qualcosa da modificare magari lo si lascia andare un po' più avanti quindi adesso guardate che comincia a piegare qualcosa sta cercando di fare vedete come sta cercando qui di piegare intorno a questa arancione quindi le zone che si mette in arancione dove lui fa la predizione dell'arancione le zone dove è blu lui fa la predizione del blu qui mentre fa il training vi fa vedere quale sarebbe la sua i suoi confini decisionali e vedete che piano piano vedete come diminuiscono poi oscillano l'addestramento va avanti durante le epoche vedete come piano piano lui riesce a catturare quella questa confine decisionale è riuscito a fare un buon lavoro infatti vedete se andate a vedere la training loss è quasi zero anche la test loss sta ridotta bene allora l'ho fermato adesso però vedete che ha fatto un buon lavoro riuscito a trovarlo quindi fate un po' di prove allora la domanda era che cosa significa il batch size cosa vuol dire giocare con il batch size il batch size è la dimensione se vi ricordate quando abbiamo parlato del training vi ho detto che il metodo di discesa gradiente c'è anche il metodo di discesa stocastico cioè anziché andare a calcolare il gradiente su tutto l'insieme di punti io posso andarlo a calcolare un punto alla volta per esempio quello puramente stocastico è un gradiente molto rumoroso ma avanzo molto rapidamente anche se in maniera rumorosa oppure posso fare un compromesso tra questi due estremi posso andare a calcolare il gradiente su un certo subset su un certo sotto insieme di punti e faccio il gradiente su quelli e avanzo di un passo in discesa sul gradiente che mi ha dato l'indicazione quel sotto insieme di punti e questo permette di velocizzare il processo di addestramento quindi tipicamente si fa questo per cui più è alto la dimensione dell'otto più sono vicino al calcolo il gradiente preciso su tutti i punti del mio data set ad ogni step più è basso questo valore più io vado veloce ma il gradiente è rumoroso quindi in certi punti andrò in salita in certi altri in discesa quindi per rispondere alla domanda i'll translate then in english first i finish in italian se io adesso vado ad aumentare il batch size mi accorgo che avrò meno potenzialmente di queste oscillazioni ma vado più piano quindi questo dovrebbe essere adesso facciamo una prova e vediamo effettivamente così vedete vedete come va più piano ed è spianato se invece vado a diminuire il batch size e lo metto a 1 questo è puramente stocastico prende un solo punto e calcolo al gradiente basato su un solo punto quindi sarà un qualcosa che potenzialmente vedete è molto rumoroso dal punto di vista anche della loss però va molto veloce vedete come la trova rapidamente se la trova una strada quindi il punto è il batch size è il dimensione il sizee che dice come quanti ti ho che ti ho che ti ho che ti ho che ti ho per l'optimizzare quindi se usate gradiente di sent hai due choices il primo è il full batch ogni punto di un'attro di un'attro contribuisce a la gradiente calcolazione quindi compite il gradiente ogni point di un'attro di un'attro di un'attro di un'attro e questo è il standard way di studiare questi sistemi oi puoi per un'attro stochastic gradiente descente che ha qualche garantia di convergere per trovare il minimo ma solo un'attro di un'attro di un'attro di un'attro gradiente based su un'attro e poi facciamo una descente toward il minimo 대박io questo è Yesio daạn raud provinces quindi comportати� potreso e�� be very noisy but you can go very fast to work convergence va bene come esercizio guardate un po questa cosa che provate un po a divertirvi con questa poi giovedì invece facciamo proprio utilizzeremo tensorflow come libreria per costruire una una rete multistrato va bene ok intanto fermiamo la lezione di oggi qui grazie