allora buongiorno bentornati e oggi diciamo l'obiettivo di oggi è diciamo vedere un po di una volta che abbiamo ieri concluso la parte relativa ai classificatori lineari binari quindi svm per cetroni e regressione logistica oggi vediamo un po di cose relative più avanti alle metriche per valutare i classificatori e prima di questo però vediamo appunto questo argomento che avevamo iniziato ieri che erano le levo e categorie e volcategoriche che vi ricordo possono essere appunto qualche volta non solo utili ma i miglior si prestano meglio ecco a a mappare sul problema quella che è una situazione reale delle categorie ieri abbiamo detto che eventualmente quello che possiamo fare in maniera del tutto naturale prendere in considerazione una una trasformazione delle etichette d'ingresso quindi anziché prendere l'etichetta ad esempio del tipo 01 trasformarla in quello che viene chiamato one hot encoding è una rappresentazione della stessa etichetta con un vettore in cui le entri di quel vettore sono alternativamente accese da cui il nome one hot quindi una codifica in cui andiamo ad attivare un vettore che ha un certo numero di entri in questo caso tante quante sono le etichette due e alternativamente accendiamo una entry oppure l'altra cioè la settiamo a 1 e questo equivale quindi a poi associare una delle una delle una delle etichette 0 oppure 1 in questo caso abbiamo detto non abbiamo più dei dei valori numerici che hanno quindi un ordine implicito ma abbiamo dei vettori e su questi vettori però possiamo fare delle operazioni che sono quelle che abbiamo fatto quando abbiamo introdotto la regressione logistica cioè quello che possiamo fare a qui rispetto diciamo giusto per insegnarlo solo una cosa che questo qui in realtà è scambiato cioè lo 0 solitamente quello che si fa è associarlo a questo e l'1 a questo ok c'è uno scambio solitamente questo e quindi ripeto non cambia cambiano poi le notazioni però ecco per essere coerenti con quello che trovate di solito è questo ovviamente capite bene che del tutto è del tutto arbitrario questa associazione per cui potremmo anche fare l'inverso però solitamente questo è lo 0 e questo è l'1 allora dicevo l'obiettivo è lo stesso lo stesso che abbiamo stesso obiettivo che abbiamo cercato di perseguire nel momento in cui abbiamo messo in piedi sempre la regressione logistica quindi siamo partiti da un dataset che era un certo numero di punti in cui associavamo a ogni punto x con p un valore scalare numerico 0 1 in questo caso anziché associare un valore scalare numerico ci associamo un vettore un vettore vettorino di due elementi che è la rappresentazione la codifica one hot della nostra etichetta tutto questo vale per t piccolo che va da un po fino a t grande dopodiché il task di classificazione se vi ricordate quando siamo partiti dalla regressione logistica abbiamo detto proviamo a fare che cosa fare una regressione a costruire una regressione lineare su questo dataset e poi facciamo passare il risultato della regressione attraverso vi ricordate una funzione non lineare una funzione gradino poi una funzione sigmoidale eccetera eccetera eccetera qui facciamo possiamo fare esattamente la stessa cosa l'unica cosa che cambia è che la regressione in questo caso una regressione cosiddetta multi output cioè il risultato è un vettore anziché un singolo valore scalare e in particolare quello che si fa si prende il solito modello lineare xp trasposto w questo modello lineare viene poi abbiamo il nostro input che vi ricordo è n dimensioni dell'input non cambia nulla ma quello che facciamo lo mappiamo in un output che in questo caso non è più a una sola dimensione quindi una regressione normale ma due dimensioni che sono le due classi no? ok? e come facciamo? la regressione logistica utilizzavamo una funzione non lineare che era lo scalino oppure la sigmoide o la tangente iperbolica quello che volete qui facciamo esattamente la stessa cosa ma introduciamo un operatore vettoriale che è un operatore che vi prende un singolo input che è questo xp trasposto w e vi restituisce due output sigma p chiamiamo questo operatore vedete che è un operatore vettoriale lo vedete dal fatto che qui abbiamo messo in grassetto la sigma e nulla di più che l'applicazione della sigmoide qui passiamo direttamente alla sigmoide perché ovviamente abbiamo visto già nella regressione logistica no? non rifacciamo tutta l'altra fila perché altrimenti perderemmo inutilmente del tempo ma esattamente lo stesso concetto andiamo direttamente alla sigmoide perché ci permette di costruire delle funzioni di costo che sono assolutamente migliori rispetto agli scalini dal punto di vista dell'ottimizzazione e questo vettore ha come prima entry esattamente la sigmoide che abbiamo visto per la regressione logistica e come seconda entry 1 meno quel valore siccome la sigmoide è definita tra 0 e 1 questi due valori sono due valori che vengono restituiti che sono valori tra 0 e 1 a loro volta questa è una trasformazione non lineare quindi abbiamo il nostro modello lineare che è questo questa trasformazione non lineare a sua volta è quella che poi può essere utilizzata per fare che cosa? per fare poi il tuning dei pesi cioè noi dobbiamo addestrare il modello quindi quello che dobbiamo fare dobbiamo fare il tuning di W e dobbiamo fare in modo che questo è il valore che mi viene restituito sia il più possibile simile a che cosa? a YP come vedete scritto qua ok? cioè se YP ad esempio è 1,0 io voglio che il risultato di questa operazione sia il più possibile simile al vettore 1,0 se YP è 0,1 viceversa voglio che il tuning dei pesi sia tale da produrmi in uscita 0,1 ma questo ci dice anche subito che la scelta che abbiamo fatto è del tutto ragionevole perché guardate che cosa succede se XP trasposto per W è tale da produrmi un valore che è nella parte alta della sigmoide quel sigma di XP trasposto W sarà un valore vicino a 1 ok? questo significa che sotto avremo un 0 viceversa se sigma di XP trasposto W va verso lo 0 pensiamo nel caso in cui sto codificando lo 0 avremo sopra lo 0 e sotto l'1 cioè 0,1 che è esattamente nel one-hot encoding la rappresentazione dell'etichetta 0 quindi io con questo piccolo artificio algebrico riesco a portare diciamo tutto quello che è di fatto l'insieme di tecniche che abbiamo visto finora in questo tipo di scenario che è quello in cui l'etichetta non è più un'etichetta singola a un singolo valore numerico uno scalare ma è un vettore se fosse a 3 il one-hot encoding non cambia perché io ho tre classi quindi supponiamo di avere le tre classi che sono A, B e C io codifico A come ad esempio 1, 0, 0 codifico B come 0, 1, 0 e codifico C come 0, 0 e aggiungo chiaramente qui allora qui diciamo il discorso diventa un po' diverso però c'è una versione che adesso poi avremo modo di vedere quando adesso iniziamo tra l'altro credo oggi o più la prossima volta direttamente la classificazione multiclass quindi la versione di questa diciamo trasformazione è quella che viene chiamata regressione logistica multinomiale è una variante sul tema si può riuscire anche in quel caso a gestire una situazione di quel genere lo diremo quando avalle del classificatore lineare in quel caso prego allora quindi l'obiettivo è fare il tuning di questo insieme di pesi W che sono N più 1 pesi in modo tale che quando sigma è uguale a 1 vado verso questa situazione cioè di andare a avvicinarmi a questa codifica quando sigma dell'argomento è uguale a 0 vado verso quell'altra situazione benissimo adesso facciamo un passo avanti in modo il tutto simile a come abbiamo fatto per le etichette numeriche quello che è possibile fare è introdurre chiaramente una funzione di costo puntuale che poi si traduce in una funzione di costo globale e anche qui analogamente a quanto abbiamo fatto con le etichette numeriche quello che si fa è sfruttare la codifica cioè lì avremmo sfruttato il fatto che le etichette erano 0 1 oppure meno 1 1 qui sfruttiamo la stessa cosa e definiamo la funzione di costo puntuale come il prodotto scalare tra il vettorino a due componenti che abbiamo appena introdotto, codificato e il logaritmo di sigma dove sigma è vettore vi ricordo cos'è il logaritmo di quel vettore? semplicemente il logaritmo di ogni entri di quel vettore ok? quindi questo è esattamente siccome yp vi ricordo è un qualcosa che ha rimanendo generici una componente p1 e una componente p2 ok? che possono essere 0 oppure 1 allora abbiamo che invece log di sigma p è un qualcosa che è il log di sigma di xp trasposto per vdoppio e sotto abbiamo 1 log scusatemi di 1 meno sigma di xp trasposto per vdoppio ok? va bene? quindi io prendo semplicemente questo vettore prendo il logaritmo del sigma p che abbiamo visto prima cioè applico il logaritmo a tutte le entri di quel vettore e quello che faccio faccio il prodotto scalare tra questi due vettori che sono yp e questo log di sigma il risultato di questo prodotto scalare che cos'è? vi ricordate no? il prodotto scalare prendo la prima entri del primo vettore e chiaramente questo viene trasposto per far tornare le dimensioni la prima entri del primo vettore la moltiplico per la prima entri del secondo vettore e così faccio con le seconde componenti il risultato è questo che vedete qui sotto ho meno yp1 che va a moltiplicare il logaritmo di sigma e ho meno yp2 che va a moltiplicare il logaritmo di 1 meno sigma sigma diciamo tralasciando l'argomento per per essere più sintetici ovviamente è sigma di xp trasposto ok questa è una funzione di costo del tutto ragionevole se ci pensate un attimo perché analizziamo cosa succede al singolo punto supponiamo di essere in una situazione in cui yp1 vale 1 e yp2 vale 0 quindi stiamo codificando l'1 ok a questo punto supponiamo che il nostro classificatore dia un risultato ragionevole cioè un qualcosa che è nella parte alta della sigmoide giusto? che cosa succede a questa funzione di costo? yp2 abbiamo detto è 0 quindi questo termine si annulla giusto? sopravvive a quest'altro termine in cui ho meno 1 per il logaritmo di un qualcosa che molto vicino a 1 idealmente quando sigma di xp trasposto w quando xp trasposto w è tale da portare quella sigma verso l'1 qui ottengo il logaritmo di 1 che è 0 l'ho codificato correttamente e non voglio pagare nessun tipo di penalty nessun tipo di loss la stessa cosa vale per il caso di 0 se invece ho sbagliato supponiamo che yp sia sempre il caso 1 0 quindi stiamo codificando l'1 e però il mio classificatore ha una configurazione di pesi che mi dice no guarda 0 1 allora se è 0 1 scusatemi sì il classificatore di pesi è tale che mi porta nella parte bassa della sigmoide quindi verso lo 0 ok questo significa che ho un numero che si avvicina a 0 ma il logaritmo di un numero che si avvicina a 0 è un numero infinitamente grande e negativa da un punto di vista sempre con il segno meno davanti quindi diventa con il segno più con il segno meno scusatemi davanti un più meno per meno per più e pago una penalty quindi esattamente lo stesso discorso che abbiamo fatto pari pari nel caso di codifiche numeriche cambia un po' la rappresentazione algebrica però questa è una funzione di costo di tipo log error del tutto analoga a quella che abbiamo introdotto e la differenza è che se voi l'andate a vedere lì avevate un qualcosa che era meno y log di sigma e poi avevate meno 1 meno y log di sigma ma esattamente di quel tipo ovviamente questo tipo di di funzione di costo la potete mediare su tutti i più grandi punti del vostro dataset di addestramento e quello che ottenete è la cosiddetta funzione di costo ad entropia incrociata di tipo categorico categorical cross entropy che è una funzione di costo che si trova parecchio insomma in giro in diverse applicazioni e come abbiamo appena detto di fatto questo è il log error che abbiamo trovato per le etichette numeriche non c'è nulla di diverso quindi fondamentalmente utilizzare delle etichette categoriche non cambia la sostanza degli approcci che abbiamo utilizzato quindi la funzione di costo che potete costruire con ad esempio una regressione logistica o con un S-Web in questo caso partendo dalle etichette categorie che vi porta poi a utilizzare gli stessi strumenti a meno di minime variazioni con appunto la costruzione di una funzione di costo leggermente formalmente diversa per tener conto ovviamente del fatto che abbiamo un vettore anziché un singolo numero però fondamentalmente quello che c'è dietro nei modelli rimane lo stesso sta qui dentro è questo prodotto scalare xp trasposto per v2 ok per il momento diciamo lasciamo da parte il discorso etichette categorie che ci torneremo sopra in un paio di occasioni avremo modo un po' di dire qualcosa ok adesso invece facciamo un piccolo passo in avanti perché cominciamo a parlare di quelle che sono le metriche di qualità della classificazione se ricordate quando abbiamo introdotto il modello di regressione lineare ci siamo anche posti il problema di come valutarlo quindi abbiamo introdotto per esempio l'errore quadratico medio abbiamo introdotto la la la deviazione media assoluta come diciamo metriche che ci permettono di valutare quanto un modello di regressione lineare è in grado di effettuare un fitting di un insieme di punti e qui diciamo l'obiettivo è lo stesso abbiamo costruito un classificatore come abbiamo detto e la prima cosa quindi vogliamo cercare di capire quali sono le prestazioni di questo classificatore la prima cosa che facciamo è cerchiamo di rispondere alla domanda ok abbiamo questo modello un modello in cui io ho congelato in qualche modo insieme dei pesi il fatto che sia stato congelato lo vedo dal fatto che qui ho messo un asterisco per dire quello è l'insieme dei pesi che è il risultato della mia minimizzazione minimizzazione della funzione di costo di quel modello che è una funzione di costo che può essere una cross-centro una cross-centro categorica una soft max un percettrone un modello percettrone può essere una funzione di costo di questo tipo con un modello svm eccetera il risultato quello che ottenete è un modello matematico in cui voi potete prendere un qualunque nuovo valore di x e fissato quell'insieme di pesi la risposta che vi dà quel modello è questa cioè x trasposto per w la potete scrivere come w0 più x1 per w1 più x2 per w2 dove i vari pesi w0 w1 w2 fino a wn hanno sopra questo asterisco per dire quello è il risultato della minimizzazione dopodiché questo è il vostro modello lineare che cosa fanno tutti quei classificatori regressione logistica percettrone svm ok cosa fanno beh prendono il risultato di di questo di questa combinazione lineare no e lo fanno passare ad esempio prendiamo la regressione logistica attraverso la sigmoide e vi restituiscono un valore no un valore tra 0 e 1 a quel punto voi mettete un valore di soglia ad esempio 0,5 e dite tutto quello che sta sopra 0,5 è la classe 1 tutto quello che sta sotto 0,5 è classe 0 però fondamentalmente il modello è questo poi c'è il discorso della soglia ma quello diciamo lo lo possiamo tranquillamente per il momento lasciare da parte nel senso che laddove io mi vale questa significa che io sto se invece ovviamente se questo è un numero diciamo sopra soglia sono in una classe sotto soglia in un'altra classe se supponiamo diciamo qui il discorso che non vi ho la cosa importante che non vi ho detto è che in realtà qui stiamo partendo dall'ipotesi per fare questo discorso che le etichette siano più 1 e meno 1 ok quindi diciamo che anziché avere la sigmoide se parliamo di regressione logistica stiamo lavorando con la tangente iperbolica ok quindi tra 1 e meno 1 laddove il modello è uguale a 0 che cosa significa chiaramente che sono sul confine decigenare ok se avessi lavorato con la regressione logistica con etichette 1 e 0 avrei dovuto imporre chiaramente anziché 1 e 0 1 e 0 5 qua come soglia allora quindi l'etichetta di default abbiamo detto più o meno 1 a questo punto questo è l'equazione del che definisce l'iperpiano che è il nostro confine decisionale e quello che noi facciamo è andare a prendere in questo caso il segno di quel modello come quella che è la nostra risposta la nostra la risposta che ci dà il nostro classificatore cioè ci dà una risposta positiva classe 1 ci dà una risposta negativa classe meno 1 ok è quello che abbiamo fatto finora quando abbiamo costruito tutti i modelli di cui abbiamo parlato ok implicitamente quindi di fatto abbiamo addestrato il nostro modello e se l'etichetta è più o meno 1 la funzione segna è quella che ci restituisce il il nostro la risposta del nostro classificatore quindi giusto per capirci se ci muoviamo in uno spazio a due dimensioni quindi abbiamo due feature di input x1 e x2 e questa è l'equazione dell'iperpianco in questo caso è una retta che definisce il nostro confine decisionale questi sono i pesi che abbiamo trovato col minimizzatore chiaramente avremmo avuto infinite alternative no che abbiamo da qui abbiamo selezionato quella ottimale dal punto di vista di che cosa della funzione di costo può essere la cross-entropi la softmax la cross-entropi categoria quello che vuol dire quindi che cosa succede succede che qui vediamo l'opera il classificatore se ho un punto che ha coordinate x1' x2' quindi sta qui e chiedo al classificatore a quale classe appartiene questo punto incognito lui lo mette in questa formula si calcola questa combinazione lineare quanto vale il segno di questa combinazione lineare lo porta a concludere è meno 1 perché sta in effetti da questa parte del classificatore avessi preso un punto che stava invece qui chiaramente la risposta sarebbe stata più 1 ecco come funzionano poi alla fine abbiamo chiuso in qualche modo il cerchio un po' di cose che abbiamo detto spesso e volentieri in queste tipologie di classificatore poi anche in altri è molto utile cercare di quantificare il livello di fiducia che un classificatore ha nella sua risposta se torniamo un attimo all'esempio precedente è intuitivo che fissato questo classificatore se io ho un punto che sta qui in questo punto arancione classificatore intuitivamente voi quello che potete dire ma non siamo molto sicuri con questo modello che questo punto sia di classe meno 1 perché basta una piccola perturbazione quel punto salta di là basta che io cambi o leggermente classificatore e quello salta e viene classificato da un altro classificatore molto simile a questo come appartenente alla classe più 1 anziché meno 1 oppure basta un po' di rumore per cui in realtà questo finisce qua ma era di qua e effettivamente cambia la classificazione questo ci dice che cosa ci dice che da un punto di vista geometrico ecco finiamo il discorso prendiamo la parte diciamo la controparte di questo ragionamento viceversa un punto che sta qui è un punto di cui il nostro classificatore può essere abbastanza ragionevolmente sicuro perché intuitivamente quindi il rumore ce ne vuole per portarlo dall'altra parte oppure di perturbazioni del confine decisionale per avere un altro classificatore che deve essere molto diverso da quello che abbiamo perché quello sia classificato in altro modo allora questo ci dice che cosa che una misura del livello di fiducia che il classificatore può avere nel valutare la sua classificazione quale può essere la distanza del punto dal confine di decisione cioè tanto più il punto è vicino al confine di decisione tantomeno il classificatore è sicuro di quello che sta dicendo cioè vi dice più uno però diciamo in qualche modo è ragionevole dire che è meno tra virgolette convinto di quello che sta facendo tant'è che se siamo esattamente sul confine decisionale il classificatore non sa prendere una decisione invece quanto più il punto si trova lontano dove quel concetto di vicino è lontano è proprio un concetto geometrico dal confine decisionale allora tanto più il classificatore sarà in qualche modo fiducioso del fatto che la risposta che sta dando rispetto a quello che il suo modello la sua idea di mondo è di separare queste due nuvole di punti in questo modo e rispetto a questa sua idea di mondo lui dice ok se il punto che mi stai facendo vedere è molto lontano dal mio confine decisionale io sono più sicuro del fatto della cosa che ti sto dicendo più uno oppure meno uno e questo è spesso importante perché voi dovete considerare che il machine learning si ha come scopo appunto classificare fare predizioni eccetera però queste classificazioni queste predizioni in generale vengono utilizzate per prendere delle decisioni a valle di questo sistema automatico e sapere quanto il sistema che ha preso che ha fatto quella predizione è più o meno fiducioso confident in inglese si dice di quello che sta facendo aiuta a prendere delle decisioni più informatiche capite bene no allora come facciamo a tradurre tutto questo in qualcosa di quantificabile numericamente andiamo a costruire proprio un quello che viene chiamato un confidence scoring cioè un punteggio di livello di confidenza di livello di confidenza del classificatore misurando proprio la distanza del punto dal confine decisionale ok e come facciamo a misurare la distanza del punto dal confine decisionale facciamo in questo modo allora noi andiamo a prendere andiamo un attimo forse vale la pena che condivida la lavagna allora noi abbiamo questo è il nostro confine decisionale che quindi è caratterizzato dall'equazione dell'iperpiano e questa sì l'abbiamo già visto sì sì l'abbiamo già incontrata fondamentalmente l'abbiamo già vista quando abbiamo fatto il concetto di margini l'introduzione dell'esquembre eccetera però torniamo un attimo brevemente su questo perché sono un paio di punti che vanno evidenziati allora qui abbiamo x trasposto per v doppio uguale a più questo è il nostro confine decisionale allora questo è il vettore omega il vettore omega che vi ricordo è il vettore delle feature touching weight che abbiamo dimostrato ieri essere ortogonale a quel confine decisionale ok qui abbiamo un punto chiamiamo xp' ok che sta sul confine decisionale poi abbiamo una traslazione di questo confine decisionale che è definita da un altro iperpiano possiamo chiamare interseca qui il vettore normale nel punto xp' ok anzi xp scusatemi perché xp' era quell'altro e quindi ci abbiamo qui xp' x' scusatemi qui lasciamo l'equazione generica come b più x trasposto per u doppio uguale beta ok lascio il generico x trasposto che poi diventa qui xp' e qui xp lo specializziamo dopo ok allora cosa possiamo scrivere di questi due punti xp' quello che possiamo fare è andare a prendere il vettore differenza xp' meno xp' trasposto per ω e questo lo abbiamo visto lo abbiamo visto ieri siccome ω è ortogonale al confine di decisione xp meno xp' sono due punti che stanno su questa direzione definita appunto dal vettore ω quindi il prodotto scalare rispetto al vettore ω sono due vettori paralleli e semplicemente il prodotto dei moduli delle lunghezze di quei vettori quindi è xp meno xp' norma L2 moltiplicato per la norma di ω ok ma la norma di xp meno xp' che cos'è? è questa distanza di che vi ho appena evidenziato ok quindi questo lo posso scrivere come d per la norma di ω allo stesso tempo quello che è vero è che possiamo utilizzare le due equazioni degli iperpiani e scrivere β meno 0 facciamo questa meno questa β meno 0 è uguale a che cosa? a va lo scrivo tutto b più xp trasposto per ω meno b più scusatemi xp' primo trasposto anzi no qui non c'è il soprassegnato perché chiaramente qui non c'è il cerchitto sopra perché siamo tornati alla versione senza l'uno perché abbiamo esplicitato il termine di bias vi ricordate il discorso ok quindi xp trasposto primo per ω prodotto scalare questo chiaramente b e b si elide risultato posso raccogliere fattore comune sfruttando la proprietà distributiva del prodotto scalare raccolgo fattore comune ω ottengo questo a questo punto confrontando la a e la b cosa abbiamo vediamo che questo e questo sono uguali quindi quello che possiamo concludere è che d per la norma tipo L2 di ω è uguale a β ovvero d che la distanza che stiamo cercando è β diviso ω norma L2 ok quindi rimane dimostrato che rispetto al confine decisionale un qualunque punto xp ha una distanza dal confine decisionale che è pari a β tratto norma del vettore ma β sappiamo anche calcolarlo perché una volta che abbiamo i nostri pesi è b più xp trasposto per ω in questo abbiamo tutto quindi nel momento in cui abbiamo un punto e abbiamo il modello di classificatore noi sappiamo calcolare la distanza geometrica di quel punto dal confine decisionale è esattamente questa ultima formula che abbiamo abbiamo detto qui abbiamo tutto perché abbiamo b abbiamo ω e quindi e abbiamo x quindi la riusciamo a calcolare ci siamo? ok a questo punto questo è un numero che fissato il vettore dei pesi fissato b a seconda di dove si trova xp sarà un numero più grande o più piccolo ora cosa diciamo manca un pezzettino in tutto questo perché già questo è quello che volevamo ottenere nel senso che se d è più alto vuol dire che il nostro classificatore è più confidente è più fiducioso del fatto che ci sta dicendo classe 1 se d è molto negativo è più fiducioso del fatto che ci sta dicendo classe meno 1 se è vicino al confine decisionale lo sarà di meno e quel valore di d sarà più ridotto ora diciamo il fatto di dire 5 8 meno 2 meno 7 ci dice poco forse diciamo solamente quando siamo vicini allo 0 potremmo dire siamo poco fiduciosi del fatto che che quel numero sia effettivamente significativo quello che si fa quindi tipicamente che cos'è è riportare questi valori tutti in un range che è un range 0-1 di modo che se siamo vicini allo 0 allora possiamo dire che il classificatore è poco a un livello di confidenza basso sulla predizione che sta facendo se siamo vicini all'1 invece è fiducioso quindi diciamo significa che il punto è lontano dal confine decisionale come facciamo a mappare un qualunque valore numerico in un intervallo 0-1 mi viene in mente pensate a cosa abbiamo fatto più e più volte in questo argomento dei classificatori lineari no perché sopraendo non ce la fate dovete utilizzare una funzione dovete far passare questo valore di d in una funzione ed è una funzione no è proprio una funzione non lineare che prende un qualunque argomento valore reale e vi restituisce un numero tra 0 e 1 è la sigmoide la sigmoide risponde esattamente a questa esigenza ed è questa cioè nel momento in cui allora questo è quello che abbiamo appena derivato ok questa è la formula che abbiamo appena ricavato giusto? a questo punto vi ricordo questo è il fattore di bias questi sono i pesi feature touching e il livello di confidence lo otteniamo semplicemente prendendo quel valore di e facendolo passare attraverso una sigma una funzione sigmoidale vi ricordo che questa funzione sigmoidale prende a come dominio meno infinito più infinito e come codominio 0 quindi vi è in grado di comprimere tutti i valori della retta dei reali in un intervallo 0 quindi quanto più d è elevato tanto più subito va a 1 quanto più d è molto negativo va a 0 rapidamente dov'è che la sigmoide vale vale 0,5 esattamente quando la distanza è 0 sigma di 0 vale 0,5 allora questo ci dice che cosa? che quando siamo molto lontani dal confine decisionale la risposta sigma di quella distanza è 1 quando siamo molto vicini alla scusatemi no ho detto una cosa inesatta ti ho portato fuori fuori strada nel senso che quando siamo nel confine decisionale in realtà vale 0 esattamente la risposta mentre man mano che mi allontano vale via via 1 cioè cresce con in questo modo cioè se voi andate a prendere andiamo un attimo sulla sigmoide adesso facciamo un po' un passo indietro eccola qua e vedete che quando x vale 0 questa vale 0,5 ma funziona anche quando vabbè la distanza non è una norma quindi è tanto difficile un attimo sì no ma quella può essere anche una distanza consegno quella è una distanza consegno adesso ritorniamo su allora no stavo guardando una cosa stavo guardando la sigmoide per cui quando ci andiamo a mettere dentro vedete quando il valore è molto negativo lui ha 0 quando è esattamente nello 0 quindi siamo sul confine decisionale lui ha 0,5 quindi in realtà era giusto la prima versione che avevo detto scusatemi vi ho portato io fuori strada ho fatto un po' di confusione x uguale a 0 sigma vale 0,5 quando sono molto questo come la leggiamo lì abbiamo due classi se la distanza è molto positiva io sono convinto no allora questo lo posso interpretare direttamente come se fossero dei valori di probabilità sono numeri tra 0 e 1 vuol dire che sono convinto al 100% che la risposta è classe più 1 quando sono distanze molto negative sono convinto allo 0% diciamo che è classe più 1 cioè quasi 100% di classe meno 1 quando sono sul confine decisionale 50 e 50 le due risposte hanno lo stesso valore è questo che stiamo che stiamo dicendo ok torniamo alla nostra ecco quindi l'aspetto interessante è che in questo modo riesco a mappare tutti i valori della distanza tra 0 e 1 e li posso interpretare come una probabilità di fatto e quindi dire il mio classificatore è sicuro al 90% che la risposta sia più 1 che significa che al 10% è sicuro che sia meno 1 in realtà quindi diciamo avete una misura che poi potete applicare in qualche processo decisionale a valle bene e questa è una distanza consegno ok ok ok allora come facciamo a valutare quindi abbiamo parlato di distanza per costruire questo confidence scoring e adesso vediamo come facciamo a valutare la qualità di un modello che abbiamo appena addestrato allora il modo più immediato è avete un classificatore una metrica che ci può venire tutto in mente e subito andare a vedere l'accuratezza del classificatore vi faccio vedere l'ho addestrato su mille punti andiamo a vedere quei mille punti quanti ne ha classificati correttamente io conosco esattamente le etichette d'altra parte il training l'ho fatto proprio l'ho costruito in questo modo ho costruito il mio classificatore in realtà non l'ho addestrato direttamente sulla funzione che ci restituisce 1-0 a seconda che lui abbia indovinato l'etichetta perché non l'abbiamo fatto era il primo tentativo che abbiamo fatto se vi ricordate era quello che produceva quel profilo di una funzione di costo a scalino con ampie zone nulle eccetera quindi in realtà noi abbiamo poi costruito delle funzioni di costo che erano surrogato di Quilk per motivi di ottimizzazione però adesso per andare a vedere quanto siamo stati bravi possiamo perfettamente utilizzare una funzione di quel tipo cioè una funzione che dice questo valeva 1 quanto hai classificato 1 ok corretto hai classificato 0 hai commesso un errore fine questo non a questo punto del nostro del nostro flusso di lavoro non inficcia nulla e quindi possiamo tranquillamente andare a prendere la predizione del nostro modello questa è una predizione lo vediamo dal fatto che solitamente viene riportato appunto questo questo simbolino insomma il circonflesso sopra l'accento circonflesso per indicare che è una predizione del mio modello che viene fatta esattamente come abbiamo detto prima e una volta che abbiamo quella predizione l'andiamo a confrontare con che cosa il mio y hat con il cappellino lo vado a confrontare con il mio y che è la verità cioè io avevo quel dataset e lì so le etichette e a questo punto vado a fare che cosa vado a calcolare il numero di quelle che vengono chiamate in inglese misclassification cioè le classificazioni errate tramite questa funzione questa è una funzione identità che semplicemente vi restituisce sì è una funzione sì praticamente è una funzione che vi resti esatto che è una funzione cosiddetta identità che restituisce adesso vi dico come è stotturata i di yp hat virgola yp è uguale a 1 nel caso in cui yp è diverso da yp hat è diverso da yp ed è 0 se invece sono uguali cioè è una funzione che vale 0 se la vostra predizione la classificazione del vostro modello coincide con la verità ok perché yp è la vostra è il data l'etichetta del data del punto del data del testamento vi restituisce uno se sono diversi sì y cappello è diverso da yp qual è il cappello è la predizione quindi yp è la verità yp con il cappello è la predizione del vostro classificatore che avete appena addestrato esatto quando è diverso dall'effettivo ho fatto un errore e allora vado a contare il numero di errori semplicemente quindi vado a incrementare di 1 il numero di errori supponiamo di avere un dataset con 100 campioni vado a contare il numero di errori ne ho sbagliati 8 questo significa un'accuratezza del 92% cioè il 92 su 100 ne ho indovinato questo è quello che faremo cioè poi andiamo a introdurre di fatto l'accuratezza a partire dal numero di misclassification come la costruiamo in questo modo come 1 meno che cosa il numero di misclassification diviso per il numero totale dei campioni e facciamo il complemento a 1 e questa è l'accuratezza esattamente cioè contro il numero di errori riprendiamo l'esempio supponiamo di avere un dataset con 200 campioni di questi 200 campioni noi ne andiamo a classificare correttamente supponiamo 150 ok 150 vuol dire che ne sbagliamo 50 vuol dire che il numero di misclassification è 50 50 su 200 vi dice che ovviamente sta 5 su 20 cioè un quarto 1 meno un quarto 3 quarti 75% è la cortezza del vostro classificatore allora qui si entra in un questa è una domanda diciamo difficile dire qual è un classificatore buono perché non c'è una regola che vale per tutti dipende che cosa stiamo classificando ci sono problemi per cui va benissimo un'accuratezza del 75% problemi e applicazioni per i quali il 75% non è assolutamente sufficiente è chiaro che più alta è meglio è sempre diciamo che poi soprattutto è una gara nel senso che in continuazione vengono proposti modelli che cercano di migliorare lo stato dell'arte e lo stato diciamo di quelle che sono le accurateze tant'è che ci sono proprio delle gare vere e proprie nel senso che come vi dicevo anche all'inizio del corso molto spesso vengono rilasciati dei dataset pubblici su cui gruppi di ricerca di università di mezzo mondo o anche di industria di mezzo mondo si cimentano per provare a dire ok ho ottenuto su questo benchmark queste performance di classificazione esattamente propongono nuovi modelli e quello diciamo è un meccanismo estremamente da questo punto di vista ha portato per esempio con l'introduzione quando sono stati introdotti in ambito computer vision le reti neurali la pubblicazione di dataset di quel tipo ha permesso di fare tantissime proposte in nuovi modelli quindi questa gara diciamo poi ha prodotto un incremento dell'accuratezza media di quei modelli dei nuovi modelli proposti rispetto a quelli di cui si è partito che diciamo ha portato ovviamente a delle prestazioni che sono per alcune cose sopra il 90% vicino al 100% che sono addirittura proprio sulla classificazione delle immagini si è visto che sono superiori alle prestazioni dell'essere umano nel senso che è stato fatto provare ad alcune persone andare a riconoscere quegli oggetti perché non sono immediatamente tu devi assegnare delle categorie anche quello per esempio assolutamente poi quando si entra in un dominio come appunto quello dove ci sono delle conoscenze specifiche lì ancora ma vale lo stesso discorso ma anche cose più diciamo elementari cioè classificare se in un'immagine che cosa rappresenta un'auto oppure un motoscafo oppure un orso eccetera l'essere umano qualche volta cioè se le immagini non hanno un'alta risoluzione magari capita di sbagliarlo ovviamente e si è visto che le reti neurali quelle d'ultima generazione riuscivano a superare a un certo punto questo è avvenuto circa 5-6 anni fa superare le prestazioni dell'essere umano medio quindi questo di cui si parla quando si parla di capacità super umane dell'intelligenza artificiale quando in certi task di riconoscimento riescono a fare meglio di quello che è l'essere umano medio oppure meglio dello specialista medio appunto per esempio in ambito medico quando si parla di supporto alla diagnosi medica quindi per esempio nell'imaging quindi raggi X risonanza eccetera perché perché sono sistemi che sono stati addestrati a vedere migliaia migliaia di esempi quindi nessun diciamo difficilmente una persona nella sua vita professionale riuscirà a vedere tutti quegli esempi e a memorizzare quindi il vantaggio è quello lavorare su ed è ovviamente un assunto abbastanza semplice però il fatto che ci sia arrivati in questi anni era tutt'altro che banale a costruire dei sistemi che avessero quelle prestazioni qui vi faccio notare una cosa che vi dicevo prima che noi non abbiamo minimizzato il numero di misclassification cioè se noi andiamo questi sono dei plot del processo di ottimizzazione quelli che abbiamo chiamato history plot a destra della loss function in questo caso la loss function è una soft max e a sinistra invece abbiamo dei plot in cui sono state andate a contare si sono contate scusate il numero di errori di classificazione per ogni iterazione cioè cosa vuol dire che ad ogni iterazione a destra abbiamo un valore della funzione di costo ci sono tre run sono tre curve diverse perché sono tre punti di inizializzazione diversa che ne sono in discesa del gradiente quindi le tre curve di destra corrispondono a tre punti di inizializzazione diversa e vedete tre minimizzazioni ad ogni iterazione andavamo a vedere siamo andati a vedere qual è il valore della funzione di costo per ognuno dei tre run all'inizio è più alta poi man mano vedete scende e poi converge ha trovato il suo minimo nel grafico di sinistra quello che è stato fatto è andare a vedere per ogni stessa iterazione dall'inizio alla fine progressivamente nel processo di ottimizzazione andare a vedere quanti errori venivano fatti man mano che si ottimizzava il modello cioè se io mi fermo a dieci iterazioni ho un certo modello giusto? quanti errori fa quel modello sul dataset di addestramento ma sulla riga blu ne faceva 30 sulla riga araccione ne faceva 38 sulla riga verde un altro punto di inizializzazione ne faceva 52 e poi sono andati avanti con 100 200 quindi questo è il tasso di errore al variare delle iterazioni durante il processo di ottimizzazione e la cosa interessante da notare del motivo per cui appunto ve l'ho riportato in questa slide è che il numero di errori vedete ha un andamento molto più a scalino chiaramente ma perché è di natura discreta ovviamente quindi questo rende conto del fatto che ci sono questi scalini prima cosa seconda cosa vedete che invece qua la funzione di cost che andiamo a minimizzare è molto più più smooth perché appunto l'abbiamo costruita così è più liscia ok la cosa l'altra cosa che possiamo notare è che non c'è proprio una corrispondenza uno a uno tra queste curve cioè ovviamente la curva verde che vi dice il numero di errori che fate ha una sua corrispondenza nella curva verde del costo softmax ma non c'è proprio una corrispondenza immediata tant'è che addirittura il numero di errori può anche risalire in certi punti mentre di là vedete scende più docilmente anche se anche quello non è detta che lo faccia l'abbiamo detto ci possono essere oscillazioni anche in quelle curve di discesa della funzione di costo ma questo è normale nel senso che noi quello che andiamo a ottimizzare non è mica il numero di errori di classificazione noi andiamo a ottimizzare questo e lo facciamo nella speranza che ovviamente questo poi sia corrispondentemente basso ok però non sono immediatamente sovrapponibili chiaramente sono due cose diverse esattamente esattamente esattamente esattamente esattamente e quello che si fa infatti poi alla fine una volta che abbiamo adestrato il modello siamo arrivati qua e si va a vedere quanti errori facciamo e quanti errori abbiamo fatto su sto dataset e può essere come dicevi tu correttamente che non ci sia una corrispondenza tra il minimo che abbiamo trovato e il minimo di errori che facciamo può essere che il minimo di errori di misclassification magari lo teniamo se ci fermiamo un po' prima quindi ecco allora questo è un altro punto noi quello che sappiamo e che abbiamo a disposizione è solo il dataset noi facciamo tutto questo nella speranza che questo poi generalizzi la capacità di un modello di machine learning di generalizzare è qualcosa di cui ancora non abbiamo parlato molto in dettaglio ma di cui parleremo ed è proprio questo cioè dire ok io la mia idea del mondo è in questo dataset su questa idea del mondo ho addestrato il classificatore quindi lui in realtà si è costruito un'idea del mondo nella speranza che ovviamente il mondo reale corrisponde a questo se questo non è così è ovvio che lì gli errori sono di più e tipicamente avviene così infatti però questo è tutto quello che possiamo riuscire a fare la capacità di generalizzazione è proprio questo la capacità di dire ho visto una serie di esempi se me li fai vedere anche un po' diversi non è che indovino a caso ma continuo a dare delle risposte ragionevoli nel momento in cui sono molto diversi da quelli su cui sono stato addestrato a quel punto sbaglio di più è certo è certo lo shift della distribuzione è un esempio di perdita di capacità di generalizzazione dei modelli però diciamo senza andare troppo in avanti per il momento quello che sappiamo è abbiamo il nostro dataset lì sopra possiamo fare esperimenti controllati e possiamo dire sul dataset dell'estramento quanti ne sbagliamo e vogliamo minimizzare quello nella speranza di minimizzare anche un domani gli errori che facciamo nel momento in cui il modello va in produzione che è un'assunzione ragionevole poi se ci pensate ok qui invece discutiamo di un altro problema che è il problema delle classi sbilanciate che è un altro problema che si porta indietro i modelli di apprendimento automatico per farvi capire di cosa stiamo parlando questo è un problema che tra l'altro c'è in diverse applicazioni diciamo scenari applicativi anche abbastanza abbastanza delicati come per esempio le diagnosi mediche di cui parlavamo prima molti dataset in ambito biomedico sono fortemente sbilanciati pensate per semplificare avete un dataset deve classificare in base a che ne so un'immagine in base a immagine clinica in base a delle delle analisi di altro tipo deve classificare un paziente sano oppure malato affetto da una determinata malattia è chiaro che io se vado a raccogliere dei dati avrò grazie Dio molti più casi di persone sane di quelle che sono malattie quindi io mi ritrovo con un dataset di addestramento in cui ad esempio ho la maggior parte dei punti relativi a una classe e pochi punti relativi a la cosa succede quando noi andiamo ad addestrare un modello su un dataset di questo tipo e questo è il problema di cui adesso vi voglio parlare un altro esempio è quello delle transazioni per esempio classificatori che in automatico prendono le transazioni delle carte di credito e cercano di capire se la transazione che è avvenuta è fraudolenta cioè sfrutto di un di un fraude oppure no quindi nel momento in cui voi fate una transazione con la vostra carta di credito vi viene fatta passare attraverso un modello di machine learning che alza in qualche modo un eventuale bandiera di allarme se ritiene che quella transazione in qualche modo è sospetta per cui può essere che qualcuno da qualche altra parte del mondo va rubato la carta di credito il codice e li sta usando a vostra insaputa ora è chiaro che anche lì per fortuna sono molti meno i casi di transazioni non legittime quelle che invece sono chiaramente legittime quindi di nuovo un esempio di data si è sbilanciato però cosa succede se noi facciamo pinta di non cioè ignoriamo questo fatto e procediamo come abbiamo visto finora normalmente allora sponiamo giusto per capirci che una classe rappresenta il 95% dei punti quindi è uno sbilanciamento molto pronunciato però qualche applicazione ci può arrivare comunque giusto per farvi capire che cosa che cosa intica questo tipo di ragionamento allora un 95% di punti di una classe 5% dell'altra io a questo punto posso costruire un classificatore del tutto naif ingenuo che fa questa semplice operazione dice ok assegno di default la classe maggioritaria cioè qualunque punto mi arriva in input io dico classe 1 supponiamo che la classe 1 sia quella più rappresentata esattamente esattamente e lui cosa fa si assilga tutti come quelli sani lui che cosa ottiene ottiene un'accuratezza del 95% perché su quei 100 campioni 95 li azzecca e 5 no allora possiamo concludere che questo classificatore così diciamo molto banale è particolarmente accurato ed è vero è ineccepibile da un punto di vista della metrica di accuratezza però la domanda che ci facciamo è quello che vogliamo cioè noi vogliamo sbagliare quel 5% di persone che non sono sane gli vogliamo dire siete sane il sistema ha detto questo vogliamo sbagliare quel 5% di transazioni di carte di credito di dire è tutto a posto quando invece sono delle frodi è ovvio che non è questo che vogliamo e allora dobbiamo disporre di qualche strumento per cercare di contrastare questo tipo di meccanismo il problema del bilanciamento nei dataset è un problema cruciale ci sono diverse tecniche adesso non abbiamo tempo di entrare in tutte però una che possiamo sicuramente mettere in campo è provare a costruire una metrica che ci renda un pochino più immuni da questo tipo di discorso cioè che valuti in maniera un po' più oggettiva il discorso accuratezza quando le classi sono sbilanciate cioè che tenga conto del fatto che ok c'è una classe ma questa è sottorappresentata e allora per introdurre questo cioè per risolvere questo tipo di problema si non si usa l'accuratezza appunto standard si introduce il concetto di quella che è l'accuratezza bilanciata ok l'accuratezza bilanciata è niente più che questa cosa si va a prendere l'accuratezza su ogni classe e poi si fa la miglia ok quindi se io faccio una cosa di questo tipo allora quello che possiamo è andare a formalizzare questo introducendo un insieme che chiamiamo omega più 1 e un insieme che chiamiamo omega meno 1 che è semplicemente l'insieme degli indici dei punti le cui etichette sono più 1 e meno 1 quindi per intenderci se questo è quello della cassa maggioritaria la sua cardinalità sarà 95% di tutto l'insieme dopo di che vado a contare il numero di errori che ho commesso sulla classe più 1 e quindi vado a fare la sommatoria dove l'indice p varia su tutti gli indici omega più 1 e vado a contare il numero di errori la stessa cosa faccio per la classe meno 1 quindi queste due notazioni ci dicono semplicemente il numero di errori che ho fatto sugli elementi della classe 1 e sugli elementi della classe meno ok facciamo quindi sto semplicemente suddividendo i punti sì o il viceversa dipende a quali sono esattamente esattamente nel primo caso se la classe più 1 è quella più popolosa ho chiaramente 5 errori se sono 100 punti in realtà lo riportiamo in percentuale quindi nel primo caso è 95% nel caso 5% e questa è l'accuratezza che chiamo a più 1 e questa la chiamo a meno 1 quindi uno vale 0,95 l'altra 0,5 a questo punto quello che mi posso permettermi fare è andare a costruire la media tra queste due e la media tra questi due è un qualcosa di molto più significativo perché è un numero sempre compreso tra 0 e 1 che vale esattamente 0,5 nell'esempio 5% 95% che abbiamo visto prima cioè se io prendo quel classificatore un po' sciocco che andava a dire sempre 1 tutti sani e che aveva il 95% di accuratezza e vado a calcolare l'accuratezza bilanciata se voi fate 0,95 più 0,05 diviso 2 ottenete 50% e qui vedete che è un'altra metrica che vi dice che cosa attenzione che da un punto di vista dell'accuratezza bilanciata il discorso cambia cioè quel classificatore particolarmente sciocco è un classificatore che non ci dice nulla perché un classificatore che vi dà un'accuratezza del 50% è come tirare una monetina e decidere a caso voi non ragionate adesso non considerate per esempio il caso dello sbilanciamento dei dataset se voi avete un dataset bilanciato e il classificatore vi dà un errore del 50% è il peggiore classificatore che potete costruire perché è esattamente uguale alla prestazione che avreste se indovinate a caso con una monetina le due classi quindi il fatto che voi abbiate 0,5 in questo caso vi dice che dal punto di vista dell'accuratezza bilanciata c'è qualcosa che non funziona e il motivo è che avete troppi pochi punti di una classe e quindi non li volete sbagliare ok quindi questa è un'altra metrica è una metrica che può essere introdotta per dire ok se il dataset è sbilanciato andiamoci con un pochino i piedi di piombo ecco muoviamoci con cautela e proviamo a vedere cosa succede all'accuratezza ma anche all'accuratezza bilanciata ok in realtà c'è un errore numerico perché non può venire 0,5 nell'esempio 95,5 cioè verrebbe 0,5 solamente se l'accuratezza fosse 0 da una parte e 100% dall'altra perché a quel punto sarebbe 50% cioè io sbaglio tutti quelli di una classe e metto corretti tutti quelli dell'altra che no che è quello che abbiamo fatto perché 5% 95% si riferisce alla suddivisione del dataset no no è giusto è corretto 95% 5% non si riferisce al fatto che non sono le accuratezze A più 1 e A meno 1 è semplicemente la suddivisione del dataset come in 5% dei campioni sono di una classe 95% di un'altra e io costruisco il classificatore poco intelligente che mi dice sempre più 1 quindi mi dice 100% l'accuratezza A più 1 e mi sbaglia il 100% della della curatezza A meno 1 quindi è 0 quindi A esatto esatto quindi A più 1 vale 1 e A meno 1 vale 0 e quindi il risultato è 0,5 quindi corretto benissimo bene allora andiamo un po' avanti vediamo cosa c'è dopo ok ci sono ci sono ulteriori strumenti che vengono utilizzati e che è bene imparare a conoscere perché quando si costruisce un classificatore cercare di fare un'analisi appunto che non è solamente la accuratezza che è un po' un numero di sintesi di quelle che sono le prestazioni del classificatore ma ci sono altri strumenti che possono essere utili per capire cosa fa effettivamente come distingue le due classi e uno di questi strumenti è la cosiddetta matrice di confusione ora matrice di confusione è una matrice in cui a partire dalla quale voi potete poi derivare delle metri più ulteriori oltre all'accurazione ed è una matrice in cui voi andate a organizzare delle informazioni su quelle che sono le prestazioni del vostro classificatore andando a mettere ad esempio anche qui diciamo può capitare che vengano invertite le righe con le colonne ma il senso del discorso chiaramente non cambia però diciamo per convenzione solitamente si associa alle righe quella che è l'etichetta effettiva ok quindi l'etichetta del campione del vostro e sugli indici di colonna invece ci associate quelle che sono le etichette che il vostro classificatore ha predetto ok quindi le prestazioni del vostro classificatore quindi per intenderci a che cosa rappresenta all'incrocio tra la riga 1 e la colonna 1 un numero che vi dice delle etichette più 1 quante il vostro classificatore ne ha correttamente previste b rappresenta invece il numero di predizioni di etichetta più 1 effettiva che il vostro classificatore invece ha classificato come meno 1 c rappresenta il numero di etichette meno 1 che il vostro classificatore ha scambiato invece come più 1 e di quelle che lui ha correttamente classificato come meno 1 essendo meno 1 se fosse uno strumento diagnostico per esempio positivo o negativo ok quindi un qualcosa che vi dice siete positivi a un certo tipo di test sulla base dell'analisi del sangue eccetera a sarebbero i veri positivi b sarebbero sarebbero dei no sarebbero dei dei veri sarebbero dei positivi che voi avete interpretato come negativo ok quindi sono dei falsi negativi c sarebbero dei falsi positivi perché il vostro classificatore vi dice positivo quando invece è negativo e d sono i veri negativi a partire da questi valori voi potete e questi ce li avete tutti perché avete sotto controllo il vostro dataset voi nel vostro training set sapete tutto avete costruito il classificatore potete costruire la matrice di confusione questo è quello che si fa comunemente quando si costruisce un modello di classificazione la matrice di confusione viene costruita e vi dà delle indicazioni molto chiare su alcune metriche ulteriori perché da questa potete anzitutto ricavare l'accuratezza che è quella che noi abbiamo definito prima a partire dal numero di errori perché lungo la diagonale io ho che cosa a e d che sono le previsioni che ha fatto correttamente il mio classificatore quindi quelle che matchano e quindi a più d è il numero di risposte corrette che ha dato se lo rapporto ad a più b più c più d che sono tutti i possibili casi ottengo il numero di previsioni corrette rispetto ai campioni che erano presenti nel dataset e dell'accuratezza poi però posso anche ricavare ulteriori metriche e ad esempio se io vado a considerare a a cioè i veri positivi e lo divido per a più b che sono la somma di veri positivi e di falso negativo ottengo quella che viene chiamata sensibilità viceversa ed è di fatto che cosa la frazione di elementi di una classe che il mio classificatore ha correttamente per quale ha fatto una predizione corretta ed è quella che nella slide precedente abbiamo chiamato a più 1 cioè è la relativa al al bilanciamento non è l'esempio del bilanciamento è proprio la l'accuratezza relativa alla classe più 1 ed è chiamata sensibilità l'accuratezza relativa alla classe meno 1 è quella che viene chiamata specificità del classificatore questi sono termini che vengono utilizzati prevalentemente appunto nella classificazione binaria quando abbiamo due classi e sono tra l'altro degli aggettivi che si ritrovano e hanno lo stesso significato quando per esempio avete degli strumenti che vi fanno fare per esempio un'analisi medica quindi per esempio un tampone quando si parlava dell'ambito della recente pandemia della sensibilità della specificità di questi strumenti si intendeva esattamente un concetto analogo quello che qui invece sono gli strumenti chiaramente automatici cioè la capacità di rilevare un caso positivo da uno negativo e quindi il rapporto tra i casi positivi e tutti quelli che il vostro strumento il vostro tampone era in grado di rilevare quindi andavano a misurare che cosa il numero di veri positivi il numero di falsi negativi che calcolavano la sensibilità o la specificità di questi strumenti questa è la stessa cosa ma ovviamente traslata nell'ambito dell'apprendimento automatico però di fatto è la stessa tipologia di problema cioè andare a misurare quanto uno strumento è capace di fornire delle risposte che siano plausibili rispetto al problema che sta cercando di risolvere che è un problema di classificazione ok e ovviamente l'accuratezza bilanciata è un mezzo a più uno più un mezzo a meno uno per come l'abbiamo descritto prima quindi vedete a partire da uno strumento semplice come un oggetto semplice come una matrice di confusione e noi riusciamo a costruire accuratezza accuratezza bilanciata e analizzare su tutta una serie di caratteristiche che ci interessano del classificatore perché poi in alcune applicazioni può essere io vado a cercare la sensibilità in altre voglia la specificità cioè dipende da che cosa sto andando a cercare quindi queste sono tutte le metriche che ci aiutano nella costruzione dell'applicazione ok qui invece c'è c'è un paio di slide finali che riguardano un qualcosa che abbiamo già visto a proposito della regressione cioè se vi ricordate vi ho detto guardate che la regressione possiamo anche andare a effettuare una regressione pesata attribuire dei pesi se vi ricordate ai campioni e qui si fa un po' la stessa cosa cioè in linea di principio io posso decidere o dei campioni del mio data serie di addestramento posso decidere di dargli più o meno peso e questo da un punto di vista matematico deriva dal fatto che le funzioni di costo sono delle somme sui vari punti individuali ok se non lo potrei fare adesso questo grafico è un grafico preso dal libro in cui c'era un esempio adesso indipendentemente dall'esempio specifico vedete in questo caso quello che cambia è che abbiamo le classi più 1 e meno 1 come leggere questo grafico abbiamo classe 1 e classe meno 1 e abbiamo i vari punti in funzione di una feature di input ok e alcuni di questi pallini sono più grandi altri più piccoli perché questi punti sono dei duplicati o dei triplicati ci sono più volte questo capita spesso quando ci sono per esempio delle dei censimenti qualcosa che riguarda per esempio il censo della popolazione quindi che ne so sto raccogliendo dei dati per costruire un classificatore che riguardano il guadagno medio della popolazione il numero di figli per famiglia chiaramente ci sono più famiglie che hanno due figli ce ne sono più famiglie che hanno tre eccetera quindi ho delle occorrenze ripetute di uno stesso valore ok allora questo stesso valore io lo devo contare solo una volta perché nel mio data set se è il numero di figli la mia feature e se ho mille famiglie che hanno tre figli io le vado a contare una sola volta quando sono mille non è corretto forse questo io voglio che quel punto che è lo stesso punto tre feature tre feature tre classe meno uno oppure feature tre classe più uno e quello stesso punto lo voglio vedere replicato mille volte voglio che il mio modello venga addestrato andando a vedere quel punto non una sola volta ma più volte anche se è sempre lo stesso tre più uno come risposta allora per fare questo si introducono dei meccanismi in cui andiamo a pesare questi punti e quindi se io vado a prendere per esempio la funzione di costo soft max che è esattamente questa che l'ho venuta a vedere quella qui eravamo arrivati nella lezione passata o due lezioni fa e io vedete in questo caso vado a fare una scansione su tutti i vari punti e ognuno si porta dietro il suo peso per cui se quel singolo punto l'ho visto una sola volta ha una sola occorrenza beta p varrà uno se invece come nel caso delle famiglie ci sono mille famiglie con tre figli quel beta p varrà mille in questo modo tengo conto del fatto che il punto ha più repliche poi ovviamente devo pesare rispetto se faccio la media beta 1 più beta 2 più delta p che mi dà la dimensione totale del mio dataset questo è un modo corretto di procedere in un caso di questo genere perché altrimenti io mi perderei un sacco di informazioni cioè questi punti li andrei a pesare tutti uguali così forse non voglio per esempio nell'applicazione dei dati questo capita ripeto spesso quando ci sono questi dati tipo censimento queste cose questo è un esempio per dirvi questo è un esempio adesso non mi ricordo neanche cos'era perché vedo un guadagno cioè il capitale quindi probabilmente sono delle aziende in funzione del del fatturato dell'azienda veniva classificata come più uno meno uno che non so cosa potesse essere non me lo ricordo nemmeno cose come quotate in borsa oppure no cose di questo genere un esempio di quel genere però posso avere chiaramente più aziende che hanno questo tipo di di fatturato e che hanno etichetta meno uno ma posso averne diverse che hanno questo tipo di fatturato e magari etichetta più uno ci siamo adesso si mancava probabilmente questa spiegazione va bene andiamo avanti io posso anche voler utilizzare questo meccanismo per una ragione leggermente diversa ok questo no direi che è la stessa cosa che vi dicevo prima cioè i pesi possono essere utilizzati per tenere conto dei punti ripetuti quindi se il punto è unico beta uguale a uno altrimenti vale R nel momento in cui ho una ripetizione di R volte e poi posso procedere con tutte le tecniche di ottimizzazione locale che abbiamo visto insomma non cambia nulla invece l'altra cosa che vi dicevo che può essere fatta è avere dei pesi che possono essere utilizzati per assegnare anche qui un livello di confidenza rispetto a certi punti cioè io ho dei punti e di alcuni di questi mi fido di più e di altri mi fido di meno perché perché sono io che ho costruito il dataset e so che alcuni di questi li ho costruiti in condizioni di rumorosità maggiore altri in condizioni di rumorosità minore e quindi di alcuni punti mi fido di più e di altri di meno e allora posso voler costruire un modello che tenga conto di questo fatto quindi assegnare un valore zero ipoteticamente a un punto di cui non mi fido per niente di fatto equivale a dire non lo vado a vedere lo scarto invece uno per punti di cui mi fido ciecamente ok e questo è un esempio di dove questo può essere utilizzato per esempio può essere utilizzato anche nei dataset sbilanciati qui supponiamo di fidarci in ugual in ugual modo quindi oltre oltre al fatto di dire rumore oppure no posso usarlo ad esempio anche per mitigare l'effetto del dataset sbilanciato è una delle tecniche che posso mettere in campo perché supponiamo di avere come in questo caso vedete cinque punti della classe rossa e tanti altri della classe 1 non so ne quanti siano se io vado a costruire il mio classificatore il mio confine decisionale è questo e vedete che mi sbaglia due punti della classe rossa due su cinque comunque posso non essere contenti ovviamente di questo tipo di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di i pesi sui vari punti e in cui il peso che assegno agli elementi della classe di ogni classe è inversamente proporzionale alla cardinalità di quella classe se la cardinalità di questa classe è il 95% dei punti qui ho un fattore di scala che è inversamente proporzionale se quello è il 5% il fattore di scala è inversamente proporzionale a quel 5% vuol dire che il peso che io assegno ai punti rossi è molto più grande rispetto al peso che assegno ai punti blu questo allora questo è semplicemente un qualcosa che vi dice proporzionale a è un simbolo matematico che vi dice beta più 1 lo dovete scegliere proporzionale a 1 diviso omega più quindi supponiamo di avere 100 punti e il 95% siano di classe blu vuol dire che questo vale è un 1 su 95 quindi dovete scegliere un numero che è proporzionale a 1 su 95 e quell'altro è proporzionale a 1 su 5 con lo stesso fattore di proporzionalità chiaramente e chiaramente 1 su 5 è un numero molto più grande di 1 su 95 quindi significa che i punti rossi pesano molto di più nella costruzione della funzione di costo cioè quando vado a fare quella somma la funzione di costo nel momento in cui vado a prendere in considerazione questi punti è una funzione di costo che va a pesare quindi se lo sbaglio il punto rosso il penalty che vado a pagare nella funzione di costo è molto più alto e allora che cosa succede? succede che vedete nell'esempio della figura al centro e poi in quella più a destra che cosa cambia? a livello grafico i punti rossi sono più grandi questo vi dice semplicemente che l'accuratezza scusate quel fattore beta più 1 va ad aumentare progressivamente per i punti di classe rossa in particolare sono state effettuate tre prove questa con beta p uguale a 1 questo beta p uguale a 5 se non sbaglio e l'altro con beta p uguale a 10 nel primo esempio pesano tutti uguali nel secondo esempio quello di mezzo i punti rossi danno un contatto contributo alla loss function che è 5 volte quella dei punti blu a destra 10 volte quella dei punti blu e quello che accade che cos'è? vedete come si sposta al confine decisionale? si sposta in modo da andare a includere progressivamente prima quest'altro punto che prima era al di sotto del confine decisionale e qua finisce sopra e poi anche quest'ultimo sì è un'osservazione corretta questa è vero che io vado a sbagliare a questo punto anziché un solo punto blu ne vado a sbagliare 4 anzi 5 però ripeto dipende dall'applicazione in questo caso ho classificato correttamente poniamo 5 pazienti che avevano bisogno di cure e qui invece 2 ne avevo rimandato a casa dicendo state tranquilli allora magari sono più contento di avere mandato dei pazienti presso una cura poi specialistica e magari ho salvato la vita al costo di dire a 5 di questi attenzione fate un'ulteriore analisi perché potrebbe essere che avete questo problema loro magari hanno fatto ulteriori analisi e hanno visto che è tutto a posto oppure ho sollevato la bandierina della transazione della carta di credito e la banca vi ha telefonato guardate ma siete stati effettivamente voi perché abbiamo il sospetto che qualcuno vi stia rubando i soldi e voi direte no è tutto a posto ok però magari di questi qualcuno effettivamente ha detto ok blocco tutto quindi questa è la logica che c'è dietro va bene? va bene direi che allora questa forse era l'ultima slide di questo blocco vediamo un po' se è così e ready si quindi direi che con questo concludiamo questa lezione concludiamo questo blocco di slide la prossima volta andiamo avanti con la teoria andremo avanti con le classificatori multiclassi iniziamo e invece con la parte di laboratorio che domani in lezione di laboratorio iniziamo la libreria di una file quindi questa è la prossima di una lezione va bene se non ci sono domande da remoto intanto interrompiamo la registrazione con domande grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti