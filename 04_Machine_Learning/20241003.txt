dunque di nuovo buongiorno a tutti allora questa è l'ultima slide del primo blocco che è il blocco introduttivo ed eravamo arrivati qui l'ultima lezione e facciamo un breve riepilogo di quello che abbiamo visto abbiamo dato delle definizioni introduttive abbiamo introdotto i problemi di classificazione problemi di regressione il concetto di apprendimento con supervisione e quello privo di supervisione quindi diciamo che da un punto di vista della proprio della della classificazione più generale sistemi gli algoritmi i sistemi gli algoritmi diciamo tutte e due le cose di machine learning sono solitamente classificati appunto in tipologie di apprendimento supervisionato in cui abbiamo degli esempi etichettati che specificano quello che il comportamento desiderato che noi vogliamo poi la macchina abbia che il sistema abbia e quelli invece problemi di apprendimento senza supervisione quindi non supervisionato non ci sono delle esempi etichettati ma semplicemente il compito che ha il sistema è di identificare dei pattern interessanti questo pattern questo interessante scusate questo aggettivo è diciamo potrebbe essere messo tra virgolette perché che cosa vuol dire effettivamente abbastanza sfumato nel dataset questi pattern devono essere riconosciuti tipicamente appunto abbiamo fatto delle considerazioni riguardanti per esempio il clustering problema del clustering era identificare dei gruppi di dati che hanno delle caratteristiche simili tra di loro questi gruppi di dati possono essere dei cluster di tipo globulare come si dice che erano quelli in un esempio che avevamo visto nella figura una delle ultime cose che abbiamo detto la volta scorso quindi a forma diciamo sostanzialmente sferica o quasi anche se se ragionavamo chiaramente uno spatto bidimensionale ma lo stesso concetto può essere esteso in qualche modo a dimensioni più alte oppure pattern che stanno su quelle che i matematici chiamano delle varietà delle varietà sono delle superfici o delle iper superfici che hanno una forma diversa per cui magari stanno lungo vi ricordate quella curva che vi avevo identificato è un problema anche questo punto non banale ma cercheremo di mettere le basi per dei concetti appunto introduttivi anche anche su questo anche su questo poi c'è tutta una famiglia di tipologie di problemi di apprendimento che non rientra in questi due ma e non avremo modo di vederlo perché chiaramente il tempo è limitato ed è quello del cosiddetto apprendimento per rinforza l'apprendimento del rinforzo è quello in cui il sistema si trova a dover fare i conti con l'ambiente circostante quindi un sistema che tipicamente interagisce con l'ambiente e per cui nel momento in cui viene addestrato il sistema viene addestrato tramite dei segnali di ricompensa quando il sistema fa un'azione che in qualche modo conforme alla policy che viene in piedi adottata quindi a quello che noi vogliamo che il sistema faccia o viceversa viene penalizzato se fa qualcosa che non che non deve fare tra virgolette diciamo gli esempi più tipici sono nel mondo per esempio della robotica mondo della robotica se dobbiamo addestrare un sistema un robot che si muove per esempio in una stanza e devi imparare non andare a sbattere contro contro contro i muri contro gli ostacoli devi imparare a riconoscere la stanza e quindi ogni volta che va a sbattere contro un ostacolo viene inviato un segnale negativo di penalizzazione e il processo di addestramento appunto modifica le caratteristiche del sistema in modo tale da evitare il più possibile situazioni di questo tipo nello svolgimento di quelle che sono le sue attività e tutto questo chiaramente è qualcosa che si colloca in un se vogliamo in un punto di vista che è diverso da quello in cui avevamo fino adesso categorizzato i nostri problemi ma che riguarda comunque l'apprendimento perché è un sistema che comunque apprende in automatico a partire dall'esperienza però l'esperienza in questo caso un'esperienza che riceve a partire dall'ambiente quindi ci sono delle interazioni con l'ambiente circostante la robotica non è l'unico caso per esempio ci sono applicazioni che possono essere applicazioni pensate al ai giochi quindi sistemi che in autonomia imparano a giocare imparano a giocare ci sono dietro delle delle basi di prendimento per rinforzo cioè ogni partita persa determina una penalizzazione nel comportamento del sistema che invece viene premiato nel momento in cui fa delle mosse pensate agli scacchi oppure per esempio c'è stato qualche anno fa 6 o 7 anni fa credo gli scacchi sfuggono un po perché già con approcci tipo forza bruta quasi forza bruta non proprio ma si era riusciti un po di anni fa a costruire un sistema che abbattuto poi la loro campione di condiare gli scacchi però c'è anche il gioco del go per esempio un altro gioco assimilabile agli scacchi è un gioco nato in oriente ed è un gioco che ha in comune con gli scacchi il fatto che si gioca su una con delle pedine su una su una tavola di gioco e ha in comune il fatto di essere un gioco di strategia in cui bisogna si sconfrona con un avversario bisogna in qualche modo distrire le proprie pedine le proprie pietre credo che si chiamino in modo da sconfiggere il nemico con una serie di mosse e però è un gioco che ha molte più combinazioni rispetto agli scacchi possibili e è stato costruito un sistema hanno costruito quelli di google define che la divisione dell'intelligenza artificiale di google che qualche anno fa i play to 5 6 forse qualcosa di più sette anni fa ha battuto il campione mondiale di questo gioco cosa che è stata ritenuta un passo avanti notevole perché si riteneva impensabile riuscire a costruire un sistema di questo genere perché giochi di strategia sono ritenuti comunque un fino a poco tempo fa erano ritenuti giustamente una sorta di presidio dell'intelligenza umana diciamo di rappresentare di punto simbolico diciamo meglio ecco di quella che è l'intelligenza umana ecco il fatto che una macchina sia in grado di battere un essere umano è per giunto appunto campione di scacchi è un gioco così sofisticato è stato un qualcosa che ha segnato un po perlomeno c'è stato un certo clamore diciamo anche sui sui media giustamente lì dietro c'è un sistema ci sono tante cose c'è anche un sistema fondamentalmente di apprendimento per rinforzi gli hanno fatto giocare un sacco di partite da cui lui ha preso dei comportamenti che erano dei comportamenti vincenti poi alla fine non avremo modo di vedere però queste cose però insomma mi sembrava corretto menzionarvela in questa in questa introduzione quello che invece cominciamo a fare adesso cominciamo andare un pochino più nel dettaglio di cose un po più ovviamente indietro se vogliamo ma che sono dei presupposti necessari quindi meno di forse anche meno appealing rispetto a queste cose di cui però abbiamo dato una così giusto dei cegni generali invece vogliamo scendere un po più nel tecnico ma dobbiamo tornare un po più in basso se vogliamo dove il termine basso in realtà è un aggettivo probabilmente non molto calzante però diciamo dobbiamo scendere più a un livello di dettaglio che è quello del nostro corso e andare un po più nel tecnico nel tecnico e nel matematico e cominciare a parlare di ottimizzazione matematica perché vi ho detto che è il presupposto fondamentale per costruire qualunque sistema di machine learning perché tramite gli algoritmi di ottimizzazione si aggiustano i parametri del modello per cercare di fare in modo che il modello faccia quello che noi vogliamo nel caso di apprendimento con supervisione che il comportamento sia effettivamente quello che vogliamo corretto se è un problema di classificazione vogliamo che classifichi correttamente degli esempi se è un problema di regressione vogliamo che ci restituisca il più possibile un valore corretto anche vedremo poi problemi non supervisionati rispondono questa logica cioè anche lì dietro ci sono degli algoritmi di ottimizzazione quindi diciamo in generale l'ottimizzazione è effettivamente il motore che permette di muovere questi sistemi per cui è importante dedicarci un po di tempo quindi passeremo un po di tempo a riepilogare alcune caratteristiche di quelle che sono alcuni sistemi di di ottimizzazione adesso vi carico intanto la slide successiva ecco come vi dicevo passeremo un po di tempo a ad analizzare questi questi sistemi questi metodi di ottimizzazione dando delle definizioni generale partendo da definizioni generali e da metodi che in realtà ci di anticipo non tutti sono utilizzati nella pratica comune per arrivare ma perché ci daranno la possibilità di costruire un po di conoscenza e di affinare un pochino i concetti per arrivare poi a quelli che effettivamente invece vengono impiegati nella pratica di tutti i giorni allora diamo un attimo dovreste riuscire a vedere questa slide anche da remoto mi auguro dunque sì sì perfetto cominciamo quindi dando una definizione di base che penso abbiate tutti ben presenti e comunque anche se non ce l'avete dovreste riuscire con poco sforzo andando a recuperare qualche qualche appunto dei corsi di matematica della laurea triennale a recuperarli quindi daremo daremo un po faremo un riepilogo veloce di alcune di alcuni aspetti dello studio delle funzioni che vengono fatti corsi di matematica di base e l'ottimizzazione in matematica di fatto prende le funzioni matematiche e che cosa fa siccome i problemi di ottimizzazione sono problemi di in cui si va a determinare il minimo il massimo di una funzione vanno a fare questo quindi essenzialmente si tratta di questo ed è un problema che è datato secoli voglio dire nelle scienze nell'ingegneria quindi problema abbastanza consolidato come tipologia di problema e come strumenti che lo affrontano loro sopra però vedremo il muoverci nell'era moderna quindi arrivando al machine learning pone delle sfide diverse e quindi bisogna fare attenzione a quali di questi strumenti si usa come si usano quali si usano e come si usano allora qui abbiamo un esempio della semplice funzione che è una funzione quadratica in una dimensione e chiaramente questa è una parabola e vedete che nella parte destra del della figura in verde evidenziato quello che il massimo intuitivamente ovviamente la funzione prende il suo valore massimo in in quel punto e questo chiaramente rappresenta il valore più alto che la funzione ha nel suo dominio di esistenza e quindi la ricerca del massimo globale e fondamentalmente la ricerca o del minimo globale del valore massimo del valore minimo che la funzione prende nel suo dominio di esistenza ovviamente nel dominio di esistenza c'è la variabile o le variabili indipendenti il valore che prende quello che viene restituito dalla funzione stiamo parlando di una funzione che va tipicamente da rn quindi n dimensioni in r noi vogliamo il valore di r massimo della funzione ma in particolare ci interessa non solo il massimo della funzione ma anche ovviamente quali sono i valori delle variabili indipendenti chiaramente che determinano quello al quale perché perché per noi quelle variabili indipendenti saranno i nostri parametri ok quindi data una funzione di n variabili e questa funzione la chiama viene chiamata allora qui la notazione io l'ho presa da uno dei libri di testo che che vi avevo indicato ma in realtà anche qui in altri libri di testo vi viene chiamata g ed è funzione di w1 w2 w n in altri in altri testi potreste trovare qualcosa tipo una l dove l sta per loss perché sono le loss function che perché questa sarà vi anticipo la nostra funzione di costo e qualche volta trovate in punzione di teta dove teta teta 1 teta 2 teta 3 teta n sono sono i parametri qui utilizzeremo durante insomma nelle slide la convenzione di testo da regi ma chiaramente una funzione generica la potete chiamare come volete allo stesso modo le variabili anziché teta o x come siamo abituati perché diciamo in matematica sono y le x 1 x 2 x n qui vengono chiamati w1 w2 w n perché w sta per weight weight chiaramente in inglese significa peso e sono i pesi del nostro modello pesi o parametri del modello ma ripeto sono del tutto convenzionali per cui sono dei parametri allora quello che abbiamo abbiamo questa funzione vogliamo risolvere un problema di minimizzazione noi essendo delle funzioni di costo vogliamo minimizzare il costo la perdita ok quindi tipicamente risolveremo dei problemi di minimizzazione come vi dirò tra poco c'è scritto anche mi anticipo qui un problema di massimizzazione può essere messo espresso in termini di problema di minimizzazione anzi lo diciamo subito nel senso che si facciamo per ordine ci arriviamo tra un attimo allora abbiamo un problema di minimizzazione vuol dire che dobbiamo cercare il w o qui cominciamo con un altro dobbiamo un attimo segnalare un altro aspetto relativo alla notazione chiaramente avendo le variabili w1 w2 fino a wn io posso inserirle in un in un unico unica notazione che è quella vettoriale in cui indico con w il vettore che è rappresentato da w1 w2 fino a wn e quando lo scriverò io lo scriverò il vettore con sopra il segno diciamo soprassegnato per per indicare che un vettore nelle slide troverete anziché il soprassegno troverete il il boldface quindi il grassetto come per indicare un vettore ok quindi in carattere normale ci sono gli scalari questo in carattere grassetto ci sono i vettori quando scriverò la lavagna scriverò chiaramente non riesco a scrivere a mano in grassetto scriverò con il segno sopra l'obiettivo appunto è minimizzare una funzione g di w quindi trovare il valore di w che minimizza il valore di questa funzione quindi significa trovare un valore specifico che possiamo chiamare w star w asterisco è questo tale che la il valore che prende la funzione in quel punto w star è minore uguale del valore che prende la funzione in tutti gli altri chiaro ci siamo qui il problema vi anticipavo prima di ma un eventuale problema di massimizzazione può essere espresso in termini di problemi di minimizzazione semplicemente andando a minimizzare di nuovo la funzione meno di veramente mettendo un segno meno davanti troviamo quello che è minimizzando meno g troviamo il massimo di g questo è anche il motivo per cui ci concentreremo su problemi di minimizzazione ma il motivo vero è che appunto abbiamo delle funzioni di perdita e noi vogliamo minimizzare le perdite nel processo di addestramento questo è chiaramente un problema che è un problema di minimizzazione che cerca quelli che vengono chiamati minimi o eventualmente i massimi globali cioè il valore più basso che prende la funzione relativo al suo dominio ma questa definizione può essere estesa anche al concetto di minimo massimo locale l'unica cosa che cambia è che anziché guardare tutto il dominio della funzione noi possiamo limitarci a cercare un qualcosa che vale questa disuguaglianza deve valere non per tutti w come abbiamo scritto qua ma diciamo localmente al punto w star cioè in un intorno quello che i matematici chiamano l'intorno e allora arriviamo quindi a con questo a definire va beh giusto per darvi via se io avessi una cosa di questo tipo ok facciamo così condivido ok ok Grazie. Grazie. Grazie. Grazie. Andiamo avanti. Andiamo avanti e facciamo questa considerazione. Ah no, scusate, ho saltato la slide precedente, che ovviamente era quella a cui eravamo arrivati. Cioè tutto questo, cioè la definizione di minimo globale e di minimo locale, appunto in base alle considerazioni che abbiamo fatto finora, ci porta appunto a quello che è riepilogato in questo quadro, che sono quelle che vengono chiamate condizioni di ottimalità di ordine zero. Condizioni di ottimalità perché appunto riguardano gli ottimi, che possono essere ottimi globali e locali, poi ne andiamo adesso a riepilogare insieme. Quindi, quindi, vi ordine zero perché? Perché sono delle condizioni in cui vedrete noi tiriamo in ballo solamente il valore della funzione. Questo per distinguerli da altre condizioni di ottimalità che ci servono per identificare i punti di massimo o di minimo, che sono quelle che per esempio, se vi ricordate nel corso di analisi matematica, per identificare il massimo delle funzioni derivabili, appunto dove c'era la derivata, si va a vedere dove la derivata prima si annulla. Quelle sono condizioni che impareremo e rinfrescheremo questi concetti, sono condizioni dette di ordine uno perché? Perché implicano l'utilizzo della derivata prima per identificare il massimo di minimo. Ma poi vedremo, ci sono anche le tecniche di ottimizzazione di ordine, di secondo ordine perché lì si va verso le derivate seconde e tutto questo viene anche trasferito in funzione di più variabili, quindi laddove la derivata prima si annulla. Significa avere non solo una derivata ma tante derivate parziali che verranno organizzate in un vettore che viene chiamato gradiente, oppure le derivate seconde e anche lì ci sono le derivate seconde parziali e li vengono organizzati in una matrice che sarà la matrice siana. Ok, però andiamo per ordine. Intanto partiamo dalle tecniche di ordine zero. Un punto quindi W star, l'abbiamo già detto implicitamente nella slide precedente quando abbiamo introdotto appunto questi concetti, si dice minimo globale della funzione G di W se e solo 6 G di W star è minore o uguale di G di W per tutti i valori di W. Stessa cosa possiamo assolutamente dire per il massimo globale, l'unica cosa che cambia è il segno della disuguaglianza per cui G di W star è maggiore o uguale di G di W per tutti i V. Passando ai minimi locali, siccome queste disuguaglianze devono valere in un intorno di quel punto, quel punto si dice essere un minimo locale se e solo se G di W star, che è appunto il punto W star, il punto di minimo locale, se il valore che prende la funzione in quel punto è minore o uguale di G di W per tutti i W, e qui ci sono un virgolettato near, cioè vicino a W, nell'intorno, e l'intorno può essere specificato da un punto di vista matematica in maniera molto precisa, quindi tramite una definizione, ma qui c'è sufficiente lasciarlo così, il concetto di intorno può essere reso, formalizzato in maniera ancora più rigorosa, ma c'è sufficiente questo, allo stesso modo un massimo si dice locale se vale questa disuguaglianza nell'intorno, di W asterisco. Allora, queste condizioni, vi dicevo prima, sono chiamate condizioni di ordine zero, sono quindi chiamate così perché gli ottimi sono definiti, i punti di ottimo, in termini della funzione. Vedete, noi qui quello che mettiamo in gioco è solo il valore della funzione, non derivate prime, non derivate sopporte. Quando invece condizioni di ordine più alto vengono coinvolte nella definizione di ottimalità, allora si parla di condizioni di ottimalità del primo e del secondo ordine, rispettivamente quando viene fatto uso di derivate prime o derivate seconde della funzione e questo è quello che faremo quando studieremo questi metodi. Però ci è utile partire ovviamente da questi che sono, dai metodi di ottimizzazione che sfruttano questa condizione di ottimalità, perché sono chiaramente i più semplici da cui partire, perché noi abbiamo la funzione e vogliamo il minimo. Non dimentichiamoci che non vogliamo fare uno studio analitico, noi dobbiamo fare questa cosa in automatico tramite un calcolatore. E come facciamo se abbiamo una funzione e vogliamo sfruttare queste definizioni, questi concetti di, appunto, di queste condizioni di ottimalità di ordine zero per ricavare il minimo della funzione? Beh, molto semplicemente, quello che possiamo fare è... andare a cercare il massimo globale, in questo caso, vedremo, della funzione. L'obiettivo intanto è risolvere il problema di ottimizzazione globale, poi vedremo subito che ci arriviamo fino a un certo punto e lì dovremo accontentarci di andare a cercare i minimi o i massimi locali. Però se dobbiamo costruire un ottimizzatore globale, quindi un algoritmo che presa una funzione, cerca il massimo o il minimo globale, sfruttando le condizioni di ottimalità di ordine zero, quello che possiamo fare è una cosa molto semplice. Abbiamo a disposizione una potenza di calcolo, possiamo andare a fare che cosa? A valutare la funzione in un certo numero di punti, possibilmente molto ampio. A quel punto abbiamo, che cosa? La possibilità di andare a vedere per ognuno di quei punti quanto vale la funzione e prendiamo il minimo. Questo chiaramente sarebbe estremamente tedioso da fare a mano, un calcolatore lo può fare in maniera molto agevole, in un attimo. Il problema qual è? Che ovviamente come scegliamo questi punti? Poi adesso c'è un esempio che chiarisce meglio questi concetti. Ma questi punti sono infiniti anche per una funzione continua. Scusate, per una funzione continua sono sicuramente infiniti anche per una funzione, ti devo dire, di una sola variabile. Quindi ovviamente al calcolatore non possiamo dare infiniti punti. Quindi dobbiamo in qualche modo discretizzare questo input e quindi andiamo a effettuare un campionamento. Cioè campioniamo il dominio della funzione e andiamo a vedere un certo numero di punti quali valori prendono. Il risultato sarà un risultato approssimato, però se ne prendiamo abbastanza abbiamo buone possibilità di andare a pescare un qualcosa che se non è l'ottimo è vicino all'ottimo. E qui introduciamo un altro concetto, cioè molto spesso nell'ambito del machine learning l'obiettivo è cercare il minimo della funzione di perdita, ma ci si accontenta di qualcosa che è comunque più basso, vedremo, di tanti possibili valori, anche se non è il più basso di tutti, tant'è che appunto molto spesso ci accontentiamo di andare a cercare minimi locali, ma anche nei minimi locali se si arriva nell'intorno del minimo può andare bene lo stesso. E questo è un aspetto da tenere sempre presente. Quindi come possiamo scegliere i punti? Campionando. E campionando ci sono due modalità fondamentalmente. Una è il campionamento uniforme e l'altra campionamento casuale. Campionamento uniforme cosa significa? Che noi andiamo a prendere i punti con una certa regolarità. Imponiamo una sorta di griglia, poi vediamo che nell'esempio nella slide successiva si capisce bene visivamente, abbiamo una griglia e in questa griglia andiamo a prendere un certo numero di punti spaziati regolarmente. Campionamento casuale, abbiamo il nostro intervallo e andiamo a pescare lì dentro casualmente dei punti. Ambedue queste tecniche possono essere viste quindi come una sorta di approssimazione delle condizioni di ottimalità. Perché? Perché noi quello che facciamo è andare a pescare questi punti e andare a prendere il punto che ci dà il valore più basso della funzione, approssimando la condizione di ottimalità. Ok, qui abbiamo due funzioni di cui adesso andiamo a vedere il grafico nella slide successiva, se non è un baglio, fatemi vedere. Che sono rispettivamente in una dimensione questa funzione e in due dimensioni quest'altra. Allora, la prima, guardiamo quella in una dimensione, è una funzione, vedete, con un termine quadratico più un termine costante e se andate a fare lo studio di funzione vi accorgete che il valore minimo, chiaramente, che prende questa funzione essendo una parabola che passa per l'origine, è passante per lo zero e quindi è il punto, scusatemi, zero e chiaramente vale 0.2. L'estensione di questa in due dimensioni è quest'altra funzione, che è la funzione di queste due variabili u1 e u2 e qui abbiamo la somma di due termini quadratici più un termine costante e anche qui, studiandolo con gli strumenti classici dell'analisi matematica, e quindi si arriva alla definizione di minimo globale nel punto, vedete, qui l'ho indicato in forma vettoriale 0, 0, cioè ambedue i parametri prendono il valore 0 e lì si può dimostrare che c'è un minimo globale, lo possiamo fare con gli strumenti dell'analisi matematica, ma a noi interessa farlo non con quello, ma con l'informatica, perché? Perché noi ovviamente non ci fermeremo a una o due dimensioni, ma ne potremmo avere 5, 10, 100. Quindi a quel punto chiaramente farlo analiticamente risulta di fatto impossibile. Allora, andiamo a vedere, però, diciamo, questo esempio ci permette comunque di catturare l'essenza di questi metodi. E allora la parte, diciamo, superiore di questa figura è quella che è relativa al campionamento uniforme. Qui abbiamo Il campionamento uniforme e qui invece abbiamo il campionamento casuale nella parte inferiore. Poi la parte, diciamo, sinistra e destra differiscono per, diciamo, la frequenza del campionamento, se vogliamo, quindi per quanto fitti vengono presi questi campioni. Allora, partiamo da sinistra, vediamo la funzione a una dimensione che è questa, è la nostra parabola. Supponiamo di campionare l'intervallo, ovviamente scegliamo un intervallo, in questo caso un intervallo tra meno 1 e 1, e scegliamo una serie di campioni che sono questo, questo, questo e questo che sono equispatiati. Per ognuno di questi andiamo a vedere quanto vale la funzione in corrispondenza di quei punti e prendiamo il minimo. E in questo caso chiaramente il minimo, siamo un po' lontani dal minimo perché saranno questi due valori. Stessa cosa possiamo fare con un campionamento casuale. Il campionamento casuale ci dice che se noi in questo intervallo andiamo a pescare, ad esempio, tre punti, e questi possono cadere qui, e questi sono i valori corrispondenti, quindi il minimo che otteniamo magari è quello. Siamo lontani, un po' lontani dal minimo globale, ma perché abbiamo preso pochi punti. Se andassimo a prendere, e andiamo su questa parte del grafico, una griglia molto più fitta di punti, e chiaramente qui vedete che riusciamo ad approssimare meglio la condizione di ottimaleità e andare più vicini a pescare il minimo globale. Anche nel caso del campionamento uniforme, vedete, c'è un addensamento chiaramente in alcune zone, ma in questo caso siamo stati abbastanza fortunati e siamo riusciti ad andare a prendere il punto nel minimo. Questo per quanto riguarda funzioni di una variabile è la stessa cosa se la funzione è di due variabili, come appunto la funzione che abbiamo prima definito, e abbiamo nel caso del campionamento uniforme questo tipo di comportamento. Abbiamo una griglia, vedete, su un piano, che è questo. Questi sono tutti i punti che andiamo a campionare con regolarità, sono tutti equispatiati, e questi in verde sono i valori che prende la funzione in corrispondenza di quei punti. Vi faccio notare che qui abbiamo una parabola in una variabile, questa è una quadratica in due variabili, che è l'estensione di quel concetto, vedete, ha una forma di paraboloide, che è una bella forma regolare. Se prendiamo dei punti generati casualmente, siamo qui con i punti blu e i corrispondenti in verde andranno a identificare più o meno, in maniera più o meno approssimata, quello che è il minimo globale. Chiaramente se andiamo anche nel caso bidimensionale a infittire, vedete, la griglia di punti, ovviamente ricopriremo quella superficie in maniera più accurata, stessa cosa avviene anche col campionamento casuale, fondamentalmente non ci sono differenze prestazionali, il campionamento casuale lo potete ripetere più volte, quindi fare in modo che andate a confrontare più run, quindi anche lì avete buone probabilità di ottenere un buon risultato, e quindi questo, diciamo, è una tecnica comunque che funziona. Funziona sempre? Punto interrogativo. Perché uno potrebbe a questo punto fermarsi qui e dire, ok, abbiamo risolto il problema, qui lo vediamo in una o due dimensioni, lo trasferiamo anche a 10, 100 o 500 o 1000 dimensioni, o semplicemente da far fare più conti al calcolatore, però voglio dire, selezionare un certo numero di punti casualmente e andare a valutare la funzione in quel numero di punti, è un problema anche di complessità, tipo sommato, banale, quindi i calcolatori moderni dovrebbero riuscirci in pochissimo tempo. Ed è così se non fosse che c'è dietro un problema di cui adesso andremo un po' a parlare. Quindi intanto qui è chiaro una cosa intuitiva, che più campioni andiamo a prendere, più accurata è la nostra approssimazione. Ci siamo fin qua? Quindi è abbastanza semplice. Adesso invece vi volevo parlare un attimo di questo concetto, che è quello che limita di fatto questo tipo di approccio. Questo tipo di approccio funzionerebbe bene a bassa dimensionalità, vi anticipo. Il problema è quando ci cominciamo a spostare, a salire di dimensione. È un approccio che non funziona più. E adesso cerchiamo di capire perché. Allora. Allora. Allora. Allora, come vi anticipavo, questo approccio basato su, quindi, l'approccio che è ottimizzazione globale, andiamo a cercare un'approssimazione del massimo globale, basato su tecniche di ordine zero, cioè valutazione della funzione, funziona solamente per funzioni a bassa dimensionalità. E quindi bassa dimensionalità significa 3, 4, 5, fino a poco più. E quindi significa che non lo possiamo utilizzare in quelli che sono i problemi di machine learning moderni, più recenti, dove abbiamo dimensioni dell'input e l'ordine delle centinaia, se va bene, ma anche 10 alla quinta, 10 alla sesta, milioni, quando non molto di più anche di variabili. E il perché è riassunto in questa slide a livello grafico. Ed è quello che viene chiamato in inglese curse of dimensionality, che significa la dannazione della dimensionalità. Quando cresce in un problema la dimensione dello spazio in cui ci muoviamo, avvengono dei fenomeni che, in prima battuta, uno non facilmente può prevedere. Proviamo a ragionarci insieme e a vedere che cosa succede. Guarda, partiamo da qui, dalla figura qui a sinistra, in cui abbiamo scelto di campionare, questo è un dominio unidimensionale, quindi siamo in una retta come se fosse il dominio di una funzione di una variabile, in cui andiamo a prendere un certo numero di punti, arbitrario, tre ne abbiamo scelti qui, che sono equispaziati a distanza di, quindi come se facessimo un campionamento uniforme, in cui prendiamo questi tre punti che distano di. Quindi se io voglio prendere un certo numero di punti e mantenere l'equispaziatura, in questo caso ho tre punti che distano di. Cioè, il punto fondamentale è dire, sono qui, chi sono i punti più vicini a distanza di? Sono questi due, sono due per forza, perché mi muovo su una retta. Se invece di muovermi in una retta mi muovessi in uno spazio bidimensionale, che cosa succede? Succede che io, per avere la stessa copertura, diciamo, del dominio, che è una copertura regolare, e ogni punto comincia, vedete, se prendo questo, per esempio, come vicino questo, questo distanza di, questo e questo, questo a sua volta vicino questo e quest'altro. Quindi i punti da tre in questo caso diventano nove. Se ci spostiamo in un dominio che non è bidimensionale, ma in tridimensionale, quindi in un cubo, e vogliamo mantenere sempre equispaziati questi punti, vedete che la griglia, e questi punti sono tutti a distanza di, quindi ognuno di questi vista dal suo vicino di, vedete che questi punti diventano chiaramente, in questo caso, quanti? Siamo passati da tre a nove, e qui se andate a vedere, uno ventisette. Quindi se prendiamo uno spazio che prima è unidimensionale, poi bidimensionale, poi tridimensionale, vedete che abbiamo questo fenomeno, per cui, per mantenere la stessa densità di punti, dobbiamo aumentare il numero di punti, e questo numero di punti cresce con una legge che, già da qui si può intuire, 3 elevato alla n, dove n è la dimensione dello spazio. E questo ci dice che cosa? Ci dice una cosa importante, che se vogliamo campionare uno spazio con una serie di punti in maniera regolare, e questi punti devono essere appunto equispaziati, il numero di punti che dobbiamo andare a inserire per campionare in maniera uniforme questo spazio cresce esponenzialmente con la dimensione dello spazio. Questo è un problema, perché la crescita esponenziale è chiaramente un qualcosa che non possiamo permetterci per risorse di calcolo. Gli algoritmi esponenziali sono gli algoritmi peggiori che possiate progettare, perché vi vincolano a tempi di calcolo infiniti molto rapidamente. E quindi significa che c'è un problema, che appunto crescendo la dimensione non riusciamo a gestire questo tipo di approccio. La stessa cosa vale della parte B della figura per per il campionamento casuale, cioè anziché sempre c'è la crescita del vedremo da qui a qui a qui la crescita della dimensione dello spazio ambiente in cui ci in cui ci muoviamo. Quello che cambia è che andiamo chiaramente a campionare in maniera casuale e quello che è fissato è fissiamo una certa unità di lunghezza questa e ci andiamo a mettere dentro un certo numero di punti a caso ad esempio di 10 e andiamo a vedere scusate l'unità di lunghezza è questa e andiamo a vedere per unità di lunghezza quanti punti cadono all'interno di quella unità. In questo caso quindi prendiamo questa unità di lunghezza poi mettiamo 3 e generiamo a caso dei punti e vediamo che qui per esempio in questo caso è un esperimento casuale supponiamo ne finiscano 3 su 10 poi ripetiamo la stessa cosa in due dimensioni e se andate a vedere quello che rimane fisso qui è il numero di punti che sono 2, 4 4, 8 e 2, 10 sono 10 punti però in due dimensioni che cosa succede? Che magari nel nel quadratino che rappresenta l'unità di misura all'interno di questo spazio bidimensionale ne cade magari uno questa volta sì se siamo fortunati due tre ripetendo chiaramente questo esperimento un numero n di volte quando n tende finito abbiamo la media ovviamente che a quel punto diventa un valore affidabile ma quello che si vede subito è che già salendo capite bene che intuitivamente la probabilità che qui dentro ci caschi un punto diventa più bassa se andiamo verso un caso tridimensionale vedete che in questo caso in questo cubo di di lato 1 non ci casca niente e questo capite bene che è un qualcosa che è vero man mano che cresciamo ancora di più tant'è che appunto dal positiva matematico di nuovo si può dimostrare che cosa? che in questo caso quello che succede è che il numero di punti la media diciamo del numero di punti per unità di allora qui abbiamo un cubo qui un quadrato qui un intervallo in più dimensioni vengono chiamati ipercubi quindi per unità di ipercubo ok che è l'estensione di questo concetto a più dimensioni ebbene la media del numero di punti per unità di ipercubo si può dimostrare seguendo questo discorso rendendolo appunto matematicamente poi più formalizzando in maniera più rigorosa che decresce esponenzialmente cioè man mano che aumento la dimensione dello spazio la probabilità di ritrovarmi dei punti all'interno di un di un'unità di superficie o di ipercubo del mio spazio diventa esponenzialmente via via più bassa e quindi questo significa che cosa? che se io voglio andare a campionare con questo metodo uno spazio a n dimensioni è uno spazio in cui i miei punti diventano estremamente sparsi cioè ci saranno enormi porzioni di quello spazio che non riesco mai a vedere e quindi mi posso scordare di andare ad approssimare in maniera corretta la funzione quindi crescendo il volume dello spazio in cui ci muoviamo i dati diventano in maniera esponenzialmente rapida via via più sparsi questo è il concetto quindi sia l'approccio basato su campionamento uniforme che quello basato su campionamento casuale sono destinati a fallire quando si cresce si sale scusatemi in dimensione a causa di questa questo concetto che è noto appunto come appunto con questo termine la danazione della dimensionalità purtroppo crescendo di dimensione i problemi ad alta dimensionalità hanno delle loro peculiarità che sono legate proprio a questo fatto qua che in questo spazio via via che cresce i punti diventano via via più ravi quindi esattamente invece qui era fissata la distanza di qualcos'altro che vuoi chiedere quella è la media del numero di punti che sta nell'unità di cresce in maniera esponenzialmente decresce in maniera esponenziale a col crescere della dimensione tant'è che puoi dimostrare che dopo poco proprio diventa già quando n e 10 sono probabilità quasi nulle ok che significa che cosa tutto questo per noi progettisti di questi sistemi che dobbiamo trovare altri metodi qui stiamo cercando l'ottimo globale quindi una prima tecnica che uno può fare tipicamente quando si trova di fronte a questi problemi cosa si fa ok vediamo se rinunciamo a qualcosa vediamo se poi rinunciare a qualche cosa ci permette di risolvere il problema in maniera più agevole in alta dimensionalità e magari non paghiamo un prezzo eccessivo allora il prezzo da pagare è dire ok anziché andare in cerca dell'ottimo globale vogliamo provare ad andare in cerca degli ottimi locali perché ci può andare che viene anche quello ok se la funzione è per esempio una bella parabola lì ha un ottimo globale ma se lo se utilizzo delle tecniche che vedremo sono appunto delle tecniche che vanno in cerca del minimo globale lo trovo comunque e quelle sono gli anticipo le funzioni cosiddette convesse per cui riusciamo molto bene a risolvere il problema e l'ottimo locale è anche globale poi ci sono tutta una serie di funzioni come quella prima che oscillava in cui abbiamo tanti minimi o massimi beh lì andiamo in cerca di un minimo che probabilmente non è quello globale però se riusciamo a farlo in maniera agevole dove agevole intendo efficiente da un punto di vista computazionale e posso anche fare più run a quel punto partendo da dei punti diversi perché vedremo sono metodi iterativi che partono da dei punti di partenza della funzione a quel punto ci può anche andare bene a ricerca di minimi locali scusatemi e magari anche fermandoci a un minimo locale come vi dicevo prima non necessariamente dobbiamo trovare per forza il globale ma magari il sistema funziona bene lo stesso perché l'obiettivo nostro è un sistema che nella pratica funzioni e quelle funzioni di costo qualche volta poi vedremo approssimano di fatto il concetto finale che noi vogliamo che è quello di una corretta classificazione o di una corretta regressione eccetera quindi non dobbiamo dimenticare l'obiettivo finale e molto spesso in realtà non abbiamo la necessità di arrivare all'ottimo globale anche se è chiaro che quello è auspicabile e allora che cosa si fa? Quello che si fa si comincia quello che si è fatto è cominciare a ragionare in termini di dire riusciamo a costruire un metodo di ottimizzazione locale ci può andare bene comunque perché magari con questo riusciamo a scalare la dimensionalità e allora ci va meglio cioè rinunciamo la pretesa di arrivare all'ottimo globale per andare in cerca dell'ottimo locale e però riusciamo a farlo non per n uguale a 3 uguale a 5 ma anche per n uguale a 1000 100.000 1 milione 20 milioni eccetera quello che fanno è che si fa effettivamente nella prassi comune è proprio quello di andare verso gli algoritmi di ottimizzazione locale e gli algoritmi di ottimizzazione locale hanno tutto uno schema comune che è quello che adesso cominceremo a descrivere che è uno schema che funziona in questo modo noi abbiamo una serie di qui abbiamo l'esempio per comodità di visualizzazione partiremo sempre da esempi a una dimensione che si capisce bene che cosa fa la funzione si riesce a visualizzare bene allora le tecniche di ottimizzazione locale hanno ne esistono vedremo diverse quindi vi anticipo che ne esistono tante ma hanno una cornice comune una cornice che è che è questa che vi descrivo adesso cioè lavorano prima cosa tramite una serie di step sequenziali di minimizzazione quindi partono da un punto iniziale e poi procedono e ripetono la stessa la stessa cosa più volte e partendo da un punto iniziale punto iniziale è che ad esempio è questo il punto che identifichiamo come W0 come lo scegliamo? supponiamo di sceglierlo casualmente oppure se abbiamo qualche motivo per cui sappiamo che c'è un miglior punto di un altro da cui partire possiamo ovviamente scegliere ma tipicamente sarà qualcosa di casuale almeno in prima battuta poi si possono fare anche qui dei ragionamenti partendo dal punto iniziale si va a vedere qual è il valore che assume la funzione in quel punto dopodiché si procede in sequenza cercando di di andare in discesa sul profilo della funzione e il punto di come andare in discesa è quello che distingue poi i vari approcci che vedremo ci sono diversi algoritmi però fondamentalmente cercare di identificare una direzione di discesa per cui quello che accade è che se parto da G di W0 e poi vado a finire in W1 beh io quello che voglio è che G di W1 sia minore ovviamente uguale uguale a G di W1 e poi una volta che sono andato a finire in G di W1 lasciamo lo strettamente minore perché sostanzialmente se è uguale non ci dà un grande vantaggio dopodiché possiamo andare nel punto W1 e da lì muoverci di nuovo in discesa verso un punto W2 e l'obiettivo è trovare un punto che sia in cui la funzione ha un valore più basso andare avanti così fino ad arrivare a un punto WK che ha la caratteristica per cui G di WK è maggiore a sua volta scusatemi inferior è inferiore ovviamente ma G di W K meno 1 questo significa che in maniera iterativa noi andiamo a scegliere una serie di punti K in cui andiamo a identificare una sequenza di punti che progressivamente scendono nel profilo della funzione e questa è la caratteristica che hanno in comune questi algoritmi che hanno algoritmi di ottimizzazione locale intrinsecamente perché in questo caso è chiaro che io qui ho un unico minimo locale che è anche un minimo globale se avessi una funzione fatta così e qui sale e poi riscende così è ovvio che se io partissi con questa tecnica da questo punto avrei una possibilità magari di andare in una direzione di discesa mi porta qua e identificerei questo che è un minimo locale non più globale però come vi dicevo prima questo è un prezzo da pagare per cercare di provare a risolvere a rimuovere quel problema della dimensionalità ci siamo? Sì per esempio le condizioni di terminazione poi ne parleremo però sono diverse posso decidere di farlo terminare fissando il valore massimo di iterazioni cioè io posso dire k e faccio mille iterazioni poi mi fermo e questo dipende anche da quanto è dispendioso quale tempo a disposizione ho quali risorse computazionali ho oppure come dicevi correttamente io arrivo a un punto in cui ad esempio questo è il minimo e non riesco più a migliorare e quindi dico ok sono arrivato nel minimo locale fermo e mi fermo però potrei avere speso prima di arrivare qua il budget computazionale che mi sono dato ok allora va bene direi che possiamo andare avanti e quindi se volessimo descrivere appunto questo in maniera più generale il questo approccio ebbene questo approccio è un approccio che procede appunto in questo modo si parte più generale perché lì eravamo in una dimensione adesso qui ragioniamo in più dimensioni quindi partiamo da un vettore w0 che mi dà le coordinate del punto di partenza il punto cruciale sarà identificare quella che viene chiamata una direzione di discesa allora la direzione è in generale un vettore noi ci muoviamo in uno spazio immaginate già su due dimensioni no? come guardate questa figura vedete che qui parto da un punto w0 e poi devo identificare un vettore di 0 che sommato a w0 mi porta nel punto w1 se sono in due dimensioni sono in un punto che è identificato da due coordinate ci sommo un vettore bidimensionale e ottengo un altro punto in due coordinate l'aspetto chiave è l'identificazione di questa direzione di discesa valida e adesso poi ci ragioneremo però intanto ammesso che io possa trovarlo posso sommare al punto w0 di 0 e trovo un nuovo punto w1 w1 se questa è una direzione di discesa valida mi porta in un punto in cui la funzione è più bassa a quel punto io posso ripetere la stessa cosa e dire identifico un vettore di discesa v1 che sommato a w1 mi porta nel punto w2 e il punto w2 è un punto che a quel punto scusate la ripetizione ha di nuovo un valore più basso della funzione e poi vado se le cose vanno come devono andare posso andare verso w3 e così via e muovermi lungo il profilo della funzione qui abbiamo una rappresentazione in realtà qui siamo in una rappresentazione tridimensionale e anzi no scusate è bidimensionale pardon e queste sono quelle che vedete qui è il profilo della funzione come curva di livello le curve di livello questo ci capiterà di vederlo adesso quindi vale la pena anche nella prossima lezione insomma nelle lezioni ma già a partire da oggi che seguiranno quindi vale la pena spenderci adesso un minuto di di tempo allora le rappresentazioni grafiche che faremo ovviamente hanno il limite di essere al massimo tridimensionale ok molto spesso quando abbiamo quindi noi riusciamo a visualizzare funzioni al massimo di due variabili perché andiamo poi nella terza dimensione con il valore che prende la funzione molto spesso quello che si fa è per rappresentarla direttamente in due variabili fare una rappresentazione cosiddetta curve di livello con le superfici di livello che sono se qualcuno diciamo ha un po' di dimestichezza con le cartine quando si va a fare una passeggiata in montagna ci sono le isolinee no? cioè vi rappresentano sulla carta quelli che sono i profili della montagna tramite delle curve che sono le curve di livello che vi dicono dove l'altitudine è sempre la stessa lungo quale percorso è come se voi tagliaste il profilo della collina o della montagna con dei piani orizzontali e lungo quei piani intersecate la superficie e ottenete queste curve di livello qui accade la stessa cosa convenzionalmente troverei qui la convenzione è che questa area qua ha un valore un colore più scuro di questa di questa di questa e poi di questa che è la più chiara perché scendiamo verso livelli più bassi come se questo fosse una sorta di imbuto di scodella insomma e noi ci muoviamo verso il minimo che sta nel C esattamente e questa è una rappresentazione che comunemente viene utilizzata questo giusto per dirvi perché poi le ritroviamo anche dopo le visualizzazioni questa è questa intanto messa lì così come come segna posto diciamo quindi l'ultima cosa che rimane da da da sottolineare è che ripetiamo questo processo troviamo k punti lo ripetiamo k volte troviamo quindi k punti in k in k passi questo è lo schema generale degli algoritmi di ottimizzazione locale che vedremo quello che cambia è l'identificazione della direzione di discesa cambia un po' che sono qui non definite ovviamente e che rimandiamo alle varie tecniche però lo schema generale è questo va bene? ok quindi qui cominciamo con una cosa che vi volevo dire sempre a proposito degli schemi di ottimizzazione locale è che le tecniche differiscono come ricariamo appunto il vettore di discesa e fondamentalmente lì si applicano tecniche di ordine vedremo 0, 1, 2 quindi qui partiremo dalle tecniche di ordine 0 e vedremo cosa riusciamo a fare poi lo estenderemo e vedremo anche tecniche di ordine 1 e 2 ok allora il generico passo di questa tipologia di approccio è questo è evidenziato qua io allora abbiamo detto che wk lo ottengo a partire da wk meno 1 che è l'iterazione precedente il valore che avevo trovato all'iterazione precedente più il vettore di discesa di k meno 1 il vettore che identifica la direzione di discesa quello che si fa comunemente è moltiplicare questo vettore di discesa per un fattore che viene chiamato alfa per una serie di motivi che adesso pian piano si chiariranno cioè io identifico un vettore e quel vettore ha una sua ampiezza ecco io voglio poter scalare il passo di quanto mi muovo di un fattore che dico io ok e quindi si moltiplica per un fattore alfa questo fattore alfa viene chiamato anche learning rate in inglese il tasso di apprendimento perché tasso di apprendimento perché tramite quel valore alfa vedremo che noi riusciamo a regolare qual è la lunghezza del passo che facciamo nell'algoritmo di minimizzazione cioè quanto mi muovo più o meno lontano a partire da un punto verso un altro punto perché chiaramente aumentando alfa io vado più lontano diminuendo alfa rimango più vicino perché poi vi anticipo questo vettore di discesa verrà normalizzato in modo da avere lunghezza unitaria quindi è alfa che regolerà quanto ci muoviamo questo fattore di scala è un fattore importante negli algoritmi di ottimizzazione e si chiama tasso di apprendimento proprio perché ci dice quanto rapidamente il nostro sistema può può apprendere nel suo processo nel suo algoritmo perché non dimentichiamo che noi stiamo minimizzando la funzione di perdita minimizzare la funzione di perdita significa produrre i parametri ottimali per il nostro comportamento voluto import output se alfa aumenta questo processo è più veloce perché io vado in meno passi vicino al minimo perché faccio dei passi più lunghi se diminuisce ci devo mettere più passi e quindi il mio apprendimento è più lento implica più passi ecco perché si chiama tasso di apprendimento poi vedremo anche che cosa implica però avere questa velocità di apprendimento maggiore o minore o minore perché in alcuni casi ci fa mancare il minimo e questo non lo vogliamo di questo parliamo tra poco allora qual è la distanza che algoritmi di questo tipo riescono a a fare a percorrere quando fanno un passo generico quindi al passo cappesimo il nostro algoritmo che distanza copre cioè questi schemi di ottimizzazione locale quale tipo di distanza riescono a coprire al cappesimo passo allora la distanza è proprio una distanza in senso euclideo cioè abbiamo dei vettori e misuriamo e abbiamo dei punti in uno spazio ragionati intanto in due dimensioni la distanza tra due punti è una distanza euclidea ma la distanza euclidea la potete applicare anche in uno spazio a tre dimensioni a quattro a cinque a venti quello che volete ok poi adesso vi do un breve riepilogo delle definizioni di distanza che vengono più utilizzate che vedremo ci capiterà di incrociare lungo lo svolgimento del corso però ecco intanto dando per scontato che qualcuno abbia in memoria il concetto di distanza euclidea e questo viene solitamente identificato noi faremo così con questo simbolo prenderemo la diciamo l'ampiezza in fisica sarebbe l'intensità di quel vettore e prendiamo con questo simbolo la norma ok la norma di quel vettore vedete c'è un 2 questo 2 identifica proprio la norma euclidea ok e viene chiamata distanza vi anticipo L2 poi vi do un breve riepilogo dei tipi di distanza che possiamo incontrare con la loro definizione però intanto è il concetto di distanza quindi è un vettore quando noi identifichiamo prendiamo un vettore x e scriviamo così intendiamo la ampiezza del vettore il vettore caratterizzato da direzione verso ampiezza intendiamo la lunghezza di quel vettore ok per cui se io dico sono in uno spazio bidimensionale e questo vale 1 questo vale 1 questo punto qui ok mi rappresenta il vettore x che posso indicare così che ha coordinate 1 1 giusto qual è l'ampiezza di questo vettore il teorema di Pitagola l'artice di 2 ok che è esattamente questo valore ok vediamo va bene la distanza proprio il concetto di distanza del teorema di Pitagola la stessa cosa la potete estendere in più dimensioni adesso poi vi do ripeto due due formulette così almeno ve le tenete generiche per per il caso nelle dimensioni e per altre tipologie di distanza allora con questa notazione che cosa intendiamo intendiamo che abbiamo due vettori wk e wk-1 sottrago l'uno dall'altro e prendo la norma questo significa che mi dà che cosa mi dà la distanza che ho percorso per andare da il punto wk verso il punto wk-1 scusate dal punto wk-1 ovviamente verso il punto wk arrivo un attimo non è dk-1 è dk-1 moltiplicato per alfa se se se ci mettiamo alfa sì assolutamente sì è quello stiamo semplicemente ridicendo la stessa cosa è importante perché è importante aver presente perché poi da queste notazioni vi scendono una serie di cose interessanti quindi la distanza effettivamente se la vado a scrivere wk-1 più alfa di k-1 che è il nostro wk ci tolgo wk-1 e quello che ottengo che questi si semplificano ed è alfa lo posso portare fuori ed è di k-1 la dimensione è quel punto esattamente però ecco muoverci un pochino di più spenderci un pochino più di tempo secondo me vi fa catturare meglio alcuni aspetti che poi non rischiano di rimanere sotto traccia allora il primo aspetto è quello che dicevo prima che alfa vi permette un po' di andare a modulare se moltiplico per un valore e già lo posso moltiplicare per un fattore che può essere 2, 5, 10, 0, 0, 5 il problema è come scegliere alfa e questo è già un primo aspetto solitamente è un valore fisso un valore abbastanza piccolo 10 alla meno 3 10 alla meno 2 in realtà si cerca di procedere per passi abbastanza piccoli però non è l'unica strategia ecco scegliere un valore fisso adesso poi vedremo un'altra strategia vi anticipo che la scelta di alfa nel machine learning rientra appunto in quello che è appunto una scelta che mi addestra un sistema a disposizione e questo parametro viene chiamato in realtà un iperparametro quando in machine learning si parla di iperparametri si parla di parametri del problema che in realtà vengono detti iper perché sono dei parametri per ottenere che fanno parte diciamo del metodo che ci porta a ottenere poi il nostro modello nel nostro modello ci sono i parametri che sono i valori di W tutti gli altri parametri che non sono parametri del modello vengono detti iperparametri quindi alfa è quello che viene detto classic medium esattamente esattamente ed è importante perché nei sistemi di machine learning per lo sviluppo del sistema di machine learning sono diversi di questi iperparametri che sono anche lì scelta del progettista e è una scienza abbastanza empirica nel senso che anche qui molto spesso ci sono delle regole generali ma spesso e volentieri si procede anche per tentativo ed errore però alcune regole generali si possono dare e quindi allora adesso cominciamo a vedere un primo esempio di algoritmo di ottimizzazione locale che è un algoritmo che riprende il concetto di campionamento casuale e vedremo un po' come fare cioè la direzione di discesa come la troviamo un modo ci può venire in mente è provare a sfruttare appunto il meccanismo di generazione di numeri pseudo casuali che abbiamo a disposizione all'interno di un calcolatore per generare un certo numero di direzioni casuali potenziali numero quanti numero fisso altri per parametro vedremo che anche questo problema esattamente come l'ottimizzazione globale soffre del problema della dimensionalità cioè scala male quando perco la dimensione dell'input però è utile perché ci permette di introdurre dei concetti che poi utilizzeremo dopo quindi diciamo è da un punto di vista pedagogico ci serve didattico diciamo per per per introdurre alcuni ulteriori concetti va bene quindi come funziona questo tipo di di algoritmo allora prima di fare questo volevo un attimo ero in debito con voi del concetto di distanza allora quella che viene chiamata quindi ve ne scrivo qua quella che viene chiamata norma euclidea o norma di tipo distanza di tipo L2 che dice norma L2 o distanza L2 è quella che vi ho detto prima si indica così del vettore x la radice quadrata della sommatoria per n piccolo che va da 1 a n grande di x con n al quadrato ho un vettore x che ha componenti x1 x2 fino a x con n dove n grande è la dimensione del mio spazio sommo i quadrati dei componenti estraggo la radice e ottengo la magnitudo diciamo del vettore x la magnitudo di quel vettore centrato nell'origine che abbiamo disegnato prima coordinate 1 e 1 era radice di 2 infatti perché ci sommava era un vettore che aveva coordinate 1 e 1 ci sommava 1 più 1 che fa 2 e prendevamo la radice questo è il classico concetto quest'anno qui ci muoviamo in uno spazio n dimensioni e definiamo in quello spazio un concetto di distanza questa distanza è la tradizionale distanza euclidea nello spazio bi e tridimensionale in cui ci muoviamo tutti i giorni esattamente esattamente esattamente però è un concetto che ovviamente noi estendiamo a partire dalla nostra esperienza quotidiana che è lo spazio tridimensionale ma lo possiamo estendere a uno spazio n dimensioni è un oggetto matematico astratto quanto volete non riusciamo a visualizzarlo ma è di fatto però possiamo definire in questi spazi vettoriali altri strumenti altri diciamo concetti di norma o di distanza matematica per esempio un'altra distanza che ci capiterà di incontrare qualche volta anche se questa è quella che vi annuncio utilizzeremo più spesso però qualche volta ci capiterà di utilizzare quella che viene chiamata anche norma di tipo L1 e si indica allo stesso modo solo che ci mettiamo un 1 per identificare l'intensità la magnitudo l'ampiezza di quel vettore ed è nulla di più che la somma su tutte le componenti del vettore del loro valore assunto ok? questa è la norma di tipo L1 per cui se io dico che mi muovo utilizzo questa norma sto intendendo esattamente quel tipo di concetto per quel vettore poi diciamo ce ne sono altre tipologie un'altra che qualche volta viene utilizzata è la cosiddetta norma L infinito quindi norma L1 norma L2 la norma L infinito e viene indicata chiaramente in questa notazione ed è questa si prende il massimo tra tutti scusate ho scritto malissimo prende il massimo da tutti gli n del valore assoluto di x quadrati ci capiterà un paio di volte di menzionare queste per determinate applicazioni lo vedremo più avanti per il momento ragioniamo su questo è la tradizionale distanza qui di la città va bene allora come lavora il metodo random search lavora in questo modo posso cancellare avete mi fermo un attimo così finite di copiare publisher la città torno l'inizio e la città perietnam lavora vediamo posso cancellare allora come funziona questo algoritmo? beh, al passo generico K quello che fa è andare a campionare un certo numero di direzioni quante? ma, supponiamo che questo numero di direzioni lo chiamiamo P, P grande, anche questo sarà un hiperparametro del nostro problema, noi siamo nel punto WK-1, campioniamo un certo numero di direzioni, il che significa che generiamo casualmente dei vettori numerici che rappresentano altrettante direzioni possibili in quello spazio e che cosa facciamo? Andiamo a selezionare quella che è più promettente, cioè andiamo a prendere, siccome ogni direzione la chiamiamo, definisce un vettore di direzione D che chiamiamo D, P dove P è minuscolo perché ce n'ho di questi P un numero P grande, quindi P piccolo che è questo va da 1 fino a P grande che è quest'altro, ok? Ogni direzione D con P definisce un punto potenziale candidato di successivo che è WK-1 più il vettore D con P, ok? Siccome il genere era caso alcuni mi possono portare in salita, alcuni in discesa, alcuni mi lasciano lo stesso livello, non lo sappiamo, è come se io fossi sul profilo di una collina e comincio bendato a dire mi muovo e adesso faccio un passo avanti, potrei andare in discesa, potrei andare in salita, potrei rimanere uguale. Ovviamente ne ho un certo numero, 3, 5, 10, 100, quello che vogliamo e quindi tra questi che cosa vado a fare? Vado a prendere quello che mi porta più in basso, quello che mi porta in discesa verso il profilo della funzione, quindi quello che andiamo a scegliere è chiaramente il migliore, cioè quello che ci fornisce la valutazione più bassa, cioè quello che chiamiamo S, che è che cosa? L'argmin, allora argmin è una funzione che viene utilizzata spesso nell'ambito del machine learning perché significa, che cosa sta a significare? È una funzione che vi dice, ok, tu hai questa funzione G, di questa funzione vuoi cercare un valore più basso, il valore più basso tra tutte queste possibili alternative è l'argmin, quindi è l'argomento che minimizza questa funzione. Quindi io ho una serie di alternative, supponiamo che P grande sia 10, P piccolo va da 1 a 10 e io provo il valore della funzione nel caso 1, nel caso 2, nel caso 3, nel caso 4, nel caso 10. Il valore più basso di queste è quello che chiamo S, quindi S mi definisce un indice, S è un indice, è riferito a questo, ecco cosa vuol dire l'argmin, quindi S è un indice, supponiamo che il valore più basso sia 3, S vale 3 e a quel punto vado a vedere che cosa, se WK-1 più D3, la direzione 3, mi porta in un punto più basso di quello precedente, allora accettiamo la mossa e ci muoviamo con vettore di discesa di con S. Ovviamente il caso è il caso per cui potrebbe essere che io non trovi alcuna direzione di discesa valida e a quel punto ho due opzioni, o mi fermo o ripeto. Penso di sì, dovrebbe essere così. Certo, sì sì, fino a così. No, non penso, sono sicuro. E quindi qui c'è scritto appunto quello che si fa, ci si ferma oppure si prova un altro lotto di direzioni. Ok, qui c'è un esempio, vediamo questo. Allora, questo esempio è un esempio in cui abbiamo di nuovo una funzione che è la funzione quadratica. In questo caso P è uguale a 3, l'abbiamo scritto qua, in principio mi devi riscriverlo, P è uguale a 3. Vedete che cosa fate? Poi abbiamo la nostra funzione quadratica, partiamo da un punto W0, e campioniamo casualmente 3 direzioni possibili che corrispondono a questi 3 vettori. Questo, P1, P2 e questo è il giallo. Questo giallo è, supponiamo appunto che, faccio notare che qui saremo 4, quindi siamo su questo punto. Chiaramente se mi muovo di qua vado verso punti che stanno più in alto, se mi muovo di qua vado verso punti che stanno probabilmente più in basso, ma sicuramente se mi muovo verso questa direzione sono stato abbastanza fortunato e ho una direzione più promettente di discesa, e quindi se questo è 1, se questo è 2, se questo è 3, quell'argmin vale 2 in questo caso. E io da W0 mi sposto in W1. Qui ripeto la stessa identica cosa, campiono tre direzioni casualmente, supponiamo che tra queste ci sia questa gialla che mi porta verso W2 e così via. E io comincio a scendere in profilo di questa, a discendere in profilo di questa superficie e andare verso il mio. Com'è? Io guardo il mio. Sì, sicuramente, sicuramente, assolutamente. Questo discorso regge finché siamo tre dimensioni, cinque dimensioni, perché poi anche più uguale a mille, quando siamo in mille dimensioni, c'è il problema di dimensioni. Quindi questo è proprio... Sì, perché lo spazio diventa talmente sparso, i punti per cui non si riesce a prendere nessuna direzione valida. Quindi vi anticipo il problema è questo, ecco. Se no, in bassa dimensionalità funziona assolutamente. Allora, qui c'è un attimo una digressione su un aspetto che prima avevamo anticipato, possiamo controllare esattamente la lunghezza di ogni passo, perché il vettore di direzione ha una sua ampiezza, no? Volendo. Quindi quello che si fa, nel senso che è una direzione, io genero dei numeri a caso, ho una direzione molto ampia, molto bassa. Allora, quello che si fa tipicamente è generare un vettore a caso e però normalizzarlo, cioè normalizzare il vettore di discesa in modo che la sua distanza sia 1. Come si fa? Si divide ogni coordinata per la dimensione appunto del vettore. Quindi quello che vale la radice di 2, se io lo normalizzassi avrei... Prima avevo componenti 1 e 1, una volta che l'ho normalizzato diventa 1 su radice di 2 fratto 1 su radice di 2. Infatti questo, se prendete la norma di questo, fate il quadrato di ogni componente, vi viene un mezzo più un mezzo che tra uomo, per cui diventa normalizzato a 1. Quindi quello che si fa è si normalizza il vettore delle distanze a 1. Dopodiché, se ripeto, no? Voglio sapere quanto ho viaggiato dal passo k-1 al passo k-2, lo calcolo in questo modo, come la norma di questo vettore, che è il vettore differenza. Quindi, di nuovo, Wk è scritto così, e questo significa di nuovo che questi si elidono, è pari di un uomo alla norma del vettore, lo dicevamo prima di, ma in questo caso ho imposto che il vettore che ho generato abbia norma unitaria, quindi vuol dire che mi sono mosso di un'unità, un passo k-1. Ma questo significa che se invece che utilizzare la versione base, utilizzo quella con il learning rate, e ripeto gli stessi passaggi, questi vanno via, rimango con la norma di alfa d, alfa è uno scalare, vuol dire che lo posso portare fuori dall'operatore norma, significa che alfa mi dice esattamente di quanto mi sono spostato. Ecco come si fa. E quindi, qui insomma, l'importanza di questo iperparametro, che appunto viene chiamato tasso di apprendimento, è grande o piccolo? Allora, se io lo scelgo piccolo, mi muovo in maniera molto fine, lungo la superficie, o l'iper superficie del mio problema. E quindi, diciamo, ho più sotto controllo quello che sto facendo. però ci metto più passi per arrivare verso il mio. Se alfa lo scelgo grande, ci metto meno passi, quindi da un punto di vista computazionale spendo meno, tipicamente. Però quello che rischio è, nel profilo della funzione, di cominciare ad andare a zigzag. E pensate un attimo alla... Poi vedremo, ci saranno anche delle slide, ci sono, non ricordo male, che proprio spiegano questo. Però, supponiamo di doverci muovere lungo questa funzione. E se io scelgo un alfa abbastanza fine, vuol dire che da qui mi muovo qui, qui, qui, qui, qui, quindi mi sposto lungo la superficie qua. Però se parto da qua, e il mio alfa è molto grande, e mi fa andare qui, e io comincio magari a rimbalzare qui. Poi magari scelgo la direzione di discesa e un'altra, è questa qua. Poi andiamo che alfa sia di nuovo grande, ritorno qua, comincio a rimbalzare di qua e di là, e manco il minimo. Quindi si tratta di trovare un giusto compromesso tra un dispendio che mi implica nel processo di... una convergenza lenta, che è determinata da un learning rate basso, e il fatto di andare più veloce, ma con il rischio di approssimare in maniera molto grossolana il minimo, di andare a rimbalzare in zone del profilo della funzione che non vogliamo. Poi ci sarà, ripeto, un esempio tra un po' di slide, ci torniamo sopra su questo, però intanto ve l'ho anticipato. Qui c'è un esempio di una funzione di nuovo quadratica in due dimensioni. E... una funzione che è data dalla somma dei quadrati delle due componenti più un termine costante 2. Ok. Con questa funzione, che è questa qui, un algoritmo di tipo ricerca casuale farebbe una cosa di questo tipo. Supponendo di partire da un punto... Allora, qui c'è un piccolo mismatch tra... questa notazione, qui le coordinate vengono chiamate W1, W2, e qui vengono chiamate W2, W1, quindi sostituite. Ok. se non è coerente. Va bene. Però al netto di questo un algoritmo di tipo random search che parte, ad esempio, da questo punto, ok, questo punto verde, che è qui, in quest'altra rappresentazione. Qual è la differenza tra sinistra e destra? Beh, qui abbiamo la funzione di due variabili rappresentate in tre dimensioni, che è questa superficie, che è questa paraloga alla tridimensionale. Qui abbiamo la rappresentazione che vi dicevo con le curve di livello, viene chiamata in inglese contour plot, come se noi andassimo ad affettare questa superficie con tanti piatti. E abbiamo le curve di livello, cioè se ci muoviamo lungo questa curva, in una di queste curve, la funzione ha lo stesso valore. Da più scuro a più chiaro, valori più bassi. Noi partiamo dal punto verde, che è questo, è questo qua, e lì generiamo un certo numero di valori casuali. Questo numero di valori casuali, quindi in questo caso partiamo, mi sembra, dal punto con coordinate W0 e 3, 4. Quindi è il punto di partenza che ha coordinata 3, sì, e 4. Vedete? e ci si muove con un certo numero di direzioni casuali. Stavo cercando di recuperare se il valore di P che era stato utilizzato in questo caso non ce l'ho notato, però scegliamo un certo valore di P, scegliamo un certo possibilmente ampio, e sicuramente tra quelli ce ne sarà una di quelle direzioni che ci porta verso quest'altro punto che è un punto più bassa di scelta, corrisponde a un'altra coppia di coordinate. Da qui ripetiamo lo stesso concetto, generiamo un certo numero di direzioni casuali, se ne genero mille sicuramente ho la possibilità di pescare quest'altro punto che mi porta nella direzione di questo giallo, e via via via finché non sono arrivato qua, che è effettivamente il minimo. e non mi ricordo quali erano, perché poi anche qui quali erano il learning rate, me ne ero notato da qualche parte, ma probabilmente, o meglio, non me l'ero annotato, e non mi ricordo adesso che cosa, quali valori fossero, se lo recupero ve lo dico, ma è abbastanza poco importante, importante che sia chiaro il metodo. E va bene, io direi che intanto per oggi abbiamo visto parecchie cose, per cui adesso se ci sono domande, poi la prossima volta ripartiamo da qua. Ah ok, no, scusate, prima di ripartire, un attimo, questo è, guarda un attimo cosa c'è dopo. Una cosa importante che non vi ho detto è che chiaramente io voglio sapere, avere sotto controllo che cosa succede nel mio processo di minimizzazione. E qui ce l'ho sotto controllo se ho il grafico della funzione, ma chiaramente il grafico della funzione non ce l'abbiamo a disposizione quando n è maggiore di 2. Allora quello che si fa è andare a tenere traccia di questo, che è il valore della funzione del punto WK e costruire quello che viene chiamato history plot, cost plot, insomma, che è un grafico della storia della minimizzazione della funzione. Che cosa vuol dire? Vuol dire che quando parto dal passo zero io sono qui e ho questo valore della funzione, se vado in discesa al passo uno avrò quest'altro ad esempio valore della funzione che se sono andato in discesa è più basso, poi vado a prendere un valore della funzione più in basso, eccetera, eccetera, fino ad arrivare dopo cinque passi al minimo. Quindi quello che si fa tipicamente quando si va a minimizzare queste funzioni si tiene conto, cioè spesso e volentieri nei framework che fanno machine learning che fanno ottimizzazione c'è un cruscotto per la possibilità appunto di tenere traccia della funzione di costo e si vede al variare del numero di iterazione come varia la funzione di costo e se questa scende siamo abbastanza sicuri che stiamo scendendo siamo sicuri che stiamo scendendo nel profilo della nostra funzione della nostra loss function e siamo quindi abbastanza sicuri che stiamo andando in una buona direzione cioè abbiamo buona probabilità di andare a pescare dei parametri che siano ragionevoli alla fine del processo. Bene, da qui poi la prossima volta ripartiamo e andremo avanti. Adesso non so se avete domande se ci sono anche da remoto domande ovviamente possiamo fermarci se no fermiamo la registrazione. Tutto chiaro, grazie. Grazie. Grazie. Grazie.