Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. il primo colonno quando facciamo i uguali meno due due un tra poco il tra poco dove un ue uguale a a 1 meno norma 1 e 1 quando facciamo i a prima ne questo norme a 1 poi 0 e poi c'è questo questi potrebbero essere 0 in generale e abbiamo questo matrice qua allora prossimo passo allora e chiamiamo questo p1 poi p2 lo definiamo in questo modo che abbiamo questa struttura 1 qui 0 0 poi qui sarà chi due in cui adesso i due è uguale a i m meno 1 meno due due trasporto un ue in cui due qui è uguale a il primo colonno di questo e questo blocco questo è tutto quindi questo primo colombolo chiamiamo 21 quindi ma questo è è uno dimensione m meno 1 capito tipo questo a questa forma uno vero ma anziché qui dove c'erano m queste erano vettore dimensioni n qui questo è un vettore dimensione m meno 1 quando facciamo allora c2 che uno abbiamo adesso a 1 poi c'erano questo è un vero qui poi abbiamo a 1 2 e c'è 0 0 0 0 0 e adesso abbiamo abbiamo adesso a così quindi adesso p3 possiamo dire in questo modo adeptamenti o di questo blocco qua esatto e quindi ingegneria questo luogo Questo, quindi continuiamo in questo modo fino a che non avremo diagnolizzato tutto. E vediamo quando facciamo questa applicazione di questo proiettore, quindi se guardiamo un attimo di questo, avevamo qui una cosa che è tipo A2, poi c'è questo in là, c'è questo in 0 e c'è questo in lì. Se lo moltiplichiamo, i 0, 0, t3, vediamo che non disturbiamo questa parte, la parte gifreggia triangolare. In generale, ok, potremmo avere, quindi se non ci chiediamo, avviamo, A1, A2, questo, poi in generale, ok, 0, questo non va la giunta di brutto perché c'è una broca di 0. Questo, ok, ci potrebbe essere qualche compito, non lo diciamo là, ma poi qui abbiamo A2, poi 0, 0, e quindi abbiamo detto. Quindi vediamo così, continuando, ogni volta che applichiamo questo proiettore, prendiamo una nuova colonna triangolare e spostiamo questa cosa non triangolizzata in questo angolo. E questo è più efficace che sembrerebbe all'inizio, proprio per questo motivo, perché anche se dobbiamo fare questo per ogni singola colonna di A, con ogni colonna successiva abbiamo meno e meno da fare. Perché per tutte le cose, qui, la prima volta c'era questo vettore di dimensione M, poi la seconda di dimensione M, meno 1, terzo M, meno 2, eccetera. Quando raggiungiamo l'ultima colonna, vedremo che abbiamo solo un numero. Quindi questo è importante perché ogni successiva volta diventa più e più facile, più e più piccolo il problema. Quindi questa è l'idea di fare la trasformazione di Householder. Penso che chiederò a voi nei prossimi esercizi una da mano, tipo sarà 3x3, forse 4x4, non ti ucciderà, ma al punto è questo. Successivamente raggiungiamo questa riduzione e non disturbiamo nessuna delle cose già premuralizzate, perché il nuovo proiettore per il prossimo colonna lo definiamo ai blocchi, è tipo questi blocchi che abbiamo già gestito, abbiamo sempre una matrice dell'identità, quindi non tocca, non disturba la struttura desiderata per il lavoro che abbiamo già fatto. Quindi questo processo ha senso a voi. Possiamo fare un esempio? No, penso che preferirei che voi fate l'esempio sugli esercizi, sui compiti. No? No, penso che ci sta prendendo tra l'amici prima, i 2x3, i 1x3. Sì, ogni singola volta però corrispondono ad una sezione alla matrice che sta rinficolendo più e più e più e più. Sì. Sì, potrei anche fare un'esempio. Sì, esatto. Però la cosa che voglio che fate presente è sempre che sta diventando sempre più piccolo. Tipo P1 è una cosa di tutta la matrice, poi ogni volta il blocco diventa più piccolo e quindi il proiettore fa la sua azione su una partizione, la partizione della matrice che sempre sta diminuendo nelle dimensioni. E questo è come otteniamo, è il modo più comune di ottenere la fattorizzazione QR. Quindi diciamo che questo è l'unico algoritmo che parlerò in dettaglio, ma esistono altri modi che in alcune situazioni specifici potrebbero essere più adatti. Io dico che questo è il sub di fattorizzazione di QR, tipo qualsiasi specie di terreno, qualsiasi applicazione forse non è il migliore ma sempre funziona. Invece forse si trova in una situazione in cui potrebbe convenire più... Una volta c'erano i smart, adesso si vede non meno e meno male, adesso si vede anche i algo, che tipo forse è per una cosa più specifica, super iper specifica. Dico, vivere dentro città potrebbe essere la migliore scelta, ma non è una macchina che è la cosa migliore a fare qualsiasi cosa. Quindi questo per un sistema generale è un modo di trasformare molto facile di implementare, molto facile di gestire. Invece altre cose potrebbero essere più specificamente eratti. In generale altri metodi sono più desiderati o forse sono più eratti quando la matrice è già molto sparso, tipo ha una grande concentrazione di zero. Allora, tornando al discorso della seconda parte di questa mattina, la seconda parte della lezione, avevamo... Abbiamo introdotto l'idea del sistema sopra determinati o sottodeterminati, cioè grasso e basso, più incogniti di equazioni. E abbiamo detto che forse dobbiamo avere un altro approccio per questo. Poi abbiamo ricordato che A, N, R, M per N. Allora, gli autovalori, sia di A, sono sempre più grande uguale a zero, stessa cosa per A, A, sposto. Quindi hanno sempre autovalori positivi, o almeno se non sono positivi sono zero. Poi abbiamo sempre che in tutti e due casi che queste espressioni sono simmetrici. E quindi, allora, in tutti e due casi esistono matrici diagonali, che tipo in questo caso lo chiamiamo... esiste U è uguale a I, R per M, quindi questa E sarà M per M, quindi corrisponde di sì, è U di U, trafotto, uguale a U, trafotto, A. E poi qui possiamo anche dire similamente che esiste B, tale che V trasporto U è uguale a U, trafotto, uguale a I, viene usata M, tale che A, a, trafotto, U, D, U, trafotto. Ok, quindi una cosa che possiamo dire questo matrice. Allora, adesso farò un giustifico solo per uno di questi, ma dobbiamo sempre tenere presente che ci sono due di queste cose da formice. A, trasposto A, e A, a, trasporto. Adesso, visto che abbiamo che questo D è un diagonale che consiste di tutti gli autovalori di A, trasposto A, e sappiamo che tutti questi autovalori sono o positivi o al massimo sono zero. Non c'è nessuna cosa di negativa, quindi non c'è nessuna ambiguità se lo definiamo una matrice in questo modo, che lo possiamo chiamare D1 quadrato, che è diagonale, tra che tipo è diagonale, con semplicemente esattamente D, una matrice diagonale, ma anziché avere questi elementi sui diagonali, abbiamo la radice quadrato positivo, che è tipo non è, non c'è ambiguità qui, perché sappiamo che questo autovalore che corrisponde ai elementi diagonali qui sono zero o positivo, quindi non abbiamo questa ambiguità che corrisponde alla situazione in cui non sappiamo quale scegliere il positivo o il negativo. La radice quadrato qui sarà quella positivo. Cosa è questo? Cosa è questo? Cosa è questo? Cosa è questo? Sotto dove? Ho questo I, I, perché abbiamo la matrice D, di diagonale, di automallori, e stiamo dicendo che tipo questi sono questi elementi di D diagonale, è un radice quadrato di I, I, sì. Esatto. Ok, quindi possiamo dire che U, A, trasporto A, è uguale a U di meno uno, di potere un mezzo, e poi, a trasporto, qual è D? E in realtà questi D non sono uguali, perché alcuni hanno dimensioni diversi. Diciamo gli elementi non zero su diagonali saranno gli stessi, però potrebbero essere diversi in generale. Allora, adesso, ok, che cosa facciamo qui? Pensiamo, un attimo, sto pensando dove è il miglior modo di scrivere questo, sarà... Non voglio precedere cose già scritte, che sono pertinenti, quindi... Ok, adesso... Adesso... Adesso... Sia... X long, uguale a A per X. Assumiamo che X è un altro vattore di altro sporto. A, quindi X è tale che... X... X... X... Questo rapporto. E quindi... Ok. Ok. Quindi... Adesso... Moltiplichiamo... Assumiamo che almeno uno... Possiamo assumere che forse qualcuno di alto valore qui è zero, però non tutti. Quindi scegliamo che... X corrisponde all'un di questi alto valori, non zero. Quindi se ne abbiamo... Moltiplichiamo per quei che cosa non zero. Ok. Adesso... Vediamo che... Possiamo... Rimpiazzare... Rimpiazzare... Questo lambda qui... Con questo A per foto albis... Da... La divisione qui... E poi... Al proviso... Abbiamo... Perché... Le matrici... Le matrici... Sono accoccettivi... Con la modificazione... Ma... Abbiamo iniziato con questa espressione... Quindi... Allora... Cosa abbiamo... Dimostrato qui... Se... E... E... E... E... E... E... E... E... E... E... E... Abbiamo... Abbiamo... Sia... Sia... Sia... Sia... Sia... Sia... Sia... E... E... E... E... E... E... Abbiamo... Sia... E... E... Possiamo chiamarlo... Il... E quindi... Abbiamo... Sia... Sia... Sia... Sia... Ok... Facciamo questo... Scaling... Perché... Ricordiamo... Che gli altri vettori... Sono sempre così... A... Che... Uguale a... C... C... C... C... Scegliamo questo... X... Tale... Che... La sua norma è uno... Abbiamo... Che la norma corrispondente... E... Questo... Y... Sarà... Questo... Avrà... Questo... Norma qua... In questo... Il quadrato... Di questo... Alto... E... Quindi... Possiamo definire... X... Qui... Come... A... X... Y... Per questo... Alto... Valore... In... Normalizzazione... Qui... Ok... Quindi... Adesso... Cosa vogliamo dire? Sappiamo che... Tutti questi qua... Corrispondono... Ai veri... Alto... Valori... Vettori... Di... Altra... Trasposto... A... Ok... Ciascun colonno di questo... Trasposto... O di questo... U... È un corrispondente... Alto... Vettore... Matrice... Alto... Questo... E... Come... Facciamo... La costruzione... Della... Di... Adesso... Quello... Che... Vogliamo... Definire... Questo... Come... Liesimo... Colomno... Liesimo... Colomno... Di... Una matrice... Di... Quindi... Di... I... Uguale... Questo... È una costruzione... Quindi... Stiamo dicendo che... Sappiamo che... Se abbiamo questi... Alto... Vettori... Altos... Possiamo... Creare... Corrispondenti... Alto... Valori... E... Alto... Altos... Posto... Utilizzando... Questi... Altos... Vettori... D... Però... L'altra cosa... Che sappiamo... Di questo... Alto... Valore... Alto... Valore... Questi... E che... Sono... In questa... Matrice... Allora... Quindi... Dove... Vogliamo... Arrivare... Consideriamo... Questa... Adesso... A... Di... E... Uguale a... A... Questo è... Dato... Quindi... Se... Multipliciamo... Tutte e due... Dati... Qui... Su... Questa... Matrice... Qua... Un trasporto... Cosa succede? Allora... Un trasporto... A... Qui... Sarà... A... Sì... Ok... Adesso... Questo... Sto solo... Multiplicando... Per uno... Quindi... Per questo... Alto... Valore... Prendo... Qui... E... Qui... Sappiamo... Qui... Che... Questo... E... Questo... E... Questo... E... Un... Autovallore... A... Quindi... Abbiamo... Un... Un... Un... A... A... Trasporto... A... X... Così... Sto facendo... Uguaglianze... Ok... Intimiamo... Questo... Quindi... E' uguale a... Uno... U... E' trasporto... A... Trasporto... A... Gli... X... Che... Uguale a... Uno... U... E' trasporto... A... Trasporto... A... Gli... X... Che... Uguale a... Uno... Lambda... U... E' trasporto... A... A... Trasporto... Qui... Y... Iguale a... I... Ok... E'... Finalmente... Allora... Abbiamo... Che... Un... Un... Questa... Sì... Un... Divomb loose... Another... Purpare... I... Pas... Cris... Cuz... Questa... ... Okay... poi l'altro valore quindi poi abbiamo ecco sì abbiamo per questo un trasposto ma sappiamo che questo da costruzione sarà quindi abbiamo tutto questo è uguale a landa posto ok no che abbiamo definito dovrebbe essere ah sì ok ecco sì perché questo allora perché qui prendiamo un fattore di radice y quindi questo diventa radice y qui però poi prendiamo un fattore di landa in zona c'è ancora questo quindi dovrebbe essere così ok e allora x è sparito perché qui si questo si questo è sparito perché a x uguale poi abbiamo costruito y per questo a x in realtà è uguale ad a y per radice a l'anno perché a c'era dovrebbe essere stato quello quindi abbiamo adesso questo che è uguale a y per un fattore di radice in zona perché hai uguale a facciamo questa sostituzione qui lasciamo stare questo per un attimo questo è la prossima espressione poi sappiamo pure che questo a ha trasposto y è uguale a landa quindi il fine di tutto questo è che abbiamo qui l'anno di u ha trasposto y dice questo perché questo è importante questo è l'idea che abbiamo un trasposto a di se continuiamo questo processo quello che otteniamo queste cose che chiamo sigma che il day e se guattinia avrà questa struttura diagonale l'anno 1 l'anno 2 0 0 0 e cosa sono questi l'anno sono gli autovalori di a trasposto a oppure di a trasposto solo alto valori di questo matrice ha trasposto questa matrice trasposto per se stesso oppure il diverso gli autovalori non 0 abbiamo in comune abbiamo questo costruzione vuoi trasporto a uguale a questo che sono che questa espressione qui che la matrice diagonale e abbiamo fatto con questo argomento vedendo che definiamo 2y quando abbiamo detto che questa è la matrice vu che a questo is non come i sui propri elementi in questo modo abbiamo fatto questa manipolazione per ottenere questa espressione qua che è una perturbazione diagonale abbiamo una cosa che compaia sulla destra che è questo ultraposto poi con questo quindi abbiamo un'espressione diagonale qui perché ripetendo questo per un altro atto valore ci riporterà allo stesso posto e abbiamo questo fu il posto a v che riduce la matrice in una forma diagonale però è un po' di aronare un po' particolare perché questo l'abbiamo costruito non da a ma da queste espressioni che sono fortemente collegati era cioè a ha trasporto era che sono queste cose che sempre esistono che sono sempre quadrati e autovalori saranno sempre sia non esserano sempre non negativi nel senso che potrebbero essere zero ma sicuramente non ci sono negativi mai facendo una manipolazione di base qui abbiamo un po' uguale a poi però possiamo tranquillamente scrivere così ma abbiamo un'impressione del genere questo è la decomposizione io io io io sono io lui mi ma a a ma oh dove 1 1 ue e m e ue v r n n ortogonale finalmente i però i oppure o forse per essere anche così dove qui qui e no questo dove dove dove e e a e finalmente e questo è importantissimo cud i radici quadrati positivi dei autoballori ti ha presposto a allora questo quindi guardiamo un attimo di tutti questi pezzi perché sono tutti importanti abbiamo una decomposizione di una matrice in tre matrici specifici questo v trasposto che ortogonale questo che è ortogonale e questa cosa qui questa sigma che è diagonale in un certo senso cioè avrà sempre questa forma o orte di terra la forma della matrice se la matrice basso e grasso avrà questa forma qua se ha un marco a questa forma qua se è quadrato allora una cosa importante di capire questo è definito che non ha trasposto e abbiamo usato a posto ma era a posto per costruirlo e abbiamo sfruttato che questi matrici sono sempre altri posto a saranno sempre quadrati avranno sempre autovalori positivi e saranno sempre simetrici quindi hanno queste varie proprietà cioè l'ortogonalità di autovalori la positività di ero non negatività di autovalori eccetera eccetera però alla fine l'abbiamo messo tutte queste insieme ma direi una cosa non di uno di queste due matrici a trasposto a o a posto ma a stesso questo è una decomposizione definito per a e un grande vantaggio a questo rispetto alla di condizione più familiare noi quello di atto voi e questo è definito per qualsiasi matrice di qualità di forma quadrato rettangolare basso rettangolare alto c'è sempre per qualsiasi matrice una corrispondente decomposizione ai valori singolari allora ci sono altre proprietà molto interessante di questo dei composizioni che voglio che parliamo o come è il rango di quando diceva quindi c'è un numero di questi auto volo di questi valori singolari si chiamano questi balloni singolari quindi sono questi si chiamano valori singolari E il numero di valori singolari non zero Corrisponde esattamente al rango della matrice Quindi il rango di A Se A ha il rango di A Avrà precisamente due autovalori Avrà precisamente due valori singolari Non zero Tipo il numero di valori singolari non zero Corrisponde al rango della matrice Allora Abbiamo detto che se Sono confusse Alla confusse dell'autovalore Come fanno a essere Questa è la definizione Possiamo sempre Si può vedere che comunque sempre esce così Quando si vuole fare un'indicomposizione di valori singolari Ma perché possiamo sempre insistere su questo? Ma come fanno a essere un'indicomposizione? Se questo è la definizione È la definizione Possiamo sempre insistere di questo però Sai perché? Immaginiamo che abbiamo fatto questo processo qui Abbiamo tipo da mano calcolato questi autovalori di A Trasporto A Trasporto A Blah blah blah blah blah Abbiamo ottenuto un U E abbiamo ottenuto un A Però poi L'ordinamento di questo non era quello che volevamo Sempre Possiamo sempre fare Per mutazione E la cosa che è super super fantastico di questo è che immaginiamo che abbiamo A E la cosa che è uguale a U E il suo Ma diciamo che è tipo 1, 3, 4 O qualcosa del genere Quindi non sono questo ordinamento che vogliamo Possiamo sempre dire Allora Voglio che Inseriamo questa matrice di permutazione qua Ok Questa matrice di permutazione dice che facciamo qualche scambiamento Quindi facciamo una permutazione Che le fa tutto in modo che vogliamo Ok E adesso chiamiamo Allora Quindi se lo chiamassimo Allora Abbiamo E non abbiamo fatto nessuna permutazione in A Perché Qualsiasi permutazione che abbiamo fatto qui L'abbiamo cancellato qui Perché qui facciamo la permutazione Qui facciamo il diverso di questa permutazione Quindi non stiamo toccando A Qualsiasi permutazione che abbiamo fatto Verrà cancellato qui Poi In più Abbiamo detto che vogliamo Matrici ortogonali qui Matrici di permutazione sono sempre ortogonali Quindi Montaplicando per questo è ancora ortogonale Montaplicando per questo è ancora ortogonale Quindi possiamo dire questo come definizione E possiamo E possiamo garantire Che se facciamo questo algoritmo Con gli autovalori di A trasposto A E A trasposto Se naturalmente non esce quello che vogliamo Vabbè possiamo sempre fare questo Per inserire che scambiamo l'ordinamento di queste cose Fino a che non otteniamo quello che vogliamo E la cosa migliore è come la fattore E la fattore stazione L In cui dobbiamo pensare di una versione permutato di A Perché abbiamo fatto questo qua Una permutazione Poi l'abbiamo fatto l'inverso della permutazione qui Quindi veramente non abbiamo cambiato A Abbiamo fatto sempre permutazioni cancellate Quindi possiamo insistere di questo Ed infatti è proprio questo il motivo perché insistiamo su questo Insistiamo su questo perché vogliamo parlare Della decomposizione a valori singolari Se ricordate stamattina ho detto che Anche se noi diciamo la fattore esazione QR È più corretto dire una fattore esazione QR Perché ci sono molti diversi modi di portarci E non sono equivalenti Cioè otteniamo sempre una fattore esazione Che sorrispa alla proprietà Ma le fattore esazioni potrebbero essere diverse tra loro Invece questo no Perché la decomposizione a valori singolari Perché insistiamo proprio su questa condizione Che compaiono in questo ordinamento Che abbiamo un'unicità a questo Quindi questi come ho detto Vengono chiamati i valori singolari Questi elementi diagonali di sigma Coloni di U Sono i vettori singolari Sinistra E coloni di B E coloni di B V Sono i vettori singolari Di destra Ok Queste sono terminologie abbastanza Secondo me sarà abbastanza intuitivo Questa è la terminologia Destra Sinistra E perché lo scegliamo Queste cose per le rispettive valori singolari E vettori singolari Allora Quindi Questo È un modo di concepire La decomposizione a valori singolari Però Voglio che Lo vediamo anche un'altra cosa Sì Sì Dove Qui Allora Questo perché Se ricordate Questa matrice Non è un quadrato Necessariamente E quindi Per far Diciamo Per far uscire correttamente Le varie dimensioni Potrebbe essere che Questa cosa Quando Tipo Quando Questo Avrà un numero di valori singolari Corrispondente solo Di non zero Al rango Della matrice Ma Sarà Limitato In pratica Da qualsiasi di queste cose qua Uno è più grande Quindi Il massimo di questo Sarà Il massimo Numero di Valori Che può avere Su questo Di aronale Sì Ma sono la finta Che è una finta quadrata Che hanno Da dire Esatto I valori I valori Sì E poi Per far tornare Può N perenne N perenne Sì Esatto Però Esattamente Come E non voglio Anticipare Troppo Ma come abbiamo visto Con la fattura Sezione QR In un certo senso Se vogliamo Solo considerare Queste parte È una Sottosezione Un sotto insieme Di queste colonne Possiamo Ma vedremo Questo tra Pochi minuti Però sì E questo è il punto Queste Potrebbero essere Necessarie Per far Uscire Le dimensioni Correttamente Ok Allora Vediamo Un attimo Dall'azione Di questo Di Consizione Di Colore Perchè Questo Potrebbe Farci Questo E come Preferisco Io A Concepire La Di Composizione Valori Singulari ok abbiamo a di u e sigma posto p ok cos'è un boom è semplicemente 12 ok se facciamo il trasposto di questo v trasporto di avrà questa struttura e questo è semplicemente ok ok questo è semplicemente una conseguenza della matrice ma vettoriale vettoriale matriciare guarda questo è semplicemente quindi è evidente se prendiamo di mettiamo sul suo lato il prodotto di v trasposto e b sarà solo questa cosa qua 1b 2 trasposto di 2 e trasposto di ok quindi questo ci sta adesso abbiamo ok poi abbiamo questo ok quindi se vediamo abbiamo struttura diagonale quindi questo elemento poco questo sigma 1 e nessun altro elemento sotto di tutto sposto di tocca il sigma 2 nessun altro elemento e poi le cose più grande di r toccano solo 0 quindi quello che abbiamo qui abbiamo un vettore che ha questo aspetto e poi abbiamo un sacco di cose 0 e poi abbiamo un sacco di cose 0 sì quindi abbiamo un sacco di cose 0 sì quindi abbiamo questo vettore di dimensione r e adesso se vogliamo un sacco di cose 0 sì sì sì sì sì sì sì sì sì quindi abbiamo questo vettore di dimensione r e adesso se vogliamo possiamo anche dire che ci sono queste cose 0 perché no ok quindi abbiamo adesso un sacco di 0 ok va bene quindi adesso finalmente abbiamo 2 che è solo un 1 più 2 e 2 e 3 e quindi abbiamo unقي Windward 2 2 e i mét 한� 6 sì no sì sì 9 10 ok quindi se abbiamo questo ma sonostilo inve Every time Siamo Se moltiplichiamo questo, due per il trafocco B, cosa succede? Allora, abbiamo questo, quindi V1, poi più V2. Possiamo vedere che forma questo. Quindi abbiamo questa struttura qua. Oppure possiamo scriverlo tutto con questa forma. A uguale a V8. Questo possiamo allora concepire la decomposizione ai valori singolari. A questa specie di decomposizione addettiva. Abbiamo la decomposizione di decomposizione al nostro matrice A in una serie di espressioni di questa forma. Abbiamo questo vettore modificato col trasporto di un altro. Questa è una matrice. Tutto modificato o scalato della presenza di questo valore singolare. Allora, ce ne sono anche R di questi. Potremmo, se volessero, considerare più di R, ma come vediamo sarebbero 0. Quindi sarebbe possiamo vedere, possiamo includerli, però non parla nessun contributo a questa somma. Quindi questo ci sta dicendo che la decomposizione ai valori singolari contiene informazioni che nonché sono un po' necessario, se vogliamo definirlo un modo super generale e stabile, diciamo, non sono strettamente necessario. Infatti, esattamente come abbiamo visto con la fatturizzazione di QR, possiamo anche considerare una decomposizione ai valori singolari in cui noi incliniamo queste informazioni redundanti. Quindi, dopo un'ottima cosa, prima di te, quando hai scoperto di un'ottima informazione di QR, ti ha scoperto di un'ottima informazione. Dove? Ah, beh, non nella prima. Ah. Ok. Ok. Allora, quello che possiamo vedere qui, in realtà, se rank A uguale a R, possiamo considerare le FVD, Marco, di A come A uguale a UR, sigma R, UR trasporto, dove? R, sigma R, sigma R, uguale a diagonale. Quindi adesso abbiamo solo un diagonale, una matrice diagonale. Questo è in R, R trasporto, R, quindi abbiamo sigma R, una matrice diagonale R trasporto, R, e poi UR, VR, sono i primi, R, R, vettori singolari, sinistra, destra, rispettivamente. Quindi è questo, come vediamo, esattamente uguale a considerare la decomposizione ai valori singolari la SVD, questo non c'è perdita di nulla, perché fino a che includiamo tutti questi valori singolari, come abbiamo visto qui con questa espansione, se non contribuiscono positivamente a questa somma, per tutti i motivi pratici la matrice A non sono necessaria per calcolarlo. abbiamo visto una cosa molto simile a quando abbiamo fatto la decomposizione ai a la fatturizzazione QR, però è una cosa in cui dobbiamo pensarci un attimo perché da un lato possiamo dire che A non è cambiato, dall'altro lato però alcune cose precedentemente che erano ben definiti, adesso un po' meno, vi spiego cosa intendo. abbiamo detto che A non è uguale Ue R R R V R un po', possiamo adesso avviamo nr per n si r per n quindi è evidente allora questo trasporto sarà questa n per vr deve essere nr però vuoi trasporto sarà r per n si quindi questo è r n questo è r e queste m r quindi ok la moltiplicazione esce la cosa con la dimensione giusto cioè m per n però questo ortogonalità cos'è successo perché adesso abbiamo matrici abbiamo prima detto che il valore la di composizione valori singolari abbiamo avuti questi mantrici ue e v che erano ottonali per essere ottonale significa che il tuo trasposto del tuo inverso ma questo un pochino non voglio questo questo come che la matrice quadrato vero perché per avere un inverso per parlare del concetto dell'inverso prisuppone che il concetto esiste cioè la matrice quadrato e adesso non abbiamo metri ci quadrati abbiamo queste cose dimensioni r che vediamo riporta ma c'è qualcosa che sarà cambiato e infatti questi non sono esattamente più portogonalità questo se facciamo qr trasposto per r abbiamo l'identità di dimensione r quindi un pochino è come un universo ma vediamo che non ci riporta però allo spazio originale perché queste m per r e questo prodotto r per r e le cose diventano ancora un pochino più strano se conserviamo un'altra cosa del genere abbiamo una matrice che in questo blocca questo blocco qua di r per r abbiamo questi identità di dimensioni r ma il resto è zero e infatti forse non vi sorprenderà per imparare che c'è una cosa simile per la matrice ma è diverso nel senso che questo è è no questo è i r si è è quindi questo però la differenza è però allora quindi queste matrici non sono proprio non sono proprio otto conali perché questi prodotti non vi portano a un inverso ben definito portano queste cose che assomigliano un pochino in versi ma non sono esattamente la stessa cosa ok questo prossima è cosa è probabilmente la proprietà più importante della matrice del di composizione ai valori singolari che c'è quindi ricordalo bene questo allora non lo dimostro la teorema è questo darò un attimo a chi che segue online forse volete fare pausa quando guardi la registrazione per scrivere ciò che c'è scritto su questo lavagna e adesso vado qui ok non lo dimostrerò questo teorema però è un teorema è un nome non mi importa che sapete il nome della teorema però dovreste sapere quello che dice ok proprietà è un teorema è un teorema è un teorema sia a a e a uguale a ok ok ok ok ok ok ok questo è come definiamo a capo e questo qui è la teorema è la teorema è la teorema è la teorema è la teorema è è la teorema è la produzione a problema di minimizzazione powin sì così armi non è e quindi è Kerry che non in vita Guardiamo questa espressione. Cosa ci sta dicendo? Ci sta dicendo se abbiamo questa matrice A e vogliamo approssimare la matrice con qualcosa di un rango più basso, quindi forse il rango di A è alto e vogliamo considerare qualche approssimazione di rango più basso, di ordine più basso. Il modo ottimale, matematicamente parlando, che si può fare questo, viene dato elegantemente da questa espressione qua, che l'unica cosa che dobbiamo fare è fare la deconfessione ai valori singolari. Teniamo le prime carte, lo facciamo in questo modo, e questo tra tutte le possibili matrici di questo rango basso, questo è quello che approssima A nel modo migliore in un senso matematicamente ben definito. Allora, chi ha mai sentito di una cosa analisi ai componenti principali? Questo in effetti, spesso in un corso della statistica, il modo in cui fanno la derivazione ai componenti principali è un pochino diverso di questo, ma questo moralmente è l'idea dietro la decomposizione ai componenti principali. Usa questa decomposizione singolare per estrarre qualche rappresentazione dai dati che ha un rango più basso, un ordine più basso, per approssimare dati alto dimensione con dati basso dimensione. E questo è questo è quello che significa fare analisi ai componenti principali. Ok, adesso torniamo. Sì. Allora, a cosa serve in generale? è che, ok, immaginiamo che abbiamo un insieme dei dati che è enorme, tipo A, N, abbiamo R, facciamo che i nostri righe sono nostri variabili, quindi ogni elemento, i nostri osservazioni consideriamo come possono vettori, e abbiamo ciascun'riga di questi colonni corrisponde a qualche caratteristica, quindi abbiamo osservazioni, consideriamo, non lo so, colesterolo, l'opatico di cuore, tipo diciamo 100 variabili diverse. Ok, abbiamo R100 e abbiamo chissà quanti osservazioni, diciamo 2500. del genere. Ok. Allora, 100 variabili sono tante, quindi A uguale a U e V. Questo abbiamo 100... Prima consideriamo questo. Quindi la dicondizione ai valori singolari, 100 dimensionale, quindi abbiamo 100 variabili, 100 valori singolari, 100 vettori singolari, 100 vettori singolari sia destra e sinistra. Ok. Adesso, però, vediamo che, quando facciamo un'analisi, vediamo, ad esempio, che, se guardiamo, tipo questo, diciamo che, vediamo che i primi due, primi tre, primi quattro valori singolari sono grandi, ma il resto sono molto piccoli, quindi contribuiscono relativamente poco a questo mantelice. Adesso diciamo che vogliamo fare questo. A4 uguale a U4, sigma 4, U4, U8. Perché questo è utile? Adesso, se moltipliamo qui... Ok. Adesso, i nostri dati, quale forma avrebbero? Qual è la dimensione di questa espressione qui? Questo qui, adesso è... Ok. Adesso, quello che avevamo prima, abbiamo avuto dati che avevano 100 variabili distinti, diversi, che erano un pochino tanti, non siamo molto bravi a fare analisi degli dati che hanno 100 variabili diversi, ma poi abbiamo visto che questo possiamo vedere, come stiamo dicendo, questi dati che sono 100 dimensionali. se volevamo avere quattro dimensioni, questo è il modo migliore di farlo. E se poi facciamo questa trasformazione di questi primi quattro valori simbolari, abbiamo adesso questo insieme dei dati, qui, che è 4V4 trasposto. e perché questo è importante. Quello che ci sta garantendo questo è che se vogliamo ridurre questo, ad avere quattro dimensioni più basso, se lo facciamo in questo modo, questo teorema garantisce che stiamo facendo in modo che minimizziamo la perdita dell'informazione. cioè, se poi vogliamo ricostruire i dati quattro dimensionali e rimetterli nello spazio originale, sarà lo spazio quattro dimensionale più ben approssimante. Quindi spesso si vuole fare questo. È probabilmente la cosa più utile di costruzione a valori simbolari. Perché è soprattutto nell'epoca in cui viviamo. spesso quello che vogliamo fare è prendere qualcosa di dimensione alto e trasformarlo in una cosa più fattibile. Infatti spesso si vedono che le persone fanno cose del genere. A volte, ad esempio, quando le persone hanno varie misure di una serie temporale, tipo diverse osservazioni e diversi punti temporali, si vedono che in realtà abbiamo una cosa che ha questa struttura, in realtà, che tipo, anche se ci sono cambiamenti in tempo, in realtà, sono modulazioni, fluttuazioni intorno a questa struttura bassa dimensione. un'altra cosa, me lo ricordo che ho fatto quando ero a Politecnico di Milano, c'era questa analisi che ho fatto, che ho guardato le diverse province in Italia e ho guardato diversi indicatori sociali, cioè reddito medio, cioè tasso di popolazione che ha compiuto sia superiore che università, che a livello ho guardato tasso di criminalità, eccetera. Quindi c'erano di nuovo 100 variabili e quello che si vedevano quando si faceva questa riduzione è spesso questi variabili che sono correlati fra loro. Prendono un'abilità di interpretare, cioè una volta si trovava che uno di questi dimensioni più basso sembrava di essere più o meno corrispondere al livello di benessere e di ricchezza generale nella regione. Però questo non spiega tanto perché sappiamo ad esempio Milano è la città più ricca in Italia ma nessuno direbbe che è una città poco violenta in Italia infatti è tra i peggiori perché questo spiega un pochino ma non tutto perché c'è anche disuguaglianza che è un'altra cosa che se vai in un'provincia dove tutti sono poveri spero non c'è tanto. Quindi ci sono queste cose che c'è correlazione tra loro e questo è quello che fa e questo prende i vettori che spiegano questa correlazione o questa varianza in modo ottimale infatti c'è una diretta correlazione tra varianza e questa espressione quello che sta dicendo questo è questi sono i vettori questi quindi i quattro vettori sono i vettori che minimizzano la varianza che spiegano la maggior la maggior parte della varianza che potrebbe che può fare con quattro vettori e basta quindi quello che si fa con questo è il modo di estrarre variabili correlati questo è come un statistico spiegarebbe i commenti principali come il modo di tipo ridurre le varie diverse cose insieme dei dati in base a loro più correlazioni però questo è esattamente la stessa cosa che si vede qui allora i statistici però chi ricorda qualcosa della statistica chi non ha mai fatto statistica nella loro propria vita allora vi ricordate quando hai una matrice dei dati tipo x che spesso c'è un modo di fare se facciamo x meno qualche mu diciamo che questa è la media che se si fa questo questo è la matrice variante con varianza questo con un paio di zucchetti si può dire che questo è una cosa in realtà dovrebbe dovrebbe questa forma qui dovrebbe io dico questo non è uguale ma dovrebbe farci pensare che questa è una struttura qui che dalla derivazione a valore di confezione a valore singolare dovrebbe sembrare familiare ed infatti spesso nell'ambito statistica quando parlano di queste idee della basso approssimazione lo iniziano così lo dicono questa è la matrice di varianza e covarianza poi definiscono questi valori e vettori come gli autovalori e autovettori della matrice di varianza e covarianza però possiamo anche vedere queste stesse cose come i valori singolari e i vettori singolari della matrice dei dati direttamente quindi è un dipendato l'ospettivo in generale a noi non piace fare questo qualcuno ricorda perché questa espressione non a noi non piace se vuoi determinare i componenti principali così rovin l'indizionamento della matrice quindi facendo così con le composizioni singolare è sempre un modo meglio di farlo perché non dobbiamo fare questa matrice moltiplicata con se stesso però adesso torniamo al discorso originale perché ormai sembra così tanto tempo fa avrete sicuramente dimenticati perché abbiamo iniziato questo discorso allora abbiamo iniziato questo discorso perché abbiamo introdotto il problema con problema quadrati minimizzati a sottodeterminati quindi abbiamo avuto a x uguale a b ma questo grasso basso questo è un datore alto eccetera questo era quello che volevamo fare risolvere questo problema allora la definizione adesso è così definizione sia a in r m per m il pseudonverso di mor pendroff di a e diciamo rank a uguale a r e come lo siamo questo simbolo di più quale a questo è il giro inverso abbiamo detto che questo rango era questo rango di a r quindi questo qua sono i primi r non zero diagonale r perere con diagonale non zero quindi possiamo invertirlo perché è diagonale con diagonale non zero e questi qua va bene sono simili a tutto dove diciamo così questo è la di magro di a quindi questo è la di magro di a questo allora ci porta a pseudo inverso allora domanda per voi guardiamo un attimo questo diciamo questo ortogonale o quasi o r colonie ortogonali questo è diagonale con elementi positivi o comunque non zero ma questo questo è anche ortogonale quindi perché questo non vale come l'SWD tipo potremmo dire che questa è l'SWD di qualche matrice possiamo dire che c'è qualche matrice a cui questo c'è l'unverso di morpendros può essere il suo SWD tipo florispa i requisiti di SWD sicuramente questi sono ortogonali o più o meno ortogonali questo vediamo va bene questo se vogliamo avere un SWD no non va bene perché ricorda che abbiamo questo per l'SWD significa che abbiamo insistito che il più grande va primo secondo più grande eccetera fino al più piccolo quindi se abbiamo una cosa con questa forma non rispetta questo ordinamento adesso questo significa che abbiamo uno quindi non esiste nessuna matrice nel mondo per cui questo è il suo proprio SWD invece però va bene come il pseudo inverso di questa matrice che ha e perché questo pseudo inverso è così utile pensiamo di questo problema qui è un problema ai quadrati minimi in cui abbiamo molti più variabili rispetto alle equazioni quindi ci sono infinitamente soluzioni quindi abbiamo A X uguale a B A per M per M M allora questa soluzione qua è speciale perché possiamo dire che allora X uguale a sovita min qui a Z uguale a più bene cosa sta dicendo sta dicendo che tra tutti i possibili soluzioni a questo perché questo abbiamo esattamente l'opposto problema rispetto a quello che abbiamo avuto prima prima con il caso magro e alto non possiamo trovare matrici che solistano questo rapporto non possiamo trovare vettori X che risolvano il sistema adesso però abbiamo una cosa leggermente diverso o no non leggermente tutto diverso perché abbiamo troppi X che solistano l'equazione sono troppi infinitamente infinitamente tanti in generale X che possiamo trovare che andranno bene quindi come possiamo scegliere quello giusto diciamo che quello giusto potrebbe variare a dipendere dalla tua applicazione ma quello che ci dà questo pseudo inverso qui è quello che ha minima norma quindi questo è quello tra tutti X che potremmo possibilmente scegliere che soliscono questo rapporto quello che otteniamo utilizzando il pseudo inverso di Morten Ross di A è quello che minimizza la norma di questa soluzione quindi è la soluzione diciamo più piccola di di l'assunzione più minimizza la norma è la cosa più importante di questo è abbiamo ritrovato un X che possiamo dire è unico abbiamo detto che abbiamo un X unico adesso che ha questa condizione che a priori sembra una condizione ragionevole insistere che questo è quello che minimizza una norma e quindi probabilmente tra tutte le possibili soluzioni è questo ottimale di scegliere c'è un'altra cosa che voglio parlarne ma penso che parlerò domattina perché non voglio non voglio essere troppo in fretta però questa cosa il pseudo inverso di Morten Ross è una cosa che è molto importante anche non solo in queste situazioni si vede più spesso diciamo nelle situazioni in cui c'è questo in cui abbiamo questo ma un'altra variante un'altra situazione oltre a questo in cui abbiamo quadrati minimizzati basso è basso e grasso può capitare quando pensiamo di alto e magro tipo può capitare che questo è alto e magro però comunque non ha rango pieno tipo anche se questi colonni ci sono molto più righe che colonni c'è ancora qualche dipendenza lineale tra le sistema deficiente tipo non pieno rambo tipo diciamo il rambo è meno nel numero di colonni in questa situazione in cui abbiamo rank deficient over determined least squares quindi questa è ancora sopra determinata ci sono ancora più equazioni di variabili ma incredibilmente c'è qualche problema col rambo del sistema c'è qualche dipendenza lineare ritroviamo di nuovo in una situazione in cui non ci sono necessariamente infinitamente x che soddisfano l'equazione esattamente ma ci sono infinitamente x che minimizzano in queste situazioni ci sono infinitamente x che risolvono il sistema ai quadrati minimi in quel caso quello che succede è che questo sistema ha quindi se a non ha rango pieno questo è ancora quadrato ma è deficiente in rango quindi significa che possiamo trovare infinitamente x che sorriteranno questo sistema in questo caso allora siamo nella situazione in cui dobbiamo scegliere tra un'infinitudine di possibilità e quindi ritrova utile questa istruzione qua che come avevo detto quella soluzione che otterrai da qr le fattorizzazioni di qr non sono necessariamente unici quindi non è detto che troverai quello che vogliamo quindi in questo caso questo è il modo di risolvere allora grazie per l'attenzione oggi e ci vediamo domani pomeriggio