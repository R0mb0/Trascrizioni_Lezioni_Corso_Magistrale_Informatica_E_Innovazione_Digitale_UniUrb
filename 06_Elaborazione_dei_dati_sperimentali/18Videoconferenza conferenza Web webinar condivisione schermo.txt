ok Grazie. Cominciamo con il vedere allora come sono questi i primi due progetti. I primi progetti sono già preferibili sul fondo alla pagina del branding, che sono questi due. Il progetto 1 è sul maximum like new parameter estimation e il progetto 2 list square method. Il progetto 1 è il progetto che si fonda su praticamente un paragrafo del libro di Cohen, che è questo 6.8, un altro esempio di maximum likelihood with 2 parameters. E si tratta di fare, quindi, che abbiamo un nuovo impatto, e che c'è appunto anche il codice su... qua nel blending. Noi l'abbiamo fatto per un parametro e per la distribuzione esponenziale. E invece questo qui è da fare con due parametri e con questa distribuzione. La distribuzione, in questo caso, è... Questa distribuzione la vedete qui. Quindi il progetto 1, eh? Sì. E la distribuzione che... La probabilità è la distribuzione per un angolo di scattering di un esperimento di parceria elementare, perché su quello è soprattutto il libro, dove abbiamo due parametri. Ok? Poi andatevi a leggere chiaramente il paragrafo di cui vi sto parlando. ed è... 1 più alfa x più beta x quadro tratto x ma meno x min, più alfa mezzi x max meno x min al quadrato, più beta x max meno x min, più al quadrato, ok? dove x... Adesso io faccio un assunto ma potrei andare a leggerlo lì. x è compreso tra meno 0,95, 0,95, ok? x... E x in realtà è coseno di z, dove z è l'angolo di scattering, e per questo è compreso tra questi due limiti, ok? Voi questo qui in realtà non vi interessa, è solo per saperlo, come vedrete lì è scritto, ma è giusto per sapere. Allora cosa bisogna fare? Bisogna stimarsi alfa e beta sulla base di che cosa? Sulla base di un file di dati che vi do, ok? Quindi questo file di dati, e qui sono un file di 100 dati, quindi sono un file di scattering, ok? Sulla base di scattering, questo x misurato, ok? E per fare questo quindi cosa dobbiamo fare? Dovevamo basarci sulla logaritma, la life logaritmica, che se è appunto la sommatoria per i da 1 al numero di dati, del logaritmo di f di xi a x a beta. Va bene? Quindi cosa dobbiamo fare? E qui lo dobbiamo fare, abbiamo fatto anche nel caso della descrizione esponenziale, qui dobbiamo trovare la stima di alfa, e quindi facciamo così, scriviamo così, di beta, e poi dobbiamo stimare anche sim a quadro di alfa e sim a quadro di beta. Ok? Allora, come facciamo? Lo facciamo trovandolo, trovando, massimizziamo questo qui, il log end. Va bene? Quindi cosa vuol dire? Vuol dire che noi ci costruiamo questa qui, che sarà una funzione, sarà una per esempio h di alfa beta, e solamente questa funzione sommatoria i mi per logaritmo di f di xi a alfa beta. Chiaramente questa è solo funzione di alfa e beta, perché questa è un'acca quindi, solo per dire un'altra funzione. Perché? che appunto gli xi sono quelli che ci sono del file dei data. Combinando tutto. Quindi questa funzione la dobbiamo massimizzare rispetto a alfa e beta. Allora, la prima cosa che possiamo fare è, soprattutto per massimizzare quindi per trovare le stime di alfa e beta, possiamo sì utilizzare un metodo numerico, questo metodo numerico cosa vuol dire? quindi utilizziamo OptiMai, che è una funzione un paio. Va bene? Oppure anche in questo caso, in realtà il medio metodo numerico, però questo secondo metodo lo facciamo anche per avere un'idea di come è questa log, questa funzione di alfa e beta, possiamo costruire una griglia, quindi plotare plot di alfa e beta, ok? E per plotare alfa e beta, quello che possiamo fare? Indiziamo i valori di alfa e beta, bene? Quindi facciamo un plot della superficie e troviamo il punto in cui appunto c'è l'Iss. Chiaramente più alfa e beta abbiamo, più questa superficie sarà disegnata e più il massimo sarà vicino a quello che troviamo con il metodo numerico. E quindi in questo caso viene una cosa, questo genere alfa e beta, e troverete una superficie, e in questa superficie andate a vedere che valora il massimo e questi saranno alfa. ok? Benissimo, prima di fare questo comunque, come sempre, una volta che avete i dati, la prima cosa che si fa che cos'è sempre? Quando si hanno dei dati la prima cosa che si fa è sempre andare a bloccare. quindi quando voi nel vostro lavoro avete dei dati dalla metà, in realtà non ho comprato l'altro, perché ci si rende avuto che come sono questi dati. Quindi magari a queste, lavorare in anno non sa quanto vale, non si sono più o meno costanti, cioè è importante perché siamo la prima idea di cosa si lavora. E in questo caso quindi fate un histogramma dei dati. e nell'istogramma dei dati poi alla fine potremo anche plottare sopra questa funzione, quando abbiamo trovato le stime di alfa e beta, potremmo plottarla sopra e vedere se appunto riproduce proprio quelli che sono i dati che abbiamo dato. questo xmin e xmax, questo sarà xmin, questo sarà xmax, ok? Ok, cioè il minimo e il massimo, si può spoiler. E questo, facendo questo quindi abbiamo a questo punto le stime di alfa e beta. Poi vogliamo che cosa? La stima della varianza. Abbiamo detto che per la stima della varianza si può sempre pensare di correre al metodo analitico. Cioè se uno ha la distribuzione può andare a far sull'integrale e dire quant'è questo qui, ma noi non lo utilizziamo, ok? in questo caso, ok? E invece cosa utilizziamo? Utilizziamo il metodo di Montecarlo. Quindi quando diciamo che il metodo è il metodo di Montecarlo vuol dire che produciamo noi dei dati che supponiamo siano congruenti con quelli che è l'esperimento, e lavoriamo su questi dati. In generale, il metodo di Montecarlo è questo. Quando facciamo delle simulazioni di Montecarlo vuol dire che riproduciamo il sostenimento tante volte con dei dati generati da noi in modo casuale. Quindi cosa facciamo? In questo caso, come è descritto anche nel libro, quindi produciamo non mi ricordo quanti due mila esperimenti tipo o duecento esperimenti, quindi n non mi ricordo come il libro cosa dice, comunque andare a vedere, quindi n esperimenti con n grande dati ciascuno. Va bene? Come facciamo a riprodurre gli esperimenti? Usiamo Montecarlo, possiamo farlo con che cosa? Con che metodo? In questo caso la distribuzione non è una distribuzione normale, in cui ci sono già funzioni già fatte su urbari. Questa è una funzione di distribuzione diversa, e quindi potremmo utilizzare che cosa? Per produrre questi dati casuali? Cioè, adesso, per essere a ridurre gli esperimenti? Per essere a ridurre gli esperimenti? diversa e quindi potremmo utilizzare che cosa per produrre questi dati casuali? Ma voi capite bene quando noi tagliamo? Se non capite qualcosa dico no perché tanto per dire che è meglio che capiamo piuttosto che poi tu puoi l'esame e non dovete ridare, anche per me, hai capito? Quindi vi fermate e tanto se siete arrivati da non molto, io parlo veloce, quindi non c'è nessun problema. Io ho studiato, ho fatto dei corsi in belga che parlavano francese e al limite non lo sapevo bene, ma era la stessa cosa, quindi sono un casino. Quindi con che cosa? Possiamo farlo con un metodo appunto di intermiss, che è quello per cui si guarda, quello che abbiamo usato tante volte. Per utilizzare il metodo di intermiss vi ricordate che dobbiamo chiaramente utilizzare questo qua, va bene? In questo qua c'è alfa e beta, allora dicono cosa bisogna fare alfa e beta? Per alfa e beta posso utilizzare i valori che ho trovato qua. Quindi metto in quella funzione quegli alfa e beta di me, faccio con intermiss mi produco praticamente n grande per n piccolo dati e quindi faccio n piccolo esperimento. Bene, per ogni esperimento cosa faccio? Per ogni esperimento mi calcolo col metodo numerico alfa e beta e così posso calcolarmi la seconda. Mi sta la semina, no? Ma da passaggio nevo, ci troviamo anche il massimo della tradizione? No, no, appunto, cioè lei deve praticamente rifare lo stesso esperimento. In questo caso lo stesso esperimento vuol dire stimarsi per n piccole volte alfa e beta. Sì, allora sono quelli che stanno... ho capito cosa vuol dire eh? Sono quelli che stanno sotto ogni volta... Ecco, intervista, ogni volta che stanno... lo accettiamo se stanno sotto l'altezza di questa qui. L'altezza lì è data da questo qua. Lei dice... io la y, ma anche la x devo tirarvi numeri a caso che vanno da zero all'altezza massima. L'altezza massima fa la derivata seconda, ok? O la derivata seconda di questo qui, oppure l'altezza massima fa semplicemente la derivata seconda di quello. E la può calcolare anche numericamente se vuole, va bene? Ok. Comunque molto semplice perché questo qua, se voi andate a vedere... quando fate il... come stiamo... il... il histogramma... è una cosa... il nostro gira... quindi l'altezza massima è il 30,95. Ok? Comunque si vede... c'è anche... se voi andate a vedere... ve lo fa vedere anche... Aspetti... la voglio farvelo vedere qua... non c'è la farvi dire... prendiamo un'altra... l'altra... allora... è una cosa... è una cosa... c'è la farvi dire... aspetta... vedi... la voglio farvelo vedere qua... non c'è la farvi dire... prendiamo un'altra... ok? ho fatto vedere... vediamo un'altra... ok? è una cosa... perché questa volta non l'ho portato comunque in questa maniera quando andate nel programma e se voi fate può fare anche perché questo qui per trovare il massimo si fa la derivata seconda rispetto a x allora vedete che sotto è una costante quindi la derivata seconda è alfa più 2b 3 e poi dopo se va da 0 1 potrà trovare solo qual è comunque lo vede anche dal grafico ok poi diceva quindi quando avete fatto questo qui per quindi per ognuno ottengo quindi n alfa beta allora io quindi conviene farlo col metodo semplicemente dell'ordimare imparare l'ordimare non imparare la guida tante volte quindi ottengo n volte alfa beta quindi col metodo numerico ok e a questo punto cosa faccio vado a calcolarmi quindi la la sample variance per esempio alfa uguale 1 su 500 meno 1 sommatoria reggela 1 a 500 di alfa j meno 1 alfa dove alfa è quello stimato qua il primo ok al quadrato va bene e così ora se incolvare è stessa cosa posso fare per beta ok questo è un metodo il secondo metodo che dovete andare applicare invece è quello del terzo metodo con l'ncf allora allora in quel caso voi sapete che dovete andare a calcolare la derivata seconda del logaritmo del logaritmo di l secondo alfa e la derivata seconda del logaritmo di l secondo beta va bene e v sarà uguale quindi a meno 1 fratto questa derivata seconda ok v alfa così è v beta uguale allora come faccio a calcolarmi da vada prima e vada seconda lo faccio con allora come faccio a calcolare la stima di alfa e l'altra stura di beta e quindi per fare questo mi conviene utilizzare come si può fare o si fa numerico e quindi per fare questo miтиando mi hanno usare un retwe members che mi inserono come si può fare ok ok adesso silenzio vivo va bene e quando come si può fare, o si fa numerico, quindi o si fa la derivata seconda numerica sulla superficie, oppure vicino al massimo, oppure si utilizza che cosa? In questo caso possiamo utilizzare SimPy, che è un audio di Patricio Python che praticamente utilizza il calcolo simbolico. E questo è il primo esercizio, il primo progetto. Per esempio... Grazie. Vi faccio vedere qui questo studente come l'aver fatto, per dargli un'idea. Qui lui aveva riscritto anche un po' le formule usate. Va bene, SimPy, riportazione delle librerie, però vi faccio vedere... Poi i dati erano diversi, log likelihood, log likelihood negativa, poi il metodo della griglia, quindi farei plot. Vabbè, qui lui ha diviso tutto, quindi è tutto strutturato con le funzioni. E poi qui è... SampleVari, poi c'è anche la parte CFBound, che usa appunto... Vedete c'è tutta la discussione, usa SimPy. Scopro. Però volevo farvi vedere... Ecco, qui ha... cosa hai dato. Poi vedete, questa... è... la distribuzione dei dati, histogramma. Ok? Va bene? Vedete che fa così come vi dicevo. Poi dopo c'è... Vabbè, i valori... i valori stimati. Poi... Adesso troppo non ci sono i dati. Vedete... Per carità i dati. I dati ci sono. Ma proprio questo però... non ci sono i dati... Vedete... No... Ci può un altro uploadare però... Non so se c'è il mio... in... Basta, c'è il judgments, diciamo? No. Grazie. E dovrei? Devo condividere, magari ve lo faccio vedere dopo. Comunque dopo c'è, qui vedete, c'è praticamente una parte in cui la prima restribuzione dei dati, poi dopo c'è la figura della superficie e poi il calcolo di alfa e beta sia con Monte Carlo che con l'RF. Ok, chiaramente Monte Carlo e RFC Fbound, vediamo in data. E va bene. E questo è il primo progetto, se anche voi avete un'intervista perplessità, per domande, per le opinioni, soprattutto dal punto di vista del posto. Ivana, ci stai seguendo? Salve, sì sì. Ok, va bene. Ci sono. Benissimo. Passiamo allora al secondo progetto. ecco, secondo progetto cosa abbiamo? Secondo progetto è list square method. Allora, in questo caso, noi abbiamo fatto l'esempio con coconut. con le scelte di Gerdiero ok, qui c'erano dei dati e dovevamo capire qual era delle tre supposte funzioni per descrivere questi dati, qui la purezza qui abbiamo lo stesso quindi questo progetto riguarda la stima di parametri di una funzione sulla base di misure sperimentali accoppiate indipendenti, in riferimento al capito 7 di coma le misure sperimentali sono riportate nel file dati qui sotto consistono in nove misure accoppiate quindi voi vedrete che c'è possiamo aprire quindi c'è la x c'è la y e c'è la standard deviation ok e la x come diciamo noi la supponiamo conosciuta senza errore quindi questi sono dei valori della x la y la y invece ognuno ha una standard deviation diversa allora la grandezza è supposta conosciuta con grande precisione mentre la grandezza y è il risultato della media di 10 misurazioni per ogni valore della x viene riportato anche il valore della standard deviation della media x ok va bene allora si suppone che la y è legata alla x da una forma funzionale in questo esercizio le forme funzionali che supponiamo sono tre quindi le nostre teorie che vogliamo testare sono queste tre ok quindi è quindi è e e e e e e e e e e e e e questo e e e e e e e e e e e e e e e e uguale a t0 più t1x più t2 e alla x queste sono le tre funzioni allora qui quello che dovete fare beh, per tutto chiaramente come al solito vi fate il gradito x versus y con gli errori quindi per vedere x e y i punti qui hanno la seconda division o più o meno la seconda division per avere un'idea di cosa è e poi qui come facciamo noi risolvere con l'ist square method con l'ist square method abbiamo due modi o lo facciamo numericamente o lo facciamo numericamente si può fare analiticamente quando abbiamo che la funzione è in armi parati quindi voi dovete individuare quale di queste funzioni sono in armi dei parametri per quelli applicati in medio analitico quindi con la funzione di barbino con la funzione di barbino ok per l'altra invece fate il metodo ecco come decide di stimare i parametri come il metodo SL per le tre funzioni per registrare test Pearson con chi quadro per decidere quale delle tre funzioni rappresenta meglio la evoluzione della y come funzione della x il metodo SL si dovrà applicare quando possibile la sua forma analitica e queste sono le equazioni l'equazione 7 e 10 e per anche dopo dovete anche calcolare il chi quadro e se potete applicare il procedimento analitico potrete applicare la formula 7 e 8 o se no altrimenti utilizzando la minimizzazione numerica per esempio con shimai optimized in questo ultimo caso il chi quadro verrà calcolato utilizzando la sua definizione ok va bene ok vi faccio presente che qui in nessuno di questi tre casi possiamo utilizzare la retta di regressione per cui non c'è nessuna retta non c'è nessuna equazione della retta va bene se avessimo un'equazione se potessimo provare con la retta di regressione potete anche provare in quel caso potete utilizzare anche le formule quelle di retta che abbiamo fatto quindi vi fate vi stimate i parametri calcolate il chi quadro e con quel titrato vi calcolate il con quel chi quadro utilizzate il test di Pearson per decidere quale delle tre funzioni rappresenta me la vostra la vostra quale delle tre funzioni rappresenta me il andamento dei vostri dati va bene più domande su nessuno o un po' ok qui c'è l'esempio del compito l'avete visto va bene domande da da remoto no no va bene come e ci sono sì no no che c'è non dubito no se aveva delle domande ah no no no no ah ok va bene va bene quindi questo è il secondo progetto 2 list list square method che però è abbastanza bene descritto anche semplicemente nella descrizione che c'è subito va bene allora oggi cominciamo a parlare quello che parliamo un po' per il resto di un po' il solito a parlare delle delle analisi delle serie temporali ok allora fino adesso abbiamo parlato perché abbiamo sempre detto che c'era un insieme di dati questi insieme di dati vanno a l'intervante sapere il barame la distribuzione il valore atteso oppure se il valore atteso è la variata se il valore atteso potrebbe essere l'errore e così via ora noi abbiamo lo stesso un insieme di dati però questi insieme di dati sono dei dati che si susseguono nel ritmo è un insieme di dati quindi temporali temporali no temporali però temporali brutto le serie si chiamano serie temporali insieme un insieme di dati misurato tipo diciamo in successivi i stati ok ora quindi questi dati quindi saranno ci avremo una variabile x sempre e sarà anch'esso sarà ancora una variabile casuale ok quindi possiamo scrivere come x di t perché oltre ad essere casuale dipende anche ora questa variabile casuale potremmo anche può essere o continua oppure può essere discreta in questo caso vuol dire continua discreta nel tempo quindi se questo è il tempo e queste x avremo se continua una cosa di questo genere se è discreta quindi avremo un susseguirsi continuo di valori in realtà quello che noi abbiamo il più delle volte è invece il valore a tempi discreti ok quindi ognuno di questo chiaramente sarà un tempo discreto ai tempi i con i che va da uno al numero di punti bene allora in questo caso sarebbe discreta ok allora quando noi pensiamo a una variabile di questo genere siccome una variabile casuale possiamo pensare che questo processo avvenga non una sola volta ma possiamo pensare che se una variabile casuale ha insieme di realizzazione possiamo pensare che questa variabile casuale la possiamo sia possibile studiarla supponendo quindi un insieme di realizzazioni sempre nella variabile x ok questo qui si chiama un ensemble di realizzazioni va bene allora in questo caso cosa abbiamo abbiamo che ci possiamo concentrare su un certo tempo ti star se ti segnate lo che segnate lo usiamo per te e possiamo andare a vedere in questi semi di realizzazioni quali sono i valori della x per quel star e vedere come è distribuito va bene in questo caso per esempio avremo che andremo a prendere come valori questi tre e tanti a avremo quindi che cosa avremo un insieme quindi un insieme di valori di x calcolato a x star bene questo insieme di valori avrà poiché la variabile x che è casuale questo insieme avrà una distribuzione una pd e quindi f di x che per esempio potrebbe essere una gaussiana verrà quindi questo è x e questo è la pdf questo è x di t star ok potrebbe essere una gaussiana o potrebbe essere anche un'altra cosa potrebbe essere per esempio anche invece una distribuzione non so fatta così una distribuzione che non è gaussiana e così va bene c'è da capire che questa qui è la distribuzione delle x presi a un certo tempo come se fossero tante realizzazioni di quel fenomeno va bene quindi vuol dire per esempio che a t star è questa se prendiamo so sapete che è venuta questa schifezza comunque non volevo adesso come faccio ah perché ho più casato qua diciamo che questo sia t due volte star quindi in questo caso avremo per esempio questi punti qua va bene allora può essere che a x in t al tempo dove star invece sia per esempio costata ok va bene va bene cioè può essere può cambiare per ogni tempo di star questa distribuzione va bene oppure può anche cambiare il tipo di distribuzione quindi quando noi per esempio diciamo che una serie temporale che gaussiana a un certo tempo vuol dire che se noi potessimo riprodurre quel fenomeno con tante realizzazioni diverse un esempio di realizzazioni che andassimo a lottare che andassimo a vedere come sono distribuiti i valori a quel tempo troveremo che l'istogramma è appunto una campana gaussiana ok va bene ci fermiamo un attimo ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok quindi è un time random process si chiama un processo casuale un processo casuale temporale non serve temporale va bene grazie dot Bryan iscriviti to Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Ok. Quindi, se considerato a diversi tempi, come stiamo facendo qua, c'è la distribuzione della nostra x, variabile casuale, a diversi tempi, il tempo, in questo caso, è considerato quindi il tempo alle funzioni di un parametro. È un parametro, per dire più semplicemente, è un parametro rispetto al quale, cambiamo il valore di questo parametro, potremo avere quindi diverse distribuzioni della nostra x. Allora, in questo caso, quindi possiamo fare a ogni fissato t, quindi fissato t, per esempio, uguale a t star, possiamo calcolarci le caratteristiche della PTF. Ok. Va bene? Per esempio, quali potranno resti queste caratteristiche? Beh, le caratteristiche di una PTF sono, innanzitutto, uno pensa che conta il valore del peso, la varianza, eccetera, eccetera, eccetera. E quindi faremo che cosa? Faremo, per esempio, e di x di t star, o x di t in generale, quindi sarà uguale a integrare del meno infinito a infinito, di x di t star, P di x di t star, in, che cosa? In x, dove, appunto, l'integrale viene fatto su tutto l'ensemble. Quindi, direi, azioni. Quindi, vediamo che in questo caso la Pdf, che qui abbiamo indicato come P di x di t star, dipende, chiaramente, dal parametro tempo. Va bene? Ok. Allora, nello stesso modo, quindi noi abbiamo sia P, quindi il valore della probabilità, la possibilità di trovare la probabilità che x ha un certo tempo, ha un certo valore, sia di vedere come questa probabilità evolve nel tempo. Bene? Come cambia. E quindi come la P dipenda dal tempo, dal parametro tempo, è da vedere, appunto, anche se i valori a un certo tempo della x influenzano i valori a un tempo successivo della x stessa. Va bene? Quindi possiamo definire anche in questo caso quelle che si chiamano la joint, come abbiamo fatto in precedenza, la joint probability density. la joint probability density, per esempio, sarà P di x1 al tempo t1 e x2 al tempo t2. Allora, se io dico questo qui, se io scrivo P di x1 al tempo t1, punte virgola, x2 al tempo t2 per di x1 al tempo t2, cosa mi calco se io faccio questa? Non mi ricordo se io faccio questa operazione. La probabilità è questa. E la probabilità congiunta, quindi, di avere x che al tempo t1 valeva x1, per x che al tempo t2 valeva x2. Allora, qui in realtà, prima che adesso dipende un po', se la x è sempre la stessa, devo fare anche per dx, però, dx qua, scriviamo dx1 e dx2. anche se è la stessa variabile, lo metto tra parentesi perché è la stessa variabile x, quindi questa qui come si calcola? questa qui, chiaramente, se abbiamo, quindi questa è la probabilità che x sia in x1, x1 più dx al tempo t2, va bene? quindi, questo è la stessa variabile, quindi, da x2, x2 più dx al tempo t2. va bene? va bene? ok? quindi è una probabilità congiunta, nello stesso modo, in questo modo, di più variabili diverse, di più eventi diversi. quindi i valori della x preso a t2 diversi sono i valori della x preso a t2 diversi. cioè, la x preso a t2 diversi. va bene? ok. ok. quindi, in questo caso, se abbiamo invece di x1, x2, abbiamo x1, x2, t1, eccetera, eccetera, potremmo scrivere anche, o lo scriviamo qua abbiamo scritto, potremmo scrivere che quindi l'integrale di P di x1, x2, xn al tempo t1, t2, tn in x1 e xn, questo è uguale a 1, chiaramente. se l'abbiamo su tutte. bene? questo qui è la stessa cosa di scrivere, certe volte lo scrivi in un modo, certe volte lo scrivi in un altro, per lo segno, per esempio, P di x1, t1, come ho scritto prima, x2, t2, è uguale, cioè, facciamo che sia, è solo un altro modo di scriverlo, di scriverlo P di x1, x2, t1, t2, ok? qualche volta ho scritto in un punto, capito? va bene? chiaramente noi possiamo anche chiedere qual è il valore solamente, cioè, qual è il valore che x1 stia, che x stia vicino a x1 al tempo t1, che x stia vicino a x2 al tempo t2, e non ci interessano tutti altri valori, quindi, come abbiamo detto, come abbiamo detto, la marginalizzazione. allora, per marginalizzare faremo semplicemente quindi che P di x1 xk ai tempi più 1 tk sarà uguale all'integrale di tutta quella roba lì, P x1 xk, x1 xn, adesso qui non mi scrive più, per lavorare, quindi, quindi, viupendo le affidità transpi, ora, così, trattate qui, integrare di P di x1 xn al tempo 1 di n, però integrato in di xk più 1 di n. Quindi non mi interessa sapere come sono distribuite, voglio sapere il valore della distribuzione del joint solo per certe variabili. Allora, anche qui, questa è la margine di realizzazione, stiamo richiamando un po' quello che abbiamo detto in precedenza per variabili normalmente. Possiamo scrivere anche il teorema di Bayes, o comunque qualcosa che assomiglia al teorema di Bayes, cioè che la probabilità, un'altra relazione, è che la probabilità di avere x1 xk, dato che si ha xk più 1 xn, non è altro che il rapporto tra la probabilità x1 xn fratto la probabilità di xk più 1 xn. Questa si chiamava, vi ricordate com'è? Questa è equivalente a P di A P di A condizionato da B uguale P di A intersecato B fratto P di B. Dove qui notate, non ho scritto, ma sono sottintesi di 1 xn. Va bene? È una sottintesi di 1 xn. Quindi questo non è altro che, come si chiama qui, l'ho detto? La probabilità condizionale. Va bene? Allora da qui possiamo anche, quindi, fare che cosa? Dire quando due insieme di valori sono indipendenti. Ok? Allora si dice che x1 xk sono indipendenti da xk più 1 xn se allora richiamando quello di prima P x1 xn non è altro che il prodotto da qui di x1 xk per per P di xk più 1 xn xn ok? Ok? Ok? Ok? O in maniera equivalente che P di x1 xk condizionato condizionato da xk più 1 xn sia semplicemente uguale a P di x1 xk cioè cioè cioè la probabilità di avere x dai diversi tempi fino a k con dei dati valori non dipende dalla probabilità che si c'erano appunto prima di quei valori ok? O dopo tanto il tempo può essere invertibile quindi in questo caso i due insiemi x1 xk e xk più 1 xn sono indipendenti va bene? allora va bene se abbiamo più processi poi magari ci ritorniamo se abbiamo più processi lo possiamo anche scrivere se abbiamo più processi quindi più random variables x e y allora si dice che sono indipendenti se qualsiasi sia mn qualsiasi siano tj si ha che p x1 xm y1 yn sono semplicemente uguali a p x1 xn xm non so se dopo si capisce più con questi scarabocchi p per p di yn x� ok Grazie. Grazie. Ok. Bene. Allora, passiamo adesso a capire un po', a cercare di descrivere cosa succede man mano che il tempo passa e quindi cosa succede alle diverse, alla distribuzione di x. Allora, noi, se un fenomeno è abbastanza regolare, ci aspettiamo che cosa? Cioè, la regolarità noi la pensiamo come la possibilità che queste PDF siano sempre le stesse a passare di tempo. Quindi, che cambiando il tempo, comunque la distribuzione, la probabilità di attivare diversi valori della x a diversi tempi diversi, segua sempre la stessa distribuzione. Allora, un fenomeno di questo tipo si chiama stazionario. Quindi, cosa abbiamo? Abbiamo che se x di t non dipende da t, nel senso che t di t, P di x di t è semplicemente uguale a P di x, quindi è la stessa per tutti i tempi, dall'origine dei tempi, quindi sempre. Allora, il fenomeno x di t è trazionario. Ok? Allora, quindi stazionario vuol dire che ha sempre lo stesso valore. Vuol dire che per ogni valore, quindi è lo stesso valore nel tempo. Vuol dire che, al passare del tempo, comunque la probabilità di trovare un x con un certo valore è sempre lo stesso. Cioè le PDF sono sempre uguali. Va bene? Ok. Allora, si può dare quindi, altrimenti non stazionario. Va bene? Allora, si può dare quindi anche una definizione più precisa. quindi P di x1 xn, calcolati al tempo, i1 tn, deve essere uguale a P di x1 xn, calcolati al tempo, i1 meno tau, i1 meno tau, i1 meno tau, qualsiasi sia n, cioè il numero di valori presi, qualsiasi siano i tempi, i, e qualsiasi sia tau. Questa è la definizione di stazionario tau. Allora, cosa vuol dire? Vuol dire che, questa è rispetto alla probabilità congiunta, quindi che ci può essere una dipendenza tra i valori di x a un certo tempo e i valori di x a un altro tempo. Va bene? Ma questa dipendenza dipende solo dalla distanza temporale che c'è tra i due tempi che consideriamo. Va bene? Quindi vorrebbe dire, per esempio, che questo è il tempo, questo è il mio fenomeno x, va bene? Vuol dire che la probabilità, se questo è questo è uno e queste due e questo è e possiamo anche fare semplicemente con uno invece con due. Eh, va bene. Faccio tutti, scusate. Questo è uno e questo è il tempo due, ok? Che la probabilità di avere x1, x2 ai tempi t1, t2 la probabilità congiunta di avere x1, x2 ai tempi t1, t2 è uguale alla probabilità di avere x1, x2 ai tempi, per esempio, a questi tempi qua, a b cioè dipende solo praticamente dallo shift temporale che io faccio, va bene? Quindi dipende solo dalla distanza tra i diversi, ok? E quindi in questo caso poi potremmo scriverlo anche in maniera diversa. Ok? Allora, quindi la pdf dipende solo dalla differenza tra i diversi tipi. Allora, la stazionalità chiaramente è un fenomeno, è un concetto molto importante in quanto rende possibile descrivere appunto i sistemi per un lungo tempo e nelle loro caratteristiche senza andare a vedere come queste caratteristiche variano al passare del tempo. chiaramente dipende anche da cosa noi intendiamo per passare nel tempo. Se per esempio prendiamo la temperatura di una stanza in un giorno, è chiaro che non è satenaria, perché? Perché di notte la temperatura va giù, va bene? però se vediamo la temperatura di una stanza in un periodo di un periodo molto più grave, quindi considerando molti giorni, in questo caso possiamo anche considerare appunto il satenario perché le scelazioni che c'è tra giorno e notte si ripetono in mente. Va bene? Possiamo quindi definire anche delle attenzioni che tengono che descrivono come appunto sono correlati diversi tempi tra di loro, il valore della x per diversi tempi tra di loro. Una di queste importanti è l'ensemble autocorrelation function che è r di t1 t2 di una certa variabile temporale casale x non è altro che il valore medio e il valore atteso di x1 di x x1 per x di t2 cioè integrare da meno infinito a più infinito di x1 x2 per la probabilità congiunta di x1 x2 più x2 in x1 x2 bene questo è l'autoporrelation function mentre l'autoporrelation function che gli assomiglia è la stessa cosa cioè vedere come i valori a due tempi diversi della stessa variabile sono correlati però non nel loro valore totale ma nel loro valore rispetto alla media e quindi che poi adesso andremo a definire quindi uguale e di x1 meno i1 per x2 meno i2 sì questo tutto masotto unutet uno per soluz Dempps l'autoporrelation e si ve un Cayce Beاط F la p ok quindi una è l'auto correlation questo è l'exemple auto correlation punch questo è l'auto covariant punch allora vedo che non state seguendo quasi per niente perché mi pare che non state seguendo allora finiamo sono il 41 finiamo un po' prima scrivendo appunto delle funzioni di cui domani poi parleremo calcoleremo anche oggi l'avevo messa oggi quindi la varianza come sarà? sarà sigma x di t quindi dipenderà dal tempo e quindi sarà e di x di t meno mi al quadrato che si può scrivere come e di x di t meno la media che dipende dal tempo al quadrato cioè ma e di x quadro scusate di t non è altro che l'auto covariant quindi e x di t meno mi quadro ok se se il fenomeno è stazionario se avrà che p di x1 x2 t1 t2 dipende solo da la differenza tra i tempi x1 t2 tau dove tau è uguale a t1 meno t2 va bene? e quindi l'autocorrelazione per i fenomeni stazionari dipende solo da tau ok e la stessa cosa la media anch'essa dipende è costante perché se appunto abbiamo che la probabilità dipende dal tempo allora c'è da un'origine temporale allora la possiamo scrivere è costante allora se abbiamo questo caso avremo che anche vediamo se riesco a scriverlo che anche sigma x al quadrato cioè la varianza è uguale all'autocorrelazione presa dal tempo zero meno il valore della media al quadrato ok va bene allora un fenomeno di questo genere in cui si può scrivere questa relazione si chiama un fenomeno wide sense stationary ok random process ok mettiamo qua anche tanto seguendo molto e domani allora riprendiamo queste cose e quello che volevo fare adesso degli esempi facciamoli esempi dei codici che ci sono già online per la promissora nella cosa di oggi domani vediamo e vediamo con diverse serie temporali come si sviluppa questo random process quindi domani vedremo ecco qua se volete anche guardare anche se puramente non avete tempo c'è il codice e qui avremo delle avremo appunto le serie dati le serie dati che ci saranno sia delle serie dati stazionari e non stazionari vedremo sia come vale la mitia la variata e anche l'autocorale di si fa ok va bene che sca non è ha Guate forse ed i passi a vedere anche le altre cose. Will all the power of cocaine? Eh sono dei sf verdi con le anche le anche due. Grazie.