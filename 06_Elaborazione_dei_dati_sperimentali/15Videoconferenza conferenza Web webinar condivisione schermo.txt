il massimo la coda cioè ricordate punto il metodo di max in poche parole era trovare appunto la funzione di likelihood quindi che dipendeva da certi parametri come prodotto di nella funzione delle pdf di n osservazioni quindi n piccoli e o questa oppure la log likelihood che ha lo stesso comportamento per quanto riguarda il massimo che quindi la sommatoria del logaritmo massimizzando questo rispetto a z quindi possiamo avere una massima funzione di una sola di s oppure ci sono più parametri abbiamo diverse massimizzazioni cioè nel senso diverse derivate si trovava il valore del parametro z quindi il valore del parametro z è in particolare l'estimatore del baranzo quindi avremmo qualcosa in cui dobbiamo dire che z è uguale a z di x ok abbiamo visto degli esempi e abbiamo visto che una volta trovato lo stimatore si tratta anche importante trovare anche che cosa? la varianza di uno struttore allora la varianza di uno struttore chiaramente e si può calcolare in diversi punti allora la varianza di uno struttore si può calcolare in maniera analitica allora in questo caso abbiamo uno può ricorrere alla solita ugualianza alla solita relazione che dice che la varianza dello stimatore è uguale alla la varianza di uno struttore è uguale alla la varianza di uno struttore è uguale alla valore atteso meno il valore atteso dello stimatore il tutto al quadrato questo qui perché analitica? perché quando andiamo a fare il valore atteso dobbiamo appunto conoscere che cosa? più che conoscere le f va bene? che conoscere è anche integrare sono degli integrali e quindi bisogna farlo analitica e quindi e la cosa è chiaramente tranne che per i casi più semplici sono dei calcoli complicati o quasi effettivi diciamo va bene? soprattutto perché noi facciamo con delle distribuzioni semplici ma ci sono delle distribuzioni anche molto complicate con tantissimi sparanze con tantissime dimensioni e quindi a quel punto fare la cosa analitica di metaforre un altro modo è quello di farlo con abbiamo detto il Monte Carlo allora Monte Carlo cosa serve? l'avevamo visto il Monte Carlo serve a simulare e a ottenere dei numeri distribuiti casualmente secondo delle distribuzioni di richieste in generale Monte Carlo è tutta volta quindi che si fanno dei calcoli ricorrendo quindi ha un approccio probabilistico quindi utilizzando dei dati creati da noi secondo delle distribuzioni richieste e in particolare si può usare non è detto che si deve usare per forza quello il metodo della RITMIS quindi in cui appunto si dice quando si prendono non si prendono ma in generale ogni volta che si usa una sequenza di numeri casuali si usa appunto si fa un approccio Monte Carlo nell'approccio Monte Carlo cosa facciamo? nell'approccio Monte Carlo riproduciamo riproduciamo l'esperimento K volte uso K per non confonderla con N che sono i numeri di dati quindi è come se per esempio se i numeri di dati sono 100 N uguale a 100 K volte vuol dire che facciamo per 10 volte 100 estrazioni fate conto è come se facessimo 100 misurazioni per 10 volte per 100 volte e per ognuna ci calcoliamo per ognuna per ognuna per ognuna per ognuna per ognuna ognuna vuol dire di queste K volte ognuna ognuna ognuna vuol dire di queste K volte il valore di Z e poi facciamo la deviazione di standard va bene? deviazione di standard utilizzando la formula del sample quindi avremo in questo caso in questo caso parliamo ZK Z chiamiamolo scusate non mi ricordo vabbè sì Z i valori con i da 1 a K ok quindi se però gli sperimenti ci togliamo lo Z e poi ci possiamo scrivere che v di Z quindi che l'abbiamo definita formata così S quadro ok il Z quindi sarà uguale a 1 fratto K meno 1 la sommatoria di che cosa? di Z i meno Z medio che è quello con cui abbiamo fatto il Monte Carlo per lì da 1 K al quadrato va bene? che sarebbe la sample bar quella che si chiama sample bar nel senso che ce la calcoliamo dai dati e così ci troviamo la sample variance e quindi se vogliamo la direzione star facciamo il terzo metodo è ricorrendo a una relazione che è quella appunto che abbiamo detto RCF cioè Rauch-Cramen-Frescher cioè Rauch-Cramen-Frescher ok che dice che esiste questa relazione io me la ricordo quindi qui fratto fratto il valore atteso di n derivata seconda della log like new rispetto a Z ci metto il segno questo qui a questo punto capisco che uno è il segno dello stimatore l'altro il segno del vettore 3 3 3 sappiamo che il parametro che possono essere per di 1 va bene? in quel caso se facciamo la derivata seconda rispetto allo stesso parametro abbiamo proprio la variazione se facciamo la derivata seconda rispetto a due parametri diversi abbiamo come la variazione v cioè questa qui la possiamo scrivere come v di zeta quindi è una matrice se c'è più di un parametro se c'è più di un parametro ok e questa matrice come fa? v i i sarà supponiamo v uguale a 0 che v sarebbe abbiamo detto il bias bias bias se non te lo scrivo quindi in zara c'è un eh nino lì se lo scritto ok queste saranno varianze mentre vij sarà ok ok queste saranno varianze mentre vij sarà vij sarà ok ok ok ok ok ok ok ok ok ok ok ok quindi è una matrice proprio la matrice è una matrice proprio la matrice di covariance la matrice di covariance è una matrice di covariance va bene quindi uno cosa può fare? può calcolarsi la matrice delle derivate seconde così fatta e poi invertirla va bene? la matrice delle derivate seconde si chiama la matrice di Fischer quindi la matrice di Fischer quindi la matrice di Fischer la matrice di Fischer la matrice di Fischer quindi la matrice derivata seconda del logaritmo di Elber secondo zi zi zi zi zi zi zi zi zi zi zi zi zi si chiama matrice di Fischer si chiama matrice di Fischer si chiama matrice di Fischer ok va bene e carolacea lì per se non guarda l'altro l'altro è il suo istituto valore 1 e quindi uno può calcolarsi questa matrice e poi invertirla per trovare appunto le covarianze e le varianze bene in quel caso bisogna invertirla perché appunto il fatto che sia uno su corrisponde a un'inversione allora da notare è che v va come uno su n dove n è il numero di osservazioni cioè la varianta di una certa di un certo stimatore è inversamente proporzionale al numero di osservazioni ok quindi più osservazioni facciamo più la varianta dello stimatore appunto diminuisce che si chiama e questo è importante va bene allora oggi proprio volevo quindi lo scriviamo la varianza dello stimatore è inversamente proporzionale al numero di osservazioni ok quindi in definitiva cosa possiamo dire possiamo dire che gli stimatori ml hanno queste proprietà sono assintoticamente unbiased unbiased cui sono assintoticamente normali cioè se il numero di osservazioni è alto si distribuiscono come una varianta normale quindi gaussiana e sono anche efficienti ok sono efficienti ok sono efficienti cioè se se per meglio dire se per meglio dire se esiste un stimatore efficiente il metodo della max immurale lo trova e efficiente vuol dire significa che la varianza è proprio uguale uguale uguale uguale a e quindi per meglio dire se per meglio dire se esiste un stimatore efficiente il metodo della max immurale lo trova significa che la varianza è proprio uguale al bound rc rc cioè è proprio uguale come abbiamo scritto qua questo perché questo sarebbe in realtà questo sarebbe in generale maggiore uguale cioè il teorema dice che è sempre maggiore uguale se è uguale il minimo che si può avere e si chiama rcf buff ok e la cd è sempre per l'outcome efficiente ok va bene allora proviamo ad applicare questi questi quindi proviamo a fare se avete il lato proviamo a proprio cercare di vedere come funziona perché poi questo stesso esercizio sarà uguale uno dei tre più gente ok allora ma che speranza secondo quello che abbiamo fatto in novembre come? che speranza secondo quello che abbiamo fatto in novembre allora la prima volta abbiamo fatto siamo a tutti di nuovo in Monte Carlo abbiamo visto che la media si distribuisce come con la varianza di misoen come la varianza di misoen va bene? qui non è che stimiamo la media qui stimiamo adesso vi darò una l'imparata una visione parola di una qualsiasi qualsiasi funzione di distribuzione non usiamo in questo esempio usiamo sempre la distribuzione la distribuzione la scriveremo la spoliziaria da che la parola la parola ok qui vediamo un po' scoperto vergas scusate Grazie. Grazie. Un insieme di misure indipendenti. Ok. E sappiamo che, o supponiamo comunque, le misure hanno una distribuzione conosciuta. Dipendente da uno o più paranzi. Ok. Ok. Allora, vogliamo trovare... Quindi valore del parametro. Ok. E... La sua... Pound gradation. Ok. Se sono più di uno... Troviamo anche... È possibile trovare comunque... Necomare. Ok. Ok. Ok. Allora... Se voi andate sulla pagina del Blended... E... E... E... Qua. E... E... E... E... E... E... E... E... E... E... E... E... C... E... E... E... E... E... Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Sì professore, salve Salve, vedi la pagina del trading? Sì, la vedo Ok, va bene, ho provvisto da me con tutto e mi disse che dava la mano Ok La sento, ora la sento un po' lontano rispetto a prima Eh sì, perché sono passato, ho fatto qualcosa Adesso mi sento mezzo? Sì, ora sì Allora Allora Sì io volevo per il tale che sto vedendo qua voi lo vedete lei lo vedete quindi dovrebbe essere allora voi cosa dite? ah no che è un esigente scuola scuola scuola questo non viene questo scuro no venga venga venga ah questo qua eh non so ma io vorremmo che si vedesse questo perché io adesso sto condividendo questo no se lo sto condividendo su zoom eh capito cioè lei sta guardando ma io l'ho già condiviso e i banner lo vede su zoom sì sì io vedo vedo adesso? sì sì ma non vede e voi non lo vedete voi guarda guarda facciamo una cosa eh lo apre da qua sì no adesso lo apre da qua lo apre lo apre lo apre lo apre lo apre lo apre lo apre lo apre lo apre ok qui esco da qua no grazie no no no allora e ritorno qua lo faccio da qua volevo farlo da sedere perché invece non ci riesco va bene allora qui no no adesso posso fare adesso vado avanti così e qui devo rifarsi po' adesso i Grazie. Ok? E sappiamo che questi dati sono distribuiti secondo una distribuzione sconenziale. Usiamo sempre questa che è abbastanza semplice ma non è che cambiamo uno. Quindi uno su tau e all'altro uno su tau. Allora attraverso questi dati cosa vogliamo? Vogliamo rimare la tua. Ok? E poi vogliamo anche rimare v di da. E vogliamo fare questo con il mezzo del maximum latino. Ambele con. Va bene? Quindi allora la prima cosa è che ci leggiamo i dati e possiamo farci un istogramma che è per vedere come sono messi. Quando ci sono dei dati la prima cosa è che si deve guardare come sono messi. quindi facciamo un plot dei dati. Ok? Quindi prima di tutto facciamo un plot dati, cioè un istituto. va bene? Poi cosa facciamo? Per utilizzare il metodo della massima risimiglianza dobbiamo costruirci la log lighting. Ok? Quindi per cui dobbiamo caricare i dati? Si deve dire la log lighting. Come dobbiamo fare? Dobbiamo proprio fare una funzione log lighting che dipenderà quindi da cosa? dai dati che sono quelli che ritorniamo da uno lì, questo tau e da tau che è un termine che è un termine che io ho la prossima. E da tau che sarà il nostro senatore. Va bene? Quello che vogliamo trovare. Fatto questo quello sappiamo, lo accusiamo, sappiamo che tau maxillulatium è quello che è tale che l'elevata di n del logaritmo di n del fondo tau, punto calcolata in questo valutore è uguale a zero. Ok? Allora questo come lo possiamo fare? Allora intanto carichiamo i dati e facciamo questa funzione maxillulatium. Allora quindi per caricare i dati ve li scaricate voi e io l'ho fatto questo programma ma si può fare anche meglio, cioè nel senso come al solito io ho fatto un programma, che dopo vi... Ah, lo devo salvare. ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... Leggo i dati, quindi con cqs leggo i dati in un'unità, e poi faccio un histogramma. Fatto l'istogramma, definisco la funzione pdf, cioè la mia power density function, che in questo caso è semplicemente quella dell'esponenziale. E quindi vedete 1 su tau per l'esponenziale al meno x su tau. E poi faccio la logline. Anche questa è una funzione che mi dice che è la somma del logaritmo di tutte le pdf. Quando facciamo così vuol dire che sommiamo tutte le pdf con x, che è quindi tutti i valori che abbiamo definito qua. Va bene? E potete cominciare a fare? Sì. Però dovete andare su quella lampa. Quindi la prima cosa, vi caricate i dati, fate l'istogramma se volete, e definite le due funzioni. La funzione pdf è la funzione che fa la log likelihood. Con GRE da dati. Come? Grazie. Importante che capiate cosa stiamo facendo, anche perché si possono fare anche più leganti, sono scritte in grado, non è che... Importante che capiate che, va bene, quindi c'è la pdf e poi la log-like, in Python la possiamo scrittere tutto. Bene? Che sarà quindi funzione sia del tau che li diamo, sia appunto dei dati, perché i x non sono altro che i dati. Ok. No, no, sicco va bene... Sì. No, non c'è un'altra. Perché ne ho messi solo due. Cioè ne ho messi tre, ma quella di te sarà nascosto. Perché dopo che lo faccio, perché adesso voglio che lo facciate voi. Dunque lo faccio, ma vedo che lo rendo finito. Allora, ok. Può anche condividere. Lei è su Zoom, ma no, non si cade niente. No, dopo facciamo quel casino. Ok, quindi lei ha ricapitati. Benissimo. E quindi abbiamo una cosa di questo genere. l'adozione. Grazie. Grazie. Grazie. Ok. Adesso lo vediamo. Qua. Ok, quindi queste sono le punzioni. Bene. E' perché lo sono da adesso, ma devo sbiscuare, infatti. E' perché non volevo farla, ma mi diceva bene, e ti spiace più. Dopo me lo condivido con il tuo punto, ma se ne sei due, e insomma così. Questo qui, adesso non c'è nessun problema, l'ho nascosto perché dopo... A parte qui c'è un'altra parte che nel file che avete voi non c'è. Comunque... Ah, ecco. Quindi quello che mi dico è semplicemente quello che mi ha fatto. Lei non ce l'ha. Ma... Ma... Anche con... Se lo fa a dire... O... No, questo è quell'altro. Quello prima. No, adesso un altro... Questo è un altro programma. Sì, stiamo facendo questo programma. Allora... Allora, sto facendo questo perché così vi faccio vedere quali sono i passi che dovete fare poi per... Con un altro idato, con un'altra pdf per fare l'esercizio. Quindi il primo passo è quello di caricare i dati e poi di... Vabbè, uno fa l'istogramma per vedere come è fatto, ok? E poi cosa fa? E poi va a definire la funzione pdf e la funzione log pdf. A questo punto, come facciamo per trovare il valore dell'ostimatura da un dialogo? Dobbiamo, infine, sfruttare questa condizione. Trovare il massimo. Allora, qui... Si possono, in generale... Seguire due modi. Uno è quello di prendere questa funzione, plottarla e trovare il massimo numero interno. Cioè, guardandogli un punto, trovi quello che vuoi il massimo. Ok? E questo è... Log out. Oppure... Usiamo... Minimind. Minimind. Minimind è una... Una funzione numerica di Shqai che, data una funzione, trova il massimo numero. Quindi, in quel caso, trova il massimo numero. Quindi, siccome noi dobbiamo trovare il massimo, poi troviamo il minimo del meno, cioè del valore opposto. Allora, quindi guardate. Adesso, saltate questo qui, che voi comunque non ce l'avete, perché non l'avevo messa a questa parte qua, però dopo ne discutiamo. Ecco, la prima cosa cosa ho fatto? Ho plottato, quindi, la funzione long likelihood. Ok? E questo plot viene... Viene questa cosa qua. Va bene? Questa quindi è la long likelihood. Ok, vedete che ha un massimo. Qui, quindi qui, sulla X, vedete non ci ho messo, però poi aggiungo un po' il fatto del D anche nel progetto che fate. chiaramente, fate un plot, qui ci mettete Tau, qui ci mettete log likelihood, cioè mettete anche gli assi, sopra lo fate poi bene. Quindi, qui c'è Tau, quindi lo stimatore. Qui invece c'è la log likelihood. Il valore che stima, secondo il massimo likelihood, meglio, il parametro cercato, cioè il tau è quello del massimo e quindi più o meno 4. Quindi più o meno 4. Va bene? Come facciamo a trovare questo valore? O cerchiamo tra tutti i punti quello che ha il maggiore valore e poi guardiamo perché Tau è, oppure usiamo Optimize. Optimize, quindi in due modi lo facciamo, una con una grippia. ecco, vedete cosa ho fatto qui? Qui ho fatto il plot, poi ho fatto estimated Tau with grid, cioè prendo il massimo tra i valori della log likelihood, ne prendo l'indice e poi prendo il Tau con su D. Ok? Se invece voglio fare con Optimize, utilizzo questo qua. Però siccome Optimize è appunto Shipai, vedete il pratico su, quindi Shipai Optimize import Minimize, quindi è una funzione del pacchetto Shipai che minimizza una funzione. Noi la vogliamo il massimo, quindi cosa facciamo? Definiamo il log likelihood un negativo, semplicemente col meno davanti e poi usiamo questa funzione Minimize. Va bene? E quindi dovete andare a vedere come funziona. bisogna metterci il valore da cui si parte, io ho messo uno, i bounds, cioè entro che valore Tau può essere trovata, e poi la funzione. E in questo modo appunto trova, se uno va a vedere maxval.x, cioè il valore di x, trova appunto il valore che ha minimizzato quella funzione, quindi massimizzato la nostra log likelihood. Se andiamo a vedere quando esce, trovate, vedete, trovate, estimated Tau with grid, che sarebbe semplicemente col grafico, viene 2.2. Tau with numerical maximization, che sarebbe appunto, usiamo Sparum, Dimine, Dimine, viene 2.18. Va bene? In realtà il valore con cui questi dati sono stati prodotti è 2.1. Quindi siamo vicini, ma per quello metico, dipende, bisogna dare una varia di quantità. Va bene? E questa era con 200 misure, ma mi sa che non sono solo 200 misure, ma che sono di più, aspettate. Quanti dati, quanti sono i dati? Sono i dati. I dati negli sono stati, quanti sono? 1.200. Ok, quindi prima cosa abbiamo fatto questa parola qua, quindi definire la funzione log L che dipende solo da Tau, perché i tx sono i valori misurati, poi vedere dove a un massimo si può fare sia biatricamente sia una fotovoltaica. che è un'altra fotovoltaica. Bene? Ok. E quindi è il valore trovato dalla vostra. Bene? Ok, fermiamoci un po' di minuti e poi continuiamo qua. Andiamo a chiedere a Paolo. Andiamo a chiedere a Paolo. Ok. Ok. Ok. Continuiamo. Allora. Ok. Ok. Ok. Continuiamo. Allora. Allora. Allora. Allora. Allora. Allora. Allora. Ok. Allora. Ok. il preso se mi sono ok quindi a questo punto siamo arrivati a conoscere la stima del nostro parato a questo punto cosa dobbiamo fare dobbiamo vogliamo trovare quindi la sua standard deviation la sua standard deviation quindi lo facciamo come? lo facciamo anche questa in due modi lo facciamo quindi a questo punto siamo su stimare la varianza e quindi la standard deviation e lo facciamo in due modi lo facciamo con Monte Carlo o con il Traum, Traum e Trecepa bene allora con Monte Carlo come fa la buona? per calcolarmi la varianza non è lì non è quello che ho provato quello che c'è lì non è quello che ho provato quello lì è della volta questo qui lo gargono dopo lui c'è l'altra che ha caricato io lo ho dei segni di questo nome ma con Monte Carlo ci stai chiedendo però i dati con Monte Carlo ci sembra i dati però sono solo quelli misurati non possiamo fare altre misure Monte Carlo serve proprio per produrre dei dati casuali che è di cui non abbiamo le misure quindi cosa facciamo? produciamo dei dati casuali distribuiti secondo la nostra distribuzione utilizzando i dati di previsto questo è un'altra misura questo è un'altra misura queste sono duecento misure se vogliamo per esempio fare dieci esperimenti simulare dieci esperimenti quanti dati dovremmo avere? un perciso ognuno duecenti quindi due mila dati chittenes ok? il che vuol dire che utilizzando Monte Carlo perché alcuni vengono scartati dovremo fare un ciclo su un numero molto più alto ok? fino a ottenere un numero di dati con il numero di esperimenti che noi intendiamo utilizzare per scrivere allora qui c'è un punto quando noi andiamo a fare Monte Carlo dobbiamo utilizzare quindi la distribuzione appunto in questo caso la distribuzione esponenziale nella distribuzione esponenziale quindi quando utilizziamo Monte Carlo quindi Monte Carlo per SNAO la variata cosa facciamo? e a guà Monte Carlo per bus城 Crow ma la v di Z e utilizziamo la pdf però nella pdf che cosa c'è? nella pdf si trova di introduci anche il valore del parametro che valore del parametro utilizziamo? quello che abbiamo trovato quindi utilizziamo la pdf con z uguale z del maximum likelihood bene? e quindi avremo a questo punto una pdf che dipende questa è la formula che dipendeva da NIRSI tau sarà missato nel nostro esempio f sarà sarà 1 su tau ml e alla meno x fratto tau ml dove tau ml sono quelle che abbiamo trovato dai dati veri ok? e questo qui lo utilizziamo kit and miss quindi il morte calo hit and miss e produciamo dati simulati per simulare a loro volta n esperimenti dopo il numero di esperimenti quindi questo è una parte quindi bisognerà fare produrre questi dati simulati va bene? prodotti questi dati simulati per ogni esperimento quindi per ogni 200 dati simulati dovrebbero ripetere che cosa? questo va bene? non conviene neanche questo conviene neanche questo cioè ripetiamo che loro dovrebbero rimanere in modo di trovare come se facessimo veramente 200 esperimenti e quindi avremo a questo punto c'è 10 esperimenti scusate quindi avremo a questo punto quindi calcolo tau maximum likelihood i per i da 1 a n con minimize ok? come abbiamo fatto qui? va bene? ok? e questo è quello che abbiamo qua dovrei averlo fatto così ok? eh qui l'ho fatto diverso in questo esempio che vi metto perché per allora quello che vi carico commento questa cosa perché per tau ma questo è solo vale l'abbiamo visto l'altra volta vale solo per la pdf esponenziale l'estime di tau non è altro che la media dei tau del sì la media non è altro che la media e quindi insomma è semplice ma in generale invece bisogna fare appunto per ognuno bisogna dei modi di dargli ok? a questo punto cosa faremo? calcoleremo la varianza con la sample variance e quindi come abbiamo scritto qua da qualche parte quindi a questo punto calcolo con minimize poi calcolo la sample ma l'avevo scritto no? questo S4Z che va a proprio parte non l'avevo scritto scusate qui ma non ho scritto questa formula ma dove non lo vedo? ma questo sì è scritta lì questo sì è scritta lì ah è un po' sempre la sample variance ok? va bene scriveremo la sample variance allora qui nel codice che c'è qua appunto come ho detto calcolo il tau semplicemente come per ogni esperimento come media tra il tau delle pdf perché così si può fare e poi abbiamo il tau delle pdf e poi abbiamo quindi la media delle pdf e poi abbiamo la varianza la varianza appunto la calcolo vedete questo qui o questo è un calcolo mio se no si può utilizzare direttamente anche la varianza il programma che stima la varianza in parte ok? ok e qui viene questo qui ok e qui viene questo qui quindi la media delle stimenti tau e poi abbiamo la varianza, la varianza appunto la calcolo, vedete questo qui, o questo è un calcolo mio, se no si può utilizzare direttamente anche il programma che stima la varianza in parte. Ok, e qui viene questo punto, questo è quello che viene, quindi la stima di tau, questo è un MC, quindi la stimazione della variante 0.018, la stima teorica, perché in questo caso si può ottenere anche la stima teorica, per il caso di Degrad, della distribuzione esponenziale, la stima teorica era 0.023, e allora ci viene 0.018. Ok? Ah beh, forse era lo stesso programma, non aveva fatto, invece si vede che l'ho fatto anche questo. Ah vabbè sì, no ha ragione. Ok. E questo qui, a questo punto abbiamo stimato con Monte Carlo, poi si può stimare con RGFBound. Allora in questo caso bisogna utilizzare la funzione SimPy. Forse l'avete mai visto. SimPy è un pacchetto che in parto fa lo sviluppo simbolico delle operazioni analitiche. Va bene? E quindi per esempio fare il dato di una funzione fa la derivata simbolica. non so se avete mai utilizzato la matematica questi programmi qua. Per il senso che sono programmi in cui uno da una funzione e non ci sarà derivata simbolica. Non si vedete. E' come se la facessi a voi. E qui si può fare e andate a vedere praticamente dovrete definire una log like simbolica. quindi ci sono questi simpi simpi e poi vedete questa log like simbolica si può differenziare ok? Quindi simpi dif questa è la derivata seconda va bene? e poi una volta che si è caricata la derivata seconda e la si calcola nel valore appunto che abbiamo trovato di tau ml scrivendo appunto quello che è l'RCF bound che era v di sera uguale meno u derivata seconda della log like di u punto z calcolata per tempo uguale a tempo a ml trovata la variazza va bene? Trovata la variazza perché qui c'erano se due reti per fare quindi genera paro come due metoli va bene? questo qui funziona bene perché qui si può fare simbolicamente perché se no bisognerebbe farlo numericamente è veramente molto complicato di fare una differenziazione numerica una doppia differenziazione numerica quindi dipende qui dopo lì ci sono sempre i numerici ma questo qui che la stima parmene a Monte Carlo qual è la lingua? allora funziona molto bene il punto è che la stima di Monte Carlo se può essere computazionalmente molto pesante perché bisogna fare molte cose e poi queste sono semplici ma se sono degli esperimenti complicati fare tanti vuol dire su un'altra le applicato se uno può utilizzare la CfBaud che ha vinte e insomma ha una stima molto buona ok va bene allora questo io insomma in realtà volevo farvelo fare a voi però devo dire che non ha funzionato la cosa mi pare questo sarà ad applicare a allora allora qua qua ecc Dankulasощ ecco e questo sarà il progetto 1 maximum latitude parameter estimation allora vedete che c'è scritto questi sono i dati saranno altri dati rispetto a questo example maximum latitude with two parameters perché riprendiamo una funzione di distribuzione che c'è anche nel coin adesso ve la faccio vedere che però non ha un solo parametro di equità ma ha due parametri quindi si starterà di stimare due parametri le loro varianze e anche se è possibile la covarianza andiamo a vedere com'è questa funzione allora il co1 qui l'ho messo da qualche parte l'ho linkato non mi ricordo se l'ho linkato qua ma questo è quello vecchio allora vediamo se lo troviamo vediamo vediamo grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti è che questa questa qui è o meglio questa questa sarà la funzione di distribuzione ok allora vedete questo è un caso in cui loro avevano messo 05 05 quindi ci sarebbe utilizzare questa invece di questa pdf esponenziale ci sarebbe utilizzare questa e appunto trovare io vi do i dati comunque i dati voi dovete trovare la stima quindi maximum likelihood di alfa e beta con lo stesso procedimento e con gli stessi procedimenti poi vedete questo qui lo dice lui e qui facciamo questi qui che sono le standard deviation these have been estimated by computing numerically the matrix of the second derivatives of the log likelihood function with respect to the parameters quindi questo che metodo è? parla di una seconda poi invece direi quello di le recente questo è l'ha fatto numerica si può fare anche simbolico se no solo lo fa numerica e ha trovato anche la covarianza tra alfa e beta bene? se no e quindi così dobbiamo farvelo facciamo anche anche facendo un Monte Carlo va bene? va bene? quindi voi io vi darò quindi 2.000 dati e poi voi farete per esempio qui 500 va bene come si fa 500 Monte Carlo e attraverso quello potete calcolare di nuovo appunto la data di quest'anno o qui cosa avremo invece di questo? qui è TAU e questo è la log likelihood qui non abbiamo solo TAU abbiamo alfa, beta e quindi non avremo una programma una superficie quindi bisogna fare un plot di una superficie e trovare il massimo di superficie e quindi abbiamo questa cosa quindi questo sarà il primo il primo esercizio poi qui fa vedere per esempio possiamo vedere questa è un'altra cosa le varie distribuzioni queste per tutti Monte Carlo per i 500 Monte Carlo alfa e beta e si vede che sono correlati perché? perché se non fossero correlati sarebbe semplicemente una cosa tutta e invece c'è una dire correlazione va bene? e vabbè queste sono le distribuzioni marginali di alfa e beta trovate sempre con il Monte Carlo ok? la descrizione di questo che vi ho detto comunque la ritrovate anche qua come utilizzare Monte Carlo questa è l'RCF bound come utilizzare il Monte Carlo non abbiamo fatto tutto noi ma parte sì è come utilizzare il Monte Carlo per calcolarsi la varianza dello stimatore c'è nel 6-5 varia il suo eme allestimento Monte Carlo e il suo eme è il suo eme che è quello che dobbiamo fare così quindi mi piace ok Ivana ci sei ancora riesci a vedere a seguire? sì sì ci sono sto seguendo sì sì ok benissimo va bene allora niente qui perché comunque siamo andati avanti abbastanza velocemente quanto poi non avete fatto il programma possiamo anche cominciare ancora abbiamo una mezz'oretta a fare il prossimo il prossimo il prossimo argomento che è altrettanto interessante e è sempre appunto in relazione a come interpretare i nanti allora ritorniamo qua ci sono domande su questo qui perché poi non ci sarà da fare tutte le cifre domande anche se lo fate però se dovete fare questo è un po' non meno come come avuto in su allora affrontiamo un altro argomento in cui abbiamo lo stesso delle misure di una quantità y per esempio ok e quindi abbiamo y i da 1 per esempio a n e in corrispondenza di queste misure abbiamo anche le misure di un'altra grandezza in corrispondenza xi che sono appunto in corrispondenza con y quindi per ogni xi avremo un y per esempio un esempio che vi fa anche dico è la temperatura supponete da avere una sbarra va bene con per esempio due temperature diverse ai capi ok e fare sei misure della temperatura a diverse punti della base stessa acqua di ok allora il problema qui è di trovare la relazione che c'è tra di x fino a e di x va bene? quindi vogliamo trovare che cosa? vogliamo trovare una funzione di questo genere cioè una funzione che mi descriva la relazione che esiste tra le x e le y vedete adesso poi diremo meglio specificeremo meglio qui cosa è? è una funzione che come al solito dipende anche da dei parametri quindi qui ci sono due due richieste una è supporre che funzioni è l'anada e poi supporso la funzione che dipenderà da dei parametri z trovare il parametri z ok? allora questo è il caso che avete già visto cioè avete visto queste cose questo si vedono non so se l'avete fatto anche in machine learning ma comunque si vede anche in fisica così per esempio supponete di andare a riportare x non e y in un grafico e che o' non so se si si o' années Grazie. Grazie. Una delle funzioni, per esempio in questo caso, che si andrebbe a provare, che cos'è? È semplicemente una retta. Ok? Una retta, quindi uno potrebbe supporre che la funzione giusta sia una retta. Va bene? Che questa sia la mia y uguale lambda di xz. Va bene? Quindi in questo caso cosa avremmo? Avremmo che le z sarebbero che cosa? Le z sarebbero, ricordo che le rette possono rappresentare come y uguale mx più q, quindi in questo caso un parante da stimare sarebbero mq. Ok? Allora, qui manca qualcosa. Chiaramente questi dobbiamo adesso definire meglio il nostro problema. Prima di tutto supponiamo che ci siano degli errori su una y. Quindi, cosa supponiamo? supponiamo che le yi siano distribuite in maniera gaussiana – adesso non posso scrivere po', scusate, non posso substances. Normalmente con media lambda i che non conosciamo bene e standard deviation sigma i ok quindi questi qui non sono altro che le y i queste sono le osservazioni non sono le lambda i perché le lambda i non le conosciamo come si procede però questi qui rappresentano le sigma ok quindi gli errori che potrebbero essere anche tutti uguali potrebbero essere interventi ok per esempio qui noi per y1 potremmo fare 10 misurazioni e mettere in punto sarebbe la media di quelle 10 misurazioni e la sigma sarebbe calcolata con la sample variance e questo lo potremmo fare per 1,2,3,4,5 e riportare questi dati poi supponiamo che invece le x siano conosciute con precisione quindi sulle x non abbiamo errori si potrebbe anche generalizzare con errori sulle x ma adesso noi facciamo questo caso qua allora adesso ci chiediamo continueremo domande per fare un sviluppo diciamo teorico ci chiediamo come trovare le domande sono due quindi come trovare i parametri quindi domande sono come trovo i parametri prima domanda seconda domanda il fit che tengo è buono ossia anche è corretto usare la lambda x z scelta quindi come faccio a misurare se il fit che faccio è buono e se la lambda scelta quindi la la funzione che scelgo è quella giusta va bene perché perché qui io potevo anche supporre che fosse meglio questa qua adesso questa è un po' subito per esempio però cioè non c'è sempre un solo fit cioè dobbiamo avere anche il metodo uno parte da quello lineare chiaramente perché è più semplice ma poi se c'è dei fit con delle parabole o dei fit con le sponenti eccetera eccetera e noi dobbiamo essere in grado di misurare quindi utilizzare diversi tipi di fit e avere una misura di quello che miglior perché quello ci può decidere anche di una teoria va bene noi possiamo teorizzare che sia una dipendenza lineare oppure che sia una dipendenza quadrata va bene quindi dobbiamo avere anche una misura di quello quindi c'è tutto sviluppato un metodo su questo che si chiama il metodo dei mini quadrati va bene che non fa altra intuitivamente non fa altra che misurare la distanza che c'è diciamo tra la retta per esempio con la linea viola e i punti ok e minimizzare quelle distanze in modo tale che venga la cosa e qui va bene c'è tutto adesso una teoria sia numerica sia anche per certi casi analitica che si può utilizzare soprattutto la morire in questo caso per i dettagli esercizi va bene ok io direi oggi di finire qua perché se cominciamo poi manco un 10 minuti cominciamo un po' ma scusate la volta non può perché da me e 51 sono va bene ok va bene arrivederci allora anche online arrivederci arrivederci arrivederci a a