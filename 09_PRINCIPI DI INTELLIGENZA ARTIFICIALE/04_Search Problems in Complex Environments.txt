Quindi con questa settimana ci spostiamo, rimaniamo all'interno del framework dei problemi di ricerca, quindi non facciamo cose che ci spostano, non capire dei problemi di ricerca che in qualche modo ci servono dato un obiettivo per trovare quella che è la strategia che ci porta a raggiungerlo. Quello che cambia è il tipo di ambienti che ci troviamo ad affrontare. Le strategie che vi faccio vedere oggi sono molto famose anche proprio come tipo di approcci nel contesto dell'intelligenza artificiale, quindi vedrete che sono ricorrenti in diversi contesti. E partiamo da, diciamo, quello che vi farò vedere sono due casi diversi. Ambienti complessi, in realtà qui vedrete che la complessità sarà non tanto in elementi di questa classicità, quanto piuttosto nel fatto che l'ambiente è talmente ricco e complesso che faccio fatica a rappresentare, riscrivere il problema con condizione di stati, ma anche per la quantità e l'esplosione sul numero di stati e anche perché in molti casi non mi serve, come nei primi esempi che vi faccio vedere, definire un piano con veri e una sequenza di azioni per raggiungere l'obiettivo, ma sono problemi questi che sostanzialmente hanno, diciamo così, l'orbanio della ricerca dell'obiettivo, senza la necessità che qui l'obiettivo sia raggiunto, per esempio, per il percorso più corto in assoluto. Quindi non mi interessa tanto il percorso per raggiungere l'obiettivo, quanto piuttosto appunto il fatto di raggiungerlo. Questo implica che la strategia di ricerca non restituisce, come i problemi che abbiamo visto fino alla settimana scorsa, l'insieme delle azioni da svolgere per raggiungere l'obiettivo, poi, a prendere un nodo da uno stato iniziale, ma mi restituisce solo ed esclusivamente la prossima azione da svolgere. Quindi è un problema talmente complesso, un agente talmente complesso che faccio fatica a descrivere tutti i suoi stati, diventa una cosa che è poco gestibile. Inoltre, non mi interessa avere informazioni su il costo del percorso, dell'intero percorso per raggiungere l'obiettivo, ma l'altra cosa che voglio fare è raggiungere lo stato che rappresenta la soluzione al problema, e lo però vedremo identificando generativamente la prossima azione da svolgere, ma senza avere nessuna idea di quello che possiamo chiamare il percorso, il percorso, il percorso, l'insieme di azioni. Quindi questa è la prima cosa che vediamo. La seconda cosa invece che vediamo è legata ai problemi di ricerca con avversario, quindi questo è poi il secondo esercizio che trovate in examen. Quindi i problemi di ricerca con avversario iniziano, invece, incominciamo a introdurre un po' di soccosticità. Quindi vedremo, come appunto vi avevo anticipato, che il nostro ambiente comincia, vedete, a essere sempre più complesso rispetto alla definizione, versione banale, quella che abbiamo visto in settimana scorsa, e dovremo imparare a gestire anche questi ambienti e questo genere di problemi. In molti problemi di ottimizzazione, il percorso, quindi quello che era l'insieme delle azioni che restituiva la strategia di ricerca fino alla settimana scorsa, in molti problemi il percorso è rilevante. L'unica cosa che ci interessa è raggiungere lo stato obiettivo, la soluzione. Ok, vi faccio vedere uno di questi problemi, così iniziamo a subito avere un pochino il quadro di quali sono i problemi che vogliamo occupare a ciò. Allora, questo qua è il problema delle... Questa è una versione semplificata, infatti vedete nel titolo si chiama N-Quins. In generale il problema per eccellenza e semplificativo che viene proposto su questo caso di studio sono le otto origine. Si parla del problema delle otto origine. Vediamo se avete delle slide qua. Eccola, questa qua. Questo è il problema un pochino, diciamo, standard di riferimento in questo contesto. Quindi questo cercate di memorizzarlo, perché anche, per esempio, noi delle volte lo proponiamo, questo problema. anche quando in programmazioni, eh, vogliamo... Sì, inventiamo degli algoritmi per... ...perche possono essere risolti algoritmicamente dagli studenti durante l'esame. e delle volte compare una versione semplificata anche di questo problema. Un problema molto carino. E il problema dell'altro origine, ripeto, che volendo, può essere rivisto in versioni semplificate o resi ancora più complessi, quindi con un numero di origine variabile, insomma. E questo è conoscente... Vedete, hai visto? In algoritmi, forse... Esatto. Esatto. Infatti, come chiedevo qua, proprio perché è un problema che, appunto, è ricorrente. Questo problema qui, te lo descrivo, ha questo obiettivo. Io ho un numero di regine pari al numero di righe, o al numero di colonne, un'attrice quadrata, e le regine possono essere una sola per colonna, ok? Quindi, per definizione, anche quando inizializziamo il nostro problema, come vedete nella figura A, anche quando inizializziamo il problema, possono essere una sola per colonna. Quindi ho, per definizione, una sola regina per colonna. E possono muoversi solo in verticale. Per fatta di corsi, perché altrimenti qui entri però più di una per colonna. Quindi possono muoversi solo in verticale, e inizializziamo il problema mettendone una sola per colonna. E l'obiettivo di questo gioco è quello di posizionarle in modo tale che nessuna di queste regine può attaccare un'altra regina. Descriviamo che cosa è proprio applicare. Due regine si attaccano vicendevolmente, o se sono sulla stessa riga, o se sono sulla stessa diagonale. Non dico sulla stessa colonna, perché per definizione del problema questo non può capitare. Ok? Quindi, se due regine sono sulla stessa riga, o sulla stessa diagonale, si attaccano a vicenda, e questo non è una cosa possibile. Stavo guardando questa sinistra. Esatto. Questa sinistra già ha una configurazione che rappresenta una soluzione, se la guardate. Perché in questa, peraltro, lo trovate anche nella caption qua sotto. Quindi nessuna, questa soluzione qui, dell'otto queens problem, posiziona le otto regine su una scacchiera, così che nessuna delle regine può attaccare nessun'altra. Ok? In particolare, guardate, invece che nella scacchiera in B, insomma, a destra, e questo è uno stato intermedio che non rappresenta una soluzione al problema, perché ci sono diverse regine che si attaccano vicendevolmente. Per esempio, questa attacca questa, poi ci sono diverse regine sulla stessa diagonale. Ok? E quindi, immaginate, in maniera casuale, questo problema, e di avere come obiettivo quello di posizionare le regine, come vedete qua a sinistra. Ok? Dopo, rientriamo nel merito di questi numeri, cosa significa, e cosa non significano, però intanto mi serve questo, questo idea, questo idea per farmi entrare nel mood, nel tipo di problemi che ci troviamo ad affrontare. Allora, in questo tipo di problema, a me non mi interessa, proprio per definizione, non mi interessa niente se ci metto 10 mosse, 20, 30, 40, 100, per raggiungere la soluzione, quindi lo stato finale, nessuna regina può cantare nessuna regina. È chiaro che, se dovessi parlare in assoluto, magari una soluzione che mi porta, insomma, un insieme di mosse che mi porta a trovare la soluzione più brevemente, potrebbe essere preferibile, ma non è un requisito di questi problemi. Il requisito è che io arrivo allo stato finale, ok? Quindi arrivo allo stato finale in cui effettivamente nessuna regina. Quindi, quello che i triangoli e i pubblici che si tratta ancora a fanno, è questo. Dato uno stato, come per esempio questo sulla destra, ok? Dato uno stato, definiscono quali sono tutti i possibili stati successivi. Tutti i possibili stati successivi in questo caso qui sono moltissimi, perché la regina, qui, le regine che si possono muovere sono 8. e ciascuna regina, oltre alla posizione attuale, ne può assumere altre 7, ok? Quindi si può muovere in verticale, perciò può, per esempio, questa regina può andare in questa posizione, può andare in quest'altra posizione, può andare in quest'altra posizione, spero che vi agli atto il cursore. Quindi, sono 8 regine, ciascuna può raggiungere, può fare sempre i mosti diversi, capite che il numero di stati che è possibile raggiungere da questo stato qui è veramente ampio, ok? Quindi, per questo, mi anticipavo, spesso, diciamo, ci troviamo a parlare di questi problemi e di parlare di complessità, perché diciamo, ad avere dei problemi da cui descrizione, in termini di grafo degli stati, non so se ricordate, insomma, quando abbiamo scuso per settimane, è sostanzialmente impraticabile, ok? e appunto, qui a me interessa solo capire quale di questi 8 alla 7 possibili stati successivi è uno stato che migliora la mia attuale configurazione, ok? quindi, non ci vorrei, ripeto, pensando a un attimo percorso, ma solo pensando a questo, sono nello stato A, voglio andare da A, nello stato B, che migliora il mio stato attuale. allora, questo concetto di migliora dovrebbe accendervi qualche lampadina e soprattutto fare pensare che se nel miglioramento si parla, che cosa viene insieme al concetto di miglioramento? C'è un qualcosa che deve messo a questo miglioramento, quindi io per poter dire che passo da B e che B è meglio di A vuol dire che ho una funzione, o quale forza, una metrica che mi dice, mi misura quanto gli stati sono buoni. Questa metrica è la nostra funzione euristica, che abbiamo già visto, no? Come funzioni euristiche, le abbiamo già viste quando abbiamo parlato dell'algoritmo star, per esempio. Non è così, il concetto è molto simile a quello della star, perché sostanzialmente all'epoca euristica della star diceva quanto sono distanti dall'obiettivo. E qui ancora mi dice, sì, quanto è migliorativo, rispetto al mio stato attuale. E quindi, quanto sono distanti dall'obiettivo potrebbe essere un'interpretazione abbastanza più valente e ragioni valenti in questo caso, ma dipende dal tipo di problema. In questo caso potrebbe andare bene, perché vi faccio un esempio di una possibile euristica che posso definire per questo problema. Vi ricordo che la definizione dell'euristica è già parte della progettazione della soluzione del problema. Puoi dire, perché proprio attraverso la definizione dell'euristica poi è cascata e dipende la soluzione del problema. Quindi è tutto meno che banale. Avevamo anche ragionato su come potevamo definire delle euristiche per i problemi che avevamo discusso nella scorsa settimana. Preparato i problemi rilassati, eccetera, eccetera. In questo caso la proposta di questo di l'euristica che poi è quella attraverso la quale computo quei numeri che vedete nella scacchiera di destra è questa. Questi numeri rappresentano il numero di coppie di regine che si possono attaccare. Ok? Quindi io so che se vado qua per esempio le coppie di regine che si attaccano sono 14 o il numero di regine non mi ricordo se sono le coppie o il numero che contiamo 1 2 allora vediamo cosa ecco allora in questo momento H uguale a 17 1 2 3 4 5 6 7 8 9 10 dovete fare tutti i conti e verificare formabili effettivamente sono 17 le coppie di regine che si attaccano in questa configurazione sicuramente lo sono per esempio ci sono sia diagonali destre che diagonali sinistre quindi insomma 17 sono le coppie di regine ok? Quindi ciascuno di quei numeri rappresenta il numero di coppie di regine che si attaccano io so che in questo momento questa configurazione qui ha una sima ok? dell'euristica pari a 17 guardate lo trovate sotto ok? Inoltre in questa scacchiera sto mostrando qual è il valore dell'euristica se spostassi la regina o una regina in quella posizione vi faccio un esempio se io prendo la regina nella prima colonna questa e la sposto qui sopra ok? nella posizione sopra l'euristica risultante è 15 quindi vuol dire che sostanzialmente vado a perdere due coppie che si attaccano perdo questa guadagno questa però però mi perdono anche quella quindi insomma se la sposto sopra avrò solo tra virgolette 15 coppie che si attaccano quindi è già uno stato migliorativo rispetto a quella tua ok? come vedete questo numero c'è in ogni posizione della scattiera e vi ricordo che le regine si possono muovere in verticale ma non per forza devono fare un passo uno quindi si possono muovere in verticale ma la regina questa qui potrebbe muoversi tranquillamente qua sopra ok? quindi a partire da questo stato per definizione di questi algoritmi che vi sto presentando l'idea è che vogliamo spostarci in uno stato più favorevole rispetto a quello attuale quindi a me non ci interessa per forse la scelta qual è il prossimo stato e quindi qual è l'azione che faccio e quella che appunto mi porta a questo nuovo stato è determinata esclusivamente dal fatto che io voglio andare in uno stato che mi migliora ok? allora dopo lo guardiamo bene questo problema però entriamo un po' nel merito di quali sono questi algoritmi allora partiamo anche perché poi un pochino si evolvono in forme diverse e questa affermazione vado nello stato migliore potrebbe essere un po' rilassata lo capiamo tra l'altro allora il primissimo algoritmo che vi presento è questo che si chiama hill climbing ok? quindi in questo tipo di algoritmi l'idea è quella di massima di di di di di di di di di di di di di di di di di di di di di di identificare degli stati che mi portano e mi garantiscono di avere un numero di di quindi in questo caso sto trovando a minimizzare se volessi ragionarla proprio in maniera inversa per ragionare come cercare un'euristica che deve massimizzare un valore cosa fareste? con un qualche tenato adesso io stiamo cercando di minimizzare le cose che si attaccano per la descrizione del problema che vi ho dato prima al contrario come posso vogliere fare? se volessi massimizzare qualcosa se volessi definire un'euristica che voglio massimizzare poi potrei definire l'inversa cioè un'euristica che mi dice che il numero di regine le posizioni per cui le regine va a contare quali sono le posizioni in cui le regine non si attaccano quindi la versione è esattamente complemento allora perché vi sto facendo questo ragionamento perché potrebbe essere utile ragionare nella generazione di massimizzare il valore piuttosto che nella direzione di volerlo minimizzare dipende da come andiamo a descrivere il problema l'algoritmo cambia poco però nella descrizione che vi fornisco è un algoritmo che ha come obiettivo quello di massimizzare il problema della situazione di rischio che si chiama climbing quindi ascesa di una montagna di una collina e questo algoritmo è davvero molto molto semplice nel senso che a partire da uno stato guarda tutti gli stati che può raggiungere anche da uno specifico stato e sceglie il migliore in assoluto quindi quello che ha il valore in assoluto che può raggiungere questo genere di problemi vengono chiamati anche problemi di ricerca locale local search e vengono chiamati così proprio perché dell'immenso spazio degli stati io non sto a guardare nulla se non il stato indietro raggiungibili da me da uno stato quindi solo ed esclusivamente gli stati che con un'azione posso raggiungere quindi una ricerca locale quando solo negli istituti e quello che viene fuori è questo guardate un attimo questa immagine allora questo è uno spazio bidimensionale ma voi lo dovete immaginare come uno spazio n-dimensionale in cui per ciascuno stato io e per ciascuna variabile del problema definisco un valore che è proprio questo in cui posso usare una funzione di un'azione per lo stato estero ok e gli stati abbiamo capito che possono essere tra i più svariati e questo valore della funzione di un'azione come vedete può avere una forma decisamente complessa quindi tipicamente questi spazi dei visitati vengono chiamati spazi rugosi brutta traduzione in italiano è questa che non è bellissima però allora vi faccio vedere per esempio uno spazio a cui sto pensando ora questo non funziona quindi non posso aprirlo peccato anche chrome e vi faccio vedere uno spazio e sul bidimensionale ancora più bello voi vedete solo le slide però le ho condiviso solo le slide se ne vanno con la testa otteni se Grazie. Grazie a tutti. Grazie a tutti. Mi sposto da uno stato all'altro dove le x e le y rappresentano le variabili con cui descrivo lo stato. Mi sposto da uno stato all'altro e posso scendere nei buchi, salire delle montagne, eccetera, eccetera. Questo spazio può essere complesso a piacimento. Adesso questo vi dirò che è anche abbastanza semplice per assurdo. E assomiglia questa cosa un po' a quella che vedevamo nel grafico che abbiamo nelle slide, a una dimensione sola. Qui vedete quindi che quella funzione euristica assume valori svariati e in particolare vi faccio notare che ci sono dei valori che sono dei massimi globali, valori che sono dei minimi globali, per esempio questo qua giù, e ci sono dei valori che sono invece dei massimi locali, nonché dei minimi locali. Allora continuiamo a vedere la cosa duale, perché ripeto dipende un po' dal problema dell'algoritmo, questo non è specifico, non cambierebbe. Lo chiamiamo il slide, quindi l'idea è di andare appunto in salita, cioè di scegliere a partire da uno stato, sempre solo lo stato con valore azzurre, vicino. Questo implica però che siamo estremamente poco robusti e sensibili da quello che è lo stato iniziale. Credo che questo sia abbastanza ragionevole e comprensibile per tutti. Se lo stato iniziale del problema è per esempio questo qui, che viene mostrato in questo slide, e l'algoritmo l'unica cosa che fa è a partire da quello stato, guardare tutti gli stati intorno e fare un gradient resente, un gradient risalita, scegliendo il stato con valore maggiore, quello che capita è che ad un certo punto, iterativamente, lo stato si sposterà e raggiungerà questo punto qua, cioè il punto di massimo locale. Questo è abbastanza ragionevole e intuitivo che capita. Raggiunge il massimo locale, da cui a quel punto però non sa più uscire. Perché non sa più uscire? Perché tutti gli stati che ha intorno sono peggiorativi. Quindi ci propone come soluzione sostanzialmente questa, perché dice sì, ho raggiunto un massimo, tutti gli stati intorno sono peggiori, quindi ho sicuramente raggiunto un massimo. Perché non riusciamo a fornire il massimo globale? Vabbè, per il dato del tipo di algoritmo, ma il vero problema è che noi non abbiamo sostanzialmente il nostro sistema, riusciamo a vedere solo tutto ciò che ci sta intorno. e quindi questo problema così definito, non so se vi ricordate, ho un'idea di ottimità, un'idea di ottimità, che problema è sicuramente completo, nel senso che ha una soluzione, cioè arriva, ok? Non è detto di questa soluzione. Allora, se volete guardare l'algoritmo come è stato definito, lo trovate di qua, ok? Quindi, l'idea è molto semplice, generale. Inizi, start wherever, da dove vuoi, ok? Che significa sostanzialmente, inizialmente, il problema random. Ripeti ogni volta, che cosa? Fai la mostra che ti porta allo stato vicino migliore. Se non hai vicini che migliorano il tuo valore dell'euristica, nello stato in cui sei, allora hai trovato la soluzione ed esci, ok? Questa qui è la formalizzazione del problema in termini di pseudocodice, insomma, lo vedete, non c'è nessuna stranezza, quindi definisco lo stato iniziale del problema come lo stato corrente, finché, well true, non piace mai molto. Il vicino ha un valore dello stato successivo rispetto al corrente superiore, vedete qua. Quindi il vicino è uno stato che io posso raggiungere a partire dallo stato corrente, finché il suo valore è maggiore, cioè se è minore restituisci current, se è maggiore spostati nel vicino, ok? A casa avete dei dubbi? Chiaro? Ok. Benissimo, quindi insomma, viene anche definito questo algoritmo, guardate, like climbing Everest in a big fall, talk with a million. Perché? Perché di base posso anche ripercorrere stati che ho già visto, non lo ricordo, se questo non è particolarmente probabile perché sto facendo una scena per la cima. E poi vedo solo intorno a me, quindi sono proprio in mezzo alla nebbia, non ho modo di vedere oltre e di scoprire che più in là c'è invece un altro picco. Quando siete in montagna e dite, ah lì c'è la cima, arrivata la cima, scoprite che c'è un'altra cima, questo è il grande classico. Quindi qua non lo scoprireste perché c'è la nebbia dappertutto, una volta che arrivate in cima pensate di essere arrivati alla cima più alta di quella montagna. Ok? Questa è l'idea. Avete delle domande a casa? Ok. Vabbè, questo è l'esempio dell'energine che direi che non ripeto perché non aggiunge nulla a quanto che ho già raccontato. E lo trovate ben descritto, quindi anche quando riguardate questi slide, lo trovate ben descritto in questo slide qua, in cui come vedete vi viene detto che l'obiettivo è avere le n-regine nella scacchiera senza conflitto, ovvero nessuna queen attacca nessun'altra. Gli stati sono rappresentati dalla disposizione delle queen nella scacchiera e le azioni sono muove la queen sulla sua colonna. Ok? E come vi dicevo prima, la funzione euristica è esattamente il numero di conflitti che posso avere. E lo trovate qua, guardate. Qui trovate l'esempio che era il calcolo che cercavo di fare prima velocemente di qua, qui è molto più semplice. Qui le regine ad attaccarsi sono cinque perché sono queste, queste, queste, queste, queste, e poi ne sposto una e già elimino un elemento di conflitto. l'obiettivo è arrivare in una situazione in cui le euristica, quindi la regia di sottotitura è un'altra. Ok. E qui trovate tutto stesso, identico risultato. Ok? La stessa identica descrizione, però, sul problema con otto regine. In questo caso, per esempio, quello che succederebbe, proprio perché abbiamo detto, noi andiamo a vedere solo gli stati immediatamente raggiungibili, succederebbe che tra tutti gli possibili stati, e ripeto, ciascuno successivo stato è uno stato in cui sposto la regina, di almeno una di queste otto regine, di almeno una posizione, tra tutti i possibili successori ci sono un tot di successori che hanno il valore dell'euristica pari a 12. No? Sono stati, sono anche un pochino evidenziati. Questi, gli stati con euristica 12, sono i migliori in assoluto, ovvero, da questo stato qui, questo qui, quindi, di favora, non posso raggiungere uno stato che ha un'euristica minore di 12. Quindi la scelta ricadrà sicuramente su uno di questi qui. Abbiamo detto che accettiamo solo mosse migliorative, andremo sicuramente, quindi, nella direzione di discesa del gradiente più importante, quindi ci sposteremo su una di queste posizioni con il versica pari a 12. Ok? Quindi l'algoritmo del climbing algorithm will be the gap one of these, quindi ne prende una, ciao. Ok. Penso che i limiti di questo algoritmo sono abbastanza evidenti, li abbiamo appunto già accennati. Vi è chiamato anche l'algoritmo greedy, quindi del greedy ne abbiamo già parlato, ve lo ricorderete che anche il greedy, che abbiamo visto nei problemi di ricerca, che abbiamo fatto le settimane scorse, e le settimane scorse in particolare erano i problemi di ricerca informata, e sono algoritmi completi, ma non ottimi. Non so se ve lo ricordate, abbiamo fatto tutti i calcoli. E anche questo ha il problema di questo studio, quindi questa ansia e velocità di andare nella, è più importante per me spostarmi subito in una posizione migliorativa, migliorativa, non mi interessa se quella scada su un lungo periodo mi può portare a raggiungere un risultato che non è l'ottimo. Chiaramente se questo fosse lo stato attuale, noi che abbiamo lo sguardo globale sul sistema, preferiamo fare un insieme di mosse peggiorative inizialmente, perché poi abbiamo la sicurezza che, grazie a quelle mosse peggiorative, ci spostiamo in un'altra regione dello spazio, che ci porterà un massimo globale. E questo il climbing non ce lo permette di fare. È così che è stato proposto un secondo algoritmo, che si chiama simulated unnilling, il quale, mi chiederei, imparare a memorizzare, perché è un algoritmo che viene veramente tanto, tanto, tanto utilizzato tuttora. Ok? E questo algoritmo fa una cosa diversa, cioè aggiunge un elemento al climbing, ovvero fornisce una formalizzazione di un metodo che ci consente di accettare occasionalmente, ok, anche i mosse peggiorativi. Quindi, accettiamo la possibilità di avere mosse peggiorative. Questa cosa, per evitare una ricerca sostanzialmente infinita e che ci fa salutare in maniera molto dinamica, da una zona all'alto dello spazio, senza controllo, ok? È una cosa che, rinunca un attimo, qual è la formalizzazione, questo algoritmo rende più probabile all'inizio della ricerca, e questo, insomma, non si trova, tipicamente, quello che questi algoritmi di ricerca fanno, in una prima fase, è esplorare lo stato, quindi è uno stato n-dimensionale, voglio spostarmi in maniera abbastanza dinamica da una regione di questo stato, di questo spazio, scusate, degli stati, a un'altra regione dello spazio degli stati. Questa si chiama diversificazione, esplorazione e diversificazione. Perché voglio fare questa cosa? Perché chiaramente voglio conoscere un pochino più quello spazio degli stati, per capire qual è la regione di questo spazio degli stati più promettente, cioè quella che potenzialmente mi porterà davvero a raggiungere un massimo o minimo globale. Quindi all'inizio, grazie a questo concetto di temperatura che vedremo tra un anno di variante, che però, ripeto, quel tempo diminuisce, mi muovo molto velocemente nello spazio degli stati dove, diciamo, queste bad moves sono accettate, quindi queste cose peggiorative sono accettate un pochino con più probabilità, mentre col passare del tempo, ovvero della ricerca su questo spazio, queste temperature qui, le mosse peggiorative sono accettate sempre con meno probabilità. Ok? Quindi, gradatamente, riduceremo la temperatura e quindi riduceremo anche la frequenza delle mosse peggiorative. E questo è Simuletant Leading. Quindi, si parla sullo stesso concetto di funzione euristica, ok? Quindi non aggiunge nulla da quel punto di vista. Quello che cambia è solo quando devo decidere, qui, qual è il current state, ok? Non lo faccio sempre se, diciamo, il current, il next è migliorativo. Potrebbe essere che lo faccio delle volte anche se il next è peggiorativo. Allora, guardiamo un attimo. Va bene, il problema viene inizializzato ancora una volta in maniera casuale, quindi viene inizializzato lo stato corrente e lo stato iniziale del problema. Questa variabile T che chiamiamo appunto temperatura, poi, sì, questa è una narrazione che vi risparmio, ma, diciamo, si chiama Simuletant Leading e quella variabile lì viene chiamata temperatura perché l'idea di questo algoritmo nasce dalla algoritmo di raffreddamento dei metalli che vengono portati in altissima temperatura e poi pian piano raffreddati per cercare di trovare la disabilizzazione di questi metalli migliori. Ok, quindi, giusto questo per darvi un significato al perché questa T grande viene chiamata temperatura. Allora, se T è uguale a zero restituisci lo stato corrente. Va bene. e, ok, poi, lo stato next è uno degli stati successori a me, current, quindi vedete successor of current, quindi uno degli stati successori, ovvero uno degli stati che io, stato corrente, posso raggiungere selezionato in maniera casuale. Calcolo il valore dell'evristica nel mio stato attuale e nello stato futuro che ho appena selezionato in maniera casuale e misuro questo delta E, quindi qual è la variazione di energia. Ok? Allora, abbiamo capito di quella variazione di energia maggiore di zero o meno di zero. chiaramente, se il valore del stato sia o meno migliorativo o peggio. Allora, se la delta E è maggiore di zero vuol dire che il mio stato è migliorativo perché sto facendo, sto cercando di minimizzare, sto facendo una ricerca che mi porta a minimizzare. Vedete, da un'ilmos, di energia, ok? Quindi, questo ve lo sottolineo proprio, ma spero di avervi convinto sul fatto che tutti questi algoritmi li possiamo vedere nelle due direzioni, dipende dal problema, è chiaro che poi la formulazione deve essere fatta in maniera coerente con la formulazione anche dell'algoritmo. qual è il nostro dettivo? Nel terzo dato stiamo facendo una discesa del gradiente. Quindi, se lo stato successivo è migliorativo, ovvero, ha un valore di energia, questo delta E è maggiore di zero, allora, lo accetto sicuramente, ok? Quindi, prendo il successore lato, se è migliorativo lo prendo. Se è peggiorativo e questo non è niente di nuovo, no? È lì il climbing al contrario, niente di nuovo. Se invece è peggiorativo, è qui l'elemento di innovazione, insomma, se è peggiorativo non è detto che lo rifiuto. Il climbing l'avrebbe rifiutato perché è peggiorativo, questo qui dice no, mi accetto che non ha certa probabilità. E la probabilità con cui l'accetto è proprio, data da questa formula e alla mia interna di delta E scusate, di questo ultimo, ok? Il valore è che, quindi, seguitemi, è tanto più alto quanto più basso è il peggioramento del delta E, no? Il peggioramento che io subirei spostandomi in quello stato e tanto più alta è la temperatura. Ok? Quindi la probabilità di accettare questo stato di cissimo dipende da quanto peggiorativo è questo stato, perché chiaramente se è molto peggiorativo è evidente che io forse non lo accetto volentieri. Non solo, ma quanto è alto il valore di quella variabile T. Il valore della variabile T che, ripeto, inizialmente è molto alto proprio perché voglio sfrutturare lo stato, quindi voglio accettare con più probabilità voglio sfrutturare lo stato di ricerca e quindi voglio appunto accettare con più probabilità la nostra stagione che per tempo diminuisce. Tant'è che, vedete, schedule, ok? determina il valore della temperatura T come funzione del tempo. Quindi il valore della temperatura come vedete in quella di canine ad ogni interazione viene modificato dalla funzione schedule, ok? Che tipicamente, ripeto, è una funzione che porta ad avere un valore di T decrescente con il numero di interazioni. Ho convinto tutti? Avete delle domande a casa? Tu? Prego. Se questa temperatura c'è tra sedere o di ricordo di sereno di terza o tu essi? Però mi sa che non ti riesco a rispondere. Ti direi che no. Ti direi che no. Però non ho risposto che posso in qualche modo diciamo l'algoritmo e questo qui è una cosa che sto studiando perché ovviamente tutti noi stiamo studiando perché c'è una cosa che è nuova per tutti e non solo per voi. Però come viene utilizzato negli LLM ancora non ti si risponde. Il prossimo anno ti si può rispondere perché ci sto lavorando proprio in questo periodo. quindi qualcos'altro a casa? Ok. Allora se non c'è altro vi racconto l'ultimo algoritmo che mi interessa è la di di questo punto tentativo di trovare delle soluzioni migliorative e soluzioni al problema. Allora gli algoritmi genetici sentiti e risentiti sicuramente perché questo è proprio se guardiamo quando parlavo di intelligenza artificiale 20 anni fa si parlava di algoritmi genetici con grandissima frequenza. Allora in questo caso vedete che ci spostiamo un pochino siamo sempre nel mondo dello spazio della ricerca nel senso che mai dovete dimenticare che comunque il nostro riferimento è sempre un qualcosa di questo tipo qua guardatelo è sempre comunque che noi abbiamo una funzione euristica che descrive quanto buono è uno stato per quelli che sono gli obiettivi che è il problema ok è sempre una funzione di negli algoritmi genetici questa funzione euristica viene chiamata fitness function se ve lo volete segnare perché in ugualtà è solo una questione di di natura ma significato è equivalente perché ovviamente i coritmi genetici riprendono e diciamo tutta una letteratura che si ispira a dei fenomeni naturali che sono appunto quelli della riproduzione genetici quindi il nostro problema lo possiamo descrivere in questi termini qua ovvero attraverso quelle stringhe di numeri che per voi sono solo stringhe di numeri in realtà vogliono rappresentare una sequenza di quelle che sono le basi all'interno del DNA quindi come se quelli stringhe di numeri fossero dei geni ok in questo specifico caso quei numeri hanno un significato ovviamente nella definizione dello stato di come lo stato è la definizione dello stato ha un significato che in qualche modo ci riporta al problema e in questo specifico esempio ciascun numero rappresenta la posizione della regina sulla colonna quindi rimaniamo sempre al problema delle autoregine così ce lo siamo tenuti come filo luge di tutta questa discussione rappresenta la posizione della regina nella prima colonna della seconda eccetera ok allora quindi sostanzialmente è un modo di descrivere la scacchiera ok è un modo di descrivere questa scacchiera con una stringa di otto numeri però descrivendo esattamente lo stato del problema con una stringa in termini di numeri abbiamo capito prima che per ciascun stato io posso identificare un valore che rappresenta la bontà di quello stato che è la famosa funzione euristica ok e lo faccio anche qua definendo questi valori che trovate questi ok in questa prima colonna di numeri che sono i valori della funzione euristica che come vi anticipavo negli algoritmi genetici viene chiamata fitness function in questo caso direi che direi che adesso questo qui non lo vedete però vabbè non è particolarmente importante in realtà qui siamo nella versione che vogliamo minimizzare il valore di quella fitness quindi massimizzarlo sì per cui non è particolarmente importante se non che è una cosa che dovete tenere a mente rispetto a tutto quello che vi racconterò tra un attimo perché come vedete il primo passaggio è quello di fare un ranking della bontà di quegli stati ok quindi il primo passaggio ho n stati faccio il ranking della bontà di quegli stati sulla barca delle fitness function benissimo il ranking in questo caso va dal più alto al più basso quindi è evidente che l'obiettivo è di possibilità quel valore quindi stiamo ragionando nella versione del problema opposta a quella che dice a scoperta voglio aumentare le ragioni che si è stata adesso ragioniamo all'imposto ora di questi quattro stati ok associo a questi quattro stati associo una probabilità di essere scelti probabilità di essere scelti che è quella che trovate in questa colonna ok e che è veramente proporzionale al valore della fitness function quindi se voi vate a sommare quei valori che sto evidenziando per resta il 100% che vuol dire che il 31% delle volte è selezionato il primo stato il 29% delle volte è selezionato il secondo il 26% il terzo il 14% il quarto con probabilità più bassa perché ci piace di meno un valore della fitness molto basso quindi i valori di queste probabilità sono proporzionali al valore della fitness ok benissimo quindi date queste probabilità in mano noi selezioniamo dei quattro stati di partenza una sottoparte e come vedete la prima iterazione viene selezionato questo stato che viene portato qua sopra come primo stato selezionato ci sta un 29% delle volte viene selezionato quindi ci sta che venga selezionato subito poi alla seconda iterazione viene selezionato questo stato che viene portato qui alla terza iterazione viene selezionato di nuovo questo ok 29% viene portato qua e alla quarta viene selezionato questo viene portato qua sotto. Quindi quello che vedete nel punto C viene definito in grado selection e non è a caso. Cosa vuol dire? Dei quattro stati di partenza io ne seleziono una sottoparte una sottoparte condizionata come sottoparte a quello che vedete si chiama il sicuro stato. Benissimo. Passo successivo, crossover. Questi stanno proprio riproducendo esattamente tutti i passaggi della riproduzione. del codice genetico durante la duplicazione delle cellule. Crossover. Allora, A2A2, quindi questi geni vengono accoppiati e vengono aiuto come posso dire? Vengono diretti a uno swap di parte del loro codice genetico. quindi in maniera casuale viene scelto un punto in cui vengono tagliati questo è casuale ok? Viene tagliato il cromosoma il gene ok? Viene scelto in maniera casuale e viene fatto uno swap su due geni della prima parte con la seconda ok? Quindi nel primo gene viene mantenuta la prima parte viene messa la seconda parte del secondo e viceversa. Ok? Stessa cosa nella coppia di sotto e ripeto il punto in cui si taglia casuale crossover per il risultato. Questo perché? Cosa sto facendo? Io voglio creare questo è da capire a livello semantico voglio creare questa qui è una popolazione di geni inizial population una popolazione di soluzioni del problema. Allora innanzitutto voglio chiaramente scelgo le migliori perché è inutile che prendo le pezzure che sono così scelgo quelle più promettenti e in più provo a combinare quelle più promettenti tra di loro per vedere se per caso tengo qualcosa di ancora meglio e questo è crossover. Poi aggiungo un secondo mezzo che è una mutazione una mutazione che vuol dire prendo un valore a caso ok? di questa stringa e lo cambio lo modifico in maniera casuale quindi per esempio prendo nel primo gene prendo il terzo dal fondo e cerate e lo cifro e lo cambio ok? Questo per cosa? In maniera lo faccio in maniera casuale e con una certa probabilità la mutazione viene con una buona per fare qualcosa quindi cosa stiamo facendo secondo voi? L'abbiamo fatto anche prima qui lo facevamo anche da lì non lo facevamo con i verità e quindi cosa stiamo facendo con la mutazione ma anche con il crossover però in generale modificando questi stati ci mettiamo nella condizione di poter potenzialmente avere degli stati peggiorativi quindi accettiamo il fatto che con la mutazione e il crossover potrebbero capitare degli stati peggiorativi però questo elemento di casualità e di accettazione probabilistica una possibile mossa positiva fa sì che noi iniziamo a spostarci a muoverci nello stato nello spazio degli stati e quindi potenzialmente trovando delle soluzioni quindi delle popolazioni più promettenti quindi in questo modo pian piano speriamo di spostarci in una regione dello spazio che è più promettente ok attendo domande se ci sono non mi pare vediamo se c'è qualcosa sulla chat ok vado avanti quindi se non avete domande questo in questo caso la selezione la popolazione la manteniamo con la stessa numerosità questa è la domanda ok quindi la popolazione rimane con la stessa numerosità e chiaramente la numerosità non dipende da cioè non è fissa dipende dal problema sì esatto esatto dipende da quali stati mi interessa valutare qui la devi immaginare perché è molto bello adesso questa parte qua effettivamente io mi fermo oggi con le lezioni di oggi non la faccio non la faccio più però sono cose su cui si è studiato tantissimo cioè io quando ho iniziato a fare a fare queste cose nei primi corsi che ho fatto con l'intelligenza artificiale mi si parlava quasi solo delle problemi genetici era sono un golfo di tante e tante linee di ricerca devi immaginare chiaramente ancora intorno a dire uno spazio all'indimensionale in questo caso lo spazio è autodimensionale ok devi immaginare questa nuvola di punti in questo caso di quattro che si sposta in questo spazio all'indimensionale di ricerca si sposta un po' a nuvola quindi la nuvola un po' si sposta insieme è ragionevole per chi mi porta dietro delle mutazioni ok dei crossover quindi mi sposto un pochino e si spera che ad un certo punto a forza di spostarmi raggiungo delle regioni dove mi posso concentrare perché lì effettivamente è tutto molto dentro quindi queste modifiche che vado a fare col crossover e la mutazione comunque sono modifiche nell'intorno di un punto che sembra essere molto contento qui qui dici allora questo è quel valore della fitness aspetta questo è quel valore della fitness ok questo è quel valore della fitness quindi ho qui il valore della fitness che dipende dallo stato e lo stato è rappresentato dalla coordinata x y e z in questo esempio che sto facendo la lavagna chiaramente nel nostro è rappresentato dagli otto valori di quelle pericolari della fitness io mi sposto però ripeto se già selezionando i migliori quindi quella con la diciamo fase C già selezionando i migliori è chiaro che non sto andando a spostarmi in una regione poco promettente però però non mi limito a selezionare i migliori perché se mi limitasse a selezionare i migliori che cosa rischio? rischio di infilarmi in un minimo locale ok o un massimo locale mentre se diversifico con il terzo della mutazione potrei riuscire ad uscire da queste famose due che qua mi sputo fuori perché con una mutazione crea un nuovo elemento di questa simpulazione che mi porta in una zona completamente diversa di questo spazio molto bello molto affascinante questo mondo ok e per me purtroppo la questione finisce qua perché adesso entrino in mondo della stockeasticità come se non ci sono domande su questi algoritmi di ricerca locali bisogna che passo a questo no no però mi dispiace dirlo perché in realtà non vorrei che si comportasse non li ho mai messi adesso valuterò perché poi i corsi come no non quest'anno ovviamente quello che avrete all'esame voi è quello che vi aspettate non ci saranno sorprese però potrei decidere nel tempo di dare un pochino più di peso nella parte appunto di lezione e in conseguenza anche all'esame in realtà questi sono belli anche da implementare non è tanto solo esatto non è tanto solo fare l'esercizio su carta ma qui sono proprio belli per noi li abbiamo anche usati in alcuni problemi di ricerca proprio perché sono una possibile quindi non so come evolverà questo corso ma potrebbe essere che in futuro diventerà parte integrante anche della prova della prova d'esame per il momento no e quindi questo vuol dire che se volete potete chiudere oggi su questo argomento la discussione ma spero che in qualche modo ci riguardiate allora invece la ricerca non deterministica di cui inizio a parlare ora questo ci serve per capire bene anche ciò che sta per capitare dopo quindi su questo vi chiederei ancora più attenzione se possibile allora qui entriamo a un framework completamente nuovo rispetto a quanto ci siamo raccontati finora un framework nuovo perché me l'avevo anticipato le chiacchiere che abbiamo fatto quando cercavo di dare un po' di visione di che cosa stiamo facendo di dove vogliamo andare però finalmente ci siamo ricordati ovvero entriamo in un mondo che prevede il fatto che non è più tutto deterministico ok non è più tutto deterministico cosa vuol dire vuol dire farò un esempio in particolare da finché due ma questo anche ci lo portiamo un po' fino alla fine del corso le nostre azioni non hanno esito certo questa è la prima forma di un esempio e vediamo qui il primo esempio ce l'abbiamo già in questa slide quindi le nostre azioni non hanno più esito certo per cui io non ho la certezza che se per esempio dico all'ospira polvere di provvedere la sua cellula la disce per davvero o ci sposti che se mi devo di spostarsi si sposta per davvero ok un'altra forma di non determinismo invece vedremo tra un attimo ma sicuramente domande si deriva dal fatto che invece c'è qualcun altro che non ha più l'ambiente sotto il mio completo controllo perché c'è qualcun altro che fa qualcosa sull'ambiente e per questo secondo freno di non determinismo di questo secondo contesto di non determinismo è la ricerca con avversari in cui c'è qualcuno che sta facendo qualcosa nel mio ambiente e che ha peraltro un obiettivo di ammetralmente imposto al mio ovviamente ognuno di noi in ricerca con avversari vedrete che viene introdotta come strumento per risolvere i giochi e è chiaro che ogni avversario vuole vincere quindi tutto ciò che sarà addirittura quindi in quel caso ancora peggio tutto ciò che farà il mio avversario sarà per riuscire a ostacolarmi piuttosto che agevolarmi il raggiungimento dell'obiettivo allora partiamo dalla cosa più semplice in questo caso la soccasticità per esempio che vi sto facendo vedere viene descritta così quando su un square quindi su una cella sporca io decido di eseguire l'azione di pulisci la il mio argentino pulisce lo square quindi la cella in cui si trova ma delle volte pulisce anche la cella adiacente se c'è quindi se c'è la cella e se è sporca quindi se la cella adiacente è sporca può capitare che la pulisca e non solo questa azione di pulisci si è applicata a una cella pulita non so se ve lo ricordate la descrizione di questo problema però effettivamente noi all'epoca quando abbiamo descritto questo problema non abbiamo selezionato le azioni sulla base dello stato cioè dicevamo che in ogni stato era possibile fare tre azioni pulisci schiera sac spostati a destra o spostati a sinistra ok e non stavamo a guardare se quella cella era o meno pulita quindi l'azione di pulisci era possibile anche se la cella era già pulita in questo caso rimanendo all'interno appunto dello stesso problema descritto esattamente nello stesso modo però abbiamo una sfortuna se decidiamo di eseguire l'azione pulisci su una cella già pulita potrebbe decidere di sporcarla quindi invece che pulirla lascia un po' della polvere che ha accumulato ok e questo crea comunque dei grossi problemi perché a questo punto sicuramente se ripensate alle strategie di ricerca che abbiamo visto nelle settimane scorse io non posso in nessun modo avere il controllo di tutto e quindi difficilmente posso fornire come avevamo appunto discusso fino alla settimana scorsa una sequenza di azioni che a partire da A sicuramente mi porta in B ok infatti quello che vedremo tra un attimo è che non c'è più una singola sequenza di azioni che risolve il problema ma c'è un piano contingentato contingency plan cosa vuol dire io nello stato 5 ti posso dire pulisci ok no vabbè scusate questo non viene specificato qual è lo stato di partenza però ecco dato lo stato in cui mi trovo io posso decidere di fare l'azione pulisci va bene però non ho la certezza di dove vado a finire che cosa cambia il modello della transizione cioè io sono nello stato A ed ed è decolazione pulisci non è detto che finisca in B questo è la vera diciamo cosa nuova eseguendo la stessa azione S potrei finire in C perché per esempio lo stato D è quello in cui effettivamente questa azione ha avuto successo lo stato C è quello in cui si è la cella in cui trovo si è in cui la C ok quindi nel descrivere il mio piano io bisogna che tenga in considerazione entrambe le possibilità quindi quando fornirò la soluzione al problema non potrò dire solo se sei in A pulisci e finisci in B dovrò dire se sei in A pulisci e se finisci nello stato C fai questo se finisci nello stato D fai quest'altro ok quindi dovrò vedete fornire una soluzione che è appunto un piano contingency plan che ti dice in quello stato pulisci se poi finisci in 5 fai queste azioni altrimenti per questo esempio non fare nulla e poi adesso lo vedremo in questo esempio quindi il mondo è sempre quello e non c'è davvero nessuna novità quindi sono il nostro sistema con due celline un argentino che pulisce l'aspirapolvere e questi sono tutti gli stati possibili ovvero dipendono dalla posizione dicevamo dell'argentino e dallo stato dell'ambiente sulla pulitura su quanto sono pulite le celle ecco quello che trovate qui è esattamente l'esempio che vi stavo facendo quindi in questo piano contingency plan che stavamo guardando prima noi partivamo da questo stato qua ok lo stato 1 in cui l'argentino si trova a sinistra ed entrambe le celle sono sporche e decidiamo di pulire non è detto che si decide di pulire è ragionevole perché noi chiaramente quando dovremo fornire una soluzione dovremo fornire la soluzione che ci porta allo stato obiettivo qual è lo stato obiettivo lo stato obiettivo è sempre lui quello che ha entrambe le celle pulite e quindi parto da qui e decido che voglio pulire questa è l'azione che decido di fare benissimo abbiamo visto però che questa azione non è certo risulti nello stato 5 che è quello che ci saremmo aspettati fino alla settimana scorsa in un problema completamente deterministico ma potrebbe risolversi anche nello stato 7 dove entrambe le celle sono pulite perché vi dicevo che appunto per come è stato descritto questo problema questa aspirapolvere è impazzita nel senso che quando pulisce una cella potrebbe pulire anche quella vicina ok e quindi come vedete quello che era il nostro albero di ricerca comincia a avere dei punti degli elementi aggiuntivi allora questi elementi aggiuntivi ci portano a distinguere i nostri rami e i nostri nodi in nodi end e nodi or allora in particolare a partire da ciascuno stato ciascuno stato ciascun nodo rappresenta un nodo end un nodo end in cui io so che posso fare l'azione a end l'azione b end l'azione c in questo caso posso fare l'azione sac e l'azione right in realtà nella descrizione iniziale c'era anche l'azione left ma lasciamo stare qui già semplificato ok benissimo scelgo di fare l'azione sac nodo or faccio l'azione sac ma posso finire o nel nodo 7 o nel nodo 5 nel nodo che rappresenta lo stato 7 o nel nodo che rappresenta lo stato 5 quindi ciascun nodo è in end ha in end le possibili azioni che può fare il risultato dell'azione è in or su tutti i possibili stati in cui vado a finire ok quindi il mio contingency plan mi dirà se sei in uno fai la d fai l'azione sac puoi finire in 5 oppure in goal se finisci in 5 non fare nulla perché hai raggiunto lo stato obiettivo se invece finisci in 5 che ve lo rifaccio vedere vedete quindi non fare nulla perché hai raggiunto lo stato obiettivo se sei in 5 invece puoi fare le due azioni right and sac right and sac se fai l'azione right allora sicuramente finisci a destra perché abbiamo visto che l'azione right è invece un'azione deterministica per come è stato descritto il problema quindi finisci a destra bene quindi in questo caso qui il nodo and ha una sola alternativa finisco in 6 e dico puoi pulire oppure andare a sinistra se pulisci in questo caso hai una sola alternativa banalmente perché se hai anche pulito il 6 era già pulito quindi non cambia niente quindi lo stato in cui vai a finire è lo stato 8 che è poi lo stato obiettivo ok bene questo è il nuovo mondo diciamo di cui parleremo tra oggi e domani ok quindi questa ricerca viene chiamata ricerca and or e la cosa veramente tra virgolette interessante è che è una ricerca che mi porta ad avere una soluzione che non è più una sequenza di azione ma un piano con diverse ramificazioni ok quindi fai A se finisci in B fai questo se finisci in C fai quest'altro e questo va previsto fin da subito io fin da subito devo prevedere il fatto che le mie azioni non possono non sempre mi portano a risultato atteso e quindi devo subito fornire una risposta alternativa ok quindi di una possibile azione da fare a fronte di una strada dell'altra quindi la soluzione come vedete in questo esempio non è descritta in termini algoritmici come una sequenza di if the nels ma viene riportata in quest'albero come la diciamo così le frecce con spessore maggiore quindi in questo caso quest'albero di ricerca porterebbe questa soluzione qui in cui sono stati tenuti in considerazione tutte le possibili ramificazioni fino al raggiungimento dello stato di domande allora questo che vi sto facendo vedere ci alza la palla per diciamo è alla base la ricerca and or and or si chiama proprio è alla base della vedete and or graph ok generati da ambienti non deterministici e è alla base di tutto quello che vedremo sull'adversario search quindi deve essere abbastanza chiaro ecco qui la cosa che mi interessa è questa farvi vedere che questo è ciò che viene restituito quindi lo vedete anche in pseudocodice ciò che viene restituito da questi algoritmi quindi non fai abcd ma se sei nello stato 1 esegui il piano 1 se sei nello stato 2 esegui il piano 2 eccetera eccetera quindi viene chiamata questa cosa pianificazione tant'è che si parla di plan pianificazione piani condizionati eccetera quindi devo fare un piano per ogni possibile ramificazione di questo problema quindi se vado a sinistra devo fare un piano se vado a destra se risulta l'azione mi porta a destra devo fare un altro piano ok io andrei avanti altri 10 minuti non vi so anche che abbiamo un attimo ritardato l'inizio mi dite a casa se avete qualche dubbio va bene quindi terminato questo blocco di slide passiamo al successivo che è diciamo l'argomento che ci accompagnerà anche per domani e che invece questo ci porterà alla discussione del secondo problema d'esame ok e sono i problemi di ricerca con avversari ai giochi allora si è parlato tantissimo in letteratura di questa cosa perché ve lo dicevo durante la prima lezione quando abbiamo visto un po' tutto il panorama delle AI abbiamo fatto vedere anche vari momenti diciamo storici delle AI e di questi grandi momenti storici ci sono anche proprio momenti in cui un algoritmo è riuscito a battere un essere umano perché è gioco poi noi iniziamo a recitare cose che ci siamo di interi e diciamo nasce un po' tutto da qua nasce un po' tutto da qua chiaramente non finisce tutto qua perché se cominciamo un pochino a vedere quanta sensibilità sulla complessità di questi problemi ne abbiamo parlato prima dicevamo ci sono degli ambienti talmente complessi che la rappresentazione come problema nell'espazio degli stati diventa un feasible non gestibile ok quindi chiaramente la questione è venuta però parte tutto da qua parte tutto dal momento in cui noi decidiamo di voler affrontare problemi in cui il nostro ambiente come dicevo un attimo fa non è sotto il nostro controllo ma c'è qualcuno che lo modifica non solo modifica fa peggio ha un obiettivo che è esattamente l'imposto del nostro quindi conflicting goals ok quindi sono ambienti competitivi in cui in cui due progetti hanno obiettivi opposti e vengono chiamati i problemi di ricerca di una persona ok il problema è un problema impredecibile proprio perché io quando inizialmente devo decidere qual è la prima mossa che faccio la faccio e la vedi però poi devo assumere quando vado a fare la seconda di dover rispondere a una mossa che ha fatto l'avversario ok quindi in questo senso entriamo nel contesto del contingency plan di cui parlavamo un attimo fa perché la mia seconda mossa che sarà la mia seconda mossa in risposta a quella fatta dall'avversario deve chiaramente quando faccio il mio piano di soluzione deve chiaramente tenere conto di tutte le possibili risposte che l'avversario ha dato diciamo così alla mia mossa iniziale ok ok quindi li definiamo così guardate sono ancora ambienti che definiamo deterministici in che senso nel senso che la mia azione c'è se si muove il cavallo in A4 sicuramente il cavallo andrà in A4 quindi rispetto al diciamo problema che mi ha portato un attimo in questo caso noi sappiamo assumiamo il fatto che la stocasticità deriva non dal fatto della mia azione a un esito diverso da quello atteso ma deriva dal fatto che qualcun altro che poi modifica l'ambiente e dalle sue modifiche devo reagire i giocatori sono due questo chiaramente è per una cosa che limitiamo i giocatori per trattabilità del problema i giochi sono giochi tra due che significa che insomma si svolgono a turno quindi io faccio la mia azione l'adversario fa la sua eccetera fondamentale l'ambiente è completamente osservabile il suono in mezzo alla nippia vede tutto ok poi sempre come descrizione del problema vengono chiamati zero sum games sono giochi zero sum games cosa significa? significa che quella che è la massima utilità per me giocatore 1 è la minima utilità per voi giocatori 2 quindi se andiamo a sommare l'utilità complessiva del sistema è zero perché se io ho vantaggio 1 voi avete vantaggio meno 1 e quindi chiaramente non posso definire una soluzione ottima perché la soluzione ottima è per uno dei due giocatori per l'altro è la peggiore in assoluto ok e vedete che il gioco degli scacchi è esattamente elencato tra uno dei giochi più rappresentativi di questo insieme di problemi che hanno queste caratteristiche quindi problemi deterministici e completamente osservabili con informazione perfetta il monopoli non lo è perché perché ce l'abbiamo a destra in questo graffittino in questo periodo esattamente proprio per i dati non è del del monopoli perché di quanto mi muovo mi spende la data con il gioco per avere un po' di sfiga un po' di fortuna cambia completamente l'evoluzione del gioco quindi questo lo sottolineo proprio perché a differenza di quanto detto nell'ultimo slide del blocco precedente in questo caso se io lancio i dadi nel monopoli non so dove vado a finire dipende dal risultato del lancio ok mentre nei problemi che vedremo oggi e domani abbiamo la certezza che tutto ha esito come sperato ok e di questo ne abbiamo già parlato vi ricordo il deep blue meraviglioso che ha vinto contro Gary Kasper con 97 e vi ricordo che invece questo gioco tipicamente mi sembra il campione degli scacchi fosse cinese non so è riuscito solo nel 2016 ad essere assoluto e questa cosa è fortemente dovuta all'initi di potenza computazionale adesso vedrete come funzionano questi algoritmi ma è chiaro che non possono data la complessità al numero di mostre al numero di possibili stati in cui posso finire a partire dal mio stato iniziale è una ricerca estensiva e sostanzialmente intattata quindi l'idea di a partire dal mio stato faccio un contingency plan che considera tutte le possibili evoluzioni del problema che tengono anche conto delle risposte dell'avversario è sostanzialmente unfeasible ok descriviamo il problema in questo modo partiamo sempre da questi casi in questi casi il suo contingency potrebbe anche non essere casuale perché sapete per esempio nel gioco delle scampi la posizione delle pedine è assolutamente definita e poi i giocatori sono due quindi ciascuno stato è associato a un giocatore che può fare la mossa e l'insieme delle azioni che posso fare in ogni stato dipende dalla regola del gioco quindi questa funzione actions sullo stato S restituisce l'insieme delle mosse legal cioè possibili nello stato S dipende chiaramente dal stato del gioco ci sarà poi una solita funzione che era la funzione goal nella versione precedente in questo caso viene chiamata terminal test che definisce se il gioco è concluso o meno ecco qui c'è un elemento che si inserisce ora in questa narrazione in questo percorso che stiamo facendo che è la funzione utilità non è troppo diversa attenzione dalle funzioni post dalle funzioni oristiche continua a essere qualcosa che noi usiamo per qualificare e quantificare la bontà di una soluzione però in questo momento viene utilizzata in modo un po' diverso e vedrete che questa cosa ce la prendiamo fino alla fine con con il market decision process quindi questa funzione utilità viene utilizzata per definire la qualità degli stati finali di un gioco quindi se lo stato terminale di un gioco è lo stato s ci sarà una funzione utilità per il giocatore p1 una funzione utilità per il giocatore p2 associata con lo stato s quindi guardate vedete le ho associate al costo e le risposte utilizzate hanno questo significato che è molto analogo però particolarmente cioè analogo nel suo significato di valutazione di una soluzione ma diverso da come viene utilizzato qui l'obiettivo non è più quello di minimizzare il costo di una soluzione la gente vuole massimizzare la sua utilità e ribadisco l'utilità mia è esattamente la non utilità tua guardate questo esempio che conoscete perfettamente questo qui è il gioco del tris nel gioco del tris insomma partiamo con quindi lo stato iniziale è assolutamente noto partiamo con una griglia completamente vuota e abbiamo due giocatori come sempre il giocatore che scrive le x e il giocatore che scrive il segno i giocchietti non c'è bisogno che descrivo il gioco ciascun giocatore posiziona le sue simboli nella posizione della scacchiera che ritiene più opportuna dopo descriveremo un po' meglio questa cosa il gioco termina quando o uno dei due giocatori ha finito o il gioco termina in attività e il pareggio allora entro dopo nel merito del gioco e perché a sinistra vedete questo max min max min mi interessa appunto in continuità con quanto detto nella slide precedente farvi vedere un esempio sul concetto di funzione e utilità direttamente più comprensibile a partire da questo esempio perché vedete che in questi stati intermedi attualmente non abbiamo informazioni quantitative al momento però sappiamo che se il gioco terminerà in questo stato ci sarà il giocatore min che avrà utilità meno uno in questo stato scusate che l'utilità di questo stato è meno uno che l'utilità di questo stato è zero che l'utilità di questo stato è più uno cerchiamo di capire a chi piace il meno uno a chi piace il più uno a chi piace lo zero e vedete che appunto è un zero cost perché se piace il meno uno a qualcuno a quell'altro non piace per niente perché quell'altro avrebbe voluto trovarsi in uno stato con utilità più allora qui l'idea è questa che quelle funzionabilità hanno significato diverso a seconda dei giocatori di loro valore ovvero il giocatore max è un giocatore a cui piace vincere ottenendo valori il più alto possibile in questo caso i valori sono meno uno zero più uno quindi quale vincere ottenendo uno il giocatore min invece è il giocatore a cui piace vince cioè che per vincere intende ottengo il valore minimo possibile non a caso appunto i due giocatori vengono chiamati max e min ok quindi sono sempre i nostri due giocatori entrambi hanno sempre lo stesso identico obiettivo voglio vincere il gioco la differenza è che per trovare l'istituzione e l'esperienza tra i due giocatori e il fatto e sottolineare il fatto che hanno i obiettivi complementari meglio composti uno all'obiettivo di minimizzare la differenza di funzionamento e la differenza quindi non a caso nelle soluzioni negli stati che vedete qua sotto lo stato di pareggio è lo stato in cui nessuno ha vinto ma lo stato meno uno è quello in cui ha vinto il giocatore min quello che disegnava i cerchietti lo stato più uno di utilità più uno è quello in cui ha detto il giocatore max che disegnava le x ok quindi entriamo un po' in questo contesto quello che faremo domani adesso che il problema è stato presentato sarà capire quindi come istruire il nostro algoritmo perché possa sostanzialmente rispondere in maniera opportuna a identificare tutte le mosse quindi sul piano di soluzione identificando tutte le mosse perché siano e tengano in considerazione anche di eventuali e non eventuali anche delle risposte del nostro avversario quindi come vedete qui l'albero di gioco comincia a complicarsi il nostro max può fare un insieme di azioni che sono queste però guardatemi qua bene quando deve fare l'azione successiva ok deve tenere in considerazione il fatto che Min nel frattempo ha fatto qualcosa e quindi potrebbe dover definire l'azione successiva partendo da questo stato da questo stato da questo eccetera eccetera quindi non potrà più dire se sei qui fai questo ma dovrà dire se sei qui fai questo se sei qui fai questo se sei qui fai questo eccetera eccetera ok va bene quindi domani vi racconterò un po' meglio di che cosa si tratta e vi farò vedere degli esercizi d'esame e credo che con domani non riusciamo a chiudere anche questo argomento quindi riusciamo sia a concludere la parte teorica sia a fare esercizi d'esame per prepararci su questa parte nel caso non riuscissimo a finire facciamo qualcosa anche la prossima settimana però in termini intendo scusate quindi