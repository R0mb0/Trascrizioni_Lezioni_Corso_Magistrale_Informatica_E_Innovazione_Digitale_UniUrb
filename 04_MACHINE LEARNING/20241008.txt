Allora. Benissimo, allora riprendiamo i discorsi che stavamo facendo ieri, che abbiamo impostato riguardanti i metodi del primo ordine e per arrivare alla definizione poi dell'algoritmo di discesa del gradiente. Quello che abbiamo visto ieri abbiamo anzitutto introdotto un po' di notazioni per inquadrare il problema da un punto di vista geometrico, oltre che da un punto di vista appunto dell'analisi matematica, nel senso che siamo andati a prendere in considerazione rette piani o più in generale in più dimensioni iperpiani e siamo andati a cercare lungo questi particolari antigeometrici quale erano le direzioni tra le infinite possibili che a partire da un dato punto che sta, che determina poi un valore sul piano, sull'iperpiano, ecco qual è il vettore direzione che ci porta nella direzione di massimizzare o minimizzare il valore della funzione su questo iperpiano. E abbiamo visto che scrivendo, facendo un po' di passaggi matematici, questo vettore direzione è un vettore che coincide con la massimizzazione di questa quantità e massimizzare questa quantità significa andare a cercare un vettore direzione che ha questa struttura quando teta è uguale a 0, questo corrisponde a cos teta uguale a 1, poi alla fine, dato che questa norma non dipende dal vettore direzione e questa è la norma del vettore direzione che è pari a 1, significa andare a massimizzare solamente rispetto al cos teta e quindi si trova un vettore direzione che ha questo, esattamente questo valore, quando cos teta è uguale a 1 ed ha il valore, è un vettore di fatto antiparallelo quando il cos teta è uguale a meno 1 e questo corrisponde alla direzione di discesa massima. Quindi lungo l'iperpiano sappiamo in che direzione muoverci per andare verso la direzione di massima ascesa oppure la direzione di massima discesa, è un vettore che calcoliamo così. Vi ricordo che b è un vettore che caratterizza invece l'equazione dell'iperpiano, l'equazione dell'iperpiano che abbiamo scritto esattamente in questo modo. E' questa. Ok? Ci siamo fin qui? Bene. Allora... Eravamo arrivati qui e adesso oggi facciamo un po' di passi avanti e vediamo un attimo di chiudere il cerchio, ma per fare questo dobbiamo introdurre altri concetti. In particolare dobbiamo ricordare quello che è il concetto alla base dell'approssimazione di una funzione tramite lo sviluppo in serie di Taylor. Anche questi sono concetti che dovreste avere abbastanza ben noti dai corsi di matematica affrontati durante la laurea triennale. Li ricapitoliamo molto brevemente. Anche qui non ci serve entrare eccessivamente nel dettaglio, però è bene tenere presente che cosa rappresentano per poter comprendere a fondo come poi sfrutteremo questo tipo di concetto. Partendo dalla funzione di una variabile, se vi ricordate, una qualunque funzione f di x può essere approssimata mediante una serie infinita di termini che rappresentano una funzione f di x in un certo dominio, funzione che deve avere certe caratteristiche, che deve essere ovviamente differenziabile, eccetera, eccetera, infinite volte, però può essere scritta come il valore della funzione nel punto più il termine che deriva dalla derivata della funzione nel punto in questione, x con 0, moltiplicato per x meno x con 0, più una serie di altri termini che sono termini infiniti che comprendono poi nel secondo termine la derivata seconda, la derivata terza e così via. Quindi mediante un'approssimazione di questo tipo, questa chiaramente è un'approssimazione, noi riusciamo, è un'approssimazione nel momento in cui tronchiamo questa serie di infiniti termini a un numero finito, la funzione risulterà approssimata. Questo è lo sviluppo, quello che ci dice appunto, sviluppo in serie di Taylor e che prevede di rappresentare una funzione in un modo alternativo tramite appunto questi infiniti, potenzialmente infiniti termini. Dicevo che se ovviamente tronchiamo questo sviluppo in serie a un numero finito di termini, abbiamo un'approssimazione della nostra funzione, approssimazione che può avere luogo al primo, al secondo, al terzo termine. In questo caso noi ci concentreremo su un'approssimazione che è un'approssimazione che è questa che vi ho appena evidenziato nel riquadro, quindi un'approssimazione al primo, al primo ordine, al primo termine, che è il termine che, guarda caso, contiene la derivata prima, cioè non andiamo a considerare le derivate seconde, così via. E' chiaro che questa approssimazione è un'approssimazione che è tanto più corretta quanto più noi siamo vicini nell'intorno al punto x con zero e non ci muoviamo troppo. Perché? Perché significa approssimare la nostra funzione f di x con una retta di fatto, questa è l'equazione di una retta. E' ovvio che questa approssimazione vale in maniera sempre meno, sempre più grossolana, sempre meno accurata, quanto più noi ci spostiamo dal punto di tangenza, perché questa poi è l'equazione della retta tangente al punto x con zero. Ok? Ci siamo fin qui? Che cosa succede? Succede che questo stesso, quindi questo è un polinomio di Taylor in cui ci fermiamo al primo termine. Potremmo andare appunto a estendere ed essere più accurati, ma per il nostro scopo appunto trattando di algoritmi che sfruttano condizioni del primo ordine è sufficiente, sicuramente pienamente sufficiente fermarci qui. La cosa che vale la pena notare è che mentre, diciamo, questa è una notazione in cui probabilmente vi ritrovate e che, insomma, è stata sicuramente affrontata nei corsi di analisi matematica di base, la stessa cosa, lo stesso concetto può essere esteso a funzioni di più variabili. E una funzione di più variabili può essere anche essa sotto certe condizioni, ovviamente, di esistenza delle sue derivate e quindi in particolare delle derivate parziali rispetto alle varie variabili, quindi l'esistenza del gradiente, però, diciamo, sotto queste condizioni può essere approssimata localmente, come è evidenziato qui nella slide, intorno a un certo punto W0, sopra ho usato la variabile X, qui torno ad usare la variabile W per coerenza appunto con il resto della notazione del slide, può essere, vi dicevo, approssimata tramite un iperpiano. Esattamente in analogia con quanto abbiamo fatto per una variabile dove l'approssimazione è data da una funzione lineare a una retta, se passiamo a 2 o 3 o a n variabili, il concetto è posso approssimare la mia funzione H tramite un iperpiano. In particolare, questo iperpiano, quindi, l'obiettivo è scriverlo secondo questa notazione, questo iperpiano è esattamente quello che viene dettato dallo sviluppo in serie di Taylor, che è il valore della funzione nel punto W0, che è questo termine, che è del tutto analogo a questo che avevamo scritto prima, più un termine che è dato dallo scarto rispetto al punto di partenza W0, quindi W-W0, premoltiplicato per un vettore, che è il vettore gradiente nel punto W0. Il vettore gradiente è un vettore, questo operatore di trasposizione è puramente per comodità, vi dicevo, di far tornare le dimensioni, cioè noi indicheremo, ve lo dicevo la volta scorsa, i vettori come vettori colonna, quindi per ottenere un prodotto scalare qui dovevo, dovremmo avere chiaramente un vettore che siccome ho scritto in questo modo, deve essere un vettore colonna e un vettore, pardon, scusatemi, un vettore a riga che va a moltiplicare un vettore colonna, quindi 1 per n per n per 1 e ottengo uno scalare come risultato. Ma al di là dell'operatore trasposto quello che ci interessava evidenziare è che qui abbiamo il gradiente della funzione nel punto W0 che gioca esattamente il ruolo che qui giocava la derivata prima rispetto a una singola funzione nel punto X con 0. Va bene? Ci siamo? Sì, sì, è chiaro. Ok, perfetto. Allora, giusto per dire le cose, per evidenziare alcune cose che stavamo facendo, questo, allora, far tornare un po' i conti, questo ovviamente gioca il ruolo di A, ok, mentre qui se vado a moltiplicare questa, diciamo, la posso scrivere come allora, scriviamola qui, questa, vado qua e la scriviamo come G di W0 chiaramente più il gradiente di W0 il gradiente, scusatemi, di G nel punto W0 scusatemi, perdono, se c'è uno 0, ok, facciamo qui, così, il gradiente, vi dicevo, nel punto W0 scalare W, W, meno il gradiente della funzione del punto W0 scalare W0. Ok, a questo punto è chiaro che A risulta essere questo, mentre questo risulta essere il termine perdono, scusate, A è questo più ovviamente questo e questo invece risulta essere il termine di trasposto per W, ok? Quindi, se io pongo A pari a G di W0 meno il gradiente di G W0 scalare W0 ottengo questa equazione. Va bene? Dove B a questo punto che cos'è? A questo punto abbiamo molto semplicemente che B è il gradiente. E allora adesso cominciamo a chiudere un po' come vi dicevo prima il cerchio perché se riandate a vedere anche solamente nella slide precedente abbiamo detto che il vettore che vi conduce adesso ci sono sovrapposte le scritte ma le lascio perché così dopo quando torno nella slide ce le abbiamo però se andate a vedere vedete che qui il vettore che troviamo è un vettore che fornisce la direzione massima di discesa o di ascesa cambia solamente il segno meno è proprio dettato da quel vettore B ma questo significa che cosa? Se dettato da quel vettore B questo significa che quel vettore B nel nostro caso è esattamente il gradiente ma questo vuol dire che cosa? Che il vettore gradiente è il vettore che ci dà le direzioni di massima discesa o ascesa di che cosa? Della funzione di fatto perché noi quello che facciamo è approssimiamo la funzione con questa espansione in serie di Taylor quindi con questo iperpiano dato che l'iperpiano nell'intorno del punto W0 rappresenta un'approssimazione ragionevole della funzione utilizziamo la direzione di discesa di ascesa massima sull'iperpiano in quel punto per identificare la direzione di discesa o ascesa massima per la funzione stessa quindi la logica è proprio andare a utilizzare l'approssimazione di una funzione mediante questo polinomio di Taylor del primordine e quindi tramite un iperpiano siccome la funzione l'approssimiamo con questo con questo con questa con questa espansione serie di Taylor con un iperpiano e sappiamo nell'iperpiano identificare la direzione in cui muoverci per andare verso la massima discesa o verso la massima ascesa lungo il profilo della funzione e questa direzione è dettata dal gradiente a quel punto abbiamo la direzione una direzione di massima discesa o di massima ascesa della funzione in quel punto ma se abbiamo questo il gioco è fatto perché a questo punto possiamo impostare un algoritmo che sfrutti esattamente questo tipo di di concetto quindi è importante avere ben presente perché abbiamo introdotto questo questo insieme di notazioni proprio per poter andare ad approssimare la funzione in in quel punto e ricavare l'informazione su qual è la direzione di massima discesa o di massima ascesa perché a quel punto noi possiamo impostare un algoritmo di ottimizzazione locale e li abbiamo cominciati a conoscere perché li abbiamo introdotti nella tipologia diciamo la cornice l'abbiamo introdotta è un algoritmo che abbiamo poi specializzato nell'algoritmo di discesa di ricerca casuale oppure nell'algoritmo di discesa o di ricerca delle coordinate qui faremo esattamente la stessa cosa usiamo quello schema ma abbiamo il vantaggio di sapere a priori qual è la direzione di discesa e la direzione di discesa è quella dettata dal gradiente va bene ci sono domande? no è chiaro allora siccome la direzione di discesa è legata al gradiente determinata proprio dal vettore gradiente noi quello che possiamo fare è utilizzare un meccanismo di questo tipo allora se noi vogliamo massimizzare e quindi utilizzare l'informazione sul gradiente abbiamo chiaramente il vettore gradiente che ci identifica la direzione di massima scesa se prendiamo il vettore gradiente col segno meno abbiamo chiaramente una direzione valida di discesa di massima discesa quindi quello che facciamo è sfruttare l'informazione che è contenuta all'interno del del vettore gradiente in questo caso con un segno meno a quel punto è abbastanza naturale utilizzare uno schema di ottimizzazione locale del tipo che abbiamo visto già nelle lezioni passate cioè io vado ad aggiornare procedo in una sequenza di passi di iterazioni in cui al passo cappesimo vado a calcolare appunto questo passo cappesimo partendo da quello precedente che era quello in cui mi ero fermato da cui riparto e vado a sommarci un vettore direzione moltiplicato per un learning rate che è il fattore alfa come scelgo questo vettore direzione molto semplicemente prendo il gradiente negativo cioè il vettore direzione è esattamente il valore che il gradiente della funzione assume nel punto wk-1 che è quello vi ricordo in cui siamo appena arrivati con il segno meno davanti quindi il punto cappesimo lo calcoliamo esattamente come w di k-1 meno alfa gradiente calcolato in w di k-1 qui è l'essenza di quello che viene chiamato algoritmo di discesa del gradiente che ad oggi probabilmente è l'algoritmo più utilizzato in gran parte delle delle applicazioni di machine learning che potete trovare non è l'unico ma è uno dei più utilizzati perché ha tutta una serie di proprietà che lo rendono particolarmente flessibile e particolarmente interessante da utilizzare funziona molto bene e in tanti casi pur non essendo l'unico che può essere utilizzato abbiamo parlato anche di algoritmo in ordine a zero vedremo ce ne sono altri di ordine che sfruttano le ottimizzazioni del secondo ordine i criteri di ottimizzazione di ordine due di secondo ordine però è sicuramente quello più popolare per diversi motivi diversi motivi che vanno dal punto del fatto che anzitutto funziona bene in tantissimi casi quindi per intenderci se dovete se aprite un framework che vi permette di utilizzare di costruire per esempio delle reti neurali nelle librerie che fanno quello dietro supportano tutte le algoritmi di scelta del gradiente perché riesce molto bene anche a minimizzare funzioni di costo su su sistemi di quel tipo perché poi molto bene riesce ad interfacciarsi con un altro meccanismo che serve per l'addestramento delle reti neurali che si chiama retropropagazione ma non solo è un algoritmo che indipendentemente anche delle reti neurali può essere sfruttato anche per altri modelli di machine learning perché come vi dicevo ha il pregio di riuscire a essere molto flessibile a funzionare bene in diverse situazioni pur avendo dei limiti alcuni dei quali chiaramente non è la soluzione per tutto alcuni di questi cercheremo anche tra l'altro di chiarirli nel corso di questo o al limite della prossima lezione l'altro punto direi chiave da tenere presente per il successo di questo algoritmo oltre al fatto che appunto funziona abbastanza bene in una serie di scenari estremamente diversi è il fatto che scala molto bene con N diciamo che il trucco qui è ricavare informazioni su quello che è il gradiente della funzione ma questa informazione si riesce a ricavare molto bene anche quando N cresce non soffre di problemi di dimensionalità e qui diciamo ci ricolleghiamo anche al fatto che un punto cruciale è il calcolo del gradiente il calcolo del gradiente che se uno lo dovesse fare a mano è tutt'altro che banale ma lo sviluppo di librerie specializzate per effettuare appunto il calcolo del gradiente di funzioni di N variabili in maniera automatica efficiente ed estremamente estremamente rapida è stato cruciale per poter portare poi al successo di questo tipo di algoritmo che poi troverete in se andate ad aprire uno qualunque di questi framework noi poi li studieremo anche quando lavoreremo faremo scusatemi l'esercitazione in laboratorio ma diciamo riprenderemo appunto alcuni di questi di queste librerie e lì dentro ci sono tanti algoritmi che fanno ottimizzazione dei modelli di machine learning come vi dicevo l'algoritmo di scesa del gradiente è uno dei più utilizzati quello che va tenuto presente è che le implementazioni che trovate sono implementazioni arricchite nel corso di questi anni da una serie di diciamo di varianti di specializzazioni per cui è questo algoritmo con in più una serie di accorgimenti di trucchi di diciamo di arricchimenti che hanno permesso di renderli ancora più efficaci ed efficienti però nella sua essenza è questo qui dentro c'è fondamentalmente tutto quello che riserva per comprendere come funziona questa tipologia di algoritmi e se noi lo vogliessimo mettere all'opera per cercare un po' di capirlo meglio su un semplice esempio di una funzione a un solo input quindi di una sola variabile come quella descritta dal grafico che qui trovate in questa figura quindi questa curva in colore nero beh quello che si fa con l'algoritmo di questo genere si sceglie un punto di partenza e qui o sappiamo dove vogliamo partire per qualche motivo che ci può far comodo perché conosciamo bene il problema e quindi sappiamo che un certo punto è particolarmente utile oppure più tipicamente partiamo da un'inizializzazione casuale e calcoliamo quello che è la funzione nel punto il valore della funzione nel punto che è questo evidenziato da questo punto rosso e lì andiamo a calcolare l'approssimazione in serie di Taylor fermandoci al primordine quindi calcoliamo la derivata prima la derivata prima ci permette di costruire questa retta verde che rappresenta la retta tangente alla funzione in quel punto e rappresenta l'approssimazione in serie di Taylor di quella funzione è chiaro che è un'approssimazione che vedete qui bene è valida fin tanto che mi muovo in un intorno abbastanza stretto della funzione nel momento in cui mi colloco qui è un'approssimazione che comincia a essere poi via via più grossolana quindi se pretendo di approssimare la funzione con questa retta e mi sposto dal punto iniziale è ovvio che l'approssimazione diventa via via più grossolana ma a noi questo non interessa più di tanto perché ci interessa solamente rimanere qui calcolare il valore della derivata in quel punto e da lì spostarci nella direzione negativa del gradiente in questo caso della derivata prima qui vedete che la funzione è tale da avere una retta tangente che ha una pendenza negativa questo significa che nel momento in cui andiamo a cercare la direzione negativa del gradiente moltiplichiamo per un questo gradiente negativo moltiplichiamo per un segno meno diventa positivo quindi vuol dire che noi dal punto w0 andiamo a transitare verso un punto w1 che avrà un valore maggiore e questo valore maggiore è punto w1 che troviamo esattamente con un aggiornamento scusatemi che è questo che vi vado appena a cerchiare ora quanto vale la funzione del punto w1 mi riporto di nuovo sulla funzione trovo questo valore e qui di nuovo effettuo l'approssimazione in serie di taylor trovando questa retta tangente di nuovo a partire da questa retta tangente mi muovo dove mi muovo qual è la direzione di massima pendenza è quella dettata da quella retta stessa e in particolare siccome quella retta ha pendenza negativa mi muoverò in avanti ovviamente quindi verso il punto w2 e nel punto w2 posso ripetere la stessa cosa andare avanti per un certo numero di passi che sono quelli che abbiamo scelto come numero prefissato per il numero di iterazioni oppure scegliere di andare avanti finché non viene soddisfatto un qualche criterio di convergenza di cui magari poi diremo qualcosa va bene questa è l'essenza dell'algoritmo nella sua nella sua nella sua complettezza allora spero che sia tutto chiaro altrimenti tornateci sopra fate domande perché è importante perché questo è un algoritmo che poi tireremo adesso discuteremo le caratteristiche nel proseguo della lezione però lo tireremo poi in ballo più volte durante il resto del corso quindi è importante diciamo comprenderne a fondo le caratteristiche qui quello che abbiamo è un esempio in cui quello che facciamo è giusto torno un attimo indietro giusto per farvi capire meglio il la scrittura specializzandola al caso di una variabile e vuol dire che partendo da l'algoritmo che cosa sta a significare in questo esempio vuol dire che cosa che partiamo da w0 e poi da w0 andiamo a cercare il punto w1 questo punto w1 in realtà non c'è bisogno di mettere il segno di vettore perché siamo in una sola variabile vi dicevo questo punto w1 come lo andiamo a calcolare lo calcoliamo a partire da w0 come w0 meno alfa per la derivata di g del punto w0 rispetto a w una volta che ho trovato w1 vado a trovare w2 e lo calcolo come w1 meno alfa derivata di g rispetto a w nel punto w1 e poi andiamo avanti così è chiaro che fin tanto che la pendenza è negativa questo termine è negativo e quindi il punto w1 è un punto che sta a destra di w0 il punto w2 è un punto che sta a destra di w1 e così via bene era giusto per dirvi qualche cosa in più qui andiamo a vedere un ulteriore esempio un esempio di una funzione non convessa funzione che ha questa struttura g di w è uguale al seno 3 w più 0.3 w quadrato l'abbiamo inquadrato anche nelle lezioni precedenti ipotizzando di partire da un punto che è 4.5 ad esempio che è questo punto qua beh quello che succede è mandando in esecuzione l'algoritmo con che abbiamo appena descritto con un learning rate pari a 0.05 si ottiene un andamento che è quello che vedete qui rappresentato nella figura di destra in particolare partendo da questo punto il valore che assume la funzione nel punto è questo questo determina una direzione di discesa che chiaramente qui abbiamo la retta tangente la direzione di discesa ci dice che il punto successivo va preso a sinistra perché chiaramente stiamo scendendo lungo il profilo della funzione e quindi il punto da cui partiamo è quello segnato da quella croce verde e andiamo verso il punto alla sua sinistra dopodiché da qui ripartiamo volevo semplicemente utilizzare questo per farvi vedere ecco con quest'altro marker quindi partiamo da qui il punto successivo sarà quest'altro e quindi saremo su questo punto poi su questo poi su questo poi su questo e via via finché non arriviamo al punto evidenziato in rosso che è il minimo locale della funzione va bene partendo da invece un altro punto che è quello pari a meno 1.5 quindi questo punto qui quello che otterremo è percorrere la funzione vedete con le croci indichiamo il valore della funzione nel punto che corrisponde a quello che è il valore che la funzione prende nei vari punti quindi questi punti i cerchi sono i vari punti w0 w1 w2 wk le croci sono i valori g di w0 g di w1 g di wk e vedete che in questo caso arriviamo a un punto di minimo che guarda caso il minimo globale della funzione in questo intervallo o comunque è un punto più basso è un minimo locale più basso rispetto a quello che avevamo trovato con la prima inizializzazione ma questa di fatto è una caratteristica di questi tipi di algoritmi appunto di minimizzazione locale che quello che ci permettono di fare è ricavare i minimi locali ovviamente e questo insomma lo sapevamo già quando abbiamo cominciato ad analizzare le prime tipologie va bene ci siamo vi faccio notare una cosa intanto che pensate eventuali domande che nell'inizializzazione a partire da 4.5 quindi da qui quindi da questo punto siamo qui sulla funzione la pendenza chiaramente presentata da questa retta che mi stavo disegnando qui è una pendenza positiva pendenza positiva significa che meno alfa per il valore di quella pendenza è un qualcosa che va a diminuire il valore di W0 da cui siamo partiti quindi andiamo in questa direzione viceversa quando partiamo da qua andiamo ad aumentare perché la pendenza è negativa va bene? bene scusi prof prego io non ho capito bene il discorso del segno del gradiente allora nell'algoritmo di minimizzazione quello che noi facciamo è andare a cercare un nuovo punto ragioniamo in una sola variabile così ma poi è la stessa cosa anche per più variabile quello che facciamo torniamo qui dietro così ce l'abbiamo qui è andare a prendere il punto WK questa struttura in una sola variabile sarebbe WK lo calcoliamo come W calcolato all'iterazione K meno 1 meno alfa per la derivata della funzione G rispetto a W nel punto WK meno 1 allora io in realtà ho messo il segno di vettore anche se non è un vettore perché siamo in una sola variabile va bene ok cancelliamo il vettore ragioniamo in una sola variabile giusto? fino a qua ci siamo? sì sì fino a qua ok allora tu guarda che cosa succede in questo se io mi posiziono ad esempio in questo punto in questo punto la pendenza della retta tangente che è rappresentata da questa derivata ok è una pendenza negativa giusto? sì quindi sarà un numero meno 1,5 poniamo poniamo che alfa sia 0,5 quello che si fa un decimo hai meno 0,1 che è alfa moltiplicato per meno 1,5 che è la pendenza negativa in quel punto meno per meno fa più ottieni wk meno 1 più un numero positivo quindi il valore di wk è un valore che si sposta da wk meno 1 incrementando il suo valore giusto? ok se tu invece fossi stato su questo punto qui quindi ti fossi posizionato in questo punto qui il valore della retta tangente sarebbe stato positivo perché la pendenza qui è positiva della curva giusto? sì ok allora se questo è positivo perché questa è una retta che ha un coefficiente angolare positivo che cosa succede? succede che questo è positivo significa che la derivata della funzione in questo punto è un numero positivo ma siccome tu lo moltiplichi per meno alfa proprio perché cerchi la direzione di discesa sempre questa espressione correttamente ti porta a dire che cosa ok se tu sei qui in wk meno 1 all'iterazione k meno 1 beh devi diminuire di un qualche valore che è dettato dal alfa moltiplicato per questa derivata per trovare il punto successivo quindi automaticamente la pendenza della curva ti dice se aumentare o diminuire il valore della variabile ok quindi nel caso di una dimensione qui ci dice semplicemente se spostarci verso destra o verso sinistra esattamente se invece vai in più dimensioni è chiaro che lì il discorso cambia in più dimensioni hai dei vettori per cui la direzione di discesa è una direzione che è dettata da una serie di componenti di n componenti ognuna delle quali ti dirà dove andare lungo quella coordinata però il principio è sempre lo stesso ok capito grazie ok prego ok allora qui abbiamo un altro esempio un altro esempio di minimizzazione di una funzione in questo caso è una funzione convessa questo è un esempio che anche questo abbiamo già incontrato ma vale la pena vedere che cosa succede a questa funzione che è una funzione quadratica che vi vado a scrivere qui a lato la funzione che possiamo scrivere come w1 e w2 che sono le due variabili è uguale a w1 al quadrato più w2 al quadrato più 2 a un minimo chiaramente nello 0 qui c'è un'esecuzione dell'algoritmo di scesa del gradiente con alfa pari a 0.1 per 10 passi e anche qui potete notare che abbiamo sulla sinistra la rappresentazione della superficie in tre variabili queste sono le due variabili qui c'è un w1 w2 ok per errore quindi andate a sostituire a questo w1 e a questo w2 però rimane vero il punto che dicevamo cioè la traccia quella che ci interessa è andare a vedere ad analizzare cosa succede partendo da questo punto iniziale ad esempio questo punto iniziale che è un punto che ha coordinate 1.5 e 2 quindi siamo a 1.5 lungo la prima variabile e 2 lungo la seconda e questi sono i vari punti che troviamo nell'algoritmo di scesa del gradiente che vedete vanno a puntare progressivamente dei punti che sono via via più bassi lungo quella superficie nella parte di destra vedete rappresentate lo stesso concetto però tramite le curve di livello in cui abbiamo questi cerchi concentrici che rappresentano appunto il valore che assume la funzione lungo ognuno dei piani se tagliamo lungo ognuno dei punti della superficie che vengono tenuti tagliando con dei piani quella superficie stessa e qui partendo da questo punto iniziale poi si trova questo questo questo e vedete che riusciamo a identificare il minimo locale che in questo caso coincide anche con il minimo globale perché nelle funzioni convesse abbiamo la proprietà di avere un solo minimo globale per cui l'algoritmo di discesa in questo caso lo riesce a identificare correttamente va bene questi sono due semplici esempi in cui l'algoritmo funziona e funziona esattamente come ci saremmo aspettati qui abbiamo ulteriori esempi che invece ci evidentano ci servono ad evidenziare poi in realtà due diciamo sono esempi di funzionamento in qualche modo che anche qui forse ci potremmo attendere il terzo è un po' imprevisto e adesso cerchiamo di andarlo ad analizzare perché questo algoritmo non è immune da qualche possibile funzionamento problematico di cui bisogna cosa della quale bisogna tener cosa che bisogna tener presente ecco della quale bisogna essere consapevoli per poterlo utilizzare in maniera corretta un punto cruciale è proprio la scelta del learning rate del passo di aggiornamento dell'algoritmo se noi anche qui abbiamo l'ipotesi di poterlo utilizzare con un passo via via decrescente oppure con un passo fisso supponiamo di ragionare sul passo fisso quindi solitamente la scelta ricade su un valore che è scelto con questo criterio cioè alfa viene scelto come 10 alla gamma dove gamma è un numero solitamente è un numero un numero intero quindi può essere 10 oppure 10 alla meno 1 10 alla meno 2 così via non necessariamente solitamente gamma numero intero di solito è negativo quindi difficilmente si va su valori superiori all'unità per alfa e questo è una possibile ipotesi l'altra ipotesi è di utilizzare un learning rate via via decrescente quindi una regola del tipo 1 su k in cui la k interesima interazione il valore di alfa prende proprio questo valore e questi li abbiamo visti anche per gli algoritmi di ordine di ordine 0 come random search ad esempio allora qui che cosa vedete riportato? ma a sinistra vedete riportato una funzione che è molto semplicemente una parabola quindi una funzione del tipo me la scrivo qui g w uguale w al quadrato che molto semplicemente ha chiaramente un minimo nello zero un minimo globale questa funzione è una funzione che su cui è stato fatto un run di discesa del gradiente a partire da da un valore iniziale quindi in realtà sono stati fatti tre run con tre valori di alfa diversi che sono quelli che vedete riportati qui ok e questi tre valori di alfa diversi sono stati però tutti effettuati a partire da un dallo stesso da un punto iniziale che è questo che in questo caso è direi qualcosa che meno quattro se non ricordo male no forse un po' di meno adesso non mi ricordo qual è ma insomma è qualcosa che potrebbe essere tipo meno tre meno due punto cinque una cosa del genere ma adesso poco importa è questo punto che viene poi evidenziato sulla funzione è questo a partire da lì quando alfa è uguale a 0,05 le cose procedono in questo modo vedete che l'algoritmo ha questo passo di aggiornamento e quindi al punto successivo si ritroverà su questo punto della funzione quindi troverà quest'altro punto poi questo che è evidenziato in giallo quest'altro in giallo questo arancione e questo rosso dopo quindi uno due tre quattro cinque iterazioni ci ritroveremo partendo da qui in questo punto e troveremo questo valore come quello che noi pensiamo sia un minimo della funzione vedete siamo ancora un po' lontani quindi l'abbiamo approssimata con un certo livello di errore se andassimo a vedere quello che è il plot della della funzione di costo troveremo un andamento di questo tipo per cui alla prima iterazione abbiamo un valore che è inferiore a otto poi abbiamo questo poi abbiamo questo poi abbiamo questo e ci ritroviamo alla fine con un valore che è a questo livello va bene? allora siamo lontani da da quello che è il minimo proviamo lontani insomma poi dipende però sicuramente possiamo fare di meglio e qui il problema qual era? era che utilizzare un learning rate un po' troppo piccolo in cinque iterazioni non ci ha permesso di arrivare a convergenza e allora con lo stesso numero di iterazioni se vogliamo arrivare più vicini al minimo dobbiamo aumentare il tasso di apprendimento aumentare il learning rate e portarlo a 0.2 significa partendo dallo stesso punto e questo quindi questo punto sulla curva significa andare verso quest'altro poi verso questo verso questo e vedete che l'history plot vi dice che andiamo a un livello decisamente più basso e arriviamo praticamente a convergenza verso il minimo atteso minimo che chiaramente non conosciamo poi nella realtà perché se no non avremmo bisogno di mettere in piedi tutto questo ma in questo caso è un esperimento controllato che ci permette di andare a verificare la bontà dell'approccio va bene? adesso andiamo a vedere cosa succede nella terza colonna quindi gli ultimi due grafici quando andiamo invece a prendere un valore pari ad esempio a 1.2 quindi un valore un po' più elevato quindi abbiamo un valore troppo basso un valore che vedremo è troppo grande e questo è il valore diciamo giusto allora un valore un po' troppo grande in questo caso che cosa ci produce? allora vi faccio notare anzitutto che la scala è diversa è qui quindi partiamo sempre dallo stesso punto che è questo che è un punto che vale un po' meno di di meno 3 ok? che era questo qua cosa succede partendo da questo punto? a questo punto siamo in un punto di discesa della funzione quindi la pendenza è una pendenza negativa quindi l'algoritmo ci dice che ci dobbiamo spostare verso destra giusto? spostarsi verso destra di quanto? ma di un valore che ha la pendenza della funzione di questo punto moltiplicato per alfa e questo determina fa sì che il nuovo punto sia questo che corrisponde a questo valore della funzione in questo punto il valore della funzione in questo punto è un punto che ha una pendenza positiva quindi questo fa sì che noi per trovare il punto successivo dobbiamo tornare indietro di quanto torniamo indietro? di una quantità che è la pendenza della funzione in quel punto moltiplicata per 1.2 ora il risultato è tale che io determini il nuovo punto come questo cioè devo tornare indietro fino a qua che corrisponde sulla funzione a questo punto giallo qui di nuovo pendenza della retta tangente negativa sempre tra l'altro una pendenza che comincia ad aumentare proprio perché la derivata prima di x quadro o di w quadro diciamo meglio è w significa che man mano che mi sposto dall'origine la pendenza aumenta e mi porta ad andare verso destra mi dice vai verso destra e vai qui qui di nuovo faccio questo gioco di rimbalzare indietro ma rimbalzo sempre di più perché vado verso quest'altro punto e poi verso quest'altro punto l'effetto netto insomma l'avete capito qual è in questo caso è quello di risalire anziché scendere il profilo della funzione e anziché andare a minimizzare vedete che noi stiamo risalendo si vede bene dal plot della storia delle varie iterazioni al passo 5 sono già arrivato oltre 160 questo significa che insomma il valore di alfa è un valore cruciale chiaramente da tenere presente quando si effettuano queste minimizzazioni e per cui è un iperparametro che va tenuto d'occhio per cui quello che si fa tipicamente si va a vedere il plot della funzione di costo del processo di minimizzazione e chiaramente in questo modo ci accorgiamo subito se c'è qualcosa che non va perché se cresce troppo se cresce già puntiamo in qualche modo la nostra attenzione se vediamo che comincia a crescere indefinitamente c'è qualcosa che chiaramente non va ho detto se indefinitamente o troppo perché ci possono essere dei casi in cui per qualche iterazione magari cresce e poi riscende qui dipende dal tipo di funzioni che andiamo ad ottimizzare l'oscillazione non necessariamente è un fattore negativo può essere contemplata l'importante è che mediamente all'aumentare il numero di iterazioni poi si vada con la funzione con la funzione di costo a scendere via via a dei livelli più bassi ma non è dita che da un'iterazione all'altra debba essere un comportamento monotonicamente decrescente va bene domande su questo? no è tutto chiaro benissimo allora andiamo avanti e vediamo cosa succede in questa slide un altro esempio particolare di algoritmo che viene messo alla prova qui la funzione come potete forse immaginare è una funzione che è una funzione valore assoluto quindi semplicemente il valore assoluto di w il valore assoluto di w è una funzione fatta esattamente così cioè sono due semirette che poi si incontrano nel punto nell'origine degli assi e qui diciamo vengono fatti due run a sinistra abbiamo l'esempio di un run che viene fatto con alfa pari a 0,5 a destra abbiamo un run che viene fatto con alfa pari a 1 su k quindi la regola di diminuzione del passo di apprendimento man mano che andiamo avanti con le iterazioni e partendo in ambo i casi da un punto che è questo che è 2 diciamo in realtà un po' meno di 2 e questo è il punto iniziale che è lo stesso per tutti e due i casi quindi partiamo in ambo i casi da questo valore questo valore ci porta sulla funzione ad avere questo valore segnato con la croce allora nel caso di step length quindi di passo fisso il passo successivo ci porta in discesa verso questo punto poi verso questo poi verso questo e qui che cosa succede? che di nuovo ho un altro passo verso sinistra vedete sono tutti regolari perché sono tutti regolari? perché alfa è fisso alfa viene moltiplicato per il valore della derivata prima della funzione in quel punto e quindi ho un passo fisso di discesa passo fisso di discesa che è dettato appunto dalla pendenza della curva che in questo caso è unitaria quindi è 1 quindi esattamente 0.5 il valore di quanto ci muoviamo quello che succede è quando siamo arrivati qui che ovviamente devo andare di nuovo di 0.5 verso sinistra e trovo questo valore della funzione che è esattamente speculare a quest'altro risultato netto è che nel momento in cui sono qui che cosa succede? che l'algoritmo di discesa del gradiente mi dice ok vai verso destra ma vai verso destra della stessa quantità di cui prima eravamo scesi e quindi ritrovo esattamente questo stesso punto e di nuovo questo l'algoritmo mi dice di andare verso lì quindi comincio a rimbalzare da sinistra a destra rimanendo fisso a questo livello un comportamento di questo genere può essere evitato se utilizziamo in questo caso un valore di alfa pari a 1 su k o questo si vede bene scusate prima di vedere cosa succede con 1 su k lo vedete nel plot nel grafico della funzione di costo durante l'esecuzione dell'algoritmo che è la curva in nero quando arriviamo qui vedete rimane costante poi indefinitamente se invece utilizzassimo un valore di alfa pari a 1 su k quello che otterremmo è un comportamento di questo tipo partiamo sempre dallo stesso valore chiaramente vedete lo vedete da qui della funzione che è 1,75 direi che è anche il punto di partenza da cui partiamo 1,75 essendo la funzione ovviamente la funzione valore assoluto dopodiché facciamo un primo passo poi ne facciamo uno un po' più piccolo un po' più piccolo un po' più piccolo e in questo caso la funzione comincia a fare cose di questo genere piano piano si avvicina vedete ha delle piccole oscillazioni per cui può essere che in realtà risaliamo lievemente nell'andare da una parte all'altra da una sponda all'altra di questa funzione di costo ma alla fine ci avviciniamo ci avviciniamo a un valore che è prossimo allo zero in maniera molto più fine di quanto non riusciamo a fare con il passo costante e quindi in questo caso è una regola che paga anche qui come sceglierlo e beh dipende un po' se uno ha una buona conoscenza di quella che è il profilo della funzione di costo può fare questi ragionamenti non sempre questo è possibile quindi diciamo lì si fanno un po' di tentativi si va a vedere sperimentalmente che cosa succede qui in questo caso essendo chiaro che la derivata della funzione è o più uno oppure meno uno seconda che w sia maggiore o minore di zero ho un problema con lo step length scusatemi il learning sì o equivalentemente il learning rate fisso va bene allora adesso vi faccio vedere un'altra slide sempre di l'algoritmo di come opera l'algoritmo di discesa del gradiente mettiamo all'opera al lavoro in cui evidenziamo come non necessariamente ma già qui un po' si poteva vedere perché vedete qui un passaggio da un punto all'altro la funzione in realtà può risalire ma qui si vede molto meglio è un esempio estremamente particolare quindi se vogliamo un esempio che potremmo anche definire patologico in cui in realtà c'è un'oscillazione cioè generalmente l'algoritmo di discesa del gradiente porta una buona convergenza che non è strettamente monotona ma diciamo ci si avvicina in questo caso ci sono delle oscillazioni molto particolari vedremo ma sono legate al tipo di funzione che è stata scelta ad hoc per evidenziare il comportamento però è comunque un qualcosa che può essere utile andare a ad evidenziare a vedere e riscrivo qual è questa funzione una funzione una funzione di due variabili che può essere scritto in questo modo W1 più W2 ambedue al quadrato più due volte il seno di 1.5 che moltiplica 1.1 più W2 più 2 ok è un esempio come dicevo molto molto particolare è un esempio in cui il minimo locale abbiamo ad esempio un minimo locale a 1.5 1.5 che è questo minimo locale qui abbiamo la funzione graficata con le curve di livello questo è un minimo locale questo che vi ho evidenziato in arancione e poi abbiamo un minimo globale che gli evidenzio ad esempio in un altro colore lo facciamo in fuchsia ok e sulla sinistra abbiamo qui abbiamo tre grafici tre esempi che corrispondono ad altrettante curve sono degli esempi in cui l'esecuzione dell'algoritmo viene fatta con rispettivamente valore di alfa pari a 10 alla meno 2 valore di alfa pari a 10 alla meno 1 e un valore di alfa pari a 10 alla 2 quindi pari a 1 allora analizziamo cosa succede con il learning rate più piccolo e sotto in corrispondenza avete le tre curve il learning rate più piccolo è quello che corrisponde al primo run quindi la curva nera è quella di alfa pari a 10 alla meno 2 poi abbiamo la curva fuchsia che è il run con alfa intermedio pari a 10 alla meno 1 e poi abbiamo la curva azzurra color ciano che è alfa pari a 1 allora vedete che in questo caso cosa succede ma il primo run quello rappresentato dalla curva nera è un run in cui evidentemente e lo si vede bene qui siamo con un learning rate eccessivamente piccolo è un learning rate questo che non non ci porta a muoverci molto lungo il profilo della funzione di costo lo si vede bene perché questi punti sono molto molto ravvicinati e questo lo si vede bene perché nella funzione di costo nel plot nell'history plot della minimizzazione della funzione di costo vedete che questa curva è praticamente piatta se cominciamo ad aumentare questo learning rate abbiamo questa situazione qui e in questo caso in pochi passi andiamo a finire siamo piuttosto sfortunati perché andiamo poi dipende sicuramente ci muoviamo meglio rispetto al caso precedente però andiamo a pescare questo minimo locale questo è un problema degli algoritmi di ottimizzazione locale potenzialmente può capitare corrisponde a questa curva color fucsia e qui chiaramente rimaniamo nel minimo locale e lì quello sarà il valore che riusciamo a trovare se volessimo identificare il minimo globale con un po' di fortuna provando il valore di alfa pari a 1 riusciremo a trovare qualcosa abbastanza particolare ripeto dettato da questo comportamento che è un po' un po' un po' pazzerello perché partiamo sempre dallo stesso punto che in realtà è qui ok e poi ci ritorneremo sopra qui perché noi da questo punto andiamo qua poi da qui andiamo qua poi rimbalza indietro e poi va verso i punti arancione e così via fino ad arrivare alla fine qua questo significa che il profilo della curva è tale per cui in certi punti risaliamo addirittura qui all'iterazione 6 risaliamo molto perché torniamo indietro verso qua quindi addirittura abbiamo un valore superiore da quello da cui siamo partiti ma poi da lì prendiamo riusciamo a trovare la strada corretta per arrivare addirittura al minimo globale è un caso ripeto molto molto particolare però è giusto per farvi capire che non necessariamente un comportamento della funzione di costo dell'history plot durante il processo di minimizzazione un comportamento che non è monotonicamente crescente quindi magari può oscillare non necessariamente è sempre negativo spesso può esserlo diciamo quello che conta è vedere su un certo numero di iterazioni quindi abbiamo preso una decina che cosa succede e tendenzialmente ci deve essere ovviamente una tendenza a scendere però ripeto tendenzialmente bene adesso ci poniamo la domanda e qui siamo arrivati a un punto diciamo in cui possiamo cominciare a tirare alcune fila del discorso prima di andare a riassumere alcune caratteristiche ed evidenziare pro e contro di questo algoritmo di scesa del gradiente però prima di arrivare in quell'intorno è bene su fermarsi un attimo su in qualche cosa che fino adesso abbiamo lasciato un po' così sotto traccia ed è il criterio di convergenza cioè i criteri di convergenza servono a dirci che cosa trattandosi di un algoritmo iterativo dobbiamo decidere quando fermarlo altrimenti andiamo avanti in maniera indefinita e quando ci possiamo fermare beh diciamo sono più modi in cui possiamo affrontare questo problema possiamo decidere di fermarci ed è molto ragionevole se il passo da k-1 a k non conduce in generale a un miglioramento significativo ok questo lo possiamo vedere in più modi fondamentalmente questo che cosa significa un miglioramento significativo nella funzione di costo vuol dire che wk rispetto a wk-1 non si sposta più di tanto e conseguentemente anche g di wk non è molto diverso da g di wk-1 questo quando può avvenire? beh questo avviene essenzialmente quando il gradiente della funzione wk comincia ad essere un vettore composto da quasi tutto il zero vuol dire che ci siamo avvicinati a un punto stazionario quindi quando il gradiente scomincia a svanire si dice significa che siamo vicino a un punto stazionario ok possiamo controllare il vettore gradiente oppure e questo di fatto lo possiamo fare andando a prendere che cosa la sua ampiezza del vettore gradiente che è rappresentata dalla norma di questo vettore quindi nel punto wk wk meno 1 e se questo è minore di una di una di una soglia prefissata che possiamo chiamare y ci fermiamo possiamo anche andare a vedere la differenza tra wk e wk meno 1 se mi sposto di poco da un'iterazione all'altra nel vettore che mi definisce le mie variabili indipendenti beh allora sono abbastanza sicuro che non ho fatto tanti progressi quindi posso prendere la norma di questo vettore differenza la posso normalizzare rispetto al numero alla dimensione dei vettori e anche questo di nuovo se è inferiore a un certo valore prefissato che definisco a priori mi fermo la stessa cosa la posso fare anziché ragionare sulla variabile indipendente sulla funzione il valore che prende la funzione se mi accorgo che la funzione di costo passando dall'iterazione k-1 all'iterazione k è inferiore a una certa soglia di tolleranza eventualmente moltiplicata per 1 su n dove vi ricordo n è la dimensione del del mio problema quindi il numero di coordinate che abbiamo a quel punto non decido di non proseguire potrei anche costruire delle variazioni sul tema dire se questa cosa accade per un certo numero di iterazioni se sono al di sotto di quella soglia per 5 iterazioni mi fermo e così via e quelli sono tutti altri capite bene che epsilon questo valore del numero di iterazioni sono tutti altri iperparametri che io introduco e quindi che di nuovo vanno in qualche modo tenuti presente perché possono modificare il comportamento dell'algoritmo di ottimizzazione dico questo perché poi nella pratica vedremo lo vedremo anche nell'esercitazione in laboratorio sono tutti aspetti che vanno ben considerati perché cambiano poi il comportamento dell'ottimizzazione e quindi del sistema che poi noi andiamo a ottenere nel modello di machine learning finale allora oltre a questo abbiamo anche un punto di vista pratico che dobbiamo tenere presente nel senso che se io comunque non raggiungo mai una condizione di questo tipo devo comunque imporre un numero massimo di iterazioni dopo le quali mi fermo un numero massimo di iterazioni che può dipendere appunto da quello che è la tipologia della funzione in generale dal valore di alfa perché abbiamo visto se il valore di alfa è molto piccolo avanzo molto poco nel processo di convergenza ma in generale dipende anche dalle risorse computazionali che abbiamo a disposizione e se io ho poche risorse computazionali significa tempo di elaborazione più limitato capacità più limitate quindi diciamo fissato il tempo di elaborazione avrò un avanzamento minore viceversa allora cosa succede se ho piccoli valori di alfa lo abbiamo detto questi valori di alfa troppo piccoli possono condurre a un progresso verso la convergenza troppo basso valori di alfa grandi viceversa possono condurre a quei fenomeni di rimbalzo intorno a posizione di minimo che anche quelli vorremmo evitare e tutto questo fa sì che appunto il tentare magari più valori qualche volta possa essere l'unica soluzione che abbiamo a disposizione e di nuovo anche qui tenere presente le risorse computazionali perché chiaramente sono quelle che ci vincolano di nuovo io se ho delle risorse computazionali quelle sono fisse avrò che posso fare un certo numero di prove in un certo unità di tempo quindi o aumento il tempo a disposizione o fissando il tempo devo fare meno prove allora fino adesso abbiamo descritto l'algoritmo di discesa degli gradienti delle sue caratteristiche diciamo che tra queste possiamo evidenziare come punti a favore il fatto che il gradiente negativo rappresenta matematicamente una direzione di discesa effettiva e questo significa che noi abbiamo di fatto un modo di calcolare in maniera agevole anche grazie appunto a dei software che permettono di costruire data la funzione in maniera efficiente scusatemi il valore del gradiente della funzione in ogni punto e poi magari nelle prossime lezioni vi farò vedere qualche esempio sicuramente utilizzeremo implicitamente questo nelle funzioni di libreria che utilizzeremo a laboratorio ma insomma magari ci torneremo sopra anche su come effettivamente possibili esempi di come questi sistemi calcolano il gradiente comunque per il momento prendete per buono il fatto che può essere fatto per via algoritmica in maniera efficiente quindi diciamo si fa in maniera efficiente anche scalando a valori di n della dimensione molto grandi ed è matematicamente un vettore che ci definisce una direzione di discesa e questo è molto buono perché rispetto ai metodi del primo ordine che avevamo visto in cui o dovevamo andare a caso e avevamo problemi della dimensionalità oppure cercavamo di scendere lungo le coordinate ma dovevamo fare quei percorsi a zigzaghi in cerca di direzione di discesa opportune il vettore gradiente ci dice immediatamente dove dobbiamo puntare e questo è un aspetto sicuramente positivo assieme al fatto che è facile calcolarlo con quel facile intendiamo da un punto di vista computazionale economico più che facile economico da un punto di vista computazionale se volessimo invece questi sono invece fino a questo punto sono i punti a favore se volessimo evidenziare dei punti critici beh ce ne sono due fondamentalmente che sono quelli riportati poi in questa slide e derivano dal fatto che il gradiente è un vettore quindi come tale è caratterizzato da una direzione e da un'ampiezza da una magnitudo e in funzione del tipo di funzione da minimizzare la direzione di questo gradiente negativo può oscillare l'abbiamo visto può oscillare in maniera molto rapida secondo il tipo di funzione che c'è e questo porta a una convergenza che può essere può essere lenta adesso poi c'è un esempio che vedremo grafico in cui questo lo cerchiamo di capirlo meglio tutto questo viene portato è noto diciamo in letteratura come comportamento a zig zag e questo eccessivo questa eccessiva oscillazione può condurre appunto a una convergenza più lenta nel caso di certe funzioni che per esempio hanno diciamo dei profili come se fossero immaginate in tre dimensioni insomma una sorta di canyon con delle valli quindi particolarmente strette e con il fondo valle piatto questo è l'esempio della figura che vedremo nella slide successiva questo significa avere delle linee di livello che sono parallele in certi punti e questo vedremo che facilita il fatto che ci possa avere questo comportamento a zig zag per cui passiamo da una parte all'altra di questo canyon rimbalziamo tra le pareti di questo canyon senza andare molto avanti verso il minimo l'altro problema è che l'ampiezza quindi questo è un problema legato alla direzione questo dello zig zag poi c'è un problema legato all'ampiezza l'ampiezza del gradiente per sua stessa natura ovviamente matematica di questo oggetto tende a diventare zero vicino ai punti stazionari l'abbiamo visto prima quando abbiamo parlato della convergenza possiamo andare a vedere si verifica che cosa che le le varie entri del vettore diventano vicino allo zero quasi tutte rapidamente e quindi in alcuni punti questo questo gradiente ovviamente vicino ai punti stazionari diventa nullo è così perché così deve essere il problema è che nel momento in cui diventa nullo può rallentare in alcuni casi il progresso verso nell'andare verso questi punti cioè quello che viene chiamato slow crawling cioè un avvicinamento lento ecco crawling non è proprio avvicinare ma diciamo è un verbo che dà l'idea di come si si avanzi in qualche modo verso verso l'obiettivo e questo è un problema che in qualche modo ci può creare del delle inefficienze con certe tipologie di funzioni perché se ci sono delle zone in cui il gradiente si annulla e non sono dei minimi e lì rimaniamo piantati con il nostro processo di minimizzazione queste sono le due potenziali i due punti critici di di questo algoritmo che però sono stati nel corso degli anni anche devo dire il caso di di di di notarlo di annotarlo qui a margine sono state risolte di fatto perlomeno parzialmente nel senso che sono stati costruiti delle variazioni dell'algoritmo che non avremo modo di vedere in ambito di questo corso ma che è bene tenere presente che permettono di appunto di risolvere sia il primo problema che è quello legato alla direzione quindi al comportamento zigzag che il secondo che è quello legato all'ampiezza che è il comportamento appunto cosiddetto di slow crawling quindi del crawling lento dell'avvicinamento lento giusto per darvi un'idea di che cosa allora poi vi dico anche i nomi dei due algoritmi che anche lì famiglie di algoritmi che permettono di risolvere di risolvere questo tipo di problematiche però prima di farvi questo vi voglio semplicemente perché poi ci permette di comprendere meglio il fenomeno per esempio dello zigzag vi voglio far focalizzare voglio vorrei focalizzare la vostra attenzione su quello che è questa che è una proprietà matematica che può essere dimostrata quindi un teorema di fatto formalmente che qui è rappresentato poi graficamente diciamo ne andiamo a verificare ovviamente la correttezza che ripeto è stabilita da un teorema in questi tre esempi che non costituiscono ovviamente una dimostrazione ma sono semplicemente una riprova del fatto che il teorema è chiaramente corretto il teorema è una proprietà del vettore gradiente e dice semplicemente che la direzione di discesa o di ascesa il gradiente di ogni funzione differenziabile in tutti i suoi input è sempre perpendicolare alla curva di livello definita da questa equazione g di w uguale g di w zero cioè fissato un valore w zero in cui un input in cui la funzione è differenziabile è definito come g di w zero il valore che prende la funzione in quel punto il gradiente se g è differenziabile in w zero è sempre ortogonale alle curve di livello e qui si vede bene in questa funzione a sinistra che è una funzione adesso vi dico quale ovviamente questa è una funzione quadratica si vede bene perché anche qui abbiamo quella una sorta di no rappresentatela in tre dimensioni come una scodella come una tazza che andiamo poi a tagliare a vari livelli con dei piani otteniamo queste curve di livello e la funzione è di w w1 al quadrato più w2 al quadrato più 2 va bene qui vedete che abbiamo preso la funzione in tre punti diversi che sono evidenziati questi cerchi verde fucsia e arancione e sono evidenziate anche le curve di livello con lo stesso colore che passano per quei punti vedete che sono dei cerchi concentrici perché abbiamo una struttura della funzione tale che lungo questo cerchio io ho sempre lo stesso valore della funzione che ho in questo punto verde lungo questo cerchio fucsia ho sempre lo stesso valore della funzione che abbiamo in questo punto fucsia e lungo questo cerchio rosso io ho sempre lo stesso valore della funzione che ho in questo punto rosso quelli che sono disegnati sono dei vettori che identificano chiaramente delle direzioni che vedete puntano verso il centro che è il minimo sono quindi i vettori negativi gradiente negativo dalla parte opposta avrei il gradiente positivo quindi direzione di massima ascesa mentre queste che sono disegnate sono di massima discesa e come potete notare sono esattamente perpendicolari ortogonali alle curve di livello in quel punto questo non è una coincidenza ripeto è un fatto che deriva da questa proprietà matematica che è dimostrabile ovviamente non ci interessa farlo forse lo avrete anche fatto in qualche in qualche corso di matematica del triennio la stessa cosa è valida per altri due punti che riguardano altre due funzioni invece che sono quelle che adesso magari vado a scrivere per completezza ma che diciamo rappresentano graficamente la stessa proprietà la prima è una funzione così strutturata è quella che peraltro abbiamo incrociato anche prima e la terza funzione che vi vado a scrivere qua me la scrivo anzi qua sotto perché non ci sta ok ok allora vedete sono funzioni che hanno dei profili chiaramente diversi delle linee diverse però quello che rimane è vero è che se voi evidenziate quelle che sono le curve di livello vedete questa in rosso vuol dire che qui questa funzione g lungo tutti questi punti ha sempre lo stesso valore ebbene se noi ci muoviamo lungo un profilo di questo genere andiamo a considerare questo punto che ripeto ha lo stesso valore sulla funzione di quest'altro e tracciamo la direzione il vettore gradiente ebbene questa è una direzione che è perpendicolare alla curva di livello in questo punto stessa cosa accade per quest'altra curva di livello o per questa e analogamente abbiamo questo per questi tre punti vi faccio notare come ognuno di questi peraltro punti verso in direzioni che sono quelle per esempio di questi di questi minimi locali o globali possono essere comunque dei minimi della funzione bene io direi che con questo oggi ci fermiamo qui poi la prossima volta ripartiamo da qui che sarà la lezione di giovedì perché vedremo come un esempio di come appunto questo le caratteristiche dell'algoritmo di scesa del gradiente compreso il fatto ecco le comprenderemo meglio proprio per questa proprietà che il gradiente è sempre ortogonale le linee di livello possono condurre a comportamento a zig zag e quindi concluderemo con un esempio grafico anche di un esempio che vi fa toccare con mano un po' quel tipo di comportamento che prima vi ho descritto ma che magari cerchiamo anche di chiarire meglio con questo esempio però ecco per oggi direi che se non ci sono domande possiamo possiamo fermarci qui va bene? allora intanto fermo la registrazione grazie a tutti grazie a tutti