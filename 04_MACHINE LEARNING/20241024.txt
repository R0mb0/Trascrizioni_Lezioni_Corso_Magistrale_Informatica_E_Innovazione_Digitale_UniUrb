buongiorno bentornati le lezioni di machine learning oggi proseguiamo con lo studio del dei classificatori binari lineari vi ricordo le ultime cose di ultima come l'ultimo argomento che abbiamo visto la scorsa settimana scusatemi la scorsa l'ultima lezione quella precedente la lezione di esercitazione di laboratorio abbiamo introdotto la regressione logistica come un modello che effettua prende spunto diciamo come ispirazione dalla regressione lineare per poi costruire un classificatore facendo passare attraverso una funzione di trasferimento non lineare il risultato della regressione effettuando il tuning dei parametri a valle di questo di questa di questa operazione tramite l'introduzione diciamo abbiamo visto che questo il tuning dei parametri può essere fatto ad esempio con una funzione di costo minimi quadrati ma abbiamo visto che ha diverse problematiche perché oltre ad essere non convessa presenta diverse zone in cui il il profilo della funzione di costo è piatto abbiamo altresì visto che presenta svariate discontinuità e quindi abbiamo introdotto un una funzione di costo estremamente allora diciamo in realtà prima ancora siamo partiti proprio il primo esempio che abbiamo visto era quello in cui avevamo non la funzione di costo minimi quadrati ma avevamo proprio la funzione a scalino e lì avevamo molte zone piatte e molte discontinuità introducendo la funzione di costo minimi quadrati che è quella nel mezzo abbiamo visto che le zone piatte si conservano ma smussiamo ovviamente le discontinuità quindi diciamo è in qualche modo minimizzabile tramite discesa del gradiente normalizzato poi però abbiamo introdotto la funzione di costo cross entropi che ha diverse buone proprietà su tutte quella di essere una funzione di costo convessa e quindi minimizzabile con non solo convessa ma anche differenziabile infinite volte ed è quella che viene di fatto utilizzata perché proprio ci permette di andare a minimizzare con metodi di ordine 0 1 2 quindi di scegliere tra queste diverse alternative e quindi qualunque tecnica di ottimizzazione locale può essere utilizzata per minimizzare questa che è appunto la la funzione di costo di tipo cross centropi che era quella a cui appunto eravamo giunti nel corso dell'ultima lezione e quindi la funzione di costo che è il risultato dell'introduzione di una funzione di costo puntuale abbiamo detto ciò che riguarda il singolo punto che viene chiamata log error e vi ricordo che diciamo va a distinguere il caso in cui l'esempio su cui stiamo lavorando su cui stiamo facendo l'addestramento si è etichettato con il valore 1 oppure 0 e cerca di penalizzare chiaramente degli errori che vengono commessi su questo esempio questa penalizzazione è una penalizzazione che ci permette di concludere appunto con il fatto che questa funzione di costo è tra l'altro in grado di appunto di evidenziare delle deviazioni da quelle che sono il comportamento voluto quindi quando noi sbagliamo quando il nostro modello è tale da sbagliare la classificazione in maniera più marcata rispetto alla funzione di costo i minimi quadrati e questo era appunto quello che è il grafico che avevamo visto la volta scorsa questa è la funzione di costo cross-entropy come l'avevamo poi scritta in un'unica formula sfruttando il fatto che appunto yp valeva o 0 oppure 1 e infine questo l'abbiamo visto il profilo appunto un esempio della conversità di questa funzione e questo è un esempio dello stesso insieme di dati su cui andiamo a fare un algoritmo di discesa del gradiente standard inizializzato nel punto con coordinate 3 3 quindi le due coordinate valgono ambe 2 3 e a sinistra e a rosso quella che è evidenziata è il fit la curva risultante sigmoidale che dà luogo al fit appunto di quei punti come se fosse questo è come se vedessimo di nuovo come regressione il problema il problema non è un problema di regressione chiaramente possiamo utilizzare poi questa curva per mettere una soglia e dire tutti i valori sopra 0 5 vengono assegnati all'etichetta 1 tutti i valori sotto a 0 5 vengono assegnati all'etichetta 0 sognerebbe diciamo una volta che il modello è già allenato già completo sì esattamente chiaramente allora qui vedremo parleremo adesso vedremo alcune slide dedicate a una variazione sul tema cioè che parte dalla domanda cosa succede se le etichette non valgono più 1 e 0 ma ad esempio più 1 e meno 1 chiaramente questo è un qualcosa che è un caso di studio che ci servirà più per introdurre alcuni concetti che per risolvere un problema reale perché capite bene che nel momento in cui noi andiamo a risolvere un problema di classificazione binaria il fatto che assegniamo delle etichette numeriche 0 1 o più 1 o meno 1 è arbitrario nel senso che io posso sempre risolvere il problema con delle etichette poi riandare a mappare questo anche in delle etichette che possono essere categoriche se ripensiamo al primo esempio da cui siamo partiti la distinzione in un'immagine tra un cane e un gatto e lì è ovvio che è del tutto arbitrario associare al cane l'etichetta 1 oppure l'etichetta 0 oppure l'etichetta meno 1 e viceversa farlo per il gatto quindi dire più 1 o meno 1 quello che ci possiamo aspettare che alla fine non cambi la sostanza del discorso effettivamente è così però ci è utile in realtà perché ci è utile introdurre un po' di notazione perché qualche volta fa comodo da un punto di vista per esempio della matematica introdurre alcuni alcune etichette dal punto di vista numerico sono diverse rispetto ad altre quindi lavorare con il più 1 e meno 1 ci permette di sviluppare magari alcuni strumenti e comunque ci dà la scusa tra virgolette di introdurre alcune notazioni che poi ci possono essere utili nel nel seguito quindi per esempio per il percetrone e l'SVM ma la sostanza come vedremo del discorso non cambia cioè arriveremo anche a costruire una regressione logistica con etichette più 1 e meno 1 che ha lo stesso comportamento ai fini pratici di quella che abbiamo introdotto con etichette 1 e 0 va bene? allora qui abbiamo lo stesso problema da cui siamo partiti quando abbiamo iniziato a parlare della regressione logistica in cui abbiamo dei punti distribuiti secondo questo scalino lo vedete qui in questa figura in alto a sinistra solo che questa volta lo scalino anziché essere 0 1 è meno 1 1 ok non cambia non cambia nulla allo stesso modo se vedo questa è la vista di regressione se guardo la vista che abbiamo chiamato di percetrone poi adesso cominciamo a parlare del percetrone tra poco si chiarirà meglio il perché si chiama così qui da sopra vedete che la distinzione vi ricordo viene fatta a livello grafico colorando questi punti secondo etichette diverse quindi avremo i punti meno 1 e i punti più 1 e questo è il punto che separa in caso è un singolo punto le due classi quindi un confine decisionale di un punto se vado in due dimensioni ho uno scalino chiaramente tridimensionale che è qui che avviene la transizione che appunto separa i punti con etichetta meno 1 dai punti con etichetta più 1 se guardo alla vista dall'alto quindi la cosiddetta vista di percetrone il confine decisionale il separatore è una retta quindi diciamo non cambia nulla rispetto alla situazione di cui siamo partiti quello che cambia è l'etichetta sono meno 1 e più 1 uno potrebbe dire ok riassocio 0 e 1 risolvo e poi nel momento in cui ho tutti gli 0 gli 0 li vado a mappare in meno 1 è perfettamente legittimo dal punto di vista logico lavorare così ma domandiamoci un attimo cosa succede andiamo a vedere se la matematica ci dice qualcosa di leggermente diverso ce lo dice ci permette di introdurre qualche notazione che ripeto poi ci portiamo magari avanti anche per qualche altro concetto quindi ci fa comodo dare questa formulazione algebrica che di anticipo è come c'è scritto qui equivalente alla funzione alla cross entro quindi è di fatto una un costo di cross entropi però con etichette anziché 0 1 più e meno 1 nel in alcuni test in particolare in uno dei due libri diciamo che vi ho indicato come libro di testo viene chiamata costo soft max secondo me questo allora ve lo segnalo perché poi anche nelle slide viene chiamato soft max però vi metto in guardia fin d'ora rispetto a questo questo nome perché può essere fonte di confusione perché nell'ambito delle reti neurali in particolar modo ma vedremo anche prima o comunque laddove noi anche anche nell'ambito della classificazione lineare con più classi con soft max si indica un'operazione diversa da questa quindi con lo stesso nome ci sono due cose diverse vedremo che c'è una soft max che viene e di solito nel nella prassi comune con soft max ci si riferisce a quell'altro tipo di operazione che è un'operazione di vedremo di normalizzazione degli output ok in questo caso viene chiamata soft max per motivi che adesso poi vi cercherò di dire anche questo tipo di di concetto che è di fatto una funzione di costo cross entropi quando le etichette sono meno uno e più uno questo fonte spesso di confusione perché chiaramente indichiamo con lo stesso nome concetti diversi però ecco vi ve lo segnalo quindi vi metto in guardia quindi è sempre bene specificare se ci riferiamo al soft max come normalizzazione dell'output o al soft max come funzione di costo di un classificatore lineare ok? cosa succede? Allora questa formulazione algebrica è quella che corrisponde a di nuovo il problema di ricavare un classificatore lineare a partire da una di fatto da una regressione quindi noi prendiamo i nostri punti li facciamo passare attraverso un regressore lineare e poi di là vi ricordo quando abbiamo costruito la regressione logistica da cui siamo partiti c'era la funzione gradino 0 e 1 giusto? In questo caso non c'è la funzione gradino 0 e 1 ma c'è una funzione segno la funzione segno di x restituisce più 1 se x è maggiore o uguale di 0 meno 1 se x è minore di 0 faccio notare che qui attribuiamo il maggiore o uguale di nuovo quando x è uguale di nuovo siamo nel punto di transizione per cui non sappiamo decidere e assegniamo arbitrariamente a una delle due classi il valore siamo sul confine decisionale confine decisionale è per definizione quel luogo di punti in cui non abbiamo un particolare motivo di dire un'etichetta piuttosto che un'altra è una decisione del tutto arbitraria quindi il confine decisionale è costituito da tutti i punti x per cui x trasposto per vw è uguale a 0 di nuovo il segno di x trasposto vw è esattamente il valore che noi vogliamo ci restituisca quella funzione ok? il nostro classificatore quindi se il segno di xp trasposto vw è uguale a yp allora il punto è stato classificato correttamente ok? allora di nuovo come nel caso precedente se io andassi a costruire una funzione di costo ai minimi quadrati su questo direttamente utilizzando la funzione segno di nuovo come di là avevo la funzione a gradino anche la funzione segno implica il fatto che abbiamo ampie zone estremamente piatte e di nuovo quello che si fa è di là cosa abbiamo fatto abbiamo rimpiazzato la funzione a gradino con un'approssimazione cosiddetta liscia dicono i matematici che era la funzione sigmoidale qui si fa un'operazione simile si rimpiazza la funzione a gradino con una sua approssimazione che è appunto la funzione tangente iperbolica ok? che è una versione scalata della sigmoide quindi stiamo ripercorrendo esattamente la stessa catena di ragionamenti che abbiamo fatto che ci ha portato a nel caso della regressione logistica a costruire poi la funzione di costo cross-centro prima prima a ragionare intorno a questa abbiamo detto c'era la funzione a gradino potevamo costruire una funzione di costo ai minimi quadrati questa aveva determinate proprietà che non ci piacevano ma prima ancora eravamo partiti dalla funzione a gradino 1 oppure 0 ok? però abbiamo rinunciato alla funzione a gradino poi per la funzione sigmoidale va bene? ok qui facciamo la stessa cosa anziché della funzione a gradino abbiamo la funzione segno potremmo costruirci la funzione di costo ai minimi quadrati di nuovo avremo una funzione di costo con ampie zone piatte quindi diciamo un po' di difficoltà di minimizzazione di nuovo introdurre un'approssimazione di questa funzione con questa che vedete è la funzione tangente iperbolica che di fatto anch'essa è una sigmoide però è una sigmoide che diciamo comprime tutti prende i valori del dominio dei numeri reali e li comprime tra meno 1 e più 1 li va tutti a distribuire con una transizione nel punto 0 in cui vale esattamente un mezzo cioè il punto 0 è il punto in cui io questa è la definizione di tangente iperbolica cioè due volte sigma di 2x meno 1 se andate a prendere la definizione di sigma di x che è la funzione sigmoidale che abbiamo introdotto nella lezione scorsa quindi è 1 diviso 1 più e alla meno x e andate a sostituire in questa equazione ottenete esattamente questa quindi ricordo che come l'abbiamo introdotta la funzione sigmoidale è questa ok? 1 diviso 1 più e alla meno x forse la scriviamo qua meglio così la tenete per che ce l'avete sott'occhio sigma di x vi ricordo la teniamo qua se andate a sostituire questa qui dentro vi ritrovate questo risultato qui vedete quello che vi dicevo cioè se sostituite x è 0 avete e alla 0 che fa 1 1 meno 1 fa 0 sotto avete chiaramente un denominatore che è diverso dal 0 perché è 2 quindi il risultato è 0 quindi il punto 0 vale 0 mentre prima valeva 0.5 e invece man mano che vi allontanate dallo 0 rapidamente andate verso l'1 o verso il meno 1 avete questa transizione che ovviamente può essere resa più o meno rapida ripida scusatemi anche più o meno rapida introducendo eventualmente un opportuno parametro questo non ci interessa più di tanto nella versione nella versione base che stiamo con cui stiamo lavorando lavoriamo con la tangente iperbolica anche se poi la tangente iperbolica in realtà prenderà un argomento che è il risultato di x trasposto per il vettore w dei pesi quindi è un qualcosa di cui teneremo in cuore però direi che questo è quello che intanto ci serve tenere presente ovviamente in analogia torno un attimo indietro quello che volevo dire è che in analogia a quanto abbiamo fatto per la regressione logistica con i minimi quadrati quella diciamo con etichette 0 1 anche in questo caso possiamo costruire una funzione di costa minimi quadrati che avrebbe una struttura di questo genere avrebbe 1 fratto p grande per la sommatoria di p piccolo che va da 1 a p grande dello scarto tra che cosa? tra la tangente iperbolica di x p trasposto per v doppio e yp lo scarto è uno scarto quadratico e questa è la funzione di costo ls list square semplicemente cosa cambia rispetto alla funzione di costo list square per la regressione logistica 0 1 che abbiamo sostituito al posto della sigmoide la tangente iperbolica peraltro è una versione scalata della sigmoide nulla di più questa funzione è di nuovo una funzione non convessa che ha diverse zone diciamo in cui la funzione stessa è totalmente piatta quindi il gradiente è nullo quindi dobbiamo utilizzare dobbiamo utilizzare il versione del gradiente tipo gradiente dell'algoritmo di discesa del gradiente tipo gradiente normalizzato per tenere conto di questo e adesso facciamo anche però quell'ulteriore passo in avanti che abbiamo fatto quando abbiamo introdotto la funzione cross-entropi cioè andremo a introdurre questa funzione che è l'equivalente diciamo della cross-entropi ma quando andiamo a tenere conto del fatto che le etichette sono meno 1 e più 1 è quella che viene chiamata appunto vi dicevo prima anche softmax che è una formulazione equivalente della regressione logistica quando le etichette sono più 1 e meno 1 e adesso proveremo a derivare anche questa anche qui procediamo perfettamente in analogia andando a quanto abbiamo fatto andando a definire una funzione di costo puntuale cioè pointwise cioè ragioniamo sul singolo punto e diciamo bene l'altra caratteristica ve l'ho detto è non convessa e vedremo che questo insomma conduce quello che andremo a fare a una formulazione convessa esattamente come era quello che andiamo a fare è introdurre appunto questa funzione di costo puntuale che ha questa struttura anche in questo caso andiamo a sfruttare il fatto che sappiamo che l'etichetta è più 1 oppure meno 1 cambiano soltanto i due casi esattamente cambiano soltanto i due casi perché ha esattamente la stessa struttura e quindi è la stessa funzione di costo ma è una funzione di costo che ci va bene perché di nuovo se yp vale 1 vedete che quello che diventa è meno logaritmo di sigma se yp vale meno 1 diventa meno logaritmo di 1 meno sigma dove l'argomento è sempre x trasposto v doppio questo significa che cosa? che se io, se il mio modello mi porta in una zona per cui il vettore dei pesi rispetto a questo punto che è un punto che io so avere etichetta 1 è tale che vado a finire in una zona alta della sigmoide ok? quindi il valore di sigma è vicino a 1 e in realtà è questo perché questa è la funzione di costo che andiamo a costruire cioè la funzione di costo è la stessa non è tangente iperbolica non c'è motivo perché in realtà se tu vai a prendere questa è una funzione di costo che risponde perfettamente alle esigenze che ci siamo dati cioè d'altra parte la tangente iperbolica è una versione scalata adesso provo a spiegartelo meglio cioè il punto da cui parti è questo tu sai che allora sigma di x è circa uguale a 0 laddove quindi se e solo se la tangente iperbolica è circa uguale a meno 1 l'altra cosa che sai è che metto qui sigma di x è circa uguale a 1 se e solo se la tangente iperbolica è circa 1 giusto? allora questo significa che c'è una corrispondenza tra sigma e la tangente iperbolica esatto oltretutto c'hai anche se ci aggiungi che 1 meno sigma di x uguale sigma di meno x e questo ti porta a un qualcosa in cui qui potresti andare a sostituire nel posto della tangente iperbolica semplicemente sigma nella funzione di costo puntuale e avresti esattamente la stessa struttura cioè laddove ti basta vedere laddove sigma è 0 la tangente iperbolica sai che è meno 1 laddove sigma e scusatemi qui non l'ho scritto è 1 la tangente iperbolica è 1 quindi possiamo andare a utilizzare semplicemente sigma come come funzione di costo cioè noi andiamo a vedere dove sigma è 0 noi andiamo se y era 1 e sigma ti restituisce un qualcosa di prossimo allo 0 allora vuol dire che la tangente iperbolica è circa meno 1 e quindi stiamo sbagliando e allora dobbiamo penalizzare viceversa quando yp è meno 1 e infatti qui ci andiamo a mettere vedi 1 meno sigma cioè da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da da le nostre esigenze perché ti dice che se tu hai etichetta più 1 se il tuo sigma è circa 1 esattamente e se il tuo sigma è circa 1 e l'etichetta era 1 vuol dire che siccome il tuo sigma è circa 1 la tangente iperbolica è circa 1 quindi vuol dire che ti ha risposto correttamente il tuo il tuo modello perché ti ha portato nella parte alta della curva se invece yp era 1 e sigma è meno 1 allora qui penalizziamo ma se sigma è scusatemi sigma è circa uguale a 0 ma vuol dire che hai sbagliato ma se sigma è uguale a 0 vuol dire che la tangente iperbolica è meno 1 quindi hai sbagliato perché il tuo modello ti ha portato a sbagliare quindi tu vai a controllare solamente sigma da quel punto è del tutto equivalente perché abbiamo introdotto la tangente iperbolica l'abbiamo introdotta perché adesso arriviamo a una formulazione dimostriamo che è equivalente perché qualche volta diciamo fa comodo utilizzare questa formulazione perché vedrete che arriviamo in fondo a una formulazione che è molto compatta e matematicamente molto molto utilizzata adesso ci arriviamo ci arriviamo per gradi allora teniamo presente questo 1 meno sigma che può essere scritto anche come meno log di sigma di meno xp trasposto per w ok proprio perché vale questa ok 1 meno sigma è sigma di meno x quindi questo lo scrivo come meno log di sigma di meno x adesso direi che forse è il caso di mettere la lavagna così avviene allora quindi la nostra funzione di costo sì a lato pratico hai ragione perché abbiamo introdotto la tangente di perbole ma per far tornare un po' i conti ma di fatto alla fine non cioè non è diverso dall'avere dall'avere ho premesso che noi potremmo lavorare tranquillamente con 0-1 e poi riportare tutto più 1-1 però la matematica è un po' è un po' diversa e qualche volta la funzione di costo qui si arriva vedete che ci tornerà utile perché magari ci permette di scrivere alcune cose in maniera poi diretta quando andiamo avanti sugli altri argomenti allora gp la scriviamo così quindi abbiamo detto è meno log di sigma sempre dell'argomento xp trasposto per u doppio se yp è uguale a più 1 e meno log di meno sigma xp trasposto per u doppio xp yp uguale a meno allora adesso siccome yp infatti adesso non usiamo più di fatto il concetto di tangente iperbolica lì l'abbiamo introdotta solamente l'abbiamo dovuta introdurre perché se no più 1 e meno 1 non li otteniamo mai per esempio e comunque il nostro modello deve restituire o più 1 o meno 1 se non l'avessimo introdotta il nostro modello non restituiva più 1 e meno 1 se voglio se voglio usare per esempio la formulazione dei minimi quadrati se uso la funzione segno non ho bisogno di introdurre la tangente ma per i minimi quadrati per esempio appunto voglio quella e anche di qua sì qui in questo caso se rinuncio alla funzione di costo di fatto la tangente iperbolica non ci serve più però nel momento in cui sì hai ragione in questo caso in realtà se imposto la funzione è così quando ragioniamo su questa funzione di costo in realtà la tangente iperbolica è una scusa nella premessa quindi è solo nella funzione di costo ai minimi quadrati quindi da questo punto di vista è una considerazione corretta quella che andiamo avanti quindi chiarito questo possiamo andare avanti siccome yp vedete vale più o meno 1 io posso scrivere questa funzione di costo puntuale semplicemente con su un'unica riga come meno log log log di sigma di yp per xp trasposto per vd scalare ovviamente sotto quando dico per vd sono vettori intendo il prodotto scalare vedete che se yp è uguale a 1 sono nel primo caso se yp è uguale a meno 1 sono nel secondo caso e quindi questa è un'unica formulazione equivalente a questa ok qui adesso arriviamo a quella formulazione che vi dicevo che spesso volentieri viene utilizzata ed è che però sono d'accordo fa meno appunto della tangente iperbolica che però è necessaria se volessimo usare la funzione di costo ai minimi quadrati la introduciamo come come premessa a questo punto sfruttiamo il fatto che il logaritmo di x è uguale al logaritmo di scusate che meno logaritmo di x è uguale chiaramente al logaritmo di 1 fratto opla scusatemi sono tantato ecco quindi è uguale lo riscrivo qua mettiamo il fatto che meno log x uguale log di 1 su x e quindi possiamo scrivere la nostra funzione di costo puntuale gp di w come log di... allora qui siccome questa meno log di tutto questo è uguale a log di 1 fratto sigma, ma 1 fratto sigma, vi ricordo che sigma è 1 diviso 1 più e alla meno x, quindi 1 fratto sigma è 1 più e alla meno l'argomento di sigma, quindi questo è log di 1 più e elevato a meno l'argomento della sigma che è y, scusatemi, per xp trasposto per w. Ok, e quindi la funzione di costo globale sarà nulla più che la media dei contributi su tutti i vari punti del mio dataset di addestramento di questa funzione di costo puntuale, quindi sarà la somma dei vari log error, 1 più e elevato alla meno yp per xp trasposto per w. Ok, questa è una formulazione diversa da un punto di vista matematico, da quella crossentropi a cui eravamo arrivati, ma è di fatto del tutto equivalente perché siamo partiti da questa cosa qua che è del tutto equivalente a crossentropi. Quindi, di nuovo, come correttamente avevi rilevato prima, la tangente iperbolica diventa una premessa che risulta indispensabile solo nel caso volessimo costruire una funzione di costo ai minimi quadrati. Per tutto il resto abbiamo ripercorso esattamente lo stesso percorso, è cambiata un po' la notazione matematica, siamo arrivati a questa che è la formulazione della funzione di costo regressione logistica quando le label, le etichette valgono più e meno 1. Ma da un punto di vista della sostanza è esattamente la stessa funzione di costo crossentropi. Questo significa che cosa? Beh, ha delle conseguenze da un punto di vista pratico. Cioè, la conseguenza principale è che la crossentropi e la funzione di costo, chiamiamola softmax, o comunque la funzione di costo della regressione logistica che abbiamo costruito per le etichette più e meno 1, sono costruite a partire dalla stessa funzione di costo e quindi sono di fatto equivalenti. Quindi questa, di nuovo, è una funzione che si può dimostrare essere sempre convessa, anche se, ripeto, algebricamente diversa dalla funzione di costo che abbiamo visto della crossentropi quando le etichette sono 0,1, ma la stessa proprietà è sempre convessa, quindi è, oltre ad essere sempre convessa, è differenziabile e dà anche la possibilità di essere ottimizzata con qualunque metodo di ottimizzazione locale. E questo, diciamo, è una conclusione abbastanza ovvia se consideriamo che alla fine le etichette sono abbastanza arbitrarie, ma non era così scontata e, diciamo, ci è utile poi, ecco, ci può tornare utile in qualche frangente perché quando parleremo del percettrone o dell'SVM ragioneremo anche lì con etichette che possono essere più o meno uno. Però le etichette in realtà possono essere arbitrarie, ecco, nel senso del discorso. E se torniamo alla presentazione, alle slide, ecco qui quello che abbiamo, che vi ho riportato, di capo la sintesi, cioè esattamente come nel caso della funzione di costo cross-entropy, la funzione di costo che abbiamo chiamato softmax, con tutte le attenzioni rispetto a questo nome che, ripeto, dobbiamo prestare, può essere dimostrata essere sempre convessa, e a parte il cambio di variabile, diciamo, meno uno con lo zero, sono di fatto totalmente equivalenti. L'altro motivo per cui si introduce la tangente iperbolica è anche perché poi è una funzione di costo che qualche volta viene utilizzata, è una funzione non lineare, non la sua funzione di costo, ma proprio la tangente iperbolica, è una funzione non lineare che viene utilizzata anche poi, per esempio, nelle reti neurali, quando parleremo delle non lineare fatte. Per cui, diciamo, ci fa comodo comunque definirla. Allora, qui abbiamo lo stesso esempio dello stesso numero di punti. La stessa distribuzione di punti, oltre che lo stesso numero, solamente che abbiamo visto sull'esempio della regressione logistica con la funzione di costo cross-entropy, quello che cambia è che questi punti sono distribuiti tra meno uno e uno, anziché zero uno, e abbiamo una minimizzazione della funzione di costo softmax, con un metodo standard di discesa del gradiente, inizializzato nei punti con coordinate 3, 3, qui, e qui c'è il percorso che arriva qua a minimizzare questa funzione di costo, questo è il profilo con le curve di contorno, le curve di livello, questo è il fit che otteniamo della curva sigmoidale, in realtà è un sigmoidale tra meno uno e più uno, quindi è di tipo tangente iperbolica, ecco, quello di nuovo ritroviamo, cioè di fatto il modello che troviamo poi alla fine è un modello tangente iperbolica, cioè indipendentemente dalla funzione di costo, io quello che vado a fare è introduco la tangente iperbolica di sigma, scusa, di w per t per x, che è questo, cioè io ho fatto il tuning dei miei pesi, ottengo il tuning dei miei pesi, è questo, e lì ritroviamo la tangente iperbolica, quindi anche nel caso in cui utilizzo la funzione di costo che abbiamo softmax, in realtà poi la tangente iperbolica ci torna utile, questo è un po' il succo del discorso, ok? e questo insomma vi fa semplicemente, vi rende conto ecco di questo, di questo fatto. ok, una cosa prima di andare avanti che, diciamo forse, non è chiara un po' dagli esempi che finora abbiamo fatto, è che, se io guardo ad esempio, questo è indipendente dalla regressione logistica, ma, diciamo, una cosa che potrebbe non essere finora chiara è che non sempre, allora qualche volta io ho una situazione di questo genere, come avevo anche per esempio qui, possiamo costruire quanti ne vogliamo di questi esempi, allora qui cosa vuol dire? perché chiaramente questi punti sono separabili da un, correttamente da una retta, quindi sono separabili linearmente si dice, è ovvio che non siamo necessariamente sempre in una condizione di questo genere, io potrei avere una condizione in cui ho un punto di questo tipo qua, un punto qua, perché magari il dataset è rumoroso, e allora qui non ho più una separabilità lineare, significa che cosa? Che non posso più applicare un modello lineare? No, il mio modello lineare, in questo caso sbaglierà, magari lo costruisco così, sbaglierà quei due punti, cioè attribuirà a questo punto, quello della classe, a questo punto che è il cerchietto, quello della classe delle croci, a questo punto, diciamo, x attribuirà la classe, qui supponiamo che questa sia classe 1, questa classe 0, qui a questo punto lo attribuisce come classe 1 sbagliando, e quest'altro punto lo attribuisce alla classe 0 sbagliando. può succedere, e ovviamente può succedere per mille motivi, uno può essere che sia effettivamente un modello adatto a quel tipo di dataset, cioè che la distribuzione dei punti sia tale da essere linearmente separabili, ma magari c'è del rumore di fondo, diverso è il caso in cui invece io ho una distribuzione di punti, che effettivamente è questa, qui magari ho torno ad altri punti, allora, per separarli correttamente, magari ho bisogno di un confine decisionale di questo tipo, allora lì vuol dire che il modello lineare fa più fatica, commette più errori, e non è forse il modello adatto, però questa è una premessa, perché man mano che andiamo avanti, vedremo altri modelli lineari adesso, alcuni tra l'altro si basano, anche ipotizzano, di che i dati siano linearmente separabili, però poi alla fine non è detta che arriviamo con dei dataset che sono linearmente separabili, ovviamente, se no sarebbe sufficiente fermarci con lo studio dei classificatori lineari. e questo, insomma, andava un attimo puntualizzato in questo, ah ecco, tra l'altro, diciamo, l'ho anticipato, non mi ricordavo che c'era anche questa slide, per cui diciamo che qui, vedete, c'è proprio un esempio che era quello che vi dicevo adesso, che era, questi punti, vengono, misclassified, cioè classificati in mano. Allora, qui c'è un riepilogo di quello che è la caratteristica appunto della regressione logistica, utilizzando questo costo che abbiamo chiamato softmax, di fatto si tratta di imparare, far imparare i pesi di un, al sistema di apprendimento, i pesi di un regressore non lineare, perché vi faccio notare che lì quella regressione lineare viene fatta passare attraverso la funzione tangente iperbolica. Allora non potrebbe dire, la funzione tangente iperbolica è non lineare, perché stiamo dicendo che quel classificatore è lineare? Perché quello che è lineare è il confine decisionale, cioè quel x trasposto, w uguale a zero, è il luogo dei punti in cui quel classificatore non sa che decisione prendere, e quello è una retta, un piano, un iperpiano. Ecco perché il classificatore è un classificatore lineare. Quello che iniziamo adesso è un altro concetto di classificatore, che prende un altro approccio, non più quello di partire dalla regressione, ma di partire proprio a classificare, a imparare, ad apprendere quel confine decisionale lineare direttamente, cioè senza passare attraverso questo regressore non lineare. Quello che vedremo è che, partendo da questo approccio, in realtà poi torniamo a una funzione di costo di tipo softmax, quindi anche lì, di fatto, spesso e volentieri, ritroviamo lo stesso confine decisionale, quindi sostanzialmente lo stesso classificatore. Ed ecco il motivo per cui anche abbiamo studiato la regressione logistica con etichette più o meno uno. E siamo arrivati a quella formazione di costo. Perché il percettrone, che è stato sviluppato storicamente, prima anche indipendentemente, per altri motivi, che poi è la base, anche se vogliamo, di alcune cose che vedremo più avanti, adesso non andiamo troppo avanti, è di fatto un modello lineare che ha lo stesso comportamento, in sostanza, della regressione logistica, partendo da un presupposto un po' diverso, che non è più quello di vedere il problema di classificazione come un problema in cui partiamo dalla regressione, ma direttamente partiamo da una situazione che è questa. Abbiamo il nostro spazio di input, in questo caso uno spazio bidimensionale, supponiamo arrivare a un problema in cui abbiamo due feature, abbiamo una serie di punti e vogliamo costruire questo confine decisionale, che è rappresentato in questo caso da questa retta, che divide lo spazio di input in due semispazie. Ora, la considerazione da cui partiamo è che il confine decisionale, di nuovo, è quello caratterizzato da questa qui, che è un'equazione di un piano, di un iperpiano, x trasposto per w uguale a 0, è la funzione, l'equazione caratteristica, di un iperpiano. La cosa che noi vogliamo è costruire questo confine decisionale che ci divide di fatto lo spazio di input in due semispazie. Da una parte avrò che qui sopra avrò che x trasposto w uguale a 0, da una parte avrò che x trasposto w è maggiore di 0, per esempio questi, di qua avrò x trasposto w minore di 0. Perché queste sono le tre opzioni che abbiamo. x trasposto w vi restituisce un numero. Quel numero può essere maggiore, minore o uguale a 0. Se è uguale a 0, state sul confine di decisione se è maggiore di 0 in un semispazio, se è minore di 0 nell'altro. E allora vediamo come arrivare a costruire direttamente questo tipo di classificatore senza passare dalla regressione, ma vedremo che poi alla fine le formulazioni sono equivalenti. per certi versi. Allora, associamo all'etichetta di una classe, scusate, ma i punti di una classe all'etichetta più 1 e i punti dell'altra classe all'etichetta meno 1. Quindi qui, diciamo, ci fa comodo lavorare con più e meno 1. Ok? Quindi quello che vogliamo trovare è un insieme di parametri w tale che x trasposto w è maggiore di 0 se quel punto ha etichetta più 1, mentre x trasposto w è minore di 0 se quel punto ha etichetta meno 1. Cioè noi vogliamo che il nostro classificatore, questo vedete, è proprio un modo diretto di andare a costruire questo classificatore. Noi diciamo, ok, abbiamo un insieme di punti w, andiamo a vedere questo prodotto scalare. Se è positivo vuol dire che siamo in una parte di quel semispazio, se è negativo in un'altra parte del semispazio. Queste due equazioni, tra l'altro, possono essere consolidate, condensate in un'unica condizione, che è questa, meno yp xp trasposto w minore di 0, perché se yp vale più 1 ho meno x per w minore di 0, cioè xp trasposto per w maggiore di 0, che è la prima condizione. Se yp vale meno 1 ho xp trasposto w minore di 0, che è la seconda condizione. Quindi siamo in questa condizione. Ok, noi vogliamo che il nostro classificatore soddisfi questa disuguaglianza e quindi a questo punto, di nuovo, che cosa facciamo? Una volta che abbiamo definito il modello, quello che facciamo è costruire una funzione di costo su quel modello. La funzione di costo deve rispecchiare che cosa? Il fatto che se l'etichetta è più 1, questa deve essere rispettata, se l'etichetta è meno 1, deve essere rispettata quest'altra, quindi di nuovo siamo in questa condizione. A questo punto, se io vado a costruire una cosa di questo tipo, se io vado a prendere il massimo tra due valori, che sono 0 da una parte e questo numero, che per noi deve essere sempre negativo, costruisco una funzione di costo che risponde alle mie esigenze. Perché? Perché se io sono abbastanza bravo da costruire il W, tale che questa sia sempre verificata, il massimo tra 0 e questo secondo argomento sarà sempre 0. Io ho sempre indovinato correttamente. Nel momento in cui io sbaglio, vuol dire che questa non è verificata per qualche punto, che cosa succede? Succede che poniamo che yp sia 1, ma in realtà xp trasposto w non sia maggiore di 0, ma minore di 0. Che cosa succede? xp trasposto per w è minore di 0, lo moltiplico per meno 1 e diventa positivo. e quindi il massimo tra 0 e un numero positivo è un numero positivo che io vado a prendere come penalizzazione. Penalizzazione che è guidata, peraltro, da tanto più ampia quanto più io sono lontano da quel confine decisionale. Cioè, se io sparo un numero molto alto, positivo, e qui me lo ritrovo tutto qui come penalizzazione, più mi avvicino al confine decisionale, più la penalizzazione sarà ridotta. nel momento in cui transito oltre il confine e ritorno a un valore negativo, in questa condizione, e allora vuol dire che la mia previsione era corretta. E di nuovo torno a pagare 0 nella mia funzione di costo. Stessa cosa se ribalto il più 1 con il meno 1. Questa è la logica dietro questa funzione di costo, che idealmente, ripeto, deve essere uguale a 0, ma non lo sarà, perché ovviamente io devo, nel processo di addestramento, non lo sarà per tutti i punti, idealmente lo deve essere alla fine, non necessariamente lo sarà, perché appunto il dataset può essere tale da non essere separabile linearmente, però questa è la condizione. Esattamente. e adesso ci arriviamo, proprio lì sotto. Intanto una cosa, prima di arrivare alla formulazione della pointwise, e quindi ripeto, questo uguale a 0 è solo nella condizione ideale. Scriviamo. Idealmente vogliamo che sia 0. Se il punto è classificato, è 0. esattamente. Allora, la forma funzionale, cioè, fondamentalmente la funzione di questo costo, cioè la forma funzionale max tra 0 e qualcos'altro, viene chiamata rectified linear unit, cioè unità lineare rettificata, e ve lo dico perché questo è un acronimo RELU, Rectified linear unit, si ritrova poi nelle rettine orali, perché è un'altra di quelle funzioni che utilizzano le rettine orali per le loro funzioni di attivazione non lineare, dove studieremo più avanti, però la ritroveremo, quindi è una forma funzionale che viene presente, anche se non è collegata appunto in quell'applicazione a questo che stiamo dicendo adesso. non lo è direttamente, diciamo bene così. Allora, questa RELU ha la caratteristica di essere sempre non negativa e restituisce 0 se il punto è classificato correttamente, lo abbiamo detto, mentre restituisce un valore positivo se è classificato non correttamente. Ed è tanto più positivo quanto più siamo lontani dal confine decisionale. Ok. Ovviamente quello che dobbiamo fare, cioè correttamente, già appunto l'avevate notato correttamente, e lo che facciamo è prendere la media di questi su tutti i punti del mio dataset. Quindi vado a iterare di nuovo su tutti i punti di piccolo che vanno da 1 fino a più grande e costruisco la mia funzione di costo. Grazie. Quindi l'obiettivo della funzione di costo è aggiustare quel vettore dei pesi in modo da minimizzare questa loss function, questa funzione di perdi. Quindi l'obiettivo del mio ottimizzatore sarà costruire, cercare quel vettore di pesi. Bene. Andiamo avanti. Questa funzione di gdv che abbiamo appena scritto è una funzione quindi questa che abbiamo appena scritto qui nella parte bassa di questa slide. vi dicevo viene chiamata fondamentalmente nota come ReLU qualche volta anche come funzione di costo a cerniera perché se voi andate a graficarla ha un andamento di questo tipo e il massimo tra 0 e x e il massimo tra 0 x quando x è negativo è 0 quando x è positivo è x e questa è esattamente la funzione il grafico di quella funzione di costo è insomma sembra una cerniera di uno sportello chiamata per questa cosa allora ha la caratteristica di essere sempre convessa però se guardate c'ha una sola derivata nel senso che di qua è 0 di qua una volta che avete fatto la derivata prima è costante e poi si annulla la derivata seconda quindi potete utilizzare solamente metodi di ottimizzazione di ordine 0 e 1 quelli di secondo ordine no perché la derivata seconda si annulla poi ha un'altra caratteristica oltretutto c'è anche qui una discontinuità quindi un pochino da diciamo da da da tenere d'occhio però è una funzione di costo che può essere gestita con i metodi del primo ordine ripeto non si applica a quelli del secondo l'altra caratteristica è che ha una soluzione banale che è una soluzione che non ci interessa che è quella di settare tutti i pesi uguali a 0 cioè un ottimo è quello w uguale a 0 perché se io setto w uguale a 0 chiaramente la funzione di costo è sempre nulla ma io voglio trovare un vettore dei pesi significativo quindi diverso da 0 quindi diciamo nel minimizzare quella funzione di costo dobbiamo stare attenti perché dobbiamo evitare la soluzione banale w uguale a 0 quindi dobbiamo trovare una soluzione che non sia quella allora per questo per tutti questi motivi quello che si fa ormai l'abbiamo capito diciamo per cominciare a evitare un po' di problemi quando abbiamo queste funzioni con gli spigoli perché fondamentalmente quello è che sono costanti a tratti quello che si fa è se cercano delle approssimazioni di quelle funzioni delle approssimazioni che siano sufficientemente lisce e che ci permettano di bypassare questi problemi ok allora per fare questo quello che si fa quindi sono problemi regati vogliamo tecnici legati proprio al processo di ottimizzazione cosa si fa? si rimpiazza questo massimo questa formulazione con il max di questo costo del del modello di percetrone con una variante che sia differenziabile almeno due volte che abbia dei requisiti sufficientemente lisce e gestibile ed è la funzione cosiddetta softmax anche questa non a caso viene chiamata softmax perché è un'approssimazione del massimo e si chiama softmax perché poi vedrete torneremo alla formulazione che abbiamo ricavato poco fa per la regressione logistica del motivo per cui quella viene chiamata anche softmax ma ripeto tutti questi softmax sono diversi e qui c'è un secondo significato della funzione softmax che è diverso da quello che vi dicevo troveremo poi più avanti quando parleremo degli output della normalizzazione degli output allora questa è un'approssimazione che viene definita in questo modo io ho un insieme di numeri s0 s1 fino a s con c meno 1 la funzione softmax di questi è semplicemente il log di e alla s0 più e alla s1 più e alla s c meno 1 e si può dimostrare che questa approssima il massimo tra questi insieme di numeri questo lo si vede bene quando diciamo abbiamo due argomenti che tra l'altro è quello che a noi interessa perché la nostra funzione relu ha esattamente due argomenti e si può vedere in questo modo se voi prendete c uguale a 2 e supponiamo senza perdita di generalità che sia s0 minore uguale di s1 questo significa che il massimo tra s0 e s1 è uguale a s1 ok a questo punto io quello che posso fare posso provare a scrivere il massimo tra s0 e s1 come s0 più s1 meno s0 ok il massimo s1 io posso scrivere questo ma questo lo posso scrivere come il logaritmo di e alla s0 più il logaritmo di e elevato alla s1 meno s0 giusto? il logaritmo di e alla qualcosa è qualcosa a questo punto vado a vedere la definizione della funzione soft soft di s0 virgola s1 che per definizione è log di e alla s0 più e alla s1 questo lo posso scrivere come log di e e alla s0 che moltiplica 1 più e alla s1 meno s0 giusto? raccolto e alla s0 e mi rimane 1 più e alla s1 meno s0 ma questo la sua volta lo posso scrivere come log di e alla s0 proprietà del prodotto logaritmo di un prodotto quindi è la somma dei logaritmi e quindi log di e alla s0 più log di quest'altro termine che è 1 più e alla s1 meno s0 ora andate a confrontare questo con questo e quello che potete concludere è che questo termine è sempre maggiore uguale di max s0 virgola s1 chiaramente perché qui il primo termine è uguale il secondo è il log di 1 più qualcosa che è lo stesso argomento logaritmo è una funzione crescente quindi se l'argomento è un argomento monotonicamente crescente che la funzione lo è e in particolare però quando e alla s1 meno s0 diventa molto maggiore di 1 sono la stessa cosa fondamentalmente quindi questo è sempre maggiore uguale ma diventa la stessa cosa rapidamente quindi questo è vero per due argomenti s0 e s1 si prendono il massimo tra più elementi e rimane lo stesso e questo si vede bene anche da ecco in questo modo riusciamo ad approssimare adesso si vede bene da una slide dove c'è la figura successiva ma quello che vi volevo dire è che il nome softmax prende proprio il nome da questo cioè dal fatto che noi approssimiamo questa funzione la funzione massimo con questa funzione che è un'approssimazione cosiddetta soft appunto del massimo una funzione un'approssimazione liscia e morbida in qualche modo soddisfatt canceled con domande andando avanti abbiamo quindi che possiamo introdurre nella nostra funzione di costo che vi ricordo prevedeva il massimo max tra zero e questo argomento ci mettiamo sotto la funzione softmax che abbiamo appena dimostrato che appunto approssima il massimo e quindi applichiamo la definizione di softmax che è log di e alla zero più e alla meno yp xp trasposto w ma e alla zero è pari a 1 quindi e log di 1 più e alla meno yp xp trasposto w guardate un attimo questa funzione di costo puntuale e andatela a confrontare con la funzione di costo puntuale che abbiamo ricavato pochi minuti fa per la regressione logistica nel caso in cui le etichette erano più 1 e meno 1 quello che ottenete che vi accorgete che è esattamente la stessa funzione di costo e non è un caso che quella appunto veniva chiamata formulazione softmax questa è ovviamente la media su tutti i punti e quindi otteniamo questa funzione di costo che è appunto la somma dei contributi dei vari punti quindi la somma dei log di 1 più e alla meno yp xp trasposto w questa è la funzione di costo di percettrone quindi se noi vogliamo costruire un percettrone un modello lineare di quel tipo quello che facciamo è semplicemente costruire questa funzione di costo andare a prendere il mio dataset andare a minimizzare questa funzione di costo a questo punto non ho più problemi di spigoli derivate che esistono solo fino all'ordine 1 eccetera di discontinuità è una funzione di costo che ha delle buone proprietà da questo punto di vista dell'ottimizzazione e arrivo con un vettore w che minimizza questa funzione di costo e che quindi mi permette di costruire un classificatore lineare e a quel punto vado a prendere i miei punti li moltiplico scalarmente per questo vettore dei pesi e se l'esito è positivo di questo prodotto scalare classe 1 esito negativo classe meno 1 con esito intendo il valore restituito qui abbiamo proprio un esempio di quella che è la funzione di costo che vi dicevo prima vedete in verde abbiamo la funzione relu quella cerniera che già vi avevo disegnato prima e quella tratteggiata è la softmax cioè se voi andate in funzione di s a graficare il log di 1 più e alla s ottenete questo cioè avete che il massimo scarto ce l'avete nei pressi dello 0 che però non è uno scarto grandissimo numericamente e man mano che vi allontanate dallo 0 positivo chiaramente cosa succede? che questo e alla s diventa rapidamente maggiore di 1 log di e alla s fa s quindi il massimo tra 0 e s è s se andate in negativo man mano che vi allontanate dal punto 0 questo numero diventa via via più piccolo e questo diventa il logaritmo di 1 che fa 0 che è la rappresentazione grafica di quella dimostrazione cina che vi ho fatto prima che questa funzione approssima il massimo in due argomenti diciamo quindi tracciamo un po' di vediamo un attimo di riepido allora questa funzione di costo che abbiamo appena visto è esattamente la funzione di costo che abbiamo chiamato softmax che abbiamo derivato poco fa all'inizio della lezione per la regressione l'approccio diciamo alla regressione logistica basato appunto per la classificazione binaria in cui avevamo appunto etichette più 1 e meno 1 quindi questa funzione di costo è convessa ha infinite infinitamente derivabile quindi possiamo usare anche il metodo di Newton per minimizzarla tra l'altro non ha la soluzione banale nulla che la minimizza quindi non abbiamo il problema di averci preoccupare di dire ok W uguale a 0 è il minimo quindi no però io voglio un qualcosa che sia minimo cioè il più possibile vicino al minimo ma diverso appunto dal minimo W uguale a 0 nella pratica appunto uno si potrebbe domandare che differenza c'è tra la regressione logistica e il percettrone ok quindi quando noi vediamo questa è una domanda ovviamente che viene e la risposta è che se voi applicate questo costo softmax al percettrone quindi se utilizzate il percettrone con questa funzione di costo non c'è differenza ovviamente è lo stesso approccio quindi per ragioni storiche nascono come approcci se vogliamo indipendenti poi cambiando la funzione di costo qualcosa cambia ma se voi usate la stessa funzione di costo è esattamente la stessa cosa e quindi all'atto pratico vi ritrovate con gli stessi risultati ok però diciamo il percettrone ha una sua importanza storica nasce prima se vogliamo perché sono i primi studi di intelligenza artificiale diciamo degli anni 50 proprio quelli in cui viene introdotto il percettrone e poi tra l'altro aveva un algoritmo di addestramento che non era di questi di cui vi ho parlato e all'inizio insomma addirittura se andate a vedere ci sono delle foto sui primi esperimenti con il percettrone in cui c'è una sorta di arpadietto con i collegamenti avevano fatto proprio una sorta di versione hardware di questo di questo questo algoritmo e all'inizio è stato anche parecchie è stato accolto con un'enfasi insomma anche nei media parlava già appunto all'epoca di uno strumento un dispositivo che era in grado di riprodurre certi aspetti dell'intelligenza umana perché riusciva e l'avevano collegato cercato di risolvere dei problemi elementari di computer vision eccetera poi in realtà qualche anno dopo negli anni 60 è stato dimostrato che questo modello di di machine learning in realtà non era in grado di risolvere problemi semplici in cui i dati non erano separabili linearmente e quindi lì si è capito che non ci si poteva fare tutto e questo è stato per molti l'inizio di una fase per esempio di decrescita di interesse in conto dell'intelligenza artificiale quindi tutti quelli che sono noti poi come diciamo l'alternarsi di inverni o primavere o estati insomma negli studi dell'intelligenza artificiale seguono questo tipo di di andamento e la regressione logistica poi diciamo viene sviluppata dopo queste due cose sono collegate cioè quando le funzioni di costo poi sono le stesse sono modelli equivalenti va bene oggigiorno diciamo si parla molto di regressione logistica per risolvere problemi di un certo tipo ed è dell'approccio che viene utilizzato fondamentalmente ma equivalente a quello dietro poi del del percettone con la funzione softmax quindi se voi prendete un regressore logistico è addestrato con la funzione di costo softmax ottenete gli stessi risultati che percettone ok allora qui adesso introduciamo poi andremo avanti la prossima volta un ulteriore tipo di modello quindi fino adesso abbiamo visto regressione logistica con varie funzioni di costo abbiamo visto il percettone anche qui con due funzioni di costo la la la la la softmax e adesso vediamo un terzo modello di classificatori sempre lineari questi sono tutti classificatori lineari e sono tutti classificatori lineari binari qui rispetto ecco mentre la regressione logistica percettone insomma al netto della variazione delle funzioni di costo stiamo girando intorno allo stesso concetto fondamentalmente, quindi la stessa tipologia di classificatore. Le SVM rappresentano una deviazione su questo percorso perché sono un concetto che falliva su altre, un modello che falliva su altri concetti, su altre premesse, che portano indietro altre conseguenze. E sono un modello di fatto molto estremamente popolare per la classificazione lineare. Anche la regressione logistica funziona bene, nonostante la sua semplicità, molto spesso viene consigliata come primo approccio. In prima battuta, se uno ha un dataset da classificare, vuole provare un qualcosa, il consiglio è provata la regressione logistica perché è facile, facile da addestrare, veloce, spesso da risultati buoni con uno sforzo tutto sommato. Poi vengono le SVM. Le SVM sono un po' più complicate da trattare, un po' più complicate e onerose da addestrare, ma sono di fatto, nell'ambito della classificazione lineare, molto popolari perché fino a qualche anno fa, pochi anni fa, erano lo stato dell'arte. Poi c'è stato un po' l'avvento delle reti neurali per tutta una serie di applicazioni, in qualche modo le hanno soppiantate, ma rimangono, ecco, non dobbiamo pensare che tutto sia risolvibile necessariamente con le reti neurali, non sono lo strumento che serve dovunque e comunque. C'è spazio anche per altri tipi di modelli, che sono per esempio modelli lineari, che possono essere l'SUM o la regressione logistica. Quindi diciamo, tutte queste cose che vediamo sono utili sia perché sono dei mattoni di conoscenza e servono poi per capire meglio quello che avviene in seguito, ma sono anche utili in sé a seconda dell'applicazione che uno va a, si trova davanti a dover, del problema che si trova davanti a dover risolvere, e l'applicazione poi conseguente che va a costruire. Allora, l'altra cosa per cui sono popolari le SWM è che in realtà possono essere modificate e usate anche per la classificazione non lineare. Non è banale, parlo, però questa è una cosa di cui dobbiamo essere consapevoli, tenerla presente. Non avremo modo di vederla questa cosa, ve ne farò forse vedere un esempio al volo quando facciamo un'esercitazione, ma non abbiamo tempo di affrontare anche questo. Però, diciamo, le SWM nascono come modello lineare, ma possono anche essere utilizzate per la classificazione non lineare, andando a modificarle, ecco, andando a modificare alcune cose. Allora, il concetto di base delle, questa SWM, che sta in inglese per Support Vector Machine, cioè macchine a vettore di supporto, poi si chiarirà meglio cosa sono questi vettori di supporto, hanno come concetto quello di separare gli esempi tramite un margine, un margine che deve essere il più possibile ampio. Allora, l'ipotesi da cui si parte è che il dataset che ha le etichette più 1 e meno 1, di nuovo torniamo alle etichette più 1 e meno 1 per comodità di rappresentazione matematica, algebrica. Il presupposto è che questo dataset sia perfettamente separabile da un punto di vista lineare. Ok? Questo è un esempio, ad esempio, nella figura, in cui abbiamo chiaramente un dataset separabile linearmente, vedete che quella retta ne separa, ne abbiamo infinito ovviamente di confini decisionali lineari che separano correttamente quell'insieme di punti. L'obiettivo dell'SWM è andare a cercare quello che corrisponde, vedremo, a un margine il più ampio possibile di separazione, dove il margine lo caratterizzeremo matematicamente in maniera opportuna. La cosa che intanto posso cominciare a dirvi è che in questa figura quello che possiamo rintracciare è sicuramente il confine decisionale che è sempre caratterizzato dalla nostra equazione di battiano x trasposto W uguale a 0. E poi se andate a vedere, questo confine decisionale che abbiamo tracciato definisce quella che viene chiamata una zona di basher, cioè questa fascia che poi corrisponde alla nozione di margine, che è quella che separa questo confine decisionale da una sua versione traslata che tocca il primo punto che incontra nel semipiano della classe più uno e di qua dall'altra parte abbiamo una controparte che è esattamente simmetrica che è la versione traslata verso il piano meno uno, quindi c'è un margine rispetto alla versione traslata del confine decisionale che è questa tratteggiata che passa sul primo punto che incontriamo della classe meno uno. L'obiettivo delle SVM è andare a fare in modo che questo margine sia il più ampio possibile, questa buffer zone sia la più ampia possibile. Perché? Perché più è ampia più io ho la possibilità di aver identificato un confine decisionale che è lontano dai punti e se è lontano dai punti minimizzo la possibilità che qualche punto venga correttamente classificato male, interpretato male, perché magari è un punto rumoroso. Adesso su queste sono tutte cose su cui torneremo. La prima cosa che vi faccio notare è che queste linee tratteggiate che corrispondono a quelle traslazioni del confine decisionale sono state identificate dall'equazione x trasposto w uguale a uno e x trasposto w uguale a meno. Allora, questo è ragionevole nel momento in cui noi diciamo che da una parte ci sono tutti i punti per cui x trasposto è maggiore di zero e dall'altra ci sono tutti i punti non so perché adesso non mi prende più dicevo, da questa parte sono tutti i punti in cui x trasposto w uguale a meno maggiore di zero e da quest'altra parte andiamo a mettere tutti i punti in cui x trasposto w uguale a meno ora ora qui questa retta è il luogo di punti in cui x trasposto w uguale a più uno lo potrebbe dire perché più uno in realtà potrei avere arbitrariamente un valore scusatemi voglio cambiare colore vediamo per esempio mi dicevo in realtà uno potrebbe dire un'equazione sempre di unitarziano qui andiamo a mettere un valore beta e quello che possiamo fare però è andare a questo punto a scalare da una parte x trasposto w uguale a beta dall'altra parte x trasposto w uguale a meno beta perché in generale può essere vero e potrei avere quindi tante versioni traslate del confine decisionale in cui beta vale uno ma può valere due può valere quello che vogliamo e quello che posso fare è un numero maggiore di zero beta quello che possiamo fare è semplicemente dire ok costruisco un nuovo vettore dei pesi w e pari a w diviso beta ok se faccio così questo significa che mi ritrovo a studiare un qualcosa di nuovo è un'equazione che mi descrive quelle due traslazioni come x trasposto w uguale a più o meno 1 questo per dirvi che noi ci concentreremo su questi ecco torniamo vi dicevo a una a una formulazione in cui ci concentriamo su queste forme x trasposto w uguale a più o meno 1 perché diciamo da un punto di vista della generalità siamo sicuri che possiamo ricondurci sempre a questo caso e l'obiettivo sarà identificare a questo punto un vettore dei pesi per cui vedrete andiamo a cercare che queste versioni traslate del confine decisionale siano tali da essere il più possibile spaziate tra di loro ok questo sarà l'obiettivo per arrivare a questo abbiamo una serie di di passaggi che faremo gradualmente il primo dei quali a introdurre il concetto di percettrone di margine o margin percettrone in inglese cosa vuol dire? vuol dire che introduciamo il percettrone in questo concetto in cui teniamo presente il margine allora da una parte di nuovo abbiamo la stessa figura di prima quindi abbiamo identificato il confine decisionale che è quello caratterizzato dall'equazione x trasposto vdo più uguale a 0 poi abbiamo una sua versione traslata che è x trasposto uguale a 1 e un'altra versione traslata che è x trasposto vdo più uguale a meno 1 abbiamo detto possiamo considerare più o meno 1 senza senza lidere in alcun modo la generalità del ragionamento quello che succede è che tutti i punti della classe più 1 stanno sul lato positivo di che cosa? di questo iperpiano x p trasposto uguale a più 1 giusto? stanno tutti di qua tutti i punti della classe meno 1 qui c'è un errore guarda questa stanno sul lato positivo di x trasposto vdo più uguale a meno 1 giusto? ok? quindi prendo questo iperpiano e vado dall'altro lato il che significa che x p trasposto vdo più sarà maggiore o uguale di 1 per i punti della classe 1 punti della classe rossa e sarà minore o uguale di meno 1 per i punti della classe blu sì giusto perché vado verso valori più negativi ok? sì dipende come definire giustamente se chiamiamo lato positivo quello in cui vado verso valori più positivi qui vado verso valori più negativi sì qui c'è un più 1 e negativo ok? incorreggetelo nella slide assolutamente corretto il concetto però è proprio questo cioè nel momento in cui x p trasposto è meno 1 sono qui se diventa meno 2 meno 3 meno 4 sono in questi altri punti e qui diventa 1 2 3 la città ok? quindi questo è il punto di partenza ok? quindi io vado in cerca a questo punto di un classificatore lineare che vedete questa è la formulazione di un percettrone siamo partiti da quello solo che la differenza con il percettrone è quale? che lì imponevamo che x p trasposto fosse maggiore di 0 se y valeva 1 e fosse minore di 0 se y valeva qui stiamo utilizzando lo stesso concetto di percettrone ma abbiamo introdotto il concetto di margine margine che c'è se questi sono separabili perfettamente c'è sempre un margine ok? perché c'è sempre questa zona di bassa quindi diciamo ripeto ve la metto qui questa confrontatela la riscrivo così almeno con la condizione confrontatela con x p trasporto w maggiore di 0 per y p uguale più 1 e x p trasposto per w scusate minore di 0 per y p uguale a meno 1 ok? che erano le condizioni che abbiamo derivato col percettrone vedete che sono del tutto hanno la stessa struttura del tutto analoge e a questo punto noi da qui possiamo condensare questa condizione in un'unica condizione che è questa y p per x p trasposto per w maggiore uguale di 0 perché se y p vale 1 ricado nella prima se y p vale meno 1 ricado esattamente nella seconda perché ho meno x p trasposto w maggiore uguale di 1 che significa x p trasposto w minore uguale di meno 1 quindi questa equivale grazie grazie grazie Di nuovo, qui le analogie sono abbastanza evidenti. Se noi andiamo avanti, abbiamo esattamente che queste due disuguaglianze possono essere combinate in una funzione di costo. Ok, questa è un'unica equazione, queste due disuguaglianze che sono equivalenti a quest'unica equazione possono essere combinate in questa singola funzione di costo. Cioè noi abbiamo, adesso l'ho scritta un po', vediamo se riesco a spostarla. No, niente, la cancello. Dovevo prima raggrupparla. Allora ve la riscrivo qua. All'altro, così la tenete presente. Allora qui abbiamo yp, x trasposto per u doppio maggiore o uguale di 1, che è equivalente a quelle due disuguaglianze. Allora, se io voglio costruire una funzione di costo a partire da queste due disuguaglianze, e in modo del tutto analogo a quello che abbiamo fatto per il percetrone, perché di fatto è una variazione del percetrone, posso costruire una funzione di costo pointwise, che è il massimo tra due valori, 0 e 1-yp xp trasposto w. Idealmente, Cioè nel caso di classificazione corretta, Noi vogliamo sempre che la loss function sia nulla. Allora, vediamo cosa succede se classifichiamo correttamente il punto. Se lo classifichiamo correttamente vuol dire che vale questa, no? Vuol dire che, speriamo che il punto sia più 1, vuol dire che x trasposto per w è un numero maggiore o uguale di 1. Ma allora 1-un numero maggiore di 1 ti dà un numero negativo e il massimo è 0. Pago 0 classificato correttamente. Analogamente se yp è meno 1, e io l'ho classificato correttamente, che cosa succede? Succede che yp è meno 1. Ho meno 1 per xp trasposto w maggiore o uguale di 1, quindi ho di nuovo un numero che è un numero negativo, perché xp trasposto w maggiore di 1 moltiplicato per meno 1 mi dà un numero che è più piccolo di 1, quindi 1 meno quello mi dà un numero negativo e il massimo di nuovo è 0. Viceversa, se la classificazione non è corretta, cosa vuol dire? Vuol dire che io ho un punto, ad esempio, yp uguale a 1, che non ho classificato correttamente. Non ho classificato correttamente vuol dire che io sono in una condizione in cui, torno indietro un attimo, non vale questa, ma vale che xp trasposto w è un numero più piccolo di meno 1. Ma se quello è un numero più piccolo di meno 1, scusate, torno qui, se quello è un numero più piccolo di meno 1, vuol dire che qui ho 1, yp vale 1, però xp trasposto w è un numero, per esempio, meno 2, quindi ho qualcosa che è più 2. E quindi è quello che vado a pagare, perché ho fatto una classificazione, il massimo tra 0 e quel numero positivo, è un qualcosa che io vado correttamente a dover imputare al fatto che la mia configurazione dei pesi non è corretta, quindi devo pagare un penalty, ok? Nella mia funzione di costo. Quindi, semplicemente, anche questa se la vado a confrontare con la funzione di costo puntuale del percettrone, che era gp di w, se andate indietro era il massimo, semplicemente, no? La funzione di costo relu, tra 0 e avevate meno, yp xp trasposto w, vedete che avete esattamente la stessa stessa, ok? Questa è esattamente quella che abbiamo visto qua. 0 meno yp xp trasposto w, e adesso l'abbiamo ritrovata. A questo punto la andiamo a mettere qui dentro, qui abbiamo semplicemente la media su tutti i punti, e di nuovo anche qui possiamo fare la stessa cosa che abbiamo fatto quando abbiamo costruito il percettrone col costo soft max, per cambiare l'operatore max con una sua versione, diciamo, più favorevole da un punto di vista dell'ottimizzazione, quindi la sua versione soft, e l'unica cosa che cambia è che qui avevamo, questo era per il percettrone, l'unica cosa che cambia è che nel percettrone, vi ricordo, arrivavamo al log di 1 più e elevato alla meno yp xp trasposto w, qui c'è un termine 1 davanti, e quindi questa è semplicemente, nel momento in cui faccio la media su tutti i punti, la funzione di costo che otteniamo, che è quella del percettrone di margine, ok, con questa funzione di costo soft max. Da qui ripartiamo la prossima volta, perché questo presupposto è quello che ci porta poi alla formulazione degli svm, va bene? Quindi fin qui quello che abbiamo fatto è semplicemente modificare il percettrone, in modo da tener conto del fatto che, se il dataset è separabile c'è un margine, e se c'è un margine io posso andare a tener conto di questo margine nella costruzione della funzione di costo. E qui c'è l'ambiente del margine che è fissa, invece abbiamo detto che la vogliamo il grande possibile. In realtà è fissa, una volta che ho fissato quel modello, ma se tu guardi la, cancello, torno indietro, se tu vai qui, questa figura, ad esempio. La distanza tra la retta sopra e la retta sopra. Sì, certo. Però in realtà è fissa qui, per questa confine decisionale, ma c'è anche per esempio questa retta che rappresenta un altro confine decisionale. Ok. Sì, però sarà sempre una, più una da quel confine decisionale che viene da me. Allora, sì, però in realtà è un più uno che dentro nasconde quel beta che è diverso. Cioè la matematica è quella, però ricordati che c'è il beta di mezzo, ok? E in realtà la distanza effettiva, adesso qui non l'ho fatto bene perché non è simmetrico, è questa distanza o questa e sarà diversa magari da questa e questa. Cioè noi tra gli infiniti piani vogliamo selezionare quello che ha il margine maggiore. Questo è l'obiettivo dell'SVM. Ok? Sì, ma più che questa targa è sempre esterita. No, quello è ovvio rimane sempre fisso. Però noi vogliamo identificare tra tutti gli infiniti piani quello che corrisponde al margine maggiore. Ok? Però adesso su questo ci torniamo la prossima volta. Adesso intanto per oggi direi che di cose ne abbiamo viste parecchie, quindi abbiamo di che meditare. La prossima volta ripartiamo e continuiamo a mettere insieme i pezzi poi arriviamo a questa formulazione. Poi ritorneremo su questo concetto di margine. Intanto per oggi direi che possiamo fermarci qua. Turchi bene.