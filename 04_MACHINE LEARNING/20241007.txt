Allora, bentornati. Questa settimana entreremo più nel vivo di quelli che sono gli algoritmi di ottimizzazione. In particolare, qui stavamo analizzando nell'ultima lezione l'algoritmo di ricerca casuale, che è un algoritmo che abbiamo detto ha più uno scopo di illustrare alcune caratteristiche di quelli che sono gli algoritmi di ottimizzazione locale, che è un effettivo utilizzo perché ha fondamentalmente, qui lo anticipiamo poi lo riprenderemo tra poco, soffre del problema della dimensionalità esattamente come le tecniche di ordine zero, gli algoritmi di ottimizzazione globale, scusate, di ordine zero, che abbiamo visto appunto quando abbiamo cominciato gli algoritmi di ottimizzazione, abbiamo visto che appunto quelli basati su campionamento casuale o uniforme soffrivano del problema della dimensionalità. Qui vedremo tra poco che siamo esattamente nella stessa situazione, però indipendentemente da questo ci offre la possibilità, lo spunto per poter approfondire alcuni, per poter introdurre alcuni concetti e approfondire alcune tecniche. Qui eravamo arrivati insomma a questo esempio di una funzione quadratica, era una funzione quadratica, ecco giusto, ero rimasto in debito di un paio di parametri che vi avevo detto a memoria, non avevo, non mi ricordavo e adesso giusto per dirvi che cosa erano questi, questi che sono degli iperparametri in realtà, come vi dicevo la volta scorsa, e semplicemente segnalo qui a margine, vi annoto scusate, qui a margine di che cosa si trattava, si trattava appunto di un utilizzo di questo algoritmo di random search con 5 iterazioni, e questo si poteva dedurre anche dal fatto che se andate a vedere qui sono esattamente 5, le iterazioni sono 6 punti, quindi sono 5 iterazioni che vi permettono di partire dal punto verde e arrivare al punto rosso, e con un valore di P grande pari a 1000, P vi ricordo è il numero di possibili direzioni casuali che andiamo a scegliere. Allora, qui eravamo arrivati insomma più o meno intorno a queste, da queste parti, avevamo detto anche che poiché, diciamo qui la visualizzazione è abbastanza comoda, sia sulla superficie che sul contour plot, chiaramente se fossimo a dimensione maggiore avremmo, saremmo nell'impossibilità di poter seguire, ovviamente l'andamento dell'algoritmo di minimizzazione, quindi quello che si fa è, tramite appunto la superficie o le curve di livello, quello che si fa è si visualizza invece l'andamento tramite quello che viene chiamato plot della storia della funzione di costo, della funzione di perdita, e questo è null'altro che un grafico che vi dice in funzione, per ogni iterazione, vedete ha sull'asse della scisse il passo cappesimo, sull'asse dell'ordinato il valore che prende la funzione di perdita, e per ogni iterazione vi dice qual è il valore della funzione di perdita, quindi vi dice se stiamo progressivamente andando a diminuire oppure no, la nostra funzione di costo, quindi quando arriviamo a un certo punto a convergenza, possiamo, ci accorgiamo che per esempio questa funzione comincia a diventare più piatta, e possiamo decidere se fermarci, eccetera. Benissimo, detto questo, qui eravamo arrivati la volta scorsa, e adesso andiamo avanti, andiamo avanti con, sempre parlando del random search, facendo un po' di considerazioni a margine, in particolare andando a vedere che cosa succede quando abbiamo una funzione non convessa. Ora, le funzioni non convesse hanno una precisa connotazione in matematica, poi magari anche qui a margine, in termini della lezione, la prossima volta quando c'è un po' di tempo vi do la definizione precisa, ma intuitivamente le funzioni convesse, se vi ricordate, in una variabile sono quelle funzioni che hanno una forma ben precisa, che è una forma, se vogliamo, a scodella, e quindi questo concetto che può essere steso anche a più variabili, può essere formalizzato in maniera precisa e rigorosa, adesso in questo momento non ci serve ancora, poi magari, ripeto, daremo anche la definizione formale, però intuitivamente, dando per scontato che ci sia appunto o una conoscenza pregressa o intuitivamente la forma convessa è una forma che tutti abbiamo ben presente, che cosa succede quando invece non abbiamo una funzione, come in questo caso, nell'esempio a sinistra, di una funzione che appunto è tutt'altro che convessa, perché ovviamente lo è solamente a tratti, quindi chiaramente è fatta di una serie di picchi e di valli che si alternano e qui cosa succede? Se mandiamo in esecuzione un algoritmo di minimizzazione di tipo locale, succede quello che ci aspettiamo, che appunto, essendo algoritmi di ottimizzazione che sono costruiti per cercare dei minimi locali e non globali, rischiamo di rimanere intrappolati in un minimo locale. Abbiamo detto che non necessariamente questo rappresenta sempre un problema, ma chiaramente può esserlo, nel senso che, se vediamo, come in questo caso, applichiamo random search a questa funzione, partendo da due punti diversi, che sono W0 pari a 4,5, che è questo punto qui, che è questo punto qua, e rispettivamente W0 pari a meno 1,5, che è quest'altro punto qui, succedono due cose chiaramente diverse, perché se vado, se parto da 4,5, e sono su questo punto verde qui, che adesso ho evidenziato in alzù, a cui corrisponde una valutazione della funzione che è identificata da questa crocetta verde sulla funzione, e quello che posso fare è dire da qui comincio a esplorare una serie, ad esempio, un migliaio di direzioni possibili, volendo, in realtà, qui, essendo una funzione di una variabile, le direzioni possibili sono solamente due, quindi un migliaio è assolutamente fuori luogo, non avrebbe senso, un migliaio, se fossimo nell'equivalente che era quello dell'esempio precedente, in cui eravamo già in due dimensioni, lì abbiamo già infinite possibilità in cui muoverci, poi questo lo vediamo, ci torniamo con una slide successivamente, quindi in questo caso semplicemente che cosa succede? Che vado a esplorare due possibili alternative e vedo subito che muovendomi verso sinistra e vado verso direzioni progressivamente di discesa della funzione, fino ad arrivare a questo punto che rappresenta evidentemente un minimo, un minimo, che però è un minimo locale, è locale, in questo intorno è un minimo, ma non è chiaramente il minimo della funzione che invece andrei a trovare se avessi una scelta più felice iniziale di W0, quindi per esempio, scusatemi, partendo da qui, questo è il punto iniziale, se io vado a scendere il profilo della funzione mi ritrovo qui e questo è il valore, questo è il U doppio che corrisponde a questo valore di minimizzazione e lì troverei anche il minimo globale, quindi la scelta chiaramente del punto iniziale rappresenta un punto cruciale per andare a esplorare porzioni diverse della funzione di perdita con gli algoritmi di ottimizzazione locale. In questo caso la funzione che è la sovrapposizione di un'onda sinusoidale, il seno di 3W, con un termine quadratico è una funzione di questo tipo. In questo caso, quindi, che cosa ci dice questo semplice esempio? Ci dice che ovviamente differenti inizializzazioni dell'algoritmo determinano differenti esiti e spesso può essere utile fare più run per cercare di confrontare poi l'esito di più run e vedere che cosa siamo arrivati a ottenere. Va bene? bene, allora, andiamo avanti, svolto questo esempio, ne vediamo un altro in cui torniamo alla nostra funzione invece convessa, questa è una funzione convessa, qui si vede bene dalla forma, ripeto chiaramente, è una funzione quadratica, tutte le funzioni quadratiche hanno la caratteristica di essere funzioni convesse e qui è interessante vedere invece che cosa all'opera, quello che è l'effetto del parametro che abbiamo chiamato tasso di apprendimento, cioè variando il passo con cui l'algoritmo si muove nelle sue iterazioni, otteniamo degli esiti diversi che sono qui evidenziati da queste da questi tre appunto esempi che corrispondono all'esecuzione dell'algoritmo di prima, l'unica cosa che cambia tra i tre run è il valore di alfa e quindi se per esempio noi partiamo da un valore di alfa che è un esempio uguale a 1 che ipotizziamo di partire da un valore di alfa pari a 1 quello che succede è che qui abbiamo di nuovo sulla destra le curve di livello quindi siamo in due dimensioni e invece qui sulla sinistra abbiamo la superficie e vedete partiamo da un punto che è un punto che è questo quindi è 1.52 come coordinate e la cosa la cosa interessante è mettere a confronto questi questi tre valori di alfa questi tre run con questi tre valori di alfa perché partendo appunto da questo punto adesso vi scrivo intanto di che funzione si tratta così almeno visto che non c'è scritto lo riprendiamo ma è sempre la nostra una funzione di tipo quadratico che dipende dai due parametri w1 e w2 e la possiamo scrivere come w1 al quadrato più w2 al quadrato più 2 partendo dal punto w0 che è questo vettore 1.52 trasposto allora per convenzione solitamente quantomeno all'interno di questo corso ma in generale spesso e volentieri i vettori nella loro nella loro forma nativa sono considerati vettori colonna quindi scrivendo così intendiamo chiaramente un vettore colonna perché risulta più comodo spesso anche nei libri anziché scrivere il vettore colonna si scrive questo chiaramente perché occupa una riga però insomma queste sono delle pure convenzioni è un vettore e cosa succede se partiamo appunto da questo vettore per esattamente esattamente solo la convenzione è che il vettore w0 dovrebbe essere un vettore colonna quindi se l'ho scritto così devo aumentare la trasposizione ok cosa succede se alfa uguale a 1 beh se alfa uguale a 1 vedete che partiamo e riusciamo ad andare progressivamente verso quello che è il fondo valle di questa superficie verso il minimo l'algoritmo di ricerca casuale con mille possibili alternative ad esempio identifica correttamente quella che è la direzione di discesa e per esempio appunto ci permette di arrivare qui ok partendo da qua andiamo verso il secondo punto poi andiamo verso il terzo punto e siamo qui e qui succede una cosa interessante perché vedete che se io mi muovo con quel passo il chiaramente la direzione successiva è sempre la stessa di di discesa e però il passo mi porta in questo punto evidenziato in rosso quel punto evidenziato in rosso è il punto verso il quale appunto mi porta questa direzione di discesa e e lì succede che cosa che io finisco di fatto dall'altra parte della della della conca della della valle quindi da lì quello che posso fare è semplicemente rimanere intrappolato lì perché lì ovviamente avrò una possibilità soltanto di andare in una direzione di discesa che mi riporta però esattamente dalla parte opposta e quindi comincio a rimbalzare avanti indietro quindi di fatto sono intrappolato a quel livello che è esattamente lo stesso che è esattamente lo stesso cioè io ho identificato la direzione ma il passo mi porta dalla parte opposta e quindi allo stesso livello e lì rimango incastrato per cui comincio a rimbalzare e non vado più da nessuna parte tra le mille alternative troviamo il tipo che è sempre lo stesso lo prendiamo proprio come accettato in questo caso sì arriverò a un certo punto in cui vedo che non riesco più a migliorare mi devo fermare tutto quello che posso fare è quello e questo è un caso che può effettivamente capitare e allora vediamo invece cosa succede se anziché scegliere un valore pari a alfa uguale a 1 andiamo nella terza riga scegliamo valore pari a 10 alla meno 2 10 alla meno 2 vedete che parto dallo stesso punto e poi effetto un certo numero di iterazioni però vedete che cosa succede qui che cosa si vede i punti sono tutti molto ravvicinati perché perché quell'alfa abbiamo detto che è regola di quanto io mi muovo di quanto io mi sposto ad ogni iterazione e qui mi sposto troppo poco evidentemente per cui la convergenza c'è ma è una convergenza estremamente lenta se invece avessimo scelto il valore di alfa pari a 0.1 vedrete che nella seconda riga quello che accade è che io vado avanti faccio un certo numero di punti e evito il problema che avevo di convergenza troppo lenta ma evito anche il problema che abbiamo incontrato nel primo caso quello di avere un passo troppo grande e rischiare di cominciare di rimanere appunto cominciare a rimbalzare e rimanere in una zona che non è corrispondente a quella del minimo effettivo è il minimo che invece riusciamo a centrare perfettamente in questo caso tutto questo per dire che cosa che effettivamente il valore del learning rate può rappresentare è un fattore critico nel processo di apprendimento del sistema e questo è vero anche per gli altri algoritmi che vedremo con i basati su tecniche del primo o del secondo ordine quindi quello che si fa è si pone attenzione a quale è il valore di questo iperparametro e si esplorano più possibili alternative tipicamente come vi dicevo la volta scorsa fare machine learning significa cimentarsi con una scienza altamente empirica anche c'è modo di ragionare anche su su quelli sono possono essere dei valori congrui pure no secondo il tipo di problema che si va ad affrontare c'è modo anche di automatizzare chiaramente tutto questo ma rimane il fatto che questo iperparametro è appunto un parametro a scelta del progettista e va in qualche modo esplorato con una certa con una certa cautela bene ciò detto direi che possiamo senz'altro andare avanti e a proposito appunto della scelta di questo parametro una cosa che vale la pena dire ovviamente è che assieme al numero delle iterazioni alfa governa che tipicamente vengono scelti insieme cioè si cerca un buon compromesso tra la necessità di arrivare a cercare il minimo e la complessità computazionale se io abbasso chiaramente il valore di alfa ho più possibilità di arrivarmi di approssimare in maniera corretta un minimo che sia anche un minimo locale ma chiaramente dovrò spendere più iterazioni e quindi anche qui diciamo dipende da quanto ho a disposizione in termini di budget computazionale se scelgo un valore di alfa più ampio rischio di essere più grossolano ma chiaramente vado a fare meno iterazioni e spesso vengono scelti come dicevo insieme però fino adesso quello che abbiamo dato per scontato è che la il passo con cui andiamo a effettuare la minimizzazione sia costante ma questo non è chiaramente nessuno può immaginare che sia l'unica alternativa probabilmente qualcuno di voi già avrà quantomeno si sarà posto la domanda se è possibile utilizzare un valore di alfa che ad esempio varia durante l'esecuzione e questo effettivamente è un qualcosa che si può fare molto spesso viene dato nella pratica anche per costante per comodità però ci sono anche delle opzioni valide alternative e una di quelle più utilizzate è appunto quella che viene chiamata appunto riportata qui e che viene chiamata la regola del passo che in maniera adattativa va a diminuire va a diminuire che cosa vuol dire vuol dire che anziché prendere un valore fisso di alfa per tutte le iterazioni questo valore viene progressivamente al crescere delle iterazioni fatto diminuire cioè il valore di alfa diventa via via più piccolo all'aumentare delle iterazioni e questo può essere fatto con una legge qualunque che ha una dipendenza in qualche modo inversa rispetto al numero delle iterazioni quella che più utilizzate che tipicamente viene adottata è quella che viene riportata qui in cui vedete il valore di alfa viene settato a 1 su k significa che al passo 1 ovviamente alfa viene scalato diciamo potrebbe essere scalato anche di un valore rispetto a un valore iniziale o semplicemente posto pari a 1 che è quello che tipicamente si fa vuol dire che al primo passo vale 1 poi un mezzo un terzo un quarto e così via questo significa che all'inizio noi procederemo con dei passi abbastanza ampi tra virgolette nel nostro processo di minimizzazione mentre nel momento in cui andiamo ad avere un certo numero di iterazioni già alle spalle questo passo viene chiaramente diminuito scalato e andiamo via via ad avvicinarci con un passo più fine che è perfettamente ragionevole perché man mano che ci avviciniamo all'obiettivo vogliamo evitare al minimo diciamo minimizzare il rischio di mancarlo quindi alla luce anche dell'esempio che abbiamo fatto nella slide precedente è una scelta del tutto ragionevole ed è una scelta del tutto ragionevole anche per un altro motivo che diciamo arriviamo a discutere tra poco ed è fondamentalmente nascosto qui dietro cioè se noi andiamo a fare il solito diciamo a calcolare come abbiamo fatto la volta scorsa quindi il solito applicare il solito trucco di andare a vedere che cosa succede se io vado a sottrarre a WK a WK-1 ottengo e prendere la norma di questo vettore quello che otteniamo è chiaramente l'ampiezza del passo che abbiamo percorso che è WK W scusatemi con indice K-1 più αd meno WK-1 e questo lo avevamo visto la volta scorsa che è pari ad α norma di D al quadrato scusate norma di D di tipo L2 e questo è uguale ad α e questo lo avevamo visto la volta scorsa la cosa interessante è che vediamo che se imponiamo una regola di tipo progressivo al valore che prende α questo ovviamente pari 1 su K e questo ci dice chiaramente intuitivamente che la distanza che andiamo a percorrere da un passo all'altro decresce man mano che ci avviciniamo e questo va bene lo abbiamo costruito esattamente per questo però quello che forse non è immediatamente chiaro è questo che se io vado a sommare tutti i contributi a tutti i vari passi quindi questo significa che con questa sommatoria per K che va K piccolo che va da 1 fino a K grande cioè è la somma delle distanze che siamo andati a percorrere con il nostro algoritmo di minimizzazione lungo il nostro percorso questa sarà chiaramente la somma di questi vettori della norma di questi vettori che è pari a 1 su K ebbene questo è interessante perché questa è di fatto una serie che in matematica è nota che è la serie armonica la serie armonica ha la caratteristica di essere divergente all'infinito questo significa che cosa che noi man mano che andiamo avanti con il numero di iterazioni facciamo dei passi sempre più piccoli però man mano che andiamo avanti continuiamo a percorrere una distanza che potenzialmente è infinita quindi significa che nonostante andiamo a fare dei passi sempre più grandi riusciamo a percorrere esattamente riusciamo a percorrere una distanza che potenzialmente è sempre più grande questo è un aspetto abbastanza interessante di cui tenere conto per cui questo meccanismo ci permette comunque di esplorare in maniera estremamente efficace quello che è il profilo della nostra funzione va bene? ok benissimo allora qui andiamo ecco invece a fare un po' di considerazioni che riguardano quello che dicevo prima che vi anticipavo prima cioè esattamente come nel caso dell'ottimizzazione globale quindi le tecniche di ordine zero per l'ottimizzazione globale che abbiamo visto soffrono del problema della dimensionalità anche la ricerca casuale come intesa ricerca casuale applicata all'ottimizzazione locale soffre dello stesso problema questo si vede bene già facendo questo confronto nel passaggio da una funzione di una variabile che è quella che avete chiaramente riportata qui a una funzione di due variabili funzioni di una variabile se noi siamo in questo punto x uguale a 1 o w uguale a 1 e quindi siamo in questo punto sulla funzione abbiamo solo due possibili alternative tra cui muoverci una ci porta in salita e una ci porta in discesa quindi gettando un dado abbiamo esattamente il 50% di possibilità di probabilità di pescare una direzione di discesa questo è una prospettiva che cambia radicalmente se aumentiamo anche solamente di uno la dimensione passiamo qui sotto a due dimensioni perché già passando da due dimensioni chiaramente le alternative non sono più due ma diventano infinite nel momento in cui io sono in questo punto qui posso muovermi ed è vedete sono queste frecce qui che poi definiscono questo cerchio che ho appena evidenziato mi posso muovere vi dicevo secondo infinite possibili alternative e di queste infinite possibili alternative è solo una frazione che non è pari al 50% perché se andate a vedere l'intersezione di questo cerchio rosso che è centrato nel minimo con il cerchio tratteggiato e poi qui continuo che vi ho appena rievidenziato vedete che è un'intersezione che vi dice quale frazione che è quella che vi sto evidenziando di direzioni vi porta in discesa lungo la funzione quella frazione non è pari al 50% questo discorso può essere reso rigoroso vedete che quindi passiamo da un 50% a un qualcosa che è meno del 50% può essere rigoroso in particolare si può dimostrare che per in generale per la gran parte delle funzioni è via via più difficile esponenzialmente più difficile trovare una discesa una direzione di discesa valida in maniera casuale quando la dimensione dell'input cresce esattamente per lo stesso motivo per cui se pretendiamo di ricoprire un certo spazio con una griglia di punti scelti a caso crescendo la dimensione dello spazio quella griglia di punti sono dei punti che diventeranno via via più sparsi in maniera esponenziale e qui succede una cosa del tutto analoga tant'è che si può dimostrare esattamente come si può dimostrare questa proprietà sopra che se noi prendiamo una qualunque funzione per esempio quadratica e una funzione quadratica in più dimensioni può essere scritta così come il prodotto di un vettore trasposto per il vettore stesso questo dà luogo a una funzione quadratica andate a vedere di fatto esattamente la stessa funzione che abbiamo scritto prima in cui avevamo v1 più v2 più 2 al quadrato più 2 e vi dicevo se fate con un po' di passaggi matematici quello che si può dimostrare è che se prendete n uguale a 30 quindi questo vettore non è più due dimensioni come l'avevamo visto prima ma sono dei vettori a 30 dimensioni a 30 componenti quello si può dimostrare che andando a scegliere rispetto all'infinite possibilità che abbiamo a caso un certo numero ampio sufficientemente di direzioni casuali comunque la probabilità di scegliere delle direzioni che siano delle direzioni di discesa valide è inferiore all'1% e questo già solo con n uguale a 30 chiaramente crescendo il valore di n questa probabilità diventa ancora più bassa questo che cosa significa? Significa che se voi andate a prendere siccome una probabilità intanto già in questo caso inferiore all'1% l'1% è molto poco anche se andate a prendere un numero molto ampio di possibili alternative è una probabilità di andare in discesa e la probabilità diventa rapidamente crescendo n di andare a pescare a caso lago nel pagliaio e quindi ovviamente è una ricerca estremamente inefficiente che cosa si può fare? ci sono delle soluzioni? sì per fortuna sì e quindi questo significa che random search è di fatto un qualcosa che viene utilizzato solamente a bassa dimensionalità dove bassa intendiamo 3, 4, 5 e però nonostante questo ci ha permesso di introdurre tutta una serie di concetti quindi come funzionano gli algoritmi di ottimizzazione locale che vedremo rispettano questo schema che è uno schema di iterazioni progressive in cui ad ogni iterazione si cerca una direzione di discesa valida ok una di queste due diciamo meglio perché sono due le tecniche che subito vengono utilizzate subito scusate che subito vedremo e che vengono utilizzate per per poter torno un attimo indietro perché volevo dire un'altra cosa qui vi scrivo anche la probabilità ecco di scegliere una direzione casualmente partendo ecco su questa funzione quadratica partendo dal punto w0 pari a allora se siamo in dimensione pari a n e parto da un vettore che è quello con coordinate 1 e tutte le altre coordinate 0 quello che si può dimostrare è che per la funzione per una funzione di questo tipo una funzione quadratica la probabilità di scegliere una direzione di discesa se la scelgo casualmente tra tutte le infinite possibili in questo caso diventa è maggiorata si dice superiormente quindi è limitata superiormente da una quantità che è questa questa è una dimostrazione matematica ovviamente sarebbe necessaria per poterlo appunto dimostrare insomma ve la do per ovviamente per buona da questo però vi rendete conto di che cosa che al crescere di n quello che succede è che questa probabilità diventa via via più piccola e in particolare appunto già con n uguale a 30 se fate un po' di conti questa probabilità è inferiore all'1% quindi giusto per rendere un po' più completo il discorso che stavamo facendo prima tornando invece alla slide successiva non si vede quello che sta scrivendo chiedo scusa non sento bene online non si vede quello che sta scrivendo online non si vede online non si vede la slide fissa ah perché c'è la condivisione dello schermo in pausa vediamo un attimo non so per quale motivo riprendiamo proviamo a riprendere no è questo ok adesso dovrebbe essere possibile però io nel frattempo ho cancellato quindi torno un attimo indietro e quello che dicevo è che adesso dovreste riuscire a vedere chiedo scusa non so per quale motivo era bloccato adesso dovreste riuscire a vedere vi riscrivo semplicemente quello che stavo che stavo dicendo prima cioè che si può dimostrare che la probabilità chiamiamola P di scegliere una direzione di discesa valida per una funzione di questo tipo partendo da un punto iniziale che è quello con 1 nella prima coordinata e 0 in tutti gli altri si può dimostrare che è limitata superiormente da una funzione di questo tipo se voi andate a mettere qui dentro un valore di n che è appunto dell'ordine di 30 vi accorgete che questo è un numero che è già inferiore a 0,01 quindi inferiore all'1% e qui era quello da cui ero partito quindi spero che adesso questo si sia riuscito a seguire e torno a la slide appunto a cui volevo arrivare che era quella che comincia a descrivere due possibili alternative che vengono prendono il nome di ricerca delle coordinate e discesa delle coordinate sono una una variazione sul tema dell'altra quindi partiamo da definire il primo che è l'algoritmo di discesa delle coordinate scusatemi di ricerca delle coordinate ma quello di discesa è assolutamente simile analogo il concetto qual è? è che nel momento in cui io cerco di utilizzare l'algoritmo di ricerca casuale quello che faccio è sto cercando in qualche modo mi muovo in uno spazio e cerco di minimizzare di fatto la funzione rispetto a tutte le coordinate in maniera simultanea cioè ho infinite possibilità già in n uguale a 2 e il problema è quello e quello che fanno questi algoritmi è invece dire ok accontentiamoci di andare coordinata per coordinata cioè non andiamo a vedere tutto insieme ma coordinata per coordinata e minimizzare quindi il nostro la nostra funzione di passo in passo rispetto a per esempio una coordinata alla volta o un insieme di coordinate alla volta questo significa che cosa? che se io detto in maniera più diciamo semplice se io diamo diamo un'occhiata alla parte superiore del disegno questa se io parto dal punto w0 e non pretendo di andare ad analizzare tutte le infinite alternative che possono avere le mie coordinate qui ci muoviamo in uno spazio bidimensionale ok? quindi ho diciamo n uguale a 2 quindi ho due coordinate però vi dicevo prima abbiamo appunto infinite alternative ma se io anziché guardare tutte infinite e quindi andare a pescare a caso tra le infinite possibilità che ho comincio a dire bene io ho la possibilità di muovermi solamente lungo le coordinate quindi lungo questa asse o lungo quest'altro e a questo punto significa che ho 2 per 2 4 possibili alternative e vado a vedere che cosa succede a queste 4 possibili alternative cioè scelgo queste come 4 possibili direzioni di marcia anziché un'infinità tra cui andare a scegliere a caso beh mi accorgo che ad esempio se sono qui la direzione migliore è quella di andare in questa direzione e vi faccio notare io l'ho scelta tra solo 4 possibili alternative chiaramente questa è una cosa che io posso fare in due dimensioni ma la posso fare anche in 3 in 4 in 5 quello che cambia è semplicemente scalando il numero delle dimensioni scalerà salirà ovviamente crescerà il numero delle possibili alternative ma come scusatemi come cresce il numero di queste possibili alternative cresce esattamente come 2n cioè io in n dimensioni vado a vedere due volte quel numero n di possibili alternative vado a considerare quindi in due dimensioni ne vado a valutare 4 in tre dimensioni 6 e così via questa è una crescita lineare ce la possiamo sicuramente permettere da un punto di vista computazionale e se la confrontiamo con quella esponenziale è evidente il vantaggio e cosa perdiamo? perdiamo il fatto che ecco io nel momento in cui ho identificato il punto w1 come punto successivo qui dovrò evidentemente ripetere il discorso che stavamo facendo e il discorso che stavamo facendo magari siccome c'è l'azzurro e il giallo scegliamo un altro colore qui facciamo il verde vi dicevo nel momento in cui sono posizionato qui ok e quello che posso fare di nuovo è ripetere lo stesso meccanismo e guardare questa direzione questa direzione questa direzione e chiaramente non ha molto senso quella che mi farebbe tornare indietro ma per completezza dovrei guardare anche quella e quello che succede è che di nuovo ne ho analizzate quattro questa sarà la migliore che mi porta in w2 qui ripeto di nuovo analizzo queste quattro possibilità mi porta qua mi porta qui e così via vedete che qui ho un percorso che è un percorso a scatti a zigzag che chiaramente è un po' meno potenzialmente efficiente rispetto a una scelta casuale che magari mi portava a identificare questa direzione poi quest'altra poi quest'altra ancora quindi qui mi muovo in qualche modo lungo una griglia di coordinate ma l'efficacia che avrei la perderei salendo di dimensionalità e qui invece non ho più quel problema cioè salendo di dimensionalità mi muovo lungo questo percorso a zigzag ma guadagno nel fatto di poter appunto con un fattore di scala che è 2n non è più esponenziale esplorare uno spazio ad alta dimensionalità questo è effettivamente un algoritmo che è utilizzato nella pratica come algoritmo di ordine zero quindi come tecniche di ottimizzazione locale di ordine zero e si trova qualche volta appunto implementato per qualche tipologia di problema e ha un suo motivo di essere anche nella pratica perché effettivamente permette di risolvere alcuni problemi e di scalare in maniera molto efficiente anche con l'aumentare della dimensione più efficiente ancora di questo è l'algoritmo di discesa delle diciamo più efficace direi anche più efficiente nel senso che come da un punto di vista computazionale meno impegnativo adesso vedremo e cercheremo di capire perché è quello di discesa delle coordinate che fondamentalmente è un algoritmo estremamente simile lo stesso però vedrete adesso vi dico ha qualche caratteristica leggermente diversa che lo porta ad andare avanti in maniera più più veloce allora come funziona questo algoritmo ma l'algoritmo di discesa delle coordinate che è quello che è rappresentato nella parte inferiore del in questa figura quello che fa è anziché andare a vedere ad ogni step ogni direzione più o meno quindi nel caso del punto di partenza W0 anziché andare a vedere questa direzione e questa ma anche queste altre ne guarda una sola quindi guarda solo una coordinata e di quella coordinata va a considerare una direzione di avanzamento e l'altra e quella opposta dopodiché passa quindi qui andrà a valutare queste due nella fattispecie e dopo aver valutato quelle due si sposta in W1 e poi in W1 non valuta più la coordinata lungo quest'asse lungo questa direzione valuta solo quell'altra lungo l'altra direzione e tra quelle due opzioni sceglie quella migliore poi ricomincia andando solo lungo questa direzione e non lungo quest'altra quindi alterna le coordinate esattamente esattamente in maniera introducendo una rotazione allora questo fa sì che anche qui diciamo l'algoritmo fa questo percorso a zigzag che ancora forse apparentemente potrebbe sembrare meno efficiente di quello che facevamo prima ma in realtà questo è solo apparentemente perché tiene fisso le altre coordinate e aggiorna una sola e che cosa succede? Succede che se io vado a vedere dopo 2n passi di questo tipo che cosa è successo? Beh dopo 2n passi qui in generale ho fatto 2n diciamo valutazioni della funzione 2n valutazioni della funzione no? qui io valuto 2n volte la funzione e avanzo di un passo prendo il minimo qui sotto dopo 2n valutazioni cosa è successo? è successo che io ho fatto in realtà n passi cioè sono andato molto più avanti mentre qui mi sono mosso solo di un passo qua che cosa succede? che io ho fatto 1 2 3 4n passi e quindi vado molto più rapidamente in realtà verso il minimo quindi di fatto tra i due è quello che effettivamente è il più efficiente e che viene spesso e volentieri questo effettivamente utilizzato anche nella pratica perché? perché dopo 2n valutazioni della funzione si muove di n passi in avanti questo in avanti è da prendere ovviamente tra virgolette ci muoviamo spazio non è inteso semplicemente procede ecco mentre qui per fare 2n un passo devo fare queste 2n valutazioni va bene? ci sono domande? vi faccio vedere un esempio di questi due algoritmi all'opera di come funzionano e abbiamo una funzione che è questa e adesso vi vado a scrivere scrivo qui ve la scrivo qui sopra è una funzione di due variabili di tre Ok. Questa è la funzione che è stata scelta. Su questo sono stati fatti 20 passi, K grande vale 20, di discesa delle coordinate a sinistra e di discesa delle coordinate a destra, con una regola di alfa pari a 1 su K, quindi con un passo che va a diminuire, che è quella tecnica che dicevamo prima. E vedete che l'algoritmo di ricerca delle coordinate si muove, riesce comunque a trovare delle varie direzioni di discesa. All'inizio non lo trova subito, poi però piano piano fa questo percorso di zag, arriva qui e dopo 20 step è ancora un po' lontano però dal risultato, mentre dal minimo che chiaramente è posizionato qui, perché queste sono le curve di livello della funzione che andiamo a minimizzare, mentre l'algoritmo di discesa delle coordinate, proprio per effetto di quel discorso che vi dicevo prima, per cui con 2n valutazioni riesce ad avanzare di n passi, nello stesso numero di passi riesce ad arrivare praticamente a trovare il minimo. Benissimo. Allora, questo conclude la trattazione delle tecniche di ordine zero, quindi per riepirogarle, le tecniche di ordine zero ci sono servite per, anzitutto dare una serie di definizioni introduttive, fare delle distinzioni tra ricerca del minimo globale e del minimo locale di una funzione, per introdurre il meccanismo generale che riutilizzeremo poi adesso anche andando avanti, di algoritmi di minimizzazione locale, che procedono in maniera iterativa cercando una direzione di discesa nel profilo della funzione. Abbiamo visto alcuni di questi algoritmi, come quello di ricerca casuale, abbiamo visto che soffre del problema della dimensionalità esattamente come gli algoritmi di ottimizzazione globale, e però abbiamo visto anche l'algoritmo di discesa delle coordinate e ricerca delle coordinate, che sono un primo algoritmo su cui possiamo contare per andare a implementare poi dei sistemi di machine learning che hanno, vi ricordo, perché quello è il nostro obiettivo, l'obiettivo di ottimizzare dei parametri rispetto a una funzione di costo. Adesso apriamo la trattazione di quelle che sono le tecniche di ottimizzazione del primo ordine, che vi anticipo sono di fatto poi quelle più utilizzate nel sistema di machine learning moderni, anche se non sono l'uniche appunto. In qualche caso si trovano anche tecniche di ordine zero per certe tipologie di problemi, in altri casi ci sono anche quelle del secondo ordine, però sicuramente quelle più utilizzate sono quelle del primo ordine, in particolare un algoritmo specifico di cui cominceremo a parlare ben presto, e che è probabilmente l'algoritmo più utilizzato oggigiorno in ambito di machine learning, che è quello di discesa del gradiente. Però prima di arrivare all'algoritmo di discesa del gradiente, dobbiamo anche qui, come abbiamo fatto per l'ordine zero, quindi per l'ottimizzazione matematica che si frutta le condizioni di ordine zero, dare un po' di definizioni, e ci è utile richiamare un po' di matematica per poter andare avanti e utilizzare queste nozioni per il nostro scopo. Allora, le tecniche di primo ordine cosa fanno? Utilizzano il concetto di derivata prima di una funzione, se stiamo parlando di funzioni di una variabile, oppure di gradiente di una funzione, se stiamo parlando di funzioni di più variabile. Il gradiente di una funzione che cos'è? Se vi ricordate, appunto dai corsi di matematica della vostra laurea, del vostro percorso di laurea triennale, il gradiente è un vettore in cui andiamo a organizzare le derivate parziali rispetto a ognuna delle variabili. Quindi se stiamo parlando di una funzione di n variabili, il gradiente di quel vettore sarà un... Quindi se abbiamo una funzione f che va da rn in r, il gradiente, quindi f è una funzione che ad esempio prende le variabili w1, w2, wn, e ve le mappa in un valore, in un singolo valore in r, ok? Allora il gradiente della funzione è una funzione, è un vettore che dipende dal vettore w, ed è un vettore che è così composto, è la derivata della funzione rispetto alla variabile w1, nella seconda entry ci andiamo a mettere la derivata della funzione rispetto alla variabile w2, nell'ennesima entry di questo vettore andremo a mettere la derivata della funzione rispetto alla variabile n. Benissimo. Ok? Questo è il gradiente. E il gradiente è, diciamo, l'estensione del concetto di derivata prima dalle funzioni di una variabile alle funzioni di più variabili. Va bene? Ok. Le tecniche di ottimizzazione del primo ordine utilizzano il concetto di derivata, o meglio quello di gradiente, nel caso di funzioni multi-input, quindi a più variabili, per minimizzare una data funzione. Ho utilizzato il termine multi-input, non a caso perché non dobbiamo dimenticare che poi noi dobbiamo avere l'obiettivo di implementare questi sistemi su un computer, su una macchina calcolatrice, che ci permetta di sfruttare appunto dell'automazione, della potenza di calcolo per risolvere problemi che, diciamo, non potremmo risolvere a mano in maniera agevole. Quindi per questo ho utilizzato il termine multi-input. Allora, prima di arrivare però a questo, facciamo un po' di breve riepilogo di alcuni concetti di, diciamo, di analisi matematica. Molto semplice, richiameremo alcune nozioni di base. la prima delle quali è che se ho una funzione differenziabile, differenziabile vuol dire, insomma, esiste la derivata, la derivata prima. Partiamo per semplicità da n uguale a 1, quindi ci muoviamo, per esempio, in un ambito che è quello di questa, di questa funzione qui. Bene, se vado a prendere una funzione che appunto ammette la derivata prima, che cosa succede? succede che la derivata prima rappresenta la pendenza, vi ricordate, della retta tangente in ogni punto dove questa funzione è derivabile, e la cosa interessante è che nel momento in cui questa retta tangente diventa questa, che è disegnata qui in verde, questa è perfettamente piatta, è parallela all'asse delle x. E questo ovviamente non è un caso, perché sapete appunto dalla matematica, che cosa? Che nel momento in cui abbiamo una funzione differenziabile, se questa, per esempio, qui ammette un minimo, beh, la derivata prima si annulla, perché la pendenza di quella retta tangente è esattamente pari a dire. Estendendo il discorso da 1 verso 2 dimensioni, beh, il ruolo che viene giocato dalla retta tangente viene giocato da un piano tangente, e questo piano tangente ha la superficie, si può ricavare per ogni punto di tangenza, ha la caratteristica che, se andiamo a prendere, e qui è disegnato quello, diciamo, che è in verde e che è tangente, ha la funzione in questo punto, che è un punto di minimo, è anche esso perfettamente, diciamo, piatto, ok? Quindi è esattamente, non ha inclinazione nulla, ok? E questo di fatto è un fatto generalizzabile, ed è quello che viene sfruttato per definire appunto le condizioni di ottimalità del, di ordine 1, del primo ordine. Allora, giusto per... Ok. Ok. Ok. Allora, giusto per, ecco, dare un riepilogo del quadro in cui ci stiamo muovendo, ho riportato qui quelle che sono note appunto come condizioni di ottimalità del primo ordine, che sono in una variabile questa condizione, che ci dice che cosa? Che se una funzione g, che è una funzione della variabile w, se quella funzione nel punto w mette un minimo, un massimo, allora la derivata si annulla. e l'estensione di questo concetto a n dimensioni è che si annullano tutte le derivate parziali rispetto alla variabile w1, rispetto alla variabile w2, rispetto alla variabile wn nel punto w, qualora questo sia un punto di massimo. Questa condizione può essere espressa in maniera molto compatta tramite una notazione vettoriale come appunto il gradiente di g nel punto w è pari a un vettore che ha tu, questa notazione si usa per dire che questo è un vettore che ha tu t zero in tutte le entri che sono esattamente n. Questo è un vettore n per 1, quindi n righe e una colonna è un vettore colonna costituito da tu t zero. Quindi io semplicemente in questa notazione compatta sto riportando il fatto che ognuno di queste entri è pari a zero, quindi posso scrivere che questo vettore che è quello che rappresenta il gradiente nel punto w fino ad arrivare a derivata a parteare rispetto a n è uguale a un vettore che ha tutti un zero e l'ampiezza di ognuno, cioè la dimensione di ognuno di questi vettori è n. E questo è esattamente questa notazione qua. Ok? Allora, questo di fatto è quello che potremmo sfruttare per andare in cerca di punti che hanno la caratteristica di essere potenzialmente dei punti interessanti che sono quelli appunto sono i cosiddetti punti stazionari. attenzione perché non solo erano tutti i punti di minimo possono essere di minimo di massimo oppure se vi ricordate anche solo in una in una dimensione che cosa c'erano? I punti di flesso sono i punti di stazionarietà però i punti di stazionarietà già andarli a identificare è un ottimo viatico per poter poi ricavare eventuali informazioni su quelli che possono essere potenzialmente dei punti di minimo. però fare questo in n dimensioni cosa significa? Significa andare a risolvere questo che è un sistema di equazioni sistema di equazioni tra l'altro che coinvolge le derivate partiali e chiaramente risolverlo in forma chiusa a mano è di fatto molto difficile tranne che per alcuni casi e diventa impensabile quando il valore di n cresce. queste condizioni del primo ordine laddove noi abbiamo delle funzioni convesse corrispondono a delle condizioni per l'identificazione dei massimi globali cioè nelle funzioni convesse se ho una semplice parabola non ho più massimi o minimi ho un unico punto che è o in massimo o in minimo che è il punto del vertice della parabola. In generale ecco quello che vi dicevo è che queste sono delle condizioni che valgono per i punti cosiddetti stazionari o critici che sono i punti di minimo i punti di massima i punti di flesso in una dimensione o più in generale i punti di sella in più dimensioni. Ok quindi questa è una slide in cui molto velocemente abbiamo fatto praticamente ripercorso probabilmente mezzo corso di analisi matematica ma è quello che ci serve per poter per poter per poter andare avanti quindi chi avesse qualche dubbio ovviamente magari va a rinfrescare a riprendergli appunti e poi se ci sono dei dubbi ne riparliamo chiaramente però questo è tutto quello che intanto ci serve per poter andare avanti e qui c'è un esempio di un po' di funzioni sono funzioni di una variabile in cui vengono evidenziati appunto i punti critici di cui queste funzioni sono portatrici ecco nella fattispecie abbiamo nella prima figura allora qui abbiamo diciamo nella parte alta abbiamo tre funzioni queste tre funzioni quindi ci sono le funzioni e nella parte bassa ci sono le derivate le derivate prime e in particolare le tre funzioni sono la prima che anzi ve la vado a scrivere direttamente qui sopra che facciamo dire che ci dovrebbe stare la prima è chiaramente un'oscillazione sinusoidale e nella fattispecie è una funzione che possiamo scrivere come il seno di 2w la seconda è una funzione cubica quindi la posso scrivere come w al cubo e la terza è la sovrapposizione di una funzione sinusoidale con una funzione di tipo quadratico ok allora la funzione seno se vedete ha appunto questi punti che sono dei punti adesso non le vengo in realtà volevo evidenziarlo in questo modo vi dicevo la funzione seno ha questo punto e questo punto che sono due massimi ok in particolare sono dei massimi locali e anche questo e questo sono dei punti di stazionalità che sono dei minimi sono minimi locali e vedete che in questa la retta tangente ha pendenza nulla qui c'è la derivata prima la derivata prima del seno e il coseno e vedete che dove si annulla la derivata prima in corrispondenza di dove si annulla la derivata prima chiaramente abbiamo dei punti di stazionalità sì tra l'altro da un punto di vista analitico la derivata del seno e il coseno e il coseno è sfasato di 90 gradi rispetto al seno la derivata di una funzione cubica v alla terza è chiaramente 3w al quadrato 3w al quadrato è una parabola parabola che si annulla nello zero e in corrispondenza dello zero abbiamo la pendenza è nulla di questa funzione abbiamo un punto di stazionalità non è in questo caso né un minimo né un massimo ma è un punto di flesso perché prima la funzione cresce e poi continua a crescere questa è un'altra funzione chiaramente non convessa che ha più punti di minimo e massimo locale e vedete che anche qui se andate a fare l'analisi di questa funzione avete che in ognuno in corrispondenza di dove la derivata prima attraversa l'asse delle ascisse quindi l'asse y uguale a zero avete che avete dei punti di stazionalità che sono di massimo e di minimo locali tutto questo per dire appunto che questo strumento ci dice qualcosa in più rispetto all'utilizzo di condizioni di ordine zero e questo qualcosa in più è quello che può essere sfruttato per costruire degli algoritmi di minimizzazione che di fatto sono anche più efficaci nel ricavare l'informazione che vogliamo cioè il minimo di una funzione perché poi le funzioni che tipicamente si vanno a minimizzare sono funzioni abbastanza complicate in molte dimensioni in molte variabili con un profilo molto frastagliato quindi altamente non convessa eccetera eccetera quindi utilizzare delle informazioni aggiuntive rispetto all'informazione sulla funzione stessa quindi per esempio informazione sul gradiente ci dà qualche possibilità in più di muoverci in questo panorama abbastanza complicato che rappresenta il profilo della funzione che dobbiamo minimizzare bene ci sono domande? allora proviamo a vedere come costruire un algoritmo che sfrutti le condizioni di ottimale del primo ordine che vi ho riportato qui sono queste sono rappresentate da questo sistema di equazioni con derivate parziali e capite bene che risolverlo ve lo dicevo anche prima a mano è molto difficile qualche volta in qualche caso possono essere risolte un non insieme ma un'equazione alla volta quindi in maniera sequenziale una specie di idea che in qualche modo va dietro l'idea di discesa delle coordinate questo è vero quando l'equazione ognuna di quelle equazioni può essere risolta in forma chiusa quindi per esempio se le funzioni da minimizzare sono quadratiche allora si possono fare delle cose ma in generale sono casi molto particolari spesso e volentieri nella pratica non ce li possiamo permettere o non corrispondono diciamo a una situazione che ci potremmo dover trovare di fronte nel costruire un sistema di apprendimento automatico e allora quello che si fa è si va verso la costruzione di quello che sono algoritmi che sono algoritmi di minimizzazione locale che sfruttano un po' la geometria del problema e in particolare vanno a costruire una sequenza di passi andando a identificare una direzione di discesa che è quella che ci viene suggerita proprio dal concetto di gradiente allora per capire bene questo dobbiamo fare un piccolo passo di nuovo indietro se vogliamo di definizione di matematica e andare a ritornare a due concetti fondamentali uno che è quello riportato nella slide che è quello di serie di Taylor del primordine allora le serie di Taylor del primordine che cosa sono? se andate indietro poco la memoria e vi ricordate o se non ve lo ricordate magari è l'occasione per andarlo a vedere perché vi può essere utile per la comprensione di quanto diremo ogni funzione che ammette sotto determinate condizioni di continuità derivabilità eccetera poniamo che appunto siano funzioni che hanno un buon comportamento quindi ammettono derivate prime ammettono un'approssimazione cioè noi possiamo approssimare una funzione in un punto come tramite quella che è proprio la retta tangente al punto e questa è un'approssimazione che vale localmente cioè nell'intorno di quel punto la retta la possiamo scusatemi la funzione la possiamo approssimare con la retta tangente se vi ricordate questo poi può essere formalizzato in maniera ben precisa tirando in ballo la retta tangente in quel punto tiriamo in ballo ovviamente il concetto di derivata e quindi la funzione la esprimiamo come un qualcosa che di fatto è la linearizzazione della funzione in quell'intorno va bene? se io vado a generalizzare questo concetto in due dimensioni ho che anziché andare a sfruttare il concetto di retta tangente posso sfruttare quello di piano tangente ed ho l'approssimazione in serie di Taylor in due dimensioni se vado in tre in quattro in cinque la stessa cosa rimane vera ho l'approssimazione in serie di Taylor in n dimensioni tramite quello che viene chiamato un iperpiano l'iperpiano è la generalizzazione del concetto di retta o di piano in n dimensioni da un punto di vista geometrico e matematico è perfettamente lecito rispetto a quella che è la geometria in cui ci muoviamo noi tutti i giorni è ovvio che è un'astrazione e che non trova riscontro nello spazio tra le dimensioni in cui viviamo oltre lo spazio tra le dimensioni non riusciamo a immaginarci questi enti geometrici però sono enti geometrici che vivono perfettamente anche al di là appunto della nostra capacità di della nostra incapacità di visualizzarli e in particolare quindi ricordatevi ecco da qui partiamo l'approssimazione in serie di Taylor e qui torneremo però per il momento scriviamo alcune alcune diciamo espressioni matematiche che riguardano la nozione proprio di iperpiano allora la nozione di iperpiano in generale a n dimensioni è quella che è riportata qui nel secondo punto ed è una funzione un iperpiano quindi in n dimensioni è definito tramite questa espressione è una funzione h di un'espressione che dipende da w1 w2 wn variabili quindi una funzione h che ci definisce il nostro iperpiano che può essere descritta in questo modo a dove a è un termine costante più b1 per w1 dove b1 è un termine costante e quindi è uno scalare e w1 è la prima delle nostre variabili poi b2 è un altro valore scalare un numero che moltiplica w2 più bn che moltiplica wn allora se guardiamo questa espressione che cos'è? è null'altro che un termine noto un termine a che è un valore scalare che viene sommato a che cosa? a una combinazione lineare delle nostre variabili indipendenti w1 w2 wn giusto? combinazione lineare perché non ho un termine ad esempio w3 al quadrato ma le nostre variabili compaiono solamente elevate alla potenza 1 e qui ho dei termini moltiplicativi ora se voi andate a fare il caso unidimensionale in cui abbiamo n uguale a 1 con che cosa ci ritroviamo? con una qualcosa che è un'espressione del tipo h di w uguale ad a b per w che è esattamente l'equazione della retta quindi l'iperpiano generalizza questa nozione a n dimensioni ci siamo? in n dimensioni e vi ricordo che noi dobbiamo fare questo sforzo di andare verso n dimensioni perché i problemi di machine learning sono in n dimensioni i parametri che dobbiamo andare a ottimizzare non sono mai 1, 2, 3, tranne in casi estremamente rari allora quello che succede è che io una volta che ho dato questa definizione posso andare a scriverla in maniera compatta e anche questa è una cosa che ci porteremo dietro nel proseguo del corso per diverse tipologie di problemi e di applicazioni di tecniche risultive ci farà comodo descrivere utilizzare una notazione vettoriale per descrivere un determinato concetto e la notazione vettoriale che ci permette in maniera molto compatta di descrivere un iperpiano è questa un iperpiano lo descriviamo mediante questa funzione h che è funzione del vettore w w1, w2, fino a wn può essere scritto tramite lo scalare a vedete lo scalare in corsivo mentre gli altri vettori e matrici vi ricordo li scriviamo in grassetto più b trasporto per w che cos'è b trasporto per w? ma b trasporto per w adesso magari lo scriviamo qua che ci dovrebbe essere posto è il prodotto scalare tra due vettori che cos'è il prodotto scalare tra due vettori? è nulla di più che un numero che otteniamo in questo modo allora vi ho detto prima che per convenzione assumiamo i nostri vettori come vettori colonna quindi b trasporto per w è un vettore che scriviamo così quindi b1, b2, fino a bn trasporto che va a moltiplicare il vettore w1 fino a wn e il prodotto scalare di due vettori così organizzati è chiaramente il valore scalare che otteniamo in questo modo b1 per w1 più b2 per w2 più bn per wn anche qui chi non si ricordasse il prodotto scalare tra due vettori se lo va a rivedere questo lo avete fatto nel corso ad esempio di logica algebra e geometria al primo anno credo o comunque insomma è qualcosa che ritrovate abbastanza agevolmente allora capite bene che questo che ho appena scritto è esattamente questa cosa qua e quindi se ci vado a sommare lo scalare a ottengo questa notazione dove b è un vettore a n componenti w è un vettore a n componenti se n è uguale a 1 e siamo qui assù nel caso unidimensionale che cosa succede? succede che quello che abbiamo a disposizione è un oggetto unidimensionale è una retta la retta chiaramente dipende da questo unico parametro fissati a e b al variare di quel parametro mi muovo lungo questa retta che è uno spazio unidimensionale vi faccio notare che è un oggetto unidimensionale che si muove però in uno spazio di input che è definito da w che è appunto unidimensionale ma che vive però in due dimensioni cioè la retta voi la rappresentate sul piano cartesano quindi in due dimensioni quindi è un oggetto unidimensionale che vive in uno spazio ambiente a due dimensioni giusto? ok se abbiamo un n generico abbiamo che questo iperpiano come l'abbiamo scritto è un oggetto a n dimensioni il suo spazio di input che è definito dal vettore w è n dimensionale ok perché w ha n dimensioni ma questo oggetto vive in uno spazio n più 1 dimensioni ora quando n è uguale a 1 quindi torniamo al caso della retta è molto facile distinguere se siamo in un punto w0 se il valore della funzione della fattispecie la funzione h cresce o decresce nel momento in cui ci muoviamo da w0 cioè abbiamo due sole direzioni possibili se io sono in uno spazio bidimensionale e sto parlando di questa retta e sono in questo punto w0 è chiaro che se mi muovo a sinistra vado verso questi punti ok nella evidenza così della retta se mi muovo verso destra vado verso quest'altra quest'altra semiretta quindi vado verso valori crescenti cosa succede quando n è maggiore di 1? e quando n è maggiore di 1 abbiamo di nuovo un numero infinito di possibilità adesso poi ci dovrebbe essere una slide che visualizza questo concetto però intanto è abbastanza intuitivo pensare che se ho un piano ho infinite possibilità esattamente lo stesso problema che avevamo prima con la ricerca casuale e noi vogliamo perché perché ci stiamo prima vi finisco di dire abbiamo infinite possibilità che permettono di dire che ho infinite alternative tra quella che rappresenta la direzione di massima discesa o di massima ascesa perché ci interessa dire che nel caso n uguale a 1 o nel caso generale n io voglio cercare la direzione di discesa o di salita perché l'algoritmo che andremo a mettere in piedi sfrutta proprio questo concetto abbiamo una funzione la approssimiamo in un punto tramite serie di terro del primordine cioè la prossimo tramite la la la retta tangente se stiamo parlando esattamente sarà quello sarà proprio quello e quindi io siccome approssimo tramite questo iperpiano la mia funzione mi muovo sull'iperpiano per dire ok siccome la funzione l'approssimo in questo punto con questa retta su questa retta se vado di qua salgo se vado di là scendo quindi ho trovato una direzione di salita o di discesa ed è questo per fare questo vedrete che ci insomma ci dovremo muovere con un po' di insomma intorno a questi concetti ma dietro c'è questo tipo di ragionamento ok sì che il concetto di derivata in una dimensione ma di fatto è proprio questo ci permette di approssimare la funzione e adesso dobbiamo capire una volta siccome approssimeremo la funzione con il gradiente a quel punto ci interessa sapere ma questo vettore gradiente dove no rispetto a questo vettore gradiente la funzione dov'è che va in discesa o in salita e la cosa bella è che il vettore gradiente vedremo tra oggi e domani rappresenta proprio la direzione di massima ascesa o discesa se prendiamo il suo opposto della funzione o meglio dell'iperpiano in quel punto e quindi della funzione quindi i gradienti rappresentano la direzione di massima pendenza della funzione adesso ci arriviamo piano piano ok intanto lasciamo da parte le funzioni ragioniamo poi noi stiamo tangenti a queste funzioni quindi ovviamente per noi rappresenteranno questa retta o questo piano o questo iperpiano l'approssimazione della funzione quindi i discorsi che facciamo su questi piani o iperpiani o su questa retta saranno discorsi che faremo sulla nostra funzione che valgono anche per le nostre funzioni però intanto ragioniamo solo su questi e domandiamoci allora qui c'è rappresentato quello che vi dicevo prima cioè il fatto che se sono in una dimensione e qui sono nel punto W0 e qui vado o di qua o di là quindi mi muovo rispettivamente in discesa oppure in salita se già sono qui in un caso bidimensionale chiaramente qui sono in un piano che è questo in azzurro che rappresenta il nostro piano bidimensionale n uguale a 2 se sono nel punto W0 dove mi muovo per andare in discesa o in salita beh ho infinite possibilità che sono quelle definite da questo cerchio qual è la direzione alcune mi portano in discesa alcune in salita qual è la direzione di massima discesa o di massima salita adesso cercheremo di capire quindi l'obiettivo è cercare perché perché io voglio la direzione di massima discesa io voglio minimizzare rapidamente la mia funzione allora per piani o iperpiani o rette più in generale appunto per iperpiani questo è matematicamente dimostrabile che diciamo è fattibile l'identificazione di questa direzione ed è quella che andremo a trovare adesso con un po' di passaggi allora la prima cosa è diciamo siamo nel punto W0 formalizziamo il fatto che vogliamo trovare un vettore D questo vettore è un vettore direzione con ampiezza unitaria va bene ok lo vogliamo con ampiezza unitaria perché così vi ricordate lo normalizziamo rispetto quindi rispetto alla sua magnitudo in modo che poi moltiplichiamo solo per alfa nell'eventuale algoritmo di ottimizzazione locale in cui lo andiamo a utilizzare noi siamo nel punto W0 e vogliamo muoverci verso un altro punto W0 più D dettato da questo vettore direzione tale che H sia massimo se vogliamo massimizzare cioè supponiamo voler andare a cercare una direzione di massima ascesa poi in realtà non ci farà comodo la discesa ma sarà esattamente speculare il discorso ok quindi tutto questo lo possiamo scrivere in questo modo noi vogliamo trovare il vettore D che massimizza H di W0 più D va bene dove H è la funzione che esprime il nostro iperpiano quindi siccome sappiamo quanto vale H significa che possiamo andare a sostituire allora H lo possiamo scrivere in questo modo abbiamo detto che è A più B trasposto e qui c'era il nostro vettore vi ricordate W prima W lo scriviamo come W0 più D ok e quindi il risultato è A più B trasposto per W0 utilizzo la proprietà distributiva del prodotto scalare più B trasposto per D ci siamo fin qua ok allora se andiamo un attimo torniamo qui ci accorgiamo di una cosa questa cosa è che se io voglio massimizzare questa espressione il primo termine che è A rispetto a D perché io voglio rispetto a D massimizzarla il primo termine è A non ha niente a che vedere con D il secondo termine lo stesso che è B trasposto per W0 non ha niente a che vedere con D non dipende da D quindi l'unico termine che mi interessa massimizzare è questo B trasposto per D quindi massimizzare quell'espressione rispetto a D è equivalente a massimizzare B trasposto per D ora B è un prodotto scalare un'altra delle proprietà del prodotto scalare se vi ricordate è che noi lo possiamo scrivere in questo modo come la norma del primo vettore moltiplicata per la norma del secondo vettore moltiplicata per il coseno dell'angolo tra quei due vettori questo è vero per la geometria due tre dimensioni ma è vero in generale a n dimensioni cioè anche se il concetto di angolo ovviamente perde la nozione che abbiamo nella geometria nostra comune dell'esperienza nostra dello spazio esiste un analogo in n dimensioni cioè quando i due vettori sono ortogonali che cosa succede? che questo prodotto pensate ragioniamo nel piano nel piano se B e D fossero ortogonali il loro prodotto scalare sarebbe norma di B per norma di D per il coseno di pi greco mezzi ma il coseno di pi greco mezzi è zero e quindi sarebbe zero però se questo torna perché? perché il prodotto scalare ha anche qui un'interpretazione che rappresenta la proiezione di uno sull'altro che se sono ortogonali è nulla ok? in generale quindi vale questa ok? questa è è un'espressione che possiamo sempre scrivere e anche qui che cosa di cosa ci accorgiamo? che quindi fino a qua ci siamo ok? perché adesso poi chiudiamo il cerchio tra poco allora siccome la norma di B ovviamente è una norma che non dipende dal vettore D e la norma di D è unitaria perché noi andiamo a cercare il vettore di reazione che ha ampiezza unitaria questo significa che massimizzare l'equazione di per piano rispetto a D significa andare a massimizzare il coseno di θ al variare di θ ma massimizzare il coseno di θ che cosa significa? dov'è che il θ dov'è scusate che il coseno di θ ha valore massimo? coseno di θ vale 1 per θ uguale a 0 il che significa quindi che D lo possiamo scrivere poi vedremo come B diviso la norma di B al quadrato e però intanto questo lo andiamo a vedere dopo però intanto ragioniamo qua cosa succede? che quando coseno di θ è uguale a 1 qui questa espressione è massima quando il coseno di θ è uguale a meno 1 questa espressione è minima il che significa che quando θ è uguale a 0 io identifico con D una direzione di massima ascesa quando θ è uguale a π il coseno vale meno 1 io identifico con D una direzione di massima discesa e in particolare D lo posso ricavare in questo modo perché posso scrivere dei passaggi di questo tipo posso fare una cosa di questo genere se cosθ è uguale a 1 io posso scrivere questa espressione come norma di B è l2 perché? perché la norma di D è 1 e il coseno di θ vale 1 ma se scrivo a questo punto quindi siamo arrivati a scrivere B trasposto per D uguale norma di B ok? ma a questo punto siccome B trasposto moltiplicato scalarmente per B è uguale alla norma di B L2 questo vale sempre cioè il prodotto scalare di un vettore con se stesso ci dà la norma di quel vettore perché io B1 per B1 quindi B1 al quadrato più B2 al quadrato più B3 al quadrato e sarebbe la norma elevata al quadrato scusatemi ovviamente qui mi manca un 2 un esponente a questo punto io posso scrivere la norma di B al quadrato come B trasposto per B quindi la norma di B L2 la posso scrivere come B trasposto per B fatto la norma di B ok se vado a sostituire questa nell'equazione precedente quello che ottengo è quindi in questa equazione qua questa in questa no ottengo che ne vado qui a scriverlo che è B trasposto per D uguale a B trasposto per B fratto la norma di B il che significa che D per forza di cose grande colore cosa succede? E D è questo deve essere per forza uguale a questa cosa qua che è esattamente questa cosa che sono arrivato a scrivere qua quindi tutto questo per dimostrare che cosa? Che se il coseno di teta vale 1 cioè teta uguale a 0 allora il vettore direzione assume questa espressione e siccome massimizzo il valore che prende la funzione H lì per piano quello mi identifica la direzione lungo la quale lì per piano cresce al massimo se coseno di teta vale meno 1 quindi teta uguale pi greco finiamo con un discorso del tutto analogo se fate un po' di conti con ricavare che trovate B come meno B fratto la norma di B vi faccio notare che questi sono due vettori antiparalleli cioè hanno stessa direzione verso opposto perché abbiamo fatto tutto questo questo questo passaggio questa serie di passaggi perché abbiamo messo in piedi un po' di di cose che ci permettono di dare delle basi solide per costruire l'algoritmo di discesa dell'ingradiente cioè domani ripartiamo da qui ripartiamo dalla direzione di massima discesa di un iperpiano e andremo a vedere che se approssimiamo la funzione con un iperpiano il gradiente della funzione in quel punto rappresenta proprio questa massima discesa o ascesa e quindi poi il gioco sarà fatto riguardate magari un po' di queste cose se se non vi sono tutte immediatamente chiare ma insomma dovrebbero essere abbastanza semplici se mai ne riparliamo va bene adesso se non ci sono domande direi che però oggi possiamo possiamo concludere qui ecco non so se da remoto avete domande se siete riusciti a seguire va bene ok allora direi che possiamo chiudere intanto la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la me la la