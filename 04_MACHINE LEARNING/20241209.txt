allora benissimo tanto buongiorno a tutti allora oggi siamo arrivati quasi in fondo vedrete che termineremo il blocco di slide con questo il di fatto il programma tra oggi domani poi domani vediamo un po come organizzare l'ulteriore ultima lezione però sono rimaste poche cose per cui vanno agli indugi andiamo subito a vedere un po di cosa di cosa stiamo parlando allora vi ricordo eravamo arrivati qui abbiamo trattato le reti neurali abbiamo le reti neurali diciamo come la maestrazione come generale come approssimatore universale abbiamo visto un particolare tipo di architettura di rete neurali che sono quelle totalmente connesse o dense e abbiamo introdotto un po di caratteristiche di queste di queste di queste reti abbiamo visto alcuni aspetti ed eravamo arrivati insomma alcune caratteristiche dell'addestramento abbiamo parlato del fatto che per esempio introducendo un termine di regolarizzazione partendo da una rete sufficientemente capace riusciamo comunque a contrastare l'overfitting confermando una cosa che avevamo detto a suo tempo quando abbiamo cominciato a introdurre l'argomento overfitting underfitting quindi strada facendo abbiamo avuto modo di vedere diverse cose oggi diciamo un paio di ulteriori analizziamo un paio di ulteriori questioni che riguardano questa tipologia di ecco una cosa che volevo sottolineare noi abbiamo visto le reti totalmente connesse le reti dense ci sono ve l'ho accennato tantissime altre tipologie di layer che spesso vengono mescolati anche alle reti dense le reti dense ve lo dicevo la volta scorsa sono presenti gli strati densi anche in altre architetture di rete poi ci sono però degli altri strati che sono degli strati dei layer che sono dipendenti anche qui molto spesso dall'applicazione quindi per esempio le reti convoluzionali trovano ampio ampio spazio ad esempio in applicazioni di computer vision le reti convoluzionali sono delle reti in cui i layer hanno un certo tipo fanno un certo tipo di operazione in particolare sfruttano la il fatto che l'input che si aspettano tipicamente nascono per gestire appunto l'immagine anche se trovano poi applicazioni non solo le immagini ma utilizzano dei principi di località per cui diciamo solamente alcuni pixel adiacenti quindi valori che provengono da quello che viene chiamato anche il campo ricettivo comunque che diciamo sono adiacenti a un determinato pixel quindi solamente dei valori locali vengono tra di loro convogliati in un neurone e quindi diciamo ogni neurone lavora su un insieme un sotto insieme di input questo permette anche ve lo accennavo la volta scorsa di limitare rispetto alle reti totalmente dense l'esplosione del numero di parametri in queste applicazioni ma le reti convoluzionali quindi i layer convoluzionali non sono l'unico altro altra tipologia di dire che che esiste anche di reti che esistono quindi sono le reti convoluzionali poi appunto come vi dicevo spesso e volentieri mescolano si mescolano le tipologie di layer quindi per esempio le reti convoluzionali hanno in fondo dei layer densi tipicamente oppure inframmezzate ce ne sono altre come vi accennavo sono le reti neurali ricorrenti che introducono dei meccanismi di feedback per cui in realtà i neuroni hanno producono un output questo output viene ricollegato in qualche modo all'input rientra e quindi diciamo c'è un sistema per cui abbiamo una scansione di memoria è un sistema memoria con una scansione che va ad analizzare ad esempio una sequenza per un certo numero di passi e poi riprende e fornisce l'output ci sono altre tipologie di architetture che sono estremamente salita in particolare alla ribalta e risultati estremamente efficaci negli ultimi recenti anni che sono cosiddetti trasformer o trasformatori che sono la base di diversi tipi di architetture più recenti e anche lì quello che che fanno è fare delle operazioni particolari adesso non abbiamo modo di entrare nella fattispecie dell'argomento per andare a snellire risolvere certi problemi che altre architetture di rete presentano ecco come sempre il gioco è si introduce una nuova soluzione quella risolve potenzialmente alcune caratteristiche di altri tipi di altri tipi di problemi che si erano presentati in precedenza poi magari si scopre che certe applicazioni su quell'architettura su quella soluzione hanno comunque dei problemi allora si trovano altre soluzioni così via non c'è al momento allora una soluzione vincente ma anche se con il discorso trasformano un po di cose sono state cambiate perché quelle effettivamente hanno applicazione più un po più ampia però specialmente anche lì trovano trovano applicazione hanno trovato finora applicazione nella gestione diciamo delle sequenze e quindi per esempio testo eccetera ma non solo perché possono essere applicate anche nell'ambito visione quindi sono un pochino più generalisti però in realtà spesso e volentieri come vi dicevo le cose vengono mescolate cioè si prendono degli strati di un tipo si mettono in un altro quindi questa architettura ognuno si può inventare un architettura di rete di fatto a miglia di principio e ovviamente non abbiamo tempo di entrare nel dettaglio perché appunto questo è poi quello che è di pertinenza di corsi di deep learning che fanno proprio solamente quello la dove la dove eventualmente ci ci sono e noi come corso di machine learning in generale ci fermeremo qui ecco come tipologia però diciamo già da questo avete capito insomma come questi sistemi possono essere imposti e qual è la base teorica dietro il loro funzionamento poi quello che cambia ripeto cambiano gli operatori alla base cioè come i neuroni gestiscono quali tipi di input prendono che cosa fanno si aggiungono degli operatori per cui vengono fatte delle operazioni particolari ma il meccanismo è sempre quello abbiamo un input che viene progressivamente trasformato da un insieme di neuroni che combinano attraverso dei pesi gli input dallo strato precedente ci sono delle funzioni di attivazione non lineare questo può essere fatto chiaramente con una varietà di combinazioni e ripeto di operazioni e di operatori arbitrario ma fondamentalmente il principio rimane quello e il punto è che attraverso l'apprendimento noi riusciamo ad aggiustare tutte le migliaia decine di migliaia milioni potenzialmente di pesi di una rete neurale in modo che il comportamento della rete neurale sia conforme a quello che il nostro dataset ci detta ok quindi questo è il principio di funzionamento ci sarebbero tante altre cose da dire funzioni di attivazione funzioni di attivazione funzioni di attivazione noi abbiamo detto che possono essere di diverso tipo e in generale questo rimane vero perché in linea di principio ogni funzionamento di attivazione non lineare può essere usata in realtà diciamo per esempio risultati di approssimazione universale valgono sì non proprio per tutte le punti di attivazione non lineare perché per esempio quelle polinomiali hanno rientrano una casistica diversa ma ci sono delle sfumature che diciamo non ci interessa più di tanto da andare a vedere quello che rimane vero è che voi potete utilizzare di fatto una varietà enorme di funzioni di attivazione non lineare e che cosa cambia fondamentalmente da un punto di vista del funzionamento della rete in linea di principio non cambia molto cambia da un punto di vista dell'implementazione dell'addestramento cioè se voi implementate una funzione di attivazione non lineare alcune vi facilitano l'addestramento e altre no in che senso adesso cercherò magari di dirvi qualcosa in più prima vi volevo dire che da un punto di vista storico all'inizio si è partiti cercando di utilizzare funzioni di attivazione che fossero il più possibile compatibili con i modelli dei neuroni biologici e quindi all'inizio siccome l'idea era che questi neuroni si attivassero come una sorta di switch di interruttore digitale quindi o 0 1 quindi sotto soglia il neurone è silente sopra soglia si attiva e produce un impulso in uscita all'inizio la prima cosa che è stata fatta è modellizzarle come uno scalino proprio quindi con una funzione scalino poi in realtà si è visto che siccome poi comunque quel modello non è ve lo dicevo anche questo la lezione precedente fu la precedente non mi ricordo non è propriamente un modello così accurato della della realtà neurofisiologica quello che è stato fatto è andare nella direzione di dire ok siccome comunque questa è un'astrazione un modello astratto quindi non è comunque così vicino e non ci interessa forse neanche più di tanto andare a riprodurre così esattamente in questa fase perlomeno la dinamica del singolo neurone utilizziamo per guidare la scelta delle funzioni di attivazione delle scelte di ordine pratico che ci facilitano ad esempio l'implementazione oppure la l'addestramento perché lo scalino se vi ricordate l'abbiamo incontrato a suo tempo quando abbiamo siamo partiti dai classificatori lineari e la prima cosa che abbiamo visto abbiamo detto beh se usiamo una funzione scalino quando facciamo una regressione logistica abbiamo detto che ci crea dei problemi perché le funzioni di costo che possiamo ricavare sono totalmente piatte con degli spigoli e delle diciamo dei dei fronti di cambiamento verticali che erano degli scalini quindi un profilo che era costante a tratti con delle con dei con dei cambiamenti da un tratto all'altro che erano di fatto del dei dei gradini quindi diciamo introducevamo delle discontinuità che risultavano difficilmente gestibili da un punto di vista del del dei metodi di ottimizzazione che sfruttano la derivazione perché la funzione era altamente non differenziabile in diversi punti ed era costante in tanti altri punti quindi di fatto la derivata dove costante una funzione è zero quindi il segnale che deve fornire al gradiente si annulla in tantissimi punti della funzione di input della funzione di costo ed è discontinuo in altri punti quindi di fatto era una era praticamente inutile e allora quello che si è fatto esattamente come abbiamo fatto quando all'epoca abbiamo introdotto l'approssimazione della funzione sigmoidale come approssimazione del della funzione gradino e quello che si è fatto si è ragionato sull'introduzione di introdurre la funzione sigmoidale quindi la funzione sigmoidale è stato un primo passo rispetto appunto dove si è partiti ed è stata la prima funzione di attivazione che è stata introdotta viene tuttora abbastanza utilizzata però è stata soppiantata nel frattempo diciamo all'inizio degli anni 2000 quindi una ventina di anni fa dalla funzione relu le funzioni relu quindi che sono il re lo sta per rectify linear unit e vi ricordo che rappresenta che cosa una funzione che il massimo tra 0 e un qualcosa che la funzione una combinazione lineare di quello che c'è all'interno del marco di quello che riceve come input e quindi se siamo in una variabile è una cosa fatta ad esempio così quindi è vero se i valori sono negativi e poi invece va con un esempio v più 0 più v più 1 per x allora questa è stata una funzione che è stata introdotta nel come vi dicevo nel ventina di anni fa grosso modo e rispetto alla alla funzione sigmoidale presenta questi vantaggi allora la funzione sigmoidale se ve lo andate a vedere invece un andamento noi abbiamo visto che una cosa di questo tipo no giusto ok va bene e allora se voi fate la derivata qui essendo questo un esponenziale basta a aumentare di poco diminuire di poco l'input e va subito tra 1 e 0 oppure anche se prendete la tangente iperbolica tra 1 e meno 1 il risultato è che se voi andate a fare la derivata ottenete un qualcosa che adesso la disegno qua scusate si vedrà moltissimo per capirci ottenete un qualcosa che è una cosa di questo genere cioè qui qui e qui è vero perché qui costante qui è costante solo qui in mezzo il presidio origine ha un valore diverso da zero allora questo fa sì che di nuovo il segnale che voi non dobbiamo dimenticare che i metodi con cui vengono addestrati metodi di ottimizzazione che sfruttano che vengono utilizzati scusatemi per addestrare le reti neurali sono metodi di ottimizzazione basati sul disceso del gradiente e sfruttano l'informazione che gli dà il gradiente allora l'informazione che dà il gradiente qui qual è? è un'informazione che anche qui di nuovo è in diverse zone nulla ok? questo problema viene chiamato problema del vanishing gradient in inglese cioè del gradiente che svanisce ok? se io ho un segnale per cui in uscita a un neurone il gradiente di quel che mi fornisce la funzione di costo in quel punto è nullo proprio perché la funzione di attivazione è quello che mi produce l'output del neurone se però quella ha la caratteristica di produrre un gradiente nullo io non ho informazione adesso poi parleremo di come tra l'altro calcolare quegli gradienti eccetera quindi il problema significa che cosa? che io se vado a calcolare il vettore gradiente rispetto a tutti i miei parametri comincio ad avere qua qualcosa che è simile allo 0 qui 0 qui 10 alla meno 3 qui 10 alla meno 8 eccetera eccetera ho un vettore con tutte entri nulle a un certo punto e questo significa che non riesco più a guidare il processo di addestramento le relu hanno questo problema qua chiaramente in questa zona qui ma se io riesco a inizializzarle sufficientemente lontano dall'origine vedete che qui non hanno più quel problema nel senso che il gradiente tende a non svanire in maniera altrettanto marcata di come accade qua però hanno un altro problema perché qui in realtà vale 0 la funzione di uscita quindi bisogna inizializzarle al di là dell'origine allora nel corso degli anni sono state diciamo introdotte altre funzioni di attivazione non lineare le relu rimangono le più popolari avete visto la volta scorsa quando abbiamo fatto l'esercitazione abbiamo utilizzato la relu come come noi abbiamo specificato se non ricordo male era era quella nelle impostazioni del notebook che avevamo utilizzato potete provare a cambiarle con quel semplice esempio che abbiamo visto su tensorflow specificare ad esempio sigmoidale vedrete che i risultati sono comunque soddisfacenti però ecco ci sono alcune applicazioni in cui è bene tenere presente che cambiando la funzione di attivazione magari il processo di addestramento risulta più o meno semplificato e nel corso degli anni ne sono state introdotte anche altre quindi oltre alla sigmoidale e alla tangente iperbolica e alla relu avete delle variazioni sul tema se voi andate a vedere la documentazione di tensorflow o di pytorch avete un elenco di possibili già implementate funzioni di attivazione non lineare che è dell'ordine della decina quindi avete e continua a crescere e ogni tanto qualcuno insomma studia qualche funzione di attivazione e produce dei risultati degli articoli scientifici in cui cerca di dimostrare anche con il supporto chiaramente della di un'analisi sperimentale che quella nuova funzione di attivazione ha determinate caratteristiche questo diciamo da un punto di vista di panoramica generale ecco è quello che mi sento di dire che possa essere utile ai fini di questo corso dire che ecco le funzioni di attivazione fondamentalmente nascono con un certo tipo di criterio poi il criterio non è più l'aderenza a un modello biologico ma diventa di natura pratica cioè dobbiamo addestrarli questi oggetti e quindi fino ad oggi diciamo queste relu sono probabilmente quelle più utilizzate ci sono anche qui ecco questo è un esempio di una variazione sul tema che è uscita una decina di anni fa è stata usata per un po di tempo poi adesso non è più così forse popolare in pratica si chiama funzione di attivazione max out di tipo max out che è una cosa di questo genere il massimo non più tra 0 e w 0 più w 1x che sarebbe la relu ma è il massimo tra una prima combinazione lineare e una seconda combinazione lineare dell'input dove le due combinazioni sono diverse quindi introduciamo dei parametri in più di fatto però questo ha per esempio presenta dei vantaggi rispetto alla tangente iperbolica o la relu stessa perché non dobbiamo prestare più attenzione all'inizializzazione come dobbiamo fare nella relu se diamo di inizializzazione significa quando andiamo inizializzare i pesi della rete casualmente e dobbiamo stare attenti che non portino troppo nella parte diciamo di risposta nulla non ha o è meno diciamo soggetta al problema del gradiente che svanisce e ha una convergenza che empiricamente si è dimostrata essere più rapida più veloce però ecco sono tutte cose però non è l'unica poi ripeto questa è stata anzi forse ultimamente un po soppiantata ce ne sono ce ne sono altre che se andate a vedere l'elenco delle funzioni di attivazione potete potete trovare ok invece qui c'è un ulteriore cosa che vale la pena vale la pena soffermarci che è questa sempre riguardante appunto l'addestramento e come queste reti funzionano soprattutto e come viene fatto funzionare l'addestramento perché noi finora abbiamo dato per scontato che da qualche parte esista la possibilità ci sia uno strumento per calcolare questi e questi gradienti abbiamo detto tutte le volte che abbiamo parlato quando abbiamo parlato del dell'ottimizzazione basata sul disceso del gradiente metodo del primordio abbiamo detto dobbiamo calcolare il gradiente della funzione di costo ora questo per modelli diciamo più semplici nella descrizione da un punto di vista matematico del modello stesso come per esempio i modelli lineari è abbastanza è abbastanza semplice si riesce a fare in linea di principio si riesce a fare anche per modelli più complicati come come le reti neurali però se torniamo un attimo indietro e andiamo a prendere un generico modello andiamo a prendere senza andare proprio quello di ordine l ma prendiamo questo ok quindi una rete neurale con due strati nascosti ok che era questa vedete che qui abbiamo il modello che era descritto da questa espressione espressione è il nostro input su cui viene applicata una trasformazione lineare c'è la funzione di attivazione a sua volta altra combinazione lineare nuova funzione di attivazione non lineare e combinazione finale lineare dei pesi ora questa è una funzione di funzioni che ci descrive in maniera molto compatta che cosa accade nel momento in cui io una mia rete strutturata in questo modo prendo l'input e l'output sarà una cosa di questo tipo ora è una descrizione molto compatta che capite bene che però ci pone un problema di dire ok io devo calcolare per addestrarla per far funzionare un algoritmo di discesa del gradiente devo calcolare il gradiente ok il gradiente vuol dire devo calcolare gradiente di che cosa della mia loss function della mia funzione di costo quindi prendete supponiamo di voler risolvere un problema di regressione abbiamo ad esempio la funzione di costo i minimi quadrati e quindi confrontiamo la risposta vera la y che devo ottenere con la risposta che mi da il mio modello che questa roba qua ok e poi a quel punto faccio lo scarto quadratico e devo calcolare la derivata parziale rispetto a ognuno dei parametri della rete quindi questo questo stanno qui dentro della della dello scarto quadratico della della min square error ok della funzione dell'errore quadratico a picchio e questa cosa comincia a non essere banale perché perché uno in linea di principio lo può fare comincia a scrivere da da qui a utilizzare o appunto delle delle regole di derivazione matematica cui calcolate la derivata di una funzione a più variabili rispetto appunto a tutta una serie di parametri sfruttando delle regole di derivazione che utilizzano o la notazione delle matrici oppure direttamente ritornando a al singolo sviluppo la singola sommatoria però capite bene che non è una cosa banalissima e di principio si può fare e di fatto questo era quello che si faceva fino a direi una quindicina di anni fa ok 20 anni fa neanche se una quindicina una quindicina di anni fa il problema è che nel momento in cui si sono cominciate a sviluppare queste architetture di rete si è visto che si potevano costruire delle reti che di fatto sono delle composizioni di funzioni cioè l'input viene progressivamente trasformato e questo lo possiamo fare andando in profondità e quindi aggiungendo complessità al nostro modello e andando a costruire per esempio già solo nel caso delle reti dense una cosa di questo tipo andare a ricavare a mano il gradiente ecco se si tratta di una regressione logistica si può fare se si tratta di una rete densa con uno due tre tratti comincia ad essere più difficile man mano che si va in profondità o man mano che si comincia a cambiare qualcosa immaginate poi quando cominciate a cambiare qualcosa nell'architettura di rete dovete di nuovo riscrivere da zero il gradiente della funzione di costo e se cambiate la funzione di costo dovete di nuovo ricalcolare i gradienti della funzione di costo parlo a mano questo significa poi significa calcolare a mano dei gradienti di funzioni a n variabili farlo a mano era di fatto quello che avveniva ma era la parte principale se vogliamo cioè fino a 10 15 anni fa se voi leggevate un articolo scientifico che presentava una rete di questo tipo gran parte del lavoro era dedicato allo sviluppo del gradiente vi facevano vedere qual era il gradiente della funzione di costo dopodiché vi dicevo questo è chiaramente un fattore limitante introduce potenzialmente un sacco di errori soprattutto in fase di sviluppo nel momento in cui cominciate a sviluppare un'idea per un'architettura di rete per un'applicazione e sbagliate qualcosa nel calcolo del gradiente questo crea dei problemi quindi rallenta ovviamente in maniera significativa tutto quello che è il processo di sviluppo e di ricerca e allora si è cominciato a ragionare su come rendere questa cosa più robusta di questo sistema e sono stati sviluppati implementati dei sistemi che sono scusate vi dicevo che sono oggigiorno lo stato dell'arte che sono dei sistemi che permettono di effettuare questo calcolo in automatico sono sistemi di cui vi ho accennato qualcosa quando abbiamo introdotto le prime le prime esercitazioni in cui abbiamo parlato di come di come appunto i metodi del gradiente può avvalersi di questi sistemi questi sistemi sono sistemi di differenziazione automatica si chiamano la differenziazione automatica è un appunto un un ambito di ricerca un argomento di ricerca nell'ambito dell'informatica che permette appunto di calcolare di differenziare in automatico delle funzioni tramite delle tecniche algoritmiche opportune vi faccio notare che questo va in una direzione diversa da quello che comunemente viene fatto nel nel calcolo numerico quando si va a calcolare una derivata per via puramente numerica cosa intendo se io volessi calcolare la derivata di una funzione in maniera numerica la prima cosa che forse ci verrebbe in mente di fare ed è quella che viene comunemente fatta per un sacco di applicazioni che non sono però di questo tipo e di dire ok la derivata prendiamo per semplicità in una variabile che cos'è il limite del rapporto incrementale giusto cioè è una cosa del tipo f di x più h meno f di x fratto h in realtà la definizione è proprio questa il limite per h che tende a zero di questa cosa qua questa è la definizione di derivata se vi ricordate giusto ok uno potrebbe dire ok io per via puramente numerica una cosa del genere la posso fare ho il valore della funzione in un certo punto prendo un valore h sufficientemente piccolo calcolo questa differenza divido per h e ottengo il valore della derivata in quel punto in effetti funziona ed è il modo in cui in tantissime di oberrie di calcolo numerico sono implementati questi questi questi questi meccanismi il problema è che quando andate cominciate ad andare nella direzione di utilizzare questo metodo per calcolare gradienti di funzioni in ambito appunto di machine learning reti neurali e cose di questo tipo si comincia a vedere che anzitutto pensate alla struttura di una rete neurale avete una serie di passi quindi una composizione di funzioni quindi voi dovete calcolare il gradienti di questa composizione di funzioni che prendono ognuna l'input del dello step precedente questo fa sì che siccome quando voi calcolate tramite questa via la derivata introducete un errore che dipende da come l'avete costruito cioè questo può essere caratterizzato ci sono diversi modi tra l'altro di costruire questo tipo di approssimazione però comunque un errore di arrotondamento è comunque un errore relativo al fatto che qui di fatto approssimate quel h che tende a zero lo introduce e questo errore si propaga si accumula e spesso e volentieri rende instabile anche il processo di addestramento quindi introduce delle degli errori di approssimazione introduce degli errori di propagazione e rende potenzialmente instabile questi processi di apprendimento oltretutto non è neanche particolarmente efficiente da un punto di vista computazionale primo problema uno potrebbe dire ok ci sono dei software che fanno per esempio quello che viene chiamato il calcolo simbolico cioè mi si dice la funzione f di x è uguale seno di x e loro calcolano in automatico la derivata dicendo f primo di x è uguale così in x ok come fanno questi sono sistemi che vengono detti cas computer algebra system ok tipo esattamente tipo wolfram matematica maples li avete sentiti nominare allora questi sono dei sistemi sicuramente potrebbero essere utili allo scopo mi presentano un problema che anche qui non sono particolarmente efficienti cioè nel momento in cui cominciate soprattutto a andare in alta dimensionalità cominciano ad avere dei problemi nel gestire in maniera efficiente questa dimensionalità proprio perché devono gestire un numero di variabili che è elevato e non sono concepiti per quello quindi anche questi creano dei problemi e allora la soluzione è una terza via quindi non è una via puramente di questa diciamo legata all'analisi numerica se vogliamo questa appunto legata ai sistemi cosiddetti cas la terza via è quella della differenziazione automatica automatica allora questa via è una via puramente algoritmica cioè sono degli algoritmi che sono stati concepiti e che vi permettono di calcolare in maniera automatica la derivata o meglio il gradiente diciamo se vogliamo parlare appunto di alta dimensionalità di funzioni arbitrariamente complesse tramite una serie di riduzioni di cui cercherò adesso di farvi capire qualcosa a diciamo a uno schema che vedrete ha una regolarità ben precisa e rischiano a fare questo in maniera esatta quindi evitando l'errore di approssimazione e anche in maniera efficiente quindi evitando le problematiche che potete incontrare nei sistemi appunto cas che chiaramente fanno anche altre cose e quindi rimangono validi perché non è che fanno solamente il calcolo della derivata allora questi sistemi di differenziazione automatica sono la base di di tutte le librerie che vi permettono di fare deep learning sono integrate all'interno di TensorFlow all'interno di PyTorch all'interno di Jax che sono le tre principali librerie che potete utilizzare per lo sviluppo di reti neurali e la differenziazione automatica è una tecnica che in realtà è nota da da prima anche qui c'erano idee che erano precedenti però è stata di fatto implementata in questi negli anni vi dicevo qui parlavo prima fino a 15 anni fa 20 anni fa e si procedeva per via manuale l'introduzione di queste funzioni di queste funzionalità in librerie diciamo robuste che poi hanno portato appunto allo sviluppo di quelle che oggi sono le attuali librerie più utilizzate è stato appunto uno dei progressi principali nell'ambito della ricerca del deep learning cioè il fatto che queste sono state queste tecniche siano queste erano note già da prima il lavoro di cui adesso vi dico poi qualcosa parliamo di back propagation che alla base della differenziazione automatica e risale al 1986 l'articolo che presentava questa tecnica però poi non era mai stato implementato in maniera sistematica in una libreria fruibile da tutti sono state cominciate dei lavori anche qui perché poi l'ingegnerizzazione un conto è descrivere un procedimento che funziona da un punto di vista algoritmico e farlo su piccola scala un conto è ingegnerizzarlo in un sistema robusto che abbia determinati requisiti soddisfi vi parlavo ci siamo fin qui allora cosa vi dicevo vi stavo dicendo di differenziazione automatica allora riepilogando quello che abbiamo detto finora i gradienti possono essere calcolati per via puramente algoritmica implementati in software e questo software è alla base di queste librerie di deep learning come appunto pytorch o tensorflow questa procedura è meno soggetta ad errore è molto più efficiente rispetto chiaramente quella manuale ma anche quella altre che possono essere diciamo concepite per via appunto in maniera automatica come appunto vi dicevo prima via puramente numerica o simbolica alla base di questi sistemi di differenziazione automatica c'è questo meccanismo che viene chiamato retropropagazione o backpropagation in inglese che è proprio un metodo per il calcolo delle derivate parziali di una funzione di perdita rispetto ai parametri di una rete ed è un metodo di cui cercherò di farvi capire qualcosa adesso nella parte restante della lezione un inciso backpropagation in realtà non è propriamente coincidente con la differenziazione automatica è una per caso particolare quello che viene chiamato reverse mode cioè la differenziazione automatica è qualcosa che è un po' più ampio backpropagation è la più famosa la più famosa modalità di differenziazione automatica perché è quella che viene utilizzata per ripeto per le reti neurali per una serie di motivi anche qui di efficienza principalmente ok quindi riassumendo cosa stiamo cercando di tracciare un quadro in cui abbiamo la nostra le nostre reti neurali che sono composizioni di funzioni funzioni di funzioni noi abbiamo la necessità funzioni di tante variabili ok perché la rete neurale è funzione di funzioni noi vogliamo costruire sulla base dell'output della rete neurale una funzione di costo quindi abbiamo una funzione di costo in cui confrontiamo qualcosa di noto con la funzione di funzioni che calcola la nostra rete neurale di quello dobbiamo calcolare il gradiente giusto? la differenziazione automatica tramite l'algoritmo backpropagation ci fornisce il modo per calcolare in maniera efficiente sistematica ed esatta il gradiente di qualunque funzione di costo ok? come fa? vedrete che adesso non entreremo nel dettaglio di tutto però cerco di darvi, di farvi capire, di farvi intuire qual è il principio di funzionamento il metodo fa queste cose attraversa vedrete diciamo la rete in realtà sì la rete se vogliamo ok? poi vi dico qualcosa di più di come viene schematizzato questo attraversamento diciamo in avanti e poi vedrete che c'ha un passo cosiddetto indietro quindi forward e backward dall'output verso il... quindi prima produce un risultato dall'input verso l'output e poi ripercorre indietro la rete calcolando una serie di derivate secondo la regola di derivazione delle funzioni composte in inglese viene chiamata regola di derivazione a catena chain rule ok per fare questo dobbiamo un attimo cercare di chiarire un paio di cose vediamo un attimo facciamo così quello lo vediamo dopo ora lo metto in la lavagna vediamo un po' allora eccoci qui vediamo un po' di scrivere qui su questa lavagna allora quello che fanno questi sistemi è anzitutto codificare il calcolo che effettua una rete tramite una struttura dati che è un grafo che viene chiamato grafo computazionale in inglese computational in graph allora il grafo computazionale che cos'è? è una rappresentazione di quello che dei calcoli che deve effettuare il sistema ma anche dei calcoli che effettua la rete suddivisa e scomposta in una serie di funzioni elementari che rappresentano gli atomi della computazione cosa voglio dire? se io supponiamo di avere per chiarire un po' di cosa parliamo una funzione semplice una funzione di solo tre variabili x, y e z e questa sia potete scegliere quella che ne volete x più y per z ok questa può rappresentare ad esempio non è ovviamente una funzione di costo però giusto per farvi capire potrebbe essere la loss function della vostra della vostra del vostro problema e quindi è collegata anche a quello che fa la rete potrebbe essere oppure potrebbe essere semplicemente quello che fa la rete compone in questo modo questi tre questi tre input e poi a partire da questo voi costruite la loss function va bene? questa vedete che è una funzione in cui potete identificare diciamo degli atomi delle operatori elementari che sono l'operatore somma l'operatore moltiplicazione va bene? allo stesso modo qualunque funzione generica di più variabili la potrete scomporre in funzioni elementari che sono somma, moltiplicazione, divisione sono le funzioni diciamo quindi operatori aritmetici e funzioni elementari quindi esponenziale logaritmo seno, cosino cose di questo tipo quelle rappresentano gli atomi diciamo del vostro della vostra espressione della vostra funzione e questa funzione a partire da questi atomi voi potete costruire un grafo che rappresenta il flusso di calcolo di questi di questi di queste espressioni quindi un grafo che rappresenta questa ipotetica funzione potrebbe essere costruito scusate ok vogliamo semplicemente spostarmi lo facciamo così andiamo avanti così ok lo potremmo costruire in questo modo potremmo dire che abbiamo un input x ok poi abbiamo questo input converge con un input y in un esattamente come se fosse un circuito in una sorta di porta che rappresenta un operatore che è l'operatore più e x più y producono un output parziale che potremmo chiamare q quindi potremmo dire che scomponiamo la nostra f in questo modo nel calcolo di q che è uguale a x più y e ad esempio a sua volta lo potremmo scomporre poi il risultato dire che è q perdita no? ok allora quello che viene fatto è di fatto proprio questo cioè si costruisce per esempio partire dall'espressione si fa il parsing di questa espressione si costruisce un grafo di questo tipo in cui i nodi rappresentano gli operatori elementari le funzioni elementari e in cui avete dei collegamenti degli input o degli output parziali dei risultati delle operazioni elementari che vengono tra di loro poi uniti in altri nodi che fanno altre elaborazioni di questo tipo quindi per esempio z abbiamo un edge un arco che potrebbe andare in questo grafo verso un ulteriore nodo in cui avete un operatore che è l'operatore di moltiplicazione questo operatore di moltiplicazione vi produce il risultato f ok quindi dall'espressione quello che fanno questi sistemi è costruire un grafo che è il grafo computazionale quindi immaginate di avere non questa espressione molto semplice di tre variabili ma una serie di layer di una rete neurale riuscite a costruire questo grafo ovviamente noi adesso per semplicità ragioniamo su questo tipo di funzione così vogliamo capire il meccanismo poi immaginate di trasporre questo meccanismo a una struttura come quella di una rete neurale però di fatto non cambia nulla abbiamo una funzione va bene? ora se io vado a mettere qui dentro voglio sapere qual è il risultato per esempio quando ho questa tripla che è x uguale a meno 2 y uguale a 5 e z uguale a meno 4 ok posso andare a mettere qui dentro faccio la somma di meno 2 più 5 che fa 3 3 per meno 4 fa meno 12 e vado a mettere questo diciamo qui dentro questo è il mio input andiamo meno 2 qui ci andiamo a mettere il 5 qui ci andiamo a mettere il meno 4 e chiaramente meno 2 più 5 fa 3 che sarebbe il risultato che rappresenta q abbiamo 3 per meno 4 che fa meno 12 che è il nostro risultato ok bene allora come funziona il sistema di backpropagation che cosa dobbiamo anzitutto cosa vogliamo dal nostro sistema di differenziazione automatica se questa è la nostra funzione ad esempio la nostra funzione di costo noi vogliamo calcolare il gradiente della funzione di costo rispetto ai parametri della rete in questo caso i parametri della rete sono i valori x, y e z sono le nostre variabili della nostra funzione di costo ok quindi noi quello che vogliamo l'obiettivo è questo lo scriviamo l'obiettivo è il calcolo del gradiente della funzione di costo quindi la derivata di f rispetto a x la derivata di f rispetto a y la derivata di f rispetto a z ok allora ecco come fare a fare una cosa del genere sistematica prima si costruisce il graf il computational grafico il grafo della computazione poi si fa una passata vedete noi siamo andati in questa direzione e abbiamo effettuato una passata in questa direzione di calcolo forward immaginate di avere una rete neurale abbiamo dato preso il nostro input abbiamo assegnato dei valori ai nostri pesi abbiamo effettuato un calcolo siamo arrivati in fondo con un valore passata forward da quella abbiamo costruito la funzione di costo che è questa f che è funzione anche dei vari parametri a questo punto come si fa per calcolare la derivata rispetto agli input di questo grafo computazionale siamo qui in fondo e vedrete che quello che facciamo è tornare indietro quindi andare indietro e mettiamolo in arancione quindi faremo vedrete una passata backward tornaremo indietro da cui il termine back propagation quindi una retro propagazione ok in cui progressivamente vedrete che andiamo a calcolare il gradiente di ogni output di questi nodi del grafo computazionale rispetto ai suoi input e questo viene fatto vedrete in maniera molto semplice sfruttando che cosa? sfruttando il fatto che nella passata forward in realtà io implicitamente ho potuto calcolare anche questo cioè quando io faccio una passata forward mi rendo subito conto di una cosa che siccome ho scritto q come x più y posso subito andare a calcolare che cosa? la derivata ve la metto qua vediamo un po' ve la scrivo dove ha un po' meno fastidio se tu dove la scrivo in blu e ve la metto qui allora vi dicevo possiamo subito calcolare che cosa? noi la derivata di q rispetto a x perché questo ho un operatore elementare di cui io so tutto e quindi la derivata di q rispetto a x questa me la calcolo la vado a vedere in una tabella di operatori elementari io so che la derivata di q rispetto a x quanto vale? y ok ci siamo? allora q abbiamo detto che x più y giusto? ok quindi se voi fate la derivata rispetto a x il termine di y è 0 quindi la derivata di q rispetto a x è 1 ok e analogamente avete che la derivata di q rispetto a y vale 1 siamo d'accordo? nel momento in cui poi faccio l'altro operatore posso subito vedere che la derivata è calcolare alla derivata di f rispetto a q che vale? quanto vale la derivata di f rispetto a q? z esattamente e posso calcolare anche la derivata di f rispetto a z che vale viceversa q siamo d'accordo? ok noi quello che sappiamo è questo sappiamo che abbiamo fatto il nostro calcolo forward sappiamo queste derivate che sono le derivate degli output rispetto agli input questo lo sappiamo perché abbiamo scomposto il grafo sono tutte operazioni elementari di ognuno di queste sappiamo calcolare queste derivate elementari queste le impostiamo e le possiamo anche calcolare direttamente mentre andiamo andiamo in avanti a questo punto come vi dicevo comincia l'operazione backward cioè si torna indietro il back propagation e si torna indietro in questo modo si comincia a calcolare come primo passo la derivata di f rispetto a se stesso cioè la derivata di f rispetto a f che è la prima cosa che si va a fare 1 la derivata di f rispetto a f quanto vale? 1 chiaramente e quindi qui ci mettiamo un bell'1 dopodiché a partire da questa io posso andare a calcolare la derivata di f rispetto ai suoi due input cioè ogni nodo calcola la derivata parziale rispetto ai nodi di input in particolare posso calcolare la derivata di f rispetto a q e la derivata di f rispetto a z allora la derivata di f rispetto a z quanto vale? io siccome lo so che l'abbiamo visto prima la derivata di f rispetto a z vale q posso subito scrivere che la derivata di f rispetto a z vale quanto? q l'ho calcolato nel passo forward vale 3 e qui ci vado a mettere 3 quindi questa la derivata di f rispetto a z è un 3 che vado a scrivere qua posso anche calcolare la derivata di f rispetto a q quanto vale questa derivata di f rispetto a q ed è il mio passo 3 la derivata di f rispetto a q abbiamo detto che vale z z io l'ho calcolato quindi lì sopra ci posso andare a mettere la derivata di f rispetto a q vale z che vale abbiamo detto meno 4 esattamente quindi questo vale meno 4 e quindi qui ci andiamo a mettere il nostro meno 4 ok adesso andiamo di nuovo indietro z ci siamo arrivati siamo già qua perché ho calcolato la derivata della mia funzione di costo rispetto a questo parametro quindi lì sono a posto qui ancora no devo tornare indietro ho un nuovo un nuovo gate un nuovo nodo del mio grafo computazionale di nuovo posso ripetere lo stesso gioco cioè io posso andare a calcolare la derivata me la scrivo qua in passo 4 la derivata di che cosa di q rispetto a x e la derivata di q rispetto ad y come faccio ecco fin qui non l'abbiamo utilizzato ma qui siccome cominciamo a essere un in cui abbiamo eravamo l'uscita e i suoi input qui siamo uno step indietro e allora cominciamo a utilizzare la regola di derivazione a catena cioè la regola di derivazione delle funzioni composte perché la regola di derivazione delle funzioni composte vi dice che cosa che la derivata di f ad esempio rispetto a y noi la possiamo scrivere come derivata siccome allora abbiamo che cosa che f è una funzione composta di di y e di x attraverso q quindi noi la possiamo scrivere come la derivata di f rispetto a q per la derivata di q rispetto ad y questo ve lo ricordate dai corsi di analisi matematica sì però vi ricordate che c'era ok quindi se la andate a vedere questa la ritrovate ok va bene però però ci siete ci siete ok qui per esempio per far arrabbiare un po' i matematici ricordarsi è una cosa solo mnemonica potreste dire che questi non glielo dite mai ovviamente perché è una cosa che da un punto di vista matematico è un'assoluta non sta né in cere né in terra però questo delta q di fatto è come se si se si elidesse no quindi da un punto di vista proprio del di come memorizzare questa informazione e rimanete con df di y non va bene però proprio ripeto sono un trucco mnemonico perché in realtà questi non sono chiaramente delle cose sono la notazione della derivata per cui non li potete cancellare come se fossero delle frazioni però è la regola di derivazione a capire quindi questa è la regola di derivazione delle funzioni composte ok allora a questo punto però guardate la cosa bella che io df di q l'ho calcolato precedentemente mentre sto risalendo perché l'abbiamo calcolato prima e vale meno 4 dq di y l'abbiamo calcolato quando siamo scesi perché una di quelle cioè è la derivata di questa porta rispetto di questo nodo rispetto ai suoi input e l'ho calcolato prima vale 1 quindi ho meno 4 quindi devo fare che cosa abbiamo detto df rispetto a dq per dq rispetto a dy allora df rispetto a dq l'abbiamo calcolato prima e vale meno 4 ok di q rispetto a dy la derivata di q rispetto a y l'abbiamo calcolata qui e vale 1 quindi questo vale meno 4 e quindi io qui ci posso andare a mettere meno 4 stessa cosa posso fare con x di nuovo applico la regola di derivazione a catena e attengo la derivata di f rispetto a q per la derivata di q rispetto a x e il risultato in questo caso è meno 4 per la derivata di q rispetto a x che vale sempre 1 quindi di nuovo meno 4 e a questo punto io potrei andare se avessi altri strati sarei di nuovo andato indietro con questo meccanismo e e questi tre valori sono esattamente cioè meno 4 meno 4 e 3 sono esattamente i tre valori del gradiente della funzione nel punto meno 2 5 4 e se voi andate a fare i conti analiticamente vi accorgete che è esattamente quello che abbiamo fatto però questo la costruzione del grafo computazionale il passo forward e quello backward sono quelli che costituiscono appunto lo satura il principio di funzionamento appunto della retropropagazione e il principio di funzionamento della retropropagazione è come vi dicevo alla base dell'addestramento delle reti numerali cioè dentro TensorFlow PyTorch Jax eccetera c'è un modulo dedicato alla differenziazione automatica che fa questo prende una qualunque espressione di funzione di costo la scompone file parsing la scompone in chiaramente noi qui per far capire che cos'è vi ho preso un esempio estremamente che non è nessuna nessuna funzione reale insomma relativa a una rete neurale a una funzione di costo di una rete neurale però voi immaginate di trasporre questo meccanismo in quell'ambito abbiamo la costruzione di un grafo computazionale quel grafo computazionale ha degli input che sono i dati effettivi perché poi voi ci dovete vedere qui non solo i parametri ma anche l'input gli arriva un input che è l'esempio del vostro dataset con quell'input che è l'x del vostro dataset con i pesi w voi costruite una funzione di costo esattamente in questo modo ne costruite il grafo computazionale fate una passata forward per ottenere l'output del risultato e quindi la funzione di costo e poi risalite questo grafo computazionale all'indietro e alla fine vi ritrovate con questa tecnica che vi ho detto vi ritrovate la derivata di ogni della funzione rispetto a ognuna delle varianti no il vantaggio di tornare indietro è proprio il fatto che io riesco a calcolare io potrei calcolarle anche mentre vado avanti ma in questo caso lo faccio in maniera più efficiente rispetto a fare solo la passata forward e indietro il vantaggio è che appunto io vado mentre torno indietro riesco a calcolare tutte le derivate di ogni output quindi all'uscita da un nodo rispetto ai suoi due input e poi comporre tutti questi risultati fino a risalire all'ingresso alla variazione quella che è la variazione di f rispetto a ognuno dei parametri questo adesso vi scrivo un'interiore generalizzazione che stiamo facendo è una cosa che di fatto vi dice che se se rappresentiamo ognuno di quei nodi ripeto come un'operazione elementare che fa una certa funzione quindi prende una serie di input quindi ad esempio un input x e altri input un altro input y e calcola un valore z come in questo caso supponiamo una funzione di x e di y no via ok il punto di poter essere somma moltiplicazione non funziona elementare eccetera che cosa abbiamo visto abbiamo visto che da qua gli arriva allora questo forse era meglio farlo di un altro colore e lo facciamo così facciamo così l'abbiamo fatto solo con due input ok allora nel momento in cui facciamo il passo forward qui mi arrivano quelli che nella slide precedente in altra lavagna avevamo scritto in verde e sono gli output il calcolo degli output ok quindi lui calcola il suo bravo valore di z dopodiché da qualche parte a valle gli tornano indietro adesso qui mi sovrappongono un po' i colori però gli tornano indietro quelli che avevamo dipinto in arancione i gradienti della funzione di costo della nostra loss rispetto a z cioè da valle noi arriviamo in questo punto e sappiamo quanto vale la derivata parziale di L rispetto a z per come siamo per come abbiamo costruito il nostro procedimento e quello che facciamo è a partire da questa con la derivazione legge di derivazione a catena quello che riusciamo a costruire è la derivata di L rispetto a y che avrà una certa espressione e la derivata di L rispetto a x e poi riendiamo indietro quindi quello che vediamo è che qui arrivano i gradienti diciamo qui mentre ho fatto la passata in avanti io sono stato in grado di calcolare che cosa quelli che vengono chiamati i gradienti locali quindi la derivata di z rispetto a x e la derivata di z rispetto a y giusto? è un operatore atomico io dico l'operatore atomico su tutto quindi quando scendo calcolo d z di x e d z di y quando torno indietro ho come input d L di z e posso calcolare d L di x e d L di y come come ad esempio se voglio d L di x me la scrivo con il colore spero coerente con la slide precedente posso scrivere d L di x come d L di z per d z per d z di x e analogamente d L di y come d L di z per d z di x ok? allora questi che sono questo e questo ok? scusatemi questo chiaramente è un y non è un x ok? questi sono vengono chiamati gradienti locali sono quello che io conosco perché l'ho fatto la passata in forward li ho calcolati li posso calcolare perché conosco l'atomo e so che cosa fa quel tipo di operazione il risultato che io ottengo cioè d L di y e d L di x lo calcolo con la regola di derivazione a catena a partire dai gradienti locali e dal gradiente che mi arriva da valle che è d L di z questo se ci pensate è un procedimento del tutto generale che potete applicare a qualunque funzione di cui voi volete calcolare i gradienti e quello che ottenete sono dei gradienti esatti non approssimati con come se approssimassimo il limite del rapporto incrementale ed è un metodo estremamente ingegnoso e vi dicevo prima l'articolo che ha descritto l'algoritmo in bad propagation applicato alle reti neurali per la prima volta nel 1986 e uno dei tre autori se non ricordo male è un articolo che è apparso su Science uno dei tre autori è Geoff Hinton che quest'anno ha ricevuto il premio Nobel per proprio per i suoi contributi sulle reti neurali premio Nobel per la fisica tra l'altro per questo ma anche per altissime diciamo poi il fatto di riuscire a implementare questo meccanismo ripeto in maniera sistematica in una libreria coerente e funzionante è stato una delle chiavi di successo dell'avvento del deep learning negli ultimi anni bene torniamo adesso alla la nostra la nostra slide ok quindi diciamo sul back propagation potremmo stare ancora di più ma credo di avervi fatto dato un'idea del come del come funziona quindi diciamo mi interessava lasciarvi un po' di input su questo questa slide appunto una delle conclusive invece un un'altra parla di un altro problema del fatto che le reti neurali in particolare le multistrato ma tutte le reti neurali qui c'è scritto le multistrato scusate non le dense quindi quelle con più quando parliamo di deep learning ecco parliamo abbiamo detto di funzioni di costo e le funzioni di costo delle reti di deep learning sono tipicamente altamente non convesse cioè a differenza di alcune funzioni che abbiamo incontrato quando abbiamo parlato di classificatori lineari regressori lineari in cui abbiamo detto se prendiamo un certo tipo di funzione abbiamo una bella proprietà di convessità quindi abbiamo garanzia di avere un minimo globale quindi lo andiamo a trovare in qualche modo con un metodo iterativo qui siamo di fronte a dei profili di funzioni di costo che sono estremamente estremamente non convessi e i metodi di ottimizzazione questo in qualche modo lo devono ne devono tener conto allora queste due figure sono due figure che sono state generate anche qui sono in un articolo scientifico che è apparso 3-4 anni fa non è vecchissimo in cui hanno studiato un po' di funzioni di costo quelle più utilizzate nelle reti neurali e poi hanno trovato il modo per fare riduzione della dimensionalità di queste funzioni di costo esattamente con le tecniche che un po' abbiamo avuto modo di vedere durante il corso con alcune di quelle tecniche e sono riusciti quindi la funzione di costo è una funzione di n parametri ok se io faccio riduzione della dimensionalità in tre dimensioni questa funzione di costo diciamo ho chiaramente perdita di informazione però posso provare a visualizzarla per cercare di capire come in funzione di tre parametri rappresentativi che sono tre direzioni lungo le quali io vado a proiettare la mia funzione di costo posso provare a vedere che cosa succede e andarla a graficare e questo è quello che hanno fatto con alcune funzioni di costo su alcune architetture di reti neurali specifiche adesso non mi ricordo queste due a che cosa si riferissero non l'ho notato però quello che hanno ottenuto vedete una cosa di questo genere quindi se immaginate di dover ottimizzare una funzione di tre variabili in realtà lì sono molte di più avreste una cosa di questo genere che vedete è un profilo estremamente estremamente frastagliato e se voi andate e vi collocate pensate immaginate di scendere da questo punto iniziale in cerca di un minimo locale è il punto che andate vi fermate qui e qui siete rimanete intrapolati quello che trovate quindi magari ripartite ripartite da un altro punto generato casualmente e vi bloccate qua e prima di arrivare qua giù in fondo ce ne sono insomma di tentativi forse da fare questo è lo stesso un altro esempio simile allora in realtà la cosa bella è che al di là di alcuni esempi molto particolari patologici diciamo e molto sfortunati quello che si vede si riscontra nella pratica che le reti neurali hanno tanti di questi minimi locali perché sono altamente non convesse però di fatto se voi cominciate ad addestrarli vedete che trovate un minimo che ne so vi trovate in una zona che può essere questa trovate questo minimo locale e quindi vi si ferma l'addestramento poi magari ripartite e rifate quest'altro trovate quest'altro quest'altro ancora vedete questi qui per esempio sono tanti minimi locali ma non differiscono di tanto quindi a meno di casi molto particolari in cui ecco qui per esempio c'è questo che è marcatamente inferiore però anche tutta questa zona qua pur essendoci molti minimi non differiscono molto in realtà di loro questo significa che nel momento in cui voi addestrate la rete e trovate uno di quei minimi o un altro minimo che sta da queste parti il valore della funzione di costo non è così drammaticamente diverso e quindi vi va bene comunque quello che riesce a fare la vostra rete quindi l'avete addestrata e trovate comunque un valore più che dignitoso ok quindi le reti neurali è vero che hanno una forma non convessa con un profilo molto frastagliato con tanti minimi locali è anche vero che molto spesso molti di questi minimi locali sono tali per cui ci va bene quello che riusciamo a trovare ci va bene perché riusciamo a trovare un buon valore comunque del minimo non è molto diverso da quello che riusciremo a fare se facessimo di meglio e soprattutto non dobbiamo dimenticare che questa è la funzione di costo noi minimizziamo questa perché vogliamo poi minimizzare l'accuratezza per esempio se vogliamo costruire un classificatore il nostro intento è costruire un buon classificatore e per fare questo passiamo attraverso questa funzione di costo ma non c'è scritto da nessuna parte che questo e questo siano così drammaticamente diversi da un punto di vista dell'accuratezza certo uno sarà un po' migliore dell'altro l'altro un po' peggiore ma tipicamente non sono così diversi e quindi questo però vi dice anche che c'è tutta un'attività di ricerca che attiva nei metodi di ottimizzazione quando la volta scorsa vi ho fatto vedere la documentazione di TensorFlow vi ho detto guardate quanti solver quanti ottimizzatori potete specificare potete specificare ADAM RSPRO potete specificarne tanti e perché anche qui quasi quotidianamente ci sono appunto persone che producono perché studiano prima e poi producono lavori scientifici con nuovi metodi di ottimizzazione che provano a districarsi all'interno di panorami di questo tipo va bene siete riusciti a seguire il filo del discorso ok e ok qui c'è un'ultima un'ultima slide che vi fa vedere cosa vuol dire cambiare anche qualche volta l'ottimizzatore perché da un lato vi ho detto guardate è vero che è molto frastagliato quel profilo ma è anche vero che ci va bene tutto sommato anche trovare un minimo locale che non sia proprio il non dico il globale ma anche rispetto ad altri può essere un po' più alto ma di solito non è tanto più alto è anche vero che qualche volta cambiando semplicemente l'algoritmo di ottimizzazione cambiano di molto le prestazioni qui c'è un esempio in cui avete 50.000 punti da quel dataset MNIST che abbiamo utilizzato la volta scorsa nell'esercitazione è stata costruita una rete neurale a quattro strati con 10 unità per ogni layer noi avevamo fatto uno solo se non sbaglio con molti più con 128 anche qui potete provare a vedere che cosa cambia se volete un po' divertirvi a cambiare appunto l'architettura di rete funzioni di attivazione tangente iperbolica funzioni di costo di tipo SOP, MAX, multiclasse approccio batch e mini batch con dimensione 200 e qui vedete che cosa succede quando questo è il batch e questo è il mini batch dovrebbe essere e sono stati provati tre tipologie diverse di ottimizzatore il primo è un disceso del gradiente standard e guardate che rimane qui costante questo è il costo e questo è l'accuratezza quindi questo è il valore della loss function qui comincia a scendere lo standard utilizzando l'approccio mini batch però scende più lentamente degli altri due perché gli altri due cosa sono? la curva in blu è un un disceso del gradiente normalizzato normalizzato componente per componente il normalizzato vi permette di non rimanere è meno sensibile al fatto di rimanere intrappolati in zone a gradiente basso quindi è una feature in più che ha il vostro algoritmo che vi permette in qualche modo di procedere anche quando il gradiente comincia un po' a spianarsi a diventare nero rmsprop è uno di quelli anche questo più utilizzato a pari di adam perché ha tutta una serie di ottimizzazioni che riguardano non solo appunto l'eventuale normalizzazione ma anche il fatto di poter accelerare quindi gli potete specificare per esempio anche un learning rate secondo un determinato schedule eccetera eccetera ha delle feature che lo rendono appunto utile come adam come altri allo stato dell'arte per andare ad accelerare la convergenza e vedete che il risultato è proprio questo se seguite questa curva è estremamente più rapida in funzione del numero di epoche e quindi l'accuratezza anche se fate il mini batch avete la stessa cosa cresce subito il 90% mentre di là dovete comunque aspettare più epoche allora l'ottimizzatore spesso fa la differenza l'algoritmo di ottimizzazione quando parliamo di capacità di convergere di far arrivare il processo di apprendimento rapidamente a convergenza e quindi ad avere una una soluzione valida in minore numero di tempo in minore intervallo di tempo bene allora come potete vedere siamo arrivati all'ultima slide di questo blocco è stata anche qui una questa lezione degli argomenti che abbiamo visto oggi è stata una panoramica una carrellata in cui io ho cercato un po' di condensare alcuni alcuni input per farvi capire che è un mondo molto sfaccettato ci sono tantissime cose e come vi dicevo già altre volte abbiamo la possibilità di usufruire di strumenti che sono molto sofisticati risolvono problemi anche complessi che sono il frutto ovviamente di ricerca in tanti ambiti quindi oggi vedete adesso abbiamo toccato l'esempio gli algoritmi di ottimizzazione prima abbiamo parlato di back propagation che è quello che fa funzionare ognuno di quegli algoritmi di ottimizzazione perché il back propagation che cosa fa? calcolo il gradiente e ognuno di questi aspetti è frutto di attività di ricerca di diversi anni anche di diverse persone e quindi questo per farvi capire che queste cose non nascono dal nulla quindi penso che anche sapere questo insomma sia un po' un valore aggiunto rispetto a chi queste cose le usa e basta perché oggi ci sono e quindi ha come vi dicevo la facilità di utilizzo è una chiave del successo di questi strumenti direi che allora con questo concludiamo proprio la parte di lezione di teoria nella prossima lezione di domani possiamo come vi dicevo vediamo come organizzare adesso vi dico qualcosa in più ma possiamo fare un quadro generale una sorta di diciamo di ricevimento se vogliamo su domande specifiche se avete dei dubbi o cose di questo tipo adesso vediamo un po' come organizzarsi ma la parte diciamo di lezione teorica che si conclude oggi con questi argomenti quindi qui di fatto concludiamo il corso come lezioni e come contenuto di queste lezioni e niente spero insomma che vi sia piaciuto o perlomeno sia riuscito a interessarvi a farvi capire qualcosa di più e niente con questo direi che concludiamo intanto mi fa piacere che siamo riusciti piano piano a partire eravamo un po' di meno magari ci siamo ritrovati un po' di più in aula questo è stato più gratificante direi per tutti sicuramente lo è stato per me quindi niente vi faccio anche ovviamente gli auguri in bocca al lupo per l'esame fate un buon lavoro già ho visto che alcuni di voi sono all'opera quindi ho visto che alcune cose che mi avete fatto vedere già secondo me vanno in quella direzione se c'è qualunque poi dubbio che avete sulle fasi esame ecco mi raccomando questo chiedete scrivete un'email insomma da questo punto di vista siete pochi e quindi riesco ancora a gestire anche il flusso di informazioni che o di richieste che arrivano e basta direi che intanto blocchiamo la registrazione di questa ultima lezione per quest'anno accademico diciamo è tutto poi invece domani facciamo una sorta di ricevimento barra lezione di diciamo di riepilogo a disposizione diciamo di quelle che possono essere vostri video curiosità sì Grazie.