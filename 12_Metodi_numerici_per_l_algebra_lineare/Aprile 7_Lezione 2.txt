ok adesso devo tre il microfono ok allora quindi questa volta ha lasciato questo perché così possiamo iniziare esattamente dove eravamo rimasti quindi prima abbiamo introdotto questa idea del metodo di stazionari per la risoluzione di sistemi lineari iterativi e abbiamo introdotto questa idea di splitting algebraico che sono l'identificazione di due matrici P e N tra cui possiamo definire una iterazione che ha questa forma e idealmente converge con più e più k alla soluzione desiderata del sistema il primo splitting come abbiamo visto è importante uno che P è invertibile ovviamente perché dobbiamo fare l'inversione di P quindi qualsiasi scelta di P deve essere per forza invertibile però anche vogliamo che P visto che la maggior parte della fatica computazionale viene a questa inversione di P e vogliamo che P in qualche modo è facile risolvere perché se sia troppo difficile ad un certo punto c'è la domanda perché non semplicemente risolvere il sistema direttamente anziché utilizzare questa tecnica iterativa poi abbiamo visto le due tecniche del genere fondamentali che sono il metodo di Giacobi in cui selezioniamo come il nostro matrice facciamo anche in cui facciamo l'inversione gli elementi diagonali di nostra matrice A poi con matrice N prendiamo tutti gli altri elementi in queste matrici e facciamo questa iterazione in cui facciamo di nuovo e di nuovo l'inversione di D aggiornando nostro X fino a che raggiungiamo la convergenza e per matrici che sono diagonalmente dominanti si può dimostrare che questo metodo converge in generale è difficile pensare di tipo una classe dei problemi o per quelli in cui possiamo garantire che Giacobi converge forse sì, forse no in generale per queste cose è il migliore che si può fare però poi abbiamo visto questa forma che veramente spiega diciamo il motore dietro questo metodo è tutto contenuto in questa idea che questa matrice P quello che facciamo di nuovo e di nuovo in versione se questa matrice P può in qualche modo approssimare l'inverso di A possiamo allora sperare sia che converge e poi anche che converge velocemente perché ok una cosa può convergere ma può anche farlo lentamente quindi vogliamo non ovviamente vogliamo che converge poi idealmente non solo che converge ma anche che converge converge abbastanza facilmente e velocemente quindi il metodo di Gauss Seidel cerca di migliorare quel metodo di Giacobi e si distingue dal metodo di Giacobi nella scelta di queste matrici PN che qui utilizziamo nella forma preangolare basso anziché solo il metodo di elementi diagonali della matrice A tutto questo sua parte triangolare inferiore basso e poi anche banalmente naturalmente se volessimo potevamo anche definire questo utilizzando la parte triangolare superiore non cambia tanto dal punto di visto numerico è sempre lo stesso livello di lavoro di fatica quindi la scelta di quale dovremmo utilizzare probabilmente dipenda dal problema ad esempio se abbiamo un problema del genere una matrice di questa forma probabilmente dovremmo utilizzare quello triangolare superiore quindi spesso diciamo la scelta di quale dovresti scegliere può essere informato anche dal semplice intuizione come vediamo qui probabilmente se dovessimo scegliere tra le due opzioni quello triangolare basso o quello triangolare alto quello basso e quello alto in questo caso sarebbe più adatto allora c'è una classe di matrice per cui possiamo garantire la convergenza di Gauss Style e fortunatamente anche se non sono ancora generali non sono ancora ubiquiti non è che tutte le matrice soliscono questo corrisponde una parte di sistemi abbastanza comune molto più comune di quelli diagonalmente dominante è che il metodo Gauss Style sia la sua forma triangolare superiore che triangolare inferiore converge che è per tutti ma qui ci ha simmetrica positivo definito quindi se ha è simmetrica cioè uguale al suo proprio trasporto e anche se questa espressione è trasporto a x è sempre positivo per tutti i vettori x che non sono zero questo è quello che significa per essere simmetrica positivo definito se questo è vero allora possiamo garantire la convergenza del metodo Gauss Style anche in questo caso vi dico che non fa una differenza se usi la forma triangolare inferiore o superiore perché? perché è simmetrica quindi è la stessa cosa è solo una questione di quale ordine vuoi risolvere le cose però in generale allora quindi abbiamo visto che Giacobbi converge per i sistemi diagonalmente dominante che Gauss Style converge per sistemi simmetrica definito positivo diciamo tutte queste sono cose non sono cose comprensive cioè è possibile trovare tantissimi sistemi di per cui non sono simmetrica definito positivo per cui Gauss Style converge o che non sono diagonalmente dominante per cui Giacobbi converge tipo non ci sono tantissime cose che sono quello tipo se è solo se in questo nessuna di queste cose sono se è solo se quindi non sto dicendo che questo funziona solo nel caso di matrici SPD allora quale sarebbe la condizione se è solo se e questo è il punto che ho detto che avrei rivisitato che l'abbiamo prima vista settimana scorsa ma ho deciso di rientrodurlo oggi perché pensavo che forse andava meglio prima dare un po' un'idea concreta di quello che vogliamo fare poi introdurre una teoria quindi quale quando convergenza di metodi stazionali ok e questa è la teorema sia a uguale a p meno n un splitting allora la sequenza xk più 1 uguale al t inverso n xk b converge a x che lo chiamiamo la funzione x stella diciamo la funzione del nostro sistema quella che vogliamo converge a questo se il raggio spettrale è il nostro interesse il me fix che vogliamo scrivere o di o di e meno di uno questo è un realtà è un sì se è solo te quindi questo è la condizione necessario è sufficiente per garantire convergenza però non parola dimostrazione in tutte due direzioni lo farò solo ok e come procediamo allora assumiamo che raggio spettrale di p meno p verso 1 meno di 1 quindi esiste qualche norma matriciale tale che a tale che possiamo garantire che esiste qualche norma matriciale strettamente meno di uno questo perché ricorda il raggio spettrale che è definito come il massimo un valore assoluto dei alto valori di P verso A questa è la definizione spettrale è l'infino di tutte le norme matriciali quindi tra tutte le funzioni che possiamo chiamare un norma matriciale di P verso A questo raggio spettrale è l'infino di questo di tutte le possibili normi matriciali e quindi in particolare c'è almeno uno che è una norma che possiamo garantire è meno di allora quindi io darò un attimo questo e mentre faccio la concilazione qui sì sì ma sembrava che l'ultima volta non è andato molto bene quindi ho deciso che sarebbe andato meglio se prima darsi qualche esempi concreti di questo splitting di che cosa stiamo facendo e forse fare questi esempi di prima di fare la dimostrazione spero che questo sia una buona idea quale questo è il se e solo se questo raggio spettrale questo corrisponde a valore assoluto del valore tipo dell'alto valore più grande valore assoluto di una matrice e raggio spettrale è un pro sì è un pro sì lo provato a renderlo un pochino ok allora quindi abbiamo nostro sequenza così ok esatto sto facendo la dimostrazione voglio dimostrare che se abbiamo questo condizione qua che possiamo garantire che questa sequenza qui converge e non solo che converge ma anche converge alla cosa che vogliamo cioè la soluzione al sistema quindi adesso quindi qui ricorda che abbiamo che B è uguale a A per nostra soluzione desiderata quindi facciamo questa sostituzione questo semplicemente perché A è uguale a P meno N quindi abbiamo solo sostituito questo in cui questa stella è la soluzione che vogliamo ok adesso facciamo l'inversione di P più stella meno il inverto N stella ok e quindi come lo possiamo vedere qui adesso quello che voglio fare porto quella stella al lato sinistro e qui siamo rimasti con sul lato destro così è solo tipica algebra della matrici e i vettori ok adesso utilizziamo questa norma qua quello che abbiamo garantito che la norma di questa matrice risultante è meno di uno quindi abbiamo ok poi adesso utilizziamo una proprietà delle norme matriciali uno quello che ci permette di fare questo posto potto ok ok questo è vero comunque per ogni capa quindi se prendiamo capo uguale 1 1 a 0 significa che questo sarebbe vero allora per la prima interazione che facciamo allora sarebbe ugualmente vero allora se facciamo adesso la seconda interazione sarebbe meno di uguale a di x1 meno x stella però poi da quello che abbiamo visto qui abbiamo che questo qua è meno di uguale a questo cioè e penso che adesso forse vedete l'idea che voglio dire qui e possiamo consigliere a quel rapporto ok sì di schermi il invecchio abbiamo che questo è sempre l'errore a il capo più uno tra il nostro interazione e la soluzione desiderata e stella è sempre meno di un po uguale a la norma di questa cosa qua non mi fa il mercato è molto più l'errore del nostro iniziale nostro quello che abbiamo usato per iniziare l'interazione e quindi adesso ricordiamo questo che questo norma matriciare la p verso n e meno di uno e quindi quello che possiamo concludere è che mentre il capo va all'infinito questo va a zero quando k va all'infinito questo non cambia semplicemente non troverò iniziale quindi non va niente quindi sei una cosa zero moltiplica un'altra cosa che non cambia qual è il risultato zero allora perché questo è meno di uno quindi una cosa se prendiamo un mezzo al potere due milioni cosa sì perché meno di uno questa è perché questo condizione qua e così importante questa è la cosa fondamentale è la condizione che stabilisce precisamente quando un metodo algoritmo del genere in cui facciamo la spezziamo la matrice in questi p e n per definire questa interazione può funzionare solo quando il raggio spettrale di questa matrice di interazione p verso n che lo stamattina ho detto questa è la matrice di interazione eccetera perché questo oggetto è importante p verso n quando questo ha tutti gli autovolori meno di uguale a 1 valore assoluto allora quando questo va all'infinito potiamo dire che la differenza tra la nostra soluzione ottenuto con questo metodo e la soluzione vera quella stella che questo va a zero quindi in questo caso in cui in un raggio spettrale delle tre della matrice di interazione e meno di uno possiamo garantire sia che la soluzione converge a quello che vogliamo e anche che sia sia che converge e anche che converge alla cosa proprio che vogliamo cioè la soluzione del sistema vediamo un'altra cosa qui si si ma ma cosa questo è la cosa importante tipo se abbiamo un teorema del genere non dobbiamo fare un punto per la posizione vera se sappiamo che questo è vero sappiamo che il portiere sarà la soluzione vera non c'è un'altra cosa qui potrebbe convertere tipo in realtà ragione che tipo come confrontiamo come confrontiamo per questo è importante che una teorema del genere esiste che garantisce non solo che converge ma anche che converge alla cosa che vogliamo perché possibile per perché la teoria è importante per darci queste garanze non so se questa non so se questa ma la risposta corta è che non in generale non possiamo assumere che abbiamo questo è ovvio negli esempi che vedremo in questo corso per motivi didattici forse avremo la soluzione vera solo per dimostrare quanto bene funziona ma no in realtà non abbiamo questo però possiamo non abbiamo questo però possiamo vi darci della teorema di convergenza che quando questa cosa è finita di fare interazioni che è la soluzione che vogliamo si il fatto che la norma di di di di di di di di di di di di di di di di di di di di qualcosa di madre te di vår e Fala che però mi ha però mi chiamiamolo per ogni matrice m possiamo dire questo questo vale per ogni m questi costanti sono sempre identi ok e il punto di questo che cos'è? Il punto è questo in un certo modo stiamo dicendo che se puoi dimostrare una cosa utilizzando una norma in particolare come l'abbiamo fatto qui perché abbiamo detto che questo raggio spettrale ci garantisce che c'è almeno una singola norma che solisima questo questa condizione è un modo formale di dire una cosa semplice se una cosa così è vero per una norma è vero per tutte le norme quindi tipo basta che dimostriamo questo per questa scelta di norma e tipo per tutte le norme deve essere anche vero perché possiamo sempre dire che possiamo limitare sia da sotto che sopra se adesso abbiamo ad esempio la norma 2 diciamo quindi adesso diciamo che questo è la norma 2 e questo qua è la norma della nostra dimostrazione possiamo sempre dire che allora se questo così che possiamo sempre dire che allora dobbiamo riuscire a sempre mettere nel mezzo del panino questa norma 2 quindi questo lo utilizziamo per garantire questa condizione alla norma ma grazie a questa proprietà che non è possibile essere messa in qualche rapporto equivalente che possiamo sempre prendere una norma e limitarlo sia da sopra che sotto con un altro basta farlo per un singolo norma e tutti i resti seguono capito? ok ok ok ok e questo sarebbe stata una domanda utile di tipo perché mi ricordo quando ho visto questo per la prima volta pensavo di bocchè ha dimostrato che questo converge in questa norma però poi ho imparato ok ma sì perché sono equivalenti e significa che se fai per uno o fai per tutti allora quindi questo è una condizione che ci serve che ci garantisce quando la cosa è vera è ovvio che è difficile guardando d'occhio un splitting di una matrice se questa cosa sia vera o no quindi però in alcuni casi come abbiamo visto con come Gassai e Giacobbi è utile anche avere qualche altra condizione che potrebbe essere forse più facile di interpretare cioè ad esempio l'idea che se è diagonalmente dominante di solito questo sarà più facile di controllare ogni approvatore però questa è in generale la condizione che vuoi fare ok c'è un'altra cosa però che veniamo qui che questo ci dice una cosa che riguarda non solo il se ma anche il come nel senso che se questo sia meno di uno converge però è evidente che tipo quanto è grande quanto meno di uno lo è è anche importante se tipo punto 9999 potrebbe essere molto lento questa convergenza se punto 0001 potrebbe essere quasi immediato questa convergenza quindi se questo è meno di uno garantisce che converge ma quanto meno di uno esattamente è una questione importante che determina non solo se converge ma anche quanto veloce converge e parleremo più di questo tra un attimo adesso adesso volevo vediamo se ok voglio parlarvi di questo ehm sì dovrei dovrei parlare di questo anche semplicemente perché è un pochino ok sì parliamo di questo ok c'è un altro modo di stesso questa questione di tipo ok è meno di uno ma quanto meno di uno forse è meno di uno ma è ancora vicino di uno significa che la cosa potrebbe convergere ma forse non in un modo molto efficente quindi potrebbe potrebbe come si dice spingere la domanda se abbiamo una cosa che converge diciamo sappiamo che converge ma non molto veloce e c'è qualche trucchetto che possiamo sfruttare per farlo forse convergere un po' più veloce e questo è uno di questi trucchetti che si chiama il metodo di rilassamento e questo è una modificazione di una schema iterativa stazionaria che vale allora assumiamo assumiamo che a uguale a e poi questo è meno di uno quindi il metodo converge quindi allora quindi allora adesso voglio un attimo fare una manipolazione qui per riscrivere questo in questa forma qua cioè no secondo me questo è un modo perfettamente giusto sto provando quale sarebbe il modo migliore di ok facciamo così ok lo riscriviamo questo in questo modo P meno A XK più B che poi ci riporta a XK più 1 è uguale a XK meno P inverso A XK più P inverso B uguale a XK più P inverso B meno A XK oppure XK più P inverso R A ok allora cosa voglio fare qui se se questo converge perché questo converge possiamo dire che questo termine va a zero con che all'infinito questa era un'ipotesi abbiamo assunto che questo schema o algoritmo del soluzione interattivo fosse convergente R è residuo e questo residuo questo è questo modo perché allora quindi questa notazione lo utilizzeremo spesso quindi abituarvi a questo R che significa il residuo quindi R che è sempre B nel nostro A X uguale B meno A X K che si si abbiamo assunto questo quindi stiamo assumendo qui come ipotesi che il rosa con il già converge si esatto esatto questo ma questa era un'ipotesi tutto ciò che sto dicendo non vale un cavolo se la cosa non è bello che non volevo essere troppo estremista ma in generale perché è vero che questo in alcuni casi può rendere alcune cose non convergente convergente ma in generale assumiamo che convergente perché altrimenti non ha tanto accento è più tipico ok ok cosa voglio dire con queste cose che è zero però stiamo assumendo che converge e quindi il punto è questo se converge se abbiamo più quello che significa è che questo tendrà a zero ok e cosa voglio dire con questo cerchiamo adesso di fare questa definizione qui oh oh è oh e facciamo questo ok forse state pensando che ho che ho cambiato l'equazione ho aggiunto una cosa ingiusto e ho fatto una moltiplicazione ingiustificato che dico adesso non è una cosa consistente perché non ho fatto nulla qui ma l'ho cambiato questo da un senso hai ragione dall'altro lato però no perché perché questo abbiamo assunto dall'ipotesi quando K va all'infinito questo comunque non contribuisce niente e quello che rimane allora sarà questo che esattamente quello che vogliamo tipo quello che voglio dire qui è questa cosa che ho fatto qua moltiplicando per questo omega e aggiungendo questo uno meno omega xk non è una cosa tra le due illegale con questa giustificazione abbiamo assunto che questa cosa converge quindi quando che è abbastanza grande questo va via e quindi abbiamo quello che si chiama una perturbazione consistente al sistema e cosa è questo? è questo è il metodo di rilassamento il metodo di rilassamento l'idea è di fare questo proprio qua si può vedervo anche in questo modo se vogliamo utilizzare la notazione di prima questo è equivalente quindi si rilassamento è qui continuo a vedervo così e semplicemente facendo questo anziché fare questo schema direttamente come lo stavamo facendo prima lo aggiungiamo questo perturbazione in questo fattore moltipliciamo questo omega e diciamo questo uno meno omega e questo si chiama il metodo di rilassamento e perché questo è vantaggioso allora si può vedere questo come se vuoi scrivere questo possiamo scrivere questo ma con una attrice di interazione con questa forma qua che sarà questa è la matrice di trazione per il metodo di rilassamento quindi come vedete è un pochino è un splitting dentro un splitting che abbiamo questo fattore di omega tra 0 e 1 e poi questo contropeso 1 meno omega questo è un trucco diciamo che serve in alcuni casi di accelerare il processo di convergenza quindi come avevo detto a volte la matrice di trazione a volte ha questa proprietà in cui è meno di 1 la sua norma ma non tanto meno di 1 e quindi l'idea qui è introduciamo questo peso che ha meno di 1 per rendere ancora più piccolo questo contributo grazie al fatto che possiamo garantire consistenza questo fattore qui aggiungiamo così lo sappiamo che non stiamo rovinando la nostra soluzione e questo da un modo molto pratico e molto facile di capire e di potenzialmente rendere più veloce la convergenza di un sistema allora per ricordarvi qui ho assunto che abbiamo già avuto un schema del genere che convergeva ed è solo che forse volessimo renderlo più veloce la convergenza è vero che in alcuni casi puoi trovare situazioni in cui forse hai una PN che non convergeno da soli e facendo qualcosa del genere puoi farli convergere ma il motivo perché non non ho introdotto così è perché poi questo giustifico che questo va a zero tipo diventa un po' più difficile giustificare questo patto però quindi in generale queste è un diciamo questo è un esempio di come puoi modificare facilmente un algoritmo del genere per renderlo più vantaggioso c'è solo un'altra cosa o no ci sono due altre cose c'è una cosa veloce e un'altra cosa che è un po' meno veloce che voglio parlare la prima cosa veloce che è anche importante ok se ve lo ricordate quando stavamo facendo tipo le basi auto lineare qualche settimana fa abbiamo parlato di matrici ai blocchi quindi matrici matrici a blocchi è una matrice che ha ad esempio questo forma mal questi è una matrice proprio quindi è una matrice composta dei matrici quindi se cosa voglio dire se abbiamo un sistema così quindi non daremo 1 e 2 e anche dividiamo questi vettori ai blocchi quindi abbiamo tutti questi sono vettori sotto vettori quindi questo tipo è un vettore in sé quindi questi sono anche questi vettori sono anche ai blocchi l'idea che volevo dire qui è che possiamo anche estendere questi dei vogliamo anche estendere questi day che abbiamo visto per le matrici normali a 2 a 0 a 1 n a n meno 1 n a 0 allora cosa ho fatto qui l'ho fatto qui una matrice che è diagonale ai blocchi quindi a tutti questi blocchi quindi non necessariamente diagonale esattamente perché questi matrici ognuno di queste matrici non è necessariamente diagonale però è di a questa struttura diagonale ai blocci cioè possiamo risolvere il sistema possiamo vederlo in questo modo come una una matrice che consiste a questi sistemi diagonalmente e poi questi non via e allora l'idea qui possiamo definire ad esempio blocchiavoli in cui possiamo dire che allora è è il quale è quello che in questo caso è il corrisponde alla sottodivisione a blocchi di questo vettore qua quindi non è collegata noi un singolo elemento del vettore e per questo di solito quando scrivo un vettore voglio indicare un singolo elemento non ho questo di solito ma qui questo per significare che ognuno di questi è un vettore da i 1 a 1 n e in questo caso possiamo difficile quando samma so kingdom and man having e ok allora quindi cosa è questo è molto simile in conciutto almeno a quello che facevamo prima ma adesso ognuno di questi blocchi è un sistema in sé quindi per fare ottenere questo blocco ex i a un dato interazione si deve risolvere questo sistema a questo sistema di armare a blocchi questi 122 eccetera eccetera quindi questi sistemi come si risolvono ovviamente dipendere dal problema ma qui bisogna utilizzare qualche tecnica per risolverlo che potrebbe essere anche a sempre non voglio tipo farle test esplorere forse per risolvere c'è alcuni di questi blocchi pure utilizziamo un sistema interattiva un metro interattivo questi si chiamano schemi interattivi molti livelli perché dico dobbiamo risolvere ogni singola blocca con qualche auto o forse a volte tipo ogni blocca possiamo utilizzare un metodo semplice come l e non sono così terribili per ciascuno blocco allora io scrivo una cosa e poi poi poi poi poi poi poi poi poi poi poi poi poi poi poi ofirda poi poi poi poi bite poi poi poi well poi poi poi poi Well contr Riv Fight了 poi Ok, assolutamente non ho nessuna voglia di scrivere un'espressione paragonabile come l'ho fatto per Bloch Giacobi, però guardando questo vedete che è possibile in principio definire una versione a blocchi di Gauss Siren, un sistema se vogliamo guardare un attimo, guardiamo in una situazione in cui è più facile scrivere cose esplicitamente, guardiamo un esempio due per due ai blocchi, quindi abbiamo a1, a1, 2, a2, 1, a2, 2, x uguale a x1, x2, b uguale a 1 di 2. Ok. Sì. Allora, schemi iterativi in molti livelli riferiscono le situazioni in cui abbiamo blocco Jacobi, però poi questo è un blocco che in sé va risolto e quindi si dice un sistema iterativi molti livelli quando poi per risolvere ognuno di questi blocchi diagonali utilizziamo pure una schema iterativo. Quindi puoi immaginare abbiamo Jacobi a blocchi, poi per ognuno di questi sistemi a IE utilizzassimo Jacobi per risolvere pure questo. Questo si chiama un schema molti livello perché si devono risolvere ciascun blocco individualmente con un blocco Jacobi e poi ognuno di questi blocchi individualmente risolviamo con Jacobi. Questa è l'idea di un schema molti livello. Però non è necessariamente necessario, ridondante, non è necessario fare un schema molti livello sempre. Ad esempio potremmo applicare blocco Jacobi facendo il sistema iterativamente nel senso dei blocchi, però con ciascuno di questi blocchi potremmo utilizzare ad esempio LU su quel blocco, mentre ancora mantenendo la struttura di LU a blocchi. Quindi un sistema a molti livello iterativo riferisce a quando si usano iterativi sia per i blocchi, sia tipo per il sistema a blocchi e poi per ciascuno blocco individualmente. Esatto. C'è un'altra cosa di blocco Jacobi, che blocco Jacobi solo recentemente è diventato molto usato. Prima era una cosa che tutti erano coscienti che esisteva, ma nessuno lo usava, ma una cosa super vantaggiosa di blocco Jacobi. E hai tutti quei blocchi che nessuno dipende da nessun altro blocco. Quindi non ho bisogno della soluzione di nessun blocco per risolvere questo. Quindi un grande vantaggio di blocco Jacobi è molto facilmente parallelizzato. Quindi posso tipo mandare questi sistemi individui a blocchi a diversi processori e risolverli separatamente e simultaneamente. Puoi metterli insieme. Questo blocco Gauss-Seidel, nonostante gole della proprietà di convergenza superiore, è meno comunemente usato, perché come vedete non è così facilmente parallelizzato. Perché devo risolvere questo, poi ho bisogno della soluzione da qui per pigliare e metterlo qui per risolvere questo successivamente. Non sono di copiati. Invece con blocco Jacobi sì. Quindi questo è un esempio in cui non voglio introdurre troppi concetti, ma tipo l'analisi numerica è piena di compromessi. compromessi. Cioè voglio fare meno iterazione, ma ciascuna iterazione è difficile, o più iterazione, ma ogni iterazione è facile. Questo con blocco Gauss-Seidel e blocco Jacobi è molto pertinente. Quindi la prima riga è blocco Jacobi e il posto è blocco? Questo è il splitting per fare blocco Gauss-Seidel. Non voglio scrivere tutta questa espressione formalmente. Se vuoi si può trovarla nel libro, per blocco Gauss-Seidel. Sono due cose diverse. Sono due cose diverse, sì. Questo è blocco Gauss-Seidel, blocco GS. Però qui è blocco GS, comunque non faccio il pigrone al 100%. Faremo blocco Gauss-Seidel per un esempio 2x2. Quindi qui avremmo... Ok. E l'idea qui allora è adesso abbiamo... C'è questo, sì, non da più. Abbiamo... Poi abbiamo... Qui, x1, 2x2. Va a... Ecco. 1, 2, k. K più di 1, 2. Ok. Quindi... Allora, abbiamo due sistemi qui. Abbiamo a, 1, 1, x1, k più 1, uguale a ma meno a, 1, 2, x2, k più di 1. Poi abbiamo... A, 1, 2, x1, k più di 1, a, 1, 2, x2, k più di 1, uguale a k2. Ok. Quindi... Prima... Proviamo... Ok. Prima risolviamo questo sistema che è blocco facile. Facile. Questo è l'ultima interazione, lo sappiamo. Questo lo sappiamo. Questo ha 1, 1. Lo sappiamo risolvere. Poi... Possiamo prendere questo, una volta che lo sappiamo, e lo mettiamo. Quindi... Qui... X2, 1, uguale a... A22, A22, inverso, B2, meno, A12, A11, inverso, A12, X2, K, più di 1. 1. Quindi... Questo è esattamente l'idea che con un sistema blocco triangolare si può procedere. Prima dobbiamo risolvere solo un singolo blocco qui per ottenere questo cosa qua. Una volta che questo cosa che abbiamo, lo possiamo inserire questo tipo è ovvio che in pratica non è che facciamo questo di nuovo, lo sappiamo, quindi lo inseriamo. Insegniamo però... Sì, ok. Quindi abbiamo il sistema qui. Esatto. Quindi questo è il sistema scritto così, ok? Prima risolviamo questo. Vedi che qui c'è il nostro incognito. Questa è l'ultima interazione, quindi lo sappiamo. Quindi è eterno. Quindi questo, tutte queste cose qui su destra, lo sappiamo. Quindi l'unica cosa che rimane tra noi e il nostro incognito qui è questa matrice 1. Quindi lo risolviamo e otteniamo. Cosa? Perché? Perché? Perché? Perché? Perché l'ho scritto un po' male, ma c'è questo più di 1 e di 2. Perché il sistema era AX uguale a B. quindi il sistema riscritto qui. Oh no, questo è A2, 1. No. Ok. Perché abbiamo avuto... Questo perché è più B1 e più B2. Perché queste cose facevano a parte del nostro problema iniziale. quindi poi lo facciamo lo splitting in cui questo è il nostro P, questo è il nostro N. Quindi lo trasformiamo questo al sistema iterativa. e poi lo trasformiamo questo al sistema iterativa. E poi lo trasformiamo questo al sistema iterativa. che vogliamo lo realizziamo adesso, e dopo dopo aver neziNo come se bis in questo caso abbiamo varo Il nostro consequentlyo del nostro perato ok quindi adesso ha più senso e questo quello che dobbiamo risolvere e ha detto prima facciamo i sistemi di equazioni individualmente che abbiamo prima a 11 e 1 k più 1 uguale a meno a 12 e 2 k più di 1 poi a 21 e 1 k più 1 più a 22 x 2 k più 1 uguale a b 2 quindi abbiamo questo sistema di equazioni di risolvere allora abbiamo una cosa bloc triangolare quindi quando abbiamo un sistema triangolare come ve lo ricordate c'è sempre questo primo elemento che ci danno per il gratis e questo corrisponde in questo caso questo blocco qui a 1 1 e 1 1 1 perché facciamo queste risolviamo questo sistema otteniamo 1 1 1 uguale a 1 1 1 verso meno meno a 12 x 2 k più b 1 questo è un altro primo quantità incognito adesso abbiamo una parte dell'equazione quindi possiamo adesso sostituire questa espressione qua sostituire questa espressione qua e otteniamo il sistema a 2 2 x 2 k più 1 uguale a molta t 1 e questo perché abbiamo bisogno di un 2 1 su questo 21 quindi questo è a 21 siamo solo facendo questo sostituzione per questo a e c'è anche un a quindi questo è solo la sostituzione di questo x 1k x 1 poi come prima adesso possiamo semplicemente risolvere questo sistema in x 2 2 per ottenere nostro facciamo facciamo così forse questa forma è più facile capire questo è se volessimo sostituire l'espressione ma qui così quindi una volta che abbiamo x 1 lo possiamo provare x 2 c'è non c'è meno in questo caso perché c'è almeno qui c'è almeno perché se pensiamo di qui dobbiamo prendere questo questa cosa qua e portarlo quindi qui non c'è almeno quindi se portiamo alla destra c'è almeno quindi questo è l'idea di fare i blocchi ok allora non so ok abbiamo un'altra cosa da fare oggi però mi sento come forse questo era più complicato che avevo immaginato allora che ne dice che lo facciamo di nuovo da capo sicuramente non dubito che c'è qualche errore da qualche parte quindi qual è il problema forse? questa riga questa riga ok lei lo SAS9 si ma in realtà questo dovrebbe essere dentro la parentesi è solo x 1 k più 1 Perché prima avevo sottolineato pure quello Ma forse non era chiaro Sì, sì, sì Questo è l'idea È una cosa che Vi consiglio di provare a fare questo calcolo Tipo voi da capo Perché sembra più complicato che lo è Quando lo fai un po' a mano questo Forse sarò un pdf solo questo Con tutti questi non saltando nessun impasto Con tutti i dettagli Va bene? Allora, non penso purtroppo che c'è Non avrebbe senso per fare il matlab oggi Che volevo fare Però c'è troppo poco tempo Quindi parlerò di una cosa Parlerò adesso Lo so, quello che posso fare adesso E introdurrò un concetto a cui torneremo domani Perché è pertinente per tutto questo argomento Allora, quindi C'era quest'idea Della rilassamento Di introdurre questo fattore di Omega Sicuramente questo è una cosa valida Che si può fare Per rendere un sistema più facilmente convergente Ok Ma immaginiamo adesso che abbiamo AX uguale a B Ok Qual è il punto? Il punto qui Quello che abbiamo visto prima E che Allora cerchiamo qualche T e N In modo che Tipo potessimo trovare Qualche approssimazione Dall'inverso, eccetera Che tutto funziona bene Con questa cosa favorevole Ma forse La cosa migliore da fare Prima che iniziamo a giocare Con parametri di rilassamento E altre cose Sarebbe una semplice osservazione qui Che sarebbe? Guardiamo un attimo qui Se Lo moltiplicassi Per qualche matrice Lo chiamiamo P K Perché Non voglio che Tipo viene con poco Troppo con questo P di prima Ma sto provando a mantenere Consistenze col libro Se Moltiplichiamo così Quindi adesso abbiamo P K A X Uguale a P K T Allora Se Sì Il ricondizionamento Allora L'idea qui Forse Ad esempio Nostra matrice A Non fosse Diagonalmente Dominante O qualcosa del genere Ok E quindi Non possiamo usare Giacobbi E pretendere nulla Quello che possiamo fare Potevamo fare Quella cosa Che Ho mostrato prima Del rilassamento Che funziona Un pochino A volte Ma forse La migliore cosa da fare Non sarebbe Quello Ma Sarebbe La semplice osservazione Che Moltiplicando Per una matrice P Non cambia La soluzione X e P Batti Cosa facciamo A tutti e due lati Vero Però Per convergere Basta Tipo Quando pensiamo Di Che cosa serve Per la convergenza Questa cosa È impertinente Quello che c'è Questa cosa Sul lato Destra Non c'entra Tanto Veramente E questa matrice Questo Coso Che Di Componiamo Questi due pezzi Queste Dove c'è Tutta la cosa Importante Quindi Anziché Cercare Il PN Perfetto Perché Non proviamo Semplicemente A trovare Qualche Trasformazione Qui Che Già Prima che Abbiamo Fatto Niente Converte Nostro Sistema Da Uno Infavorevole Ad Uno Favorevole Forse Trasformando Il Sistema In Un Oro Riusciremo A raggiungere Facilmente La Convergenza Senza Fare Nessuna Cosa Di Complicato E Questo Un Pochino L'idea Qua Ad Esempio Immaginiamo Che Anziché Fare Lo Splitting Diagonalmente Ad Esempio Se Facessimo La Moltiplicazione Già Per Prima Con Qualche Trasformazione Diagonale Oppure Questa È Una Cosa Molto Comune Immaginiamo Che Abbiamo Qualche Una Delle Cosi Che Facile Che Possiamo Fari Immaginiamo Che A Uguale A L Ok Come Avessimo Un Moro Individualmente Approssimare L E U Forse Facendo Questo Questo Sistema Poi La Cosa Che Risulta Questa Cosa Che Poi Facciamo Adesso In Splitting Se Scegliamo Tipo Qualche P Meno N Forse Adesso Riusciremo A fare Un splitting Con Pi Pi Adatti E Quindi Anziché Fare Il Rilassamento Anziché Fare Tutte Queste Altre Cose Se Semplicemente Facciamo Partendo Da Un Sistema Già Trasformato Ci Ci Posso Riportare Una Cosa Che È Più Favorevole Per Noi Ad Utilizzare Questa È L'idea Di Precondizionamento L'osservazione Che basta Che Questa Matrice Invertibile Possiamo Moltiplicare Questo Sistema Per Qualsiasi Cosa Che Vogliamo Senza Cambiare La Soluzione Però Solo Perché La Soluzione Non Cambia Sicuramente Non Significa Che Le Proprietà Algebraica Del Sistema Non Cambiano Quindi La Soluzione Non Cambia Ma Forse Adesso Questo Sistema È Diagonalmente Dominante Per E Faremo Cose Più Detaliate Specifico Del Precondizionamento Domani Ma Questo È Il Concetto È Qualche Trasformazione Che Si Fa Prima Di Fare Nient'altro Con Con L'intenzione Di Recuperare Qualche Condizione Per Pavorevole L'altra Cosa Che Posso Dirvi In Generale E Che Vogliamo Più o Meno L'obiettivo E Possiamo Riassumere In Questo Nuro Vogliamo Che Il Numero Di Condizionamento Di Questo King A È Molto Meno Del Numero Di Condizionamento Di A Come Vedremo Possiamo Vedere Che Questa Cosa Non È Già Andata Via Questo Nostro Vecchio Amico Il Numero Di Condizionamento Ancora Gio Grand Bolo Ne Prossime Lezioni Quindi L'idea Del Condizionamento E La Disponibilità Di Splitting Padrevole E Sono Sempre Collegati A A Avere Il Numero Di Condizionamento Basso Quindi L'idea È Trasformando Il Sistema Possiamo Tenere Lo Stesso Soluzione Però Con Mori Più Facili Da Fare Allora Questa Concluda La Lezione Brocci Hier Sté injured Be щоб mir Weiter Mah Numero help is l'e��게 IN Lamise