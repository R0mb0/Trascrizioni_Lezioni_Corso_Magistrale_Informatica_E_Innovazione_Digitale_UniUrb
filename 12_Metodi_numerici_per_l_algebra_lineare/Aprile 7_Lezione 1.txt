Ok, allora, quindi abbiamo avuto qualche domanda Dei esercizi che avevo messo Quello esercizi 3 Quindi, ok Penso che 2 e 3 sarebbero dovuti essere Sarebbero dovuti essere stati abbastanza facili 2 e 3 Ok, allora, parliamo principalmente di questo esercizio 1 Che era un pochino più... Ok Sì, sì, allora Forse in realtà questo esercizio anche lo utilizzeremo Perché diciamo che uno dei problemi più importanti Nella matematica e la scienza in generale È il problema di... Ok Ok Sì, sembra che... Ok È un problema di... Poisson Che è... Così Quindi Poi ho a volte si viene che è B Qualche funzione di questa forma E poi abbiamo di solito bisogno di... O è... Qualche condizione al bordo Questo è... Equazione di calore Equazione di dispersione Equazione di elasticità Può essere visto più o meno così Quindi è un problema importante E questo primo problema Nei esercizi 3 Praticamente dice che... Ok In questo caso abbiamo detto che abbiamo una funzione Quindi qui Nostro dominio Tra l'intervallo Tra 0 e 1 E abbiamo una funzione Una funzione x Che va da Nostro dominio Ai numeri reali E L'idea è che Abbiamo Questo intervallo 0 e 1 E l'idea è che Anziché considerare questo intervallo Come un continuo Perché questo non è possibile fare In realtà Se vogliamo fare cauzioni pratici Dividiamo questo In qualche numero di sottointervalli Equispaziali Quindi chiamiamo Assumiamo Assumiamo Anche se i miei disegni Non sono perfetti Questi sono Tutti ecco Sparati Con Larghezza Delta x E l'idea Adesso E che vogliamo Fare un'approssimata Vogliamo approssimare Questa equazione Con qualche Formula qui E tra Penso che sarà Forse l'altra settimana Subito dopo Pasqua Vedremo esattamente Da dove proviene Questa formula Che viene questa formula Ma l'idea è questa Che Si Allora Utilizzerò Questo Tipo Questo Non è stato Usato In realtà Non ho dato un'equazione ancora Quindi l'idea Però è questo Che abbiamo qualche funzione Che assumiamo che ha qualche derivata Ma è In Non so se ho messo No in questo caso Non l'ho messo No Ma questo non Non è un forte tipo Si tratta solida Solo di Diciamo Ok Una Tipo questa Basta che si mette un Meno davanti O Tipo È una cosa che Cambia solo il segno Non Non Ma sostanza Però ok Ha ragione Comunque L'idea qui però È che Si può dire In questo caso Cioè Possiamo Se abbiamo F Quindi immaginiamo che Abbiamo F A ciascuno di questi punti Quindi abbiamo pochi vettori Che abbiamo questo X Zero X Uno Quattacattata X N L'idea qui È che se abbiamo Pochi vettori X Che lo diremo X Zero Quindi Come dati Vi do Qualche vettore Che contiene Come i tuoi elementi Quindi è Un vettore Colomino Che contiene tutti questi punti di X Di F Valutati a tutti questi X Nel nostro intervallo E l'idea È che Possiamo Fare un'approssimata Alla seconda derivata Di questa funzione Con la stessa formula Qui F Sì Esercizio Esercizio 1 Sui numero 1 Sui numero 1 Di esercizi 3 Ok Ok Questa è l'idea Che abbiamo un pochi vettore Che contiene i valori di F F X E Che c'è una formula che dice che questo Dato che abbiamo questi valori di F Possiamo approssimare la seconda derivata di F Con questo qua E quindi parte 1 Era Utilizzare questa espressione Per trovare una matrice A Che Che Proviamo A Questa è l'idea Vogliamo trovare l'A Che quando moltiplichiamo questo vettore F Che contiene tutti questi valutazioni delle funzioni dentro Che abbiamo una funzione Abbiamo un vettore Che approssima non F Ma la seconda derivata di F rispetto a X Quindi vediamo questa struttura qua Quello che abbiamo qui Pensiamoci di se lo restimo solo tre punti Quindi F X Zero F F F X its 2 F F F F F F F F F F F F F F F F F F F F F X Ok, quindi se avessimo una matrice per ricornare questo, in questo caso la matrice sarà un ventore di riga, ma avrebbe questa forma. Giusto perché se moltiplichiamo A per questo, F per questo A avremmo, se prendiamo questo e lo mettiamo sul suo lato e lo moltiplichiamo qui, Fx2 sotto questo 1 qua, questo x1 viene focato da questo meno 2, e questo x0 da questo 1. Poi, per questo 1 diviso x quadrato, delta x quadrato, questo fattore è lo stesso identico per tutti questi pezzi di F, quindi sembra che questo dovrebbe starci. Adesso estendiamo questo ragionamento, e adesso introduciamo un quarto punto, e adesso vogliamo fare Fx2, o no, un terzo punto qui. Beh, un quarto punto ma l'ho annunciato a 0, quindi sarà. In questo caso, allora, sarà simile, ma tutte queste cose verranno aggiornate da un indice di tipo. Quindi adesso, se volessimo esprimere questa matrice in modo che prenda in considerazione tutti questi punti, avrebbe adesso questa forma qua. qua. E questo è più o meno l'idea. Non penso che devo convincervi tantissimo se volessimo aggiungere un altro punto che avrebbe questa struttura qua. Quindi, l'idea è che la matrice che ci serve non sarò super puntiglioso di come esattamente è scritto. Il punto è che dobbiamo trovare una matrice così. diciamo quindi abbiamo due su diagonale, poi abbiamo sempre qui meno uno, meno uno, meno uno. Quindi abbiamo una matrice che si chiama questa struttura tridiagonale, e quello che significa che è zero dappertutto, è questo, è tutto questo diviso, un diviso delta x quadrato. Questa è la struttura tridiagonale, che significa che è zero dappertutto, tranne che il diagonale è subito sopra e subito sotto il diagonale. Allora, l'abbiamo scritto in questo modo, ma forse come potete immaginare, in pratica probabilmente potremmo anche sviluppare una struttura o qualche modo di tenerlo in memoria, in modo che non dobbiamo mantenere tutta questa cosa informazione redundante, ma anche questo è un altro discorso per adesso. Allora, quindi la funzione, la parte B era semplice, volevo semplicemente che scrivesse una funzione che produceva questo. Allora, forse state pensando a una cosa che è una cosa pertinente pensare, che avrete visto che un pochino ho barrato, ho iniziato ad x1 non è 0. E questo infatti è un punto importante per questo problema, perché abbiamo bisogno di tre punti per fare l'approssimazione della seconda derivata ad un singolo punto. Veri? Per x1 abbiamo bisogno di questo x2 e questo x0 per x2 per approssimare la seconda derivata abbiamo bisogno sia del f ed x2 ma anche f ed x3 ed f ed x1. E quindi è vero che questa matrice può essere veramente solo ben definita per i punti diciamo interni, cioè questi. in questo caso non era così interessato a fare questo punto diciamo perché non è che vogliamo veramente risolvere un problema con questo, volevo solo che implementassi una cosa che per la creazione di questa matrice e poi la parte seconda in cui potevamo descrivere un algoritmo efficiente per risolverlo. come lo gestiamo questo problema qui in pratica? In pratica quello che facciamo è facciamo questa cosa in cui e questo di solito corrisponde alla soluzione di un'equazione differenziata. Potete immaginare perché c'è questa cosa che approssima una derivata. in generale quando dobbiamo utilizzare questa matrice in pratica quello che facciamo è dobbiamo insistere dobbiamo diciamo fissare un valore di if a qualche punto e quindi consideriamo questa prima riga di essere un po' da parte del resto della matrice ma per adesso volevo solo questa questa idea che tipo cosa facciamo una costruzione di una matrice che apprende questo vettore e per ciascuna riga del vettore tranne che il primo e l'ultimo risulta questa espressione e quindi sarà questa cosa qui poi vi ho detto matrice tridiagonale che quando ho creato la matrice ha questo punto di due vabbè questa è l'approximazione avevo detto che la matrice la matrice ha questa struttura tipo o in questo caso non ho meno quindi ok questo è più sensibile o più esplicito dobbiamo avere una matrice che sui elementi diagonali poi c'è ok c'è questa qui sugli elementi diagonale abbiamo meno due sugli elementi subito sopra il diagonale abbiamo uno e poi sotto abbiamo uno e tutto viene moltiplicato da uno diviso a delta x quadrato dove delta x è la distanza tra i vari punti e questo era faceva parte del problema se non sbaglio ho detto che volevo che scrivesse una funzione che produceva questa matrice per un dato numero di punti quindi per n per tipo dieci punti sarebbe una matrice che faceva questo considerando una disfittizzazione di dieci punti però comunque l'unica cosa che cambierebbe di questo sarebbe quanto è grande sarebbero comunque sempre il meno due e l'uno questo ovviamente lo spazio tra i punti cambierà in base quanti punti abbiamo perché ho insistito che i punti sono equidistanti equospaziati ma questa era l'idea si può no questa matrice dovete solo controllare questo perché la matrice non contiene le derivate da solo si ma gli x sono solo tipo ogni membro di questo vettore sì perché stavo perché stavo iniziando qui con un punto per tipo farci per un singolo punto avrà questa scrittura poi tipo adesso abbiamo bisogno di uno che tipo non iniziano solo per un punto ma per tutti quindi dobbiamo avanzarci secondo quando doveva essere ah ok sì ho capito sì ma era perché stavo solo provando diciamo che c'è un piccolo problema con quello che ho scritto io direi ok consideriamolo così in questo caso particolare questi punti questi punti a bordo della matrice sono un problema perché possiamo avere questi tre punti solo nell'incorno però io immaginavo che semplicemente potete mettere per questi tipo una cosa incompleto diciamo che diagonale 2 o il meno 1 sotto e sopra che per tutti i punti tra la prima e l'ultima dà la cosa corretta non so se questa risponde alla tua domanda non sono molto in cura se avevo capito la matrice sarebbe riferita a x 0 cosa la matrice sarebbe riferita esatto e questo è il punto problematico ma come facciamo che per x i meno 1 allora in realtà il modo ci sono vari modi in cui si possono farlo il primo modo in cui si possono farlo è questo è un modo di fare un'approssimazione della seconda derivata c'è un altro ci sono altri modi di farlo che usano solo due punti ma direi quello che è più comune in realtà quello che si fa è che si accetta un pochino che non possiamo avere la derivata a questi punti quindi lo sappiamo che qui ai è un problema a quei punti alla fine e quindi di solito quando lo facciamo pensiamo già che considereremo solo i risultati punti tipo nell'intorno al vettore e spesso quello che si fa in questo caso e si considera il vettore di F ad iniziare con quello che si chiama una ghost point cioè abbiamo anche qui un F e si spesso lo usano un po' meno uno per significare questo quindi implicitamente stiamo dicendo che non riusciremo ad avere un'approssimazione della derivata qui ma se abbiamo bisogno solo dalla derivata da qui in poi basta che aggiungiamo questo punto questo altro punto fuori nostro dominio e poi stiamo a posto l'altra cosa che si fa a volte sì anche si fa una cosa simile al punto finale sì il punto finale in generale presenta meno problemi perché spesso questo tipo di problema ha una si potrebbe direzionalità cioè appunto per uscire non un pochino non ce ne freghiamo così tanto cosa succede fuori nel nostro dominio tipo perché spesso stiamo parlando di una cosa che tipo sta muovendo con questa direzione quindi quello che succede qui ce ne freghiamo ma poi se nostra approssimazione non è accurata qui e da qui in poi che è quello che succede con questo punto finale non è importante perché se c'è un problema qui propaga in tutto il dominio se c'è un problema qui è solo un problema là questo è un po' il ragionamento per la parte c diciamo che secondo me volete potete ancora fare questo ma l'idea è che se guardate questa matrice qua ha questa struttura in cui qui abbiamo queste righe con tre punti e basta e poi qui abbiamo un punto che ne ha solo due qui ne ha solo due esiste un modo diciamo di sviluppare un algoritmo che intelligentemente riesce a manipolare il sistema utilizzando questi rapporti tra i variabili così lo possiamo risolvere in un modo veloce senza dover utilizzare una fattorizzazione di LU eccetera perché questo non è in una forma LU c'è di anale c'è qualcosa di sopra e c'è qualcosa di sotto però come forse vedete già c'è una certa logica a come è strutturata questa matrice se volessimo potremmo metterla in una forma LU ma questa già ha una forma abbastanza sfruttabile diciamo LU lo facciamo per matrici generali quando non c'è nessuna forma in particolare perché questo è uno che in generale lo possiamo sfruttare ma ogni tanto si incontreranno una matrice del genere che nonostante che non è una cosa già LU non è necessario per forza utilizzarlo possiamo anche pensare di un modo di farlo se vogliamo possiamo anche parlarne forse se non domani tipo anche forse metto una cosa online però se avete se volete se volete no non voglio dare questo come indizio perché ricordate sempre coda significa quando stiamo risolvendo un sistema lineare stiamo sempre dicendo che è un sistema di variabili che tipo mettendo questo insieme a questo porta questa ugualianza quindi se sappiamo che ad esempio xn diciamo x-1 meno 2x n più 1 uguale di n più 1 ok sappiamo questo possiamo forse vedi questi due termini comunque compaiono anche qui quindi portiamo un pochino vedere che questo è collegato a questo con l'involuzione di un singolo variabile nuovo quindi se possiamo sfruttare questo in qualche modo vedi che tipo c'è ancora qui adesso c'è se aggiungi vediamo possiamo aggiungere queste equazioni in modo di eliminare un variabile questa è l'idea e quindi si può fare queste sostituzioni e poi una volta che non voglio darvi la soluzione ovviamente ma l'idea è questo che vediamo che abbiamo tre rapporti per tutti i posti tranne che qui e qui dove ce ne sono solo due e quindi c'è un modo di sfruttare questo rapporto in modo che poi possiamo risolvere un problema sostituendo rapporti tra i variabili se avete ancora bisogno di aiuto forse dovreste cercare lo dico a voce ma non lo scrivo perché non voglio renderlo troppo banale se cercate Thomas algorithm forse troverai quello che sto dicendo ok sui esercizi esercizio due era abbastanza facile secondo me c'è solo un allora c'erano due parte uno era di trovare la fattorizzazione LU con l'eliminazione di Gauss però la parte A era una vero falco vedere l'applicazione di definizione che ne abbiamo parlato forse questo perché parleremo di nuovo di questo concetto sia oggi che domani vale la pena rientrodurlo uno poi c'era tre mezzi due mezzi poi zero tre e tre ok parte A di problema due su questi esercizi chiedevo se fosse necessario se volessimo trovare la fattorizzazione LU di fare qualche permutazione per scambiare le righe o la colonne e ho chiesto sarà necessario in questo caso è possibile capire questo senza fare un singolo calcolo e se sì come lo sappiamo spesso quando io ero studente risolvevo questi problemi con intuizione cioè probabilmente la risposta è sì perché perché se non fosse sì diciamo che ci sono moli spesso ci sono moli per garantire certe cose ma spesso per non garantirli no in matematica quindi c'è un non ancora ancora più facile ve lo ricordate che avevo fatto una definizione dominante diagonalmente dominante diagonalmente significa che per tutte le righe i l'elemento diagonale il valore assoluto è più grande di uguale a allora con per almeno una riga quindi interpretiamo un attimo questa espressione sta dicendo oh no oh mio dio questo è a i i quindi questo sta dicendo per ogni singola riga il valore assoluto dell'elemento diagonale è più grande di o uguale a la somma nel valore assoluto sempre di tutti gli altri elementi su quel proprio riga per essere proprio diagonalmente dominante più grande di è uguale a generalmente è ok ma per almeno una singola riga deve essere questo stretto più grande quindi in questo caso abbiamo che l'elemento diagonale è uguale alla somma di tutti gli altri elementi in valore assoluto stessa cosa qui questo diagonale è uguale alla somma di questi due a valore assoluto ma in questa riga vediamo che abbiamo la disuguaglianza stretta quindi possiamo concludere che questo è diagonalmente dominante dominante diagonalmente si può ordinare come voi però in particolare questo significa quando una matrice è diagonalmente dominante che quando a è diagonalmente dominante di esistono l u senza nessuna permutazione quindi non dobbiamo fare nessun riordinamento in generale ci potrebbe essere necessario qualche p a uguale l u ma quando è diagonalmente dominante significa che è garantito che è già ordinato correttamente basta che facciamo quell'algoritmo che abbiamo visto e non incontreremo mai qualche problema quindi questa era la parte di esercizio due che volevo che verificasse e poi una volta che lo sappiamo questo lo sapete quando iniziate a fare l'algoritmo per trovare gli fattori l u che non incontreremo mai nessun problema in cui la permutazione è necessaria poi esercizio 3 era facile secondo me devi solo fare un pochino di dimostrazione per dimostrare effettivamente che se hai matrici 2x2 triangolari inferiori che quando si moltiplicano due matrici triangolari inferiori il risulto del prodotto è anche triangolare inferiore che l'inverso di una matrice triangolare inferiore è anche una matrice triangolare inferiore e poi c'era la parte in cui dovete vedere che non sono non è un gruppo abeliano cioè trovare due matrici triangolari inferiori in cui uno moltiplicato per l'altro non da AB non è BA questo questo era questo è pertinente perché questa specie di teorema aiuta quando stiamo parlando di questi algoritmi in generale perché se come ricordate abbiamo avuto quell'espressione che è un prodotto di tutte quelle matrici triangolari e se potete dire ah si sono in gruppo quindi possiamo moltiplicare un numero arbitrario di tanti matrici triangolari inferiori e comunque risulterà una matrice triangolare inferiori e una cosa si si ma da parte perché ho chiesto come sai ah ok si beh non volevo esplicitamente dire la risposta a questa parte a con la parte b ok se ricordiamo dove eravamo rimasti ho iniziato a parlare di soluzioni interattivi di sistemi lineare ax uguale a b quindi ricordiamo un pochino che cosa significa l'idea è che l'idea è che l'idea è questo che a volte abbiamo a x uguale a b con a grande è un spesso a spartro che significa che significa che in maggior parte gli elementi sono sono 0 quindi spesso a struttura come quello che avevo fatto un esempio spesso a spartro spartro significa che la maggioranza dei suoi elementi sono 0 con solo relativamente pochi che sono non 0 e in questo caso la fattorizzazione LU o metodi del genere diretti possono introdurre problemi perché facendo la fattorizzazione LU una matrice che era sparso è molto facile di trovare esempi di matrici molto sparsi che tipo uno di meno per cento degli elementi sono non 0 che tipo poi la fattorizzazione LU è completamente denso e quindi quando le matrici sono enormi questo può introdurre grandissimi problemi con la memoria nel sistema poi c'è un'altra specie d'esempio in cui ho fatto questo in cui hai una matrice che è un pochino tipo che è quasi non è identico tipo non siamo già necessariamente alla all'inverso ma potrebbe avere questo tipo di forma quindi sappiamo che per A I uguale a B sappiamo che X dovrebbe essere abbastanza simile a B perché questa matrice è già quasi l'identità non è l'identità ma quasi e quindi potrebbe essere un grande spreco di tempo fare tutta la procedura della fattorizzazione LU eccetera eccetera quando sappiamo di già essere vicino alla soluzione ok per una matrice 3x3 ovviamente non è mai niente di che ma potete immaginare forse se avessimo un esempio di una matrice simile che fosse 2 milioni per 2 milioni sembrerebbe un po' ridicolo a provare a fare una batterizzazione in una soluzione diretta quando sappiamo già che in un certo senso ci siamo quasi vorremmo sfruttare questa informazione in qualche modo e l'idea con questo il modo più comune di affrontare problemi del genere è con un metodo iterativo quindi l'idea è abbiamo A qualche matrice nxn assomiamo che la matrice comunque è invertibile che il sistema ha una soluzione quindi abbiamo anche una d nrm e vogliamo provare x tale che a x uguale a b con una sequenza a x l'artico k vogliamo definire qualche sequenza di sequenza successiva in cui possiamo calcolare di nuovo e di nuovo qualche approssimazione della soluzione x e ovviamente questo se lo facciamo così perché se prendiamo questa sequenza all'infinito che abbiamo una soluzione nei nostri calcoli successivi alla soluzione desiderata allora dovrebbe essere forse dovrei dire questo esplicito infatti lo dico esplicito per questo di valersi la pena sarà necessario allora che per valersi la pena la costa computazionale per capolare k più unesimo termine di queste sequenze deve essere molto meno di calcolare direttamente però quindi o l o su le e questo attento perché allora dobbiamo calcolare un'interazione e dobbiamo aggiornarlo qualche numero di volte non sappiamo a priori esattamente quanti potrebbero essere dieci potrebbero essere cento potrebbe essere mille ma ovvio che non sarà uno quindi deve essere una cosa in cui l'iterazione è così meno costoso dal punto di vista di computazione che ancora vale la pena farlo e anche se ci servono duecento duemila dipende dal problema tante l'iterazione non può essere un pochino meno di risolverlo direttamente perché già se diciamo la costa di calcolare l'iterazione è la metà di risolvere il sistema direttamente già se abbiamo bisogno di più di due interazioni già è un spreco di tempo e energia quindi deve essere un problema molto più facile per giustificare questo quindi questo dovrebbe un po' spingere l'idea qui è che quando stiamo definendo o cercando di definire una sequenza di un metodo iterativo dobbiamo sempre farlo in modo che aggiornando questo stimata di in qualsiasi modo che la facciamo deve essere sempre una cosa facile idealmente solo con prodotti matrici vettori o prodotti scalari o prodotti scalari tra vettori quindi specificamente vorremmo che possiamo fare queste interazioni facendo solo queste operazioni semplici possiamo anche dire risolvere risolvere risolvere sistemi semplici e quando dico semplici intendo che il sistema è già nella forma che ci serve non dobbiamo calcolare nessuna fattorizzazione o niente tipo se possiamo garantire che calcolare ciascun iterato nella sequenza è sempre facile costa poco idealmente possiamo farlo facendo solo prodotti con matrici vettori prodotti tra vettori forse la risoluzione di un sistema semplice che non dobbiamo fare tanto lavoro ottenere questa è la cosa che valga la pena questa è una cosa che potrebbe essere superiore in alcuni casi rispetto alla risoluzione diretta ricordaci questo è il punto deve essere non solo una cosa che funziona ma possiamo in certi casi preferire anziché risolvere direttamente allora diciamo la classe di metodi più elementari ma più diciamo fondamentali per questa idea utilizzano le tecniche splitting quindi tecniche metodi di splitting autograico anche questi metodi stazionari possiamo parlare un po' perché stazionari probabilmente state pensando che ci sono metodi stazionari devono esserci anche metodi non stazionari e ci sono ma adesso parleremo di questi metodi stazionari l'idea è questo abbiamo un sistema a a x uguale a t proviamo t e n tale che a può essere dicomposto in questa forma quindi non è a possiamo trovare un p e un n ciò che possiamo di comporre questa in questa differenza e voglio dire questo non è una fattorizzazione come l questa è una cosa fatta addettivamente quindi ad esempio le a 12 1 potremmo fare p uguale a 120 n uguale a meno 300 0 meno 300 0 e poi come vedete questo è quello che intendo possiamo trovare questi due fattori che quando si fanno questa adizione o sottrazione che si combinano di formare il nostro matrice a cosa è quadrati deve essere sì perché stiamo stiamo riscrivendo il sistema quindi a r n per n e poi se due matrici possiamo aggiungerli insieme o soffrarli per fare a deve essere necessariamente il caso che anche p e n hanno le stesse dimensioni la moltiplicazione per le matrici possiamo essere un po' più meno stringenti con le dimensioni ma con le disioni deve essere per forza rigido devono essere identiche ok l'idea qui allora se a a questa forma adesso sostitutiamo qui e facciamo questo vediamo che possiamo riorganizzare il sistema così e anche allora questa cosa ok questo non necessariamente non sembra necessariamente utile però sicuramente è il caso che se questo x fosse nostra soluzione desiderata che questa espressione sarebbe vera l'idea qui e qui dobbiamo usare un po' la fantasia l'idea qui è guardando questa espressione come detto se non struis e che volessimo se la cosa che cerchiamo significa che questo rapporto sarebbe vero allora è ovvio che non sappiamo questo x però guardando questa espressione spesso quando abbiamo la cosa che vogliamo sia da un lato che l'altro di un'equazione spesso la cosa che nell'analisi numerica questo potrebbe suggerire e definire qualche sequenza cioè definire questo in modo che questa espressione qua come l'ho detto fine in fondo stiamo cercando di definire questa sequenza che idealmente converge al nostro sistema del nostro sistema che si tratta questo non potrebbe essere un'embreza in una k però ok non ho ancora parlato però di come esattamente definiamo questo sequenza questa è l'idea della definizione della sequenza possiamo splittare a in questi due fattori aritativi tale che così facendo abbiamo un modo di ottenere la prossima la successiva iterazione nella nostra sequenza allora adesso voglio ricordarvi a questo discorso che ho fatto prima di aver scritto questa espressione quello di per valersi la pena qui la costa di calcolare ciascuno nuovo iterato deve essere molto meno e quando dico molto meno non intendo la metà o 25% nemmeno 10% stiamo dicendo deve essere così meno che è proprio banale una praticamente una cosa inesistente rispetto alla costa di calcolare la fattura di esattura della matrice idealmente è una cosa che possiamo fare come ho detto prodotti in matrice vettoriale prodotti scalare ok decisione tra vettori anche qui però c'è questo sistema quindi ho detto che possiamo risolvere un sistema forse se il sistema è sempre sufficientemente facile risolvere forse quale potrebbe essere il tipo di sistema più facile possibile da risolvere un sistema diagonale forse tipo se fosse un sistema tipo 3 2 1 questo è facile risolvere vero dobbiamo solo fare tre divisioni tutti gli elementi sono indipendenti quindi quando dico che abbiamo bisogno qui per questo di essere una buona idea che potrebbe presentare qualche alternativa migliore rispetto a risolvere il sistema diretta deve essere facile risolvere quando dico facile intendo facile tipo così lo diagonale deve essere non singolare per forza perché lo stiamo risolvendo questo sì è ovvio che non singolare se in questo caso se la matrice ha ha dei elementi su diagonale tutti non zero questo è non singolare quindi parleremo tra un attimo in più dettaglio di questo no parlerò prima lo introduciamo esempi di equazioni quindi a le due splitting più facili prima parliamo di questo facciamo così scriviamo così a e non faremo questo certo di essere molto è e questa è la notazione che usa il libro ok quindi immaginiamo che a viene può essere descritto in base a questi tre componenti quindi abbiamo di che sono gli elementi diagonali di a abbiamo e la parte triangolare interiore di a e abbiamo s nella parte triangolare di a di a e non perché questi dovrei dire strettamente triangolari inferiori triangolari superiori questo è un po' diverso delle triangolari inferiori e superiori che abbiamo visto con l perché in questo caso queste loro proprio diagonale sarà zero perché il diagonale della matrice viene assorbito tutto in questo termine di allora se abbiamo questi possiamo definire che i propri questi propri elementi ci permettono per chi che segue online allora dato un'opchiata qui questo splitting della matrice qui nella parte diagonale questa parte strettamente triangolare inferiore e questa parte strettamente triangolare inferiore inferiore superiore ok questi sono formano con questi definizioni potremmo ottenere qualche interazione che secondo me solisterebbero la mia criteria di un sistema interattivo iterativa desiderabile il metodo 1 questo si chiama il metodo di di giacobi il metodo 1 di giacobi dice che dovremmo definire p come nostro diagonale del sistema e n come questo quindi qui abbiamo una matrice con questa forma qua e poi qui abbiamo una matrice con questa forma qua quindi qui abbiamo gli elementi diagonali del nostro sistema e poi tutti gli altri elementi che non sono diagonali e è ovvio che se consideriamo abbiamo di meno meno i più f che è il nostro sistema quindi questo costituisce uno di questi splitting in cui separiamo la matrice in questa forma e allora possiamo prima scrivere in questo modo l'elemente i etimo all'interazione che più uno così ha questa forma i i meno g uguale a 1 n g nome mai qual è lì a i j i j a questo se volessimo vedere l'elemento ha questa forma quindi se preferisci questo modo di scrivere si può scrivere così io personalmente preferisco però una volta che abbiamo definito matrici vettori eccetera io penso che è più facile concepire in questo modo quindi i i f si si meno i più f qui qui f non quindi come successivamente la risoluzione per ogni singola interazione in questo sistema diagonale qui poi lo utilizziamo l'ultima interazione l'ultima cosa a xk da meno i più f dove ricordi i più e sono questi componenti triangolari della nostra matrice sì questo di e la diagonale di a e lo scritto questo modo perché ero mi intenzione dobbiamo fare questa inversione diagonale quindi qui di e questo sia l'ordine e la matrice che consiste solo degli elementi diagonali di a zero e tutti altri posti poi questo n e meno i più f quindi oppure poi se preferite così pensarlo come vabbè quello che ha però abbiamo tolto tutti i suoi elementi diagonali ok allora questo è ovvio che è compatibilmente facile perché dobbiamo solo fare un singolo in versione diagonale c'è una cosa che vogliamo voglio parlarne qui questo si chiama la matrice di interazione è meno di a questa espressione qua e in generale parliamo questo è il caso principico il genere in generale è che è per cosa si può in qualche modo si la matrice di interazione è questo di meno di inverso e più f quindi è meno dell'inversione di questo complicato per questo in generale in generale per chi è generico la matrice di interazione e questo di inverso n quindi abbiamo una chi di n che insieme formano a sono un splitting adattivo di a e la matrice di interazione è p inverso n e c'è un altro modo di scrivere p inverso n n generico significa sono qualsiasi due matrici e p e n in modo che t meno n c da a questo era una scelta specifica di p e n quindi ho detto che possiamo definire una sequenza se mi dai una p invertibile e un n tale che p meno n c da a possiamo sempre definire una sequenza del genere questo di Jacobi era ok utilizziamo questa scelta di p e questa scelta di n non c'è nessuna legge che dice che devono per forza esserci però come ho detto idealmente soprattutto per p che è quello che dobbiamo risolvere vorremmo che p fosse facile risolvere se p è in positivo è ugualmente difficile risolvere come a non ha tantissimo senso farlo quindi questo probabilmente sarebbe la scelta di p più ovvio il diagonale quindi boh se mi chiedessi di fare mi indovina quale splitting potrebbe essere più facile la prima di provare la matrice di interazione qui per questo per Jacobi ha questa forma qua in generale la matrice di interazione per questi metodi stazionari andrà dato da questa espressione pi inverso n c'è un altro modo in cui possiamo vedere pi inverso n che è utile per capire quello che stiamo provando a fare e poi introdurre il prossimo metodo specifico ma volevo prima fare un esempio concreto questo è un metodo che parleremo per un attimo che potremmo provare utilizzare per risolvere il sistema la matrice di interazione è una cosa utile un pochino forma forma la sostanza di quello che stiamo facendo questa matrice qua possiamo anche scriverlo in un altro mondo perché abbiamo a uguale a t meno n significa che possiamo anche scrivere scrivere n come p meno a abbiamo solo fatto un pochino di abbiamo switchato praticamente n e a qui se scriviamo n in questo modo vediamo che p inverso n uguale a p inverso p meno a che questo è anche la matrice di interazione non abbiamo fatto nessuna cosa nuova abbiamo utilizzato semplicemente esattamente la stessa espressione che c'era qui e l'abbiamo scritto in un modo diverso però perché questo forma è utile perché ok è evidente che non è una nuova informazione è un modo di riscrivere il sistema in un modo che però potrebbe darci un nuovo modo di pensare infatti utilizziamo un attimo questo modo di scrivere il sistema quindi prima abbiamo do x k più 1 uguale a p inverso n x k più p inverso p ok quello che vogliamo fare adesso è utilizzare questa espressione qua per p inverso n quindi i meno p inverso a x k più t inverso b allora però p inverso b facciamo un attimo allora x k meno p inverso a x k più t inverso b allora se ricordiamo b b è uguale a x dove questo è nostra soluzione desiderata e a x infatti è uguale a p meno n x quindi potiamo anche riscrivere questo come x k meno p inverso a x k più p inverso i meno n p a x e questo ci porta a x k meno p inverso a x k più x meno p inverso n x e allora cosa vogliamo fare adesso qui c'era x k a poi c'era c'era aspetta no non è esattamente quello che volevo fare non è esattamente no non è esattamente quello che volevo fare ok quello che volevo fare era di semplice meno male quello che volevo fare era questo che adesso possiamo scrivere questo come x k più p inverso b meno a x k quindi questo è il residuo x k questo è b meno x k quindi l'idea qui è come possiamo anche vedere questo come come come un'espressione che è uguale a x k come una correzione del residuo dove questo è b meno a x k quindi idealmente quando questo converge quello che significa che questa contribuzione va via e siamo rimasti con solo x k più 1 x k ma c'è anche un altro comodo di notare qui che vediamo che quando questo succede quando abbiamo questo sistema che converge quello che significa è che questo contribuzioni se vogliamo vedervi così possiamo vedere questo come una cosa che successivamente questo è la noveltà questo t verso b non cambia mai questo è sempre fisso questo invece questa porzione del sistema cambia ad ogni singola iterazione perché x k stessa cambia e quindi cosa significa quando abbiamo una situazione del genere quindi riscriverò in modo un po' più chiaro abbiamo che x k 1 uguale a i meno inverso a x k u inverso b ok quando siamo a nostro soluzioni desiderato significa che siamo un punto fisso dovrebbe essere che non c'è nessuna nuova novetà che viene dalla sequenza che stiamo aggiungendo zero sto provando a spiegarmi mi dirai quale parola sequenza novetà novetà ok si novetà significa che stiamo aggiungendo questo termine questo sta cambiando rispetto alle termine nuovi che lo stiamo dato x k perché questo cambia con ogni k quindi in un certo senso possiamo vedere questo come una cosa che si ferma quando x k non fa più niente quando siamo rimasti solo così a questo punto stiamo aggiungendo zero e questa è l'idea che voglio far vedere qui però quando stiamo aggiungendo zero e non c'è questo stiamo aggiungendo zero quando questa espressione è tranquillamente zero e l'idea qui è il punto che volevo embalizzare per avere un metodo che funziona bene con un splitting questo è quello che in effetti vogliamo vogliamo una scelta di questo p tale che il suo inverso in un certo senso fa un' approssimazione dell'inverso di a perché quando è così significa in effetti che l'iterazione dovrebbe terminare tra poco perché questa cosa è quasi zero questa è l'idea perché quando p se p fosse uguale all'inverso saremmo già finito tipo nessun lavoro da fare quindi vogliamo una p che è simultaneamente quasi a inverso ma abbiamo un pochino una situazione una non so come si dice un catch 22 perché vogliamo che p è quasi uguale ad inverso ma se l'avessimo saputo anverso non c'è nessun bisogno per fare tutto questo quindi come però adesso voglio ritornare alla scelta specifico del Giacobbi perché adesso forse siamo più ben attrezzati di valutare la qualità o la sfruttabilità sì esatto l'idea però è se pi inverso è quasi a inverso non è uguale giusto visto che non è uguale proprio questo non sarà mai zero ma se è quasi uguale significa che le concuzioni di questi saranno pochi e quindi idealmente convergerà eppure convergerà velocemente quindi questa è un po' l'idea che pi inverso deve in qualche modo approssimare in modo facile l'azione di anverso tipo dovrebbe essere una matrice semplice che anche in un modo ben chiaro simile a anverso quindi parleremo sto pomeriggio rifarò quella dimostrazione che secondo me era tipo tutto difficile diciamo faremo la la criteria rigorosa però secondo me questa è una cosa che è meglio capire l'intuizione prima del rigore quindi se vogliamo pi inverso di approssimare a verso è anche essere facile in generale questa è la scelta più semplice che possiamo probabilmente fare per P l'elemento diagonale della matrice a però se stiamo seguendo questo ragionamento è evidente che non possiamo sempre pretendere che questo funzionerà funzionerà solo nel caso in cui il diagonale di a dà qualche approssimazione efficace di a e se ve lo ricordate quando abbiamo parlato dell'esercizio dell'altra settimana ho detto che utilizzeremo più tardi oggi una definizione questo metodo di Jacobi funziona nel caso in cui a è diagonalmente dominante e adesso forse potete intuire perché se è diagonale dominante significa che insomma è dominato dai suoi elementi diagonali che gli elementi diagonali contengono la maggior parte dell'informazione utile in questa matrice tuttavia se selezioniamo il diagonale come nostro modo di approssimare l'inverso di a dovrebbe funzionare questo e può essere dimostrato formalmente quando la matrice e lo scrivo questo da qualche parte perché secondo me è importante però se a se a è diagonalmente dominante il metodo di covid converge alla soluzione desiderata ok e questo è la giustificazione perché ho riscritto la matrice di interazione in questa forma perché secondo me si può vedere questo meglio che quando pi inverso è quasi anverso significa che il metodo dovrebbe funzionare meglio però purtroppo matrici diagonalmente dominante non sono rari necessariamente però non sono sicuramente quello che dovremmo pretendere la maggior parte dei matrici e sistemi che vorremmo risolvere purtroppo non saranno diagonalmente dominanti se ci fossero secondo me non saremmo in questo corso adesso avrebbero già insegnato questo superiore e sarebbe fatto tutto quindi come potete immaginare non funziona bene sempre ma funziona quando ovvio è diagonalmente dominante però adesso torniamo qui qui quindi adesso diciamo che A non è diagonalmente dominante quindi Giacobbi non funziona potremmo forse sarà un pochino più lavoro di un'inversione diagonale ma non sarà terribile c'è un'altra cosa che potrebbe funzionare che è ancora abbastanza semplice per valersi la pena e potrebbe in generale dovremmo pretendere che è meglio come un'approssimazione rispetto al semplice diagonale c'è una cosa che sto pensando che potrebbe essere un'altra scelta per P e N altre scelte qualcuno avere qualche idea se invece di prendere solo il diametro e basta se facessimo diciamo questo come P e poi questo come N cioè se facessimo P come facciamo D più E N come meno F quindi adesso questo sarà così D zero e questo sarà zero F poi zero ok quindi adesso l'idea è simile ma anziché fare solo il diagonale della matrice A come nostro P forse se facciamo tutto questo porzione triangolare inferiore forse questo funzionerà meglio intuitivamente dovrebbe perché stiamo includendo più informazione di A dentro questo P quindi anche se non è diagonalmente dominante in generale questo dovrebbe essere dovremmo immaginare che questo dà una migliore approssimazione all'inverso rispetto a nostro semplice diagonale e questo è quello che si chiama allora non so se abbiamo già visto il suo nome sì penso che l'ho detto una singola volta quando stavamo allora questo si chiama il metodo di un po' così metodo di Gauss Gauss Gauss Gauss non ha avuto niente a che fare con questo metodo ma per qualche motivo ha il suo nome quindi il metodo di Gauss è un classico metodo stazionario ma adesso nostra matrice P definiamo con la parte triangolare inferiore compreso diagonale della matrice A e la matrice L è la parte stretta lente triangolare superiore quindi non c'è il diagonale compreso qui e poi come prima possiamo definire l'interazione in questa forma quindi meno F K B e poi se facciamo l'invenzione di questa matrice siamo rimasti con con e la matrice di idrazione viene data per questa espressione o possiamo scriverlo in questa forma di forma T M oppure così A T meno T T meno T e come detto queste sono le stesse matrice se lo calcoli a matlab o da mano vedrete che queste espressioni sono uguali però diciamo che sono diversi quando vogliamo dimostrare cose perché si potrebbe trovare che per alcuni problemi uno è più o meno facile utilizzare ma comunque parleremo più formalmente dopo la pausa ma potete immaginare in un caso in cui la parte triangolare è inferiore è un'ottima è una buona approssimazione da anverso questo convergerà di nuovo purtroppo avrei voluto vorrei dirvi che questo converge sempre purtroppo non è così però vedremo dopo dopo pranzo che almeno la classe di problemi in cui converge è almeno più grande rispetto a Giacobi però c'è una c'è un'ultima cosa che volevo dire perché forse state già pensando questo se volessimo essere questo l'ho scritto Gauss nella forma triangolare inferiore se pensiamoci un attimo è sempre un sistema triangolare quindi è un po' più difficile rispetto ad uno diagonale ma ancora non è così difficile abbiamo già tutte le cose che serviamo se A è sparso come avevo detto che potrebbe essere non dovrebbe essere così terribile però in generale non c'è nessuna cosa più vantaggiosa di un sistema triangolare inferiore rispetto ad un sistema triangolare superiore cioè se l'avessimo voluto potessimo potuto semplicemente definirlo così e poi avremo la forma di Gauss Seidel di triangolare superiore e dal punto di visto numerico di quanto tempo ci vuole per calcolare eccetera è identico tradizionalmente si vede presentato Gauss in una forma generica nella sua forma triangolare inferiore ma triangolare superiore è anche ugualmente valido e dipende dipende dal problema potresti incontrare situazioni in cui uno funziona bene uno no dipende come la matrice è strutturata e le sue proprietà o forse tutte e due funzionano ma uno convergerà molto più veloce comunque questa è una relazione per stamattina quindi ci vediamo sto pomeriggio dato questo di lavagna un attimo se c'è ancora qualcuno che deve copiare qualcosa