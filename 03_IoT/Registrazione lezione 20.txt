Ok, allora l'esercitazione di oggi in realtà sarà un'esercitazione dove useremo sempre ESP, ma proveremo a utilizzare un strumento di machine learning da caricare all'interno del nostro dispositivo ESP. Per fare che cosa? Per fare la fase di inferenza sul dispositivo. Quindi adesso vedremo tutta l'esercitazione che ci permetterà prima di creare un modello, di addestrarlo, chiaramente l'addestramento del modello non avverrà sul nostro dispositivo, ma avverrà in cloud, grazie a una piattaforma che adesso vi farò vedere. Una volta ottenuto il modello addestrato, questo modello si potrà estrarre dal cloud sotto forma di libreria per Arduino, quindi useremo Arduino Sketch per fare la fase di inferenza, la fase di inferenza che è quella fase, vi ricordo, che semplicemente utilizza il modello addestrato. Quindi nel nostro caso l'ESP eseguirà semplicemente la fase di inferenza, leggerà valori dai sensori e con questi cercherà di definire qualcosa. Allora, lo strumento di machine learning che useremo oggi sarà lo strumento di machine learning molto utilizzato, che sono quegli strumenti di machine learning che vanno sotto il nome, diciamo sotto la famiglia di rilevamento delle anomalie. Che cos'è un sistema per rilevare le anomalie? Voi avete una serie numerica che magari rappresenta la temperatura, l'umidità, oppure rappresenta la misura della CO2, eccetera. Se non è un sistema per rilevare le anomalie, addestrate il vostro modello con un rilevamento che per voi è un rilevamento normale, il modello una volta addestrato sarà in grado di riconoscere su un dato mai visto se quella serie numerica rientra nella normalità di quei valori, oppure se è un'anomalia. Un'anomalia che può essere dovuta a un sensore che si è danneggiato, oppure un'anomalia perché davvero è successo qualcosa di molto particolare, ad esempio uno scoppiato un incendio e quindi il sensore di CO2 produce dei valori che non rientrano, diciamo così come andamento e forma, in quello che il modello ha preso dalla vostra fabbrica. Quindi oggi lavoreremo con questi modelli di machine learning che si chiamano appunto modelli per rilevare le anomalie, che utilizzano un particolare strumento di machine learning che è il clustering, K-Means, l'avete probabilmente studiato con Valerio Freschi, è uno di questi sistemi che appunto si basano sull'apprendimento e l'apprendimento supervisionato che vi danno la possibilità di generare appunto un clustering e da qui riconoscere il sistema. Allora per fare questo vando alle ciance perché dobbiamo iscriversi su una nuova piattaforma. Vi propongo sempre queste nuove piattaforme e vi dicevo anche oggi siete liberi di non farlo se non avete intenzione di creare un account di questa piattaforma, comunque è una piattaforma aperta e gratuita e adesso vi faccio vedere. Lo facciamo direttamente dalla macchina virtuale così saremo più agili. Faccio la condivisione della macchina virtuale. Ok. Creeremo un account di questa piattaforma online, che è una piattaforma dedicata proprio al mondo IoT che vi permette in maniera molto facile di registrare un modello e trasportarlo sul mondo IoT. Allora la piattaforma si chiama Edge Impulse, quindi cercate su Google Edge Impulse. E il primo link è proprio quello che interessa, vedete? Making things smarter. Allora, in questo qui chiaramente abbiamo il piano gratuito, che è quello che useremo noi, che ci permette di fare dei test e come limitazione al numero di CPU per fare il training, il numero di cicli, insomma un po' di cosine che potete immaginare. Ma dal nostro punto di vista è più che sufficiente. E' una piattaforma abbastanza recente, vedete, si basa proprio sul fatto che con il device siamo in grado di acquisire dati, quindi possiamo già acquisire i dati direttamente al nostro device, creare un dataset, addestrare un modello. Una volta addestrato il modello, trasportare il modello con la fase di deploy sul device e da quel momento in poi il device lavorerà col modello addestrato. Facciamo un login, quindi facciamo un'iscrizione. Io sono avanti nel senso che come potete immaginare l'ho già fatta, quindi faccio semplicemente il login, poi fate l'iscrizione. Io devo solo ricordarmi la password, che non è cosa comunque banale. Quando fate il login, probabilmente, visto che è la prima volta, vi chiederà anche di creare un nuovo progetto, probabilmente. Io ho chiamato un progetto aiutivo, voi chiamatelo pure come volete. E così mi trovo dentro il mio progetto, che è vuoto come il vostro. Quindi quando siete riusciti a trovarvi in questa condizione, avvisatemi pure. Se avete fatto il login, vi avrà detto di creare un progetto, probabilmente. No, non abbiamo scelto niente ancora, ho un nome di un progetto. Io l'ho chiamato un progetto IoT, chiamatelo come volete. Dovreste trovarmi in questa condizione, dove avete creating your first impulse, 0% o qualcosa del genere. Ce l'avete così? Perfetto. Allora, questa è una piattaforma che vi permette di... Vedete, in cima avete devices, data acquisition sulla sinistra, impulse design. L'impulse design è quello per creare il modello. E poi ci avete sotto retrain model, classification, live classification, model testing, versioning and deployment. Deployment è l'ultima fase. Quando avete addestrato il modello e l'avete pronto, col deployment scaricheremo la libreria per Arduino. Ok? La cosa che dobbiamo fare adesso però è, siccome il nostro progetto è vuoto, produrre dei dati per poter addestrare il nostro modello. Per produrre dei dati andremo proprio a fare un'acquisizione di dati in tempo reale dal nostro dispositivo. Quindi adesso andiamo ad attaccare uno di questi qua con il nostro sistema RSP dove abbiamo il DHT, quindi useremo il sensore di temperatura di unità. E per caricare i dati sulla nostra piattaforma, quello che andremo a fare sarà creare uno sketch semplice da Arduino che vada a stampare semplicemente sulla porta seriale il valore, ad esempio, della temperatura. Perché? Perché questa piattaforma Edge Impulse poi vi fornisce, vi farò vedere, un tool che si preoccupa lui di inviare i dati sul cloud. Quindi non dobbiamo scrivere noi lo sketch con le librerie di Edge Impulse come abbiamo fatto per InfluDB eccetera per poter inviare i dati, ma semplicemente il nostro sketch Arduino scriverà sulla seriale. E poi ci sarà quello che si chiama Data Forwarder, che è un tool che forniscono loro dell'Edge Impulse eseguito sulla macchina Linux che prende dalla seriale di questo dispositivo il dato e lo spara sul cloud. Quindi è molto semplice, vedremo. L'unica cosa che dobbiamo fare sarà installare questo tool che si chiama Edge Forwarder, qualcosa del genere. Quindi, se siamo arrivati a questo punto, mettiamo un attimo in background il nostro browser e lanciamo Arduino. Siamo pronti per creare un nuovo tool. In realtà lo sketch non lo facciamo da zero, ma andiamolo a prendere, l'ho caricato ieri sera, lo andiamo a prendere su Blended Learning, così facciamo prima. Quindi Blended UniURB. Ci avvantaggiamo, tanto non è questo il fulcro dell'esercitazione, nel senso che adesso lo sketch lo commenteremo, ma è molto semplice. Inizializza il DHT e poi stampa il valore della temperatura. Quindi, se andiamo su... Templogger. Esatto, allora se ce n'è più di uno, adesso iniziamo con Templogger. Allora, andiamo sull'ultima directory delle esercitazioni, che si chiama esercitazione SP più Machine Learning più Edge Impulse più Arduino Sketch. Andiamo ad aprire questo directory. Qua dentro c'è un po' di cose. Andiamo subito a prendere Artificial Intelligence SP8266 Templogger.ino. E questo qui è semplicemente il logger della temperatura. Lo salviamo localmente sulla nostra macchina. su Downloads, lo vado a spostare magari da qui. Faccio un Ctrl X da qui. Lo metto su Home Arduino. E poi lo apriamo. E adesso andiamo a commentare. Vediamo cosa fa questo Templogger. Allora, questo Templogger fa davvero poco, nel senso che, se l'avete già aperto, vediamo che include la libreria DHT. definisce il solito DHT-Pin che è il D5. Buongiorno. Definisce il DHT5, il DHT-Type e poi una frequenza in hertz di campionamento. Poi, nel setup, abilitiamo la porta seriale. Ricordiamoci che questo sistema andrà semplicemente a stampare nella seriale. Inizializzo il DHT. Nel mio loop, vabbè, faccio un po' di controlli se è ora di leggere, leggo temperatura e umidità, ma in realtà quello che vado a stampare sarà solo la temperatura. E lo stampo come valore numerico senza nessun tag, perché poi il data forwarder che vi ho detto raccoglierà questo valore numerico e lo sparerà in cloud. Quindi qui ci sono un po' di print line che avevo messo giusto così, ma le possiamo togliere tranquillamente. Anche la lettura dell'umidità la possiamo commentare, tanto non ci serve. E come vedete questo codice semplicemente ogni 200 millisecondi circa stamperà il valore di T. Ok? Quindi è un codice molto molto semplice. Adesso lo andiamo a compilare e a uploadare e vediamo intanto c'è la funzione. Ok. Ok. Ci mettiamo un po'. Intanto vado a chiudere la funzione. Ok. Ok. Connecting. Ah, scusate, dovete togliere il jumper, c'è il jumper del deep slip, con il jumper non si programma. Tanto oggi non ci serve, quindi dobbiamo ricordarci quando usiamo la programmazione di togliere il jumper del deep slip, altrimenti non si programma perché quello monopolizza il canale di reset, quindi il programmatore non riesce a raviare la CPU. Bene. Adesso il nostro tool banale sta stampando 17.10 gradi, è molto freddo qui dentro. Siamo in linea, però non va bene, al di là di tutto. Un'aula a 17 gradi non vedo che sia approvata dal Ministero. Non lo so, però freddo. Dobbiamo metterci il solito dito, se ci mettete il dito, aumenta. 17.30. Abbiamo capito che questo sketch funziona. Ok. Lo sketch sta funzionando. Allora, una volta che lo sketch funziona, possiamo chiudere tranquillamente lo sniffer qui di Arduino, perché adesso invece ci servirà installare il data forwarder per caricare i dati sulla nostra piattaforma. Una volta che avete fatto l'account, vedremo che questo strumento si collegherà con i nostri credenziali sul cloud e comincerà a inviare i dati leggendoli dalla seriale. Ok. Per fare questo, però, visto che nella macchina virtuale non è installato il data forwarder, dobbiamo installarlo noi a mano. Perché quando... Apro un terminal. Perché quando ho congelato la macchina virtuale, non avevo trovato questo tool, questa piattaforma. E quindi dobbiamo organizzarci in altro modo. Ok. Allora, per fare questo andiamo di nuovo su Blended, perché su Blended avrete visto che c'è e install script main.zip. E questo terzo file che appunto contiene l'eseguibile per installare il data forwarder. Quindi lo scarichiamo. Lo possiamo salvare dove ci pare sulla nostra piattaforma locale. E lo dezippiamo. Quindi adesso ce l'ho su Download, lo dezippiamo qui. Ce l'avete fatto a dezipparlo? Ah, io l'ho fatto dall'interfaccia grafica. Comunque è unzip, perché quello è uno zip. Se lo fai dall'interfaccia grafica, chiudi clicco il destro, fai strike qui. Comunque... Ce l'abbiamo nel Download. Ok? Adesso riprendiamo il nostro terminale. Facciamo un cd Download. Andiamo dentro questo e install script. E qui dentro ci abbiamo, vedete, un install Linux sh. Ci abbiamo due eseguibili, vedete. Install Mac e install Linux. Chiaramente lo dobbiamo dire install Linux. Confuso. Install Linux sh. Password. ESP. È abbastanza onerosa la fase di installazione. Quindi lo mettiamo a lavorare, perché prima fa l'aggiornamento dei pacchetti, poi aggiunge il reposito, insomma fa un bel po' di lavoro. Quando l'ho fatto io sulla macchina virtuale non ha avuto problemi, quindi speriamo che in questo momento riesca ad andare tutto liscio, anche se, come dicevo, è abbastanza onerosa la cosa. Facciamo lì. Grazie. Prima, come vi dicevo, forza la ptget update, ma fa un po' di cosine e poi arriva a scaricare effettivamente il tool che ci serve. Sì, templogger. Adesso intanto scarichiamo il templogger che ci serve per produrre dati e mandarli in cloud, così da poter addestrare un modello machine learning. effettivamente ci impiega sul tempo. Ricordo che ci aveva messo un po'. tre volte. Tiene listo di. Quasi la dommica. forse hanno avuto un eccesso di zelo in questo tool di script perché aggiornato tutta la piattaforma di installare la cosa che poi ci serve però l'ho trovato molto solido la piattaforma è questo questo cloud edge in pool è molto intuitivo molto semplice molto solido funziona bene e la cosa sorprendente produce poi un modello che funziona al primo colpo cioè non ho avuto problemi di compilazione neanche una volta nei tutti test che ho fatto quindi e non sarà banale portare il modello sopra un dispositivo come questo perché poi vedremo nel null nella prossima lezione giovedì che esistono degli algoritmi di riduzione della complessità del modello soprattutto delle dimensioni perché un modello che magari diventa 12 megabyte e qui sopra non ci sta perché abbiamo 4 mega di flash e pochi k di ram quindi capite ci sono tutti algoritmi di riduzione della complessità e del peso di un modello che chiaramente cercano di mantenere l'accuratezza più alta possibile perché è chiaro che ci sarà un trade off fra dimensione del modello e mantenimento della città di una certa ci siamo quasi e quindi finalmente sta installando i partiti che gli servono prima era proprio un aggiornamento ed impulsi e un generico io l'avevo chiamato io sì perché poi a me ancora sta andando quindi ti ha terminato con un errore sì sì ancora da me sta andando ci sono dei vuoi adesso abbiamo un errore anche noi però rilanciamolo no perché se lo rilanciamo secondo me dopo sì dopo non fa più tutta la parte iniziale grazie Great, thank you. se lo seguiamo senza sudo secondo me peggio non vorrei che non mi ricordo se l'avevo installato come sudo senza sudo non vorrei che volesse un'installazione sono direttori locale io l'ho fatto tempo fa si è una roba poi voglio dire lo è stato la stessa macchina virtuale solo che dal mio ufficio di là qualche tempo fa ma vediamo se anche senza sudo però questi ci piacciono di più ecco allora ho fatto bene va bene dai mi sa che va bene l'abbiamo fatto senza sudo è meglio ok adesso dobbiamo eseguire su allora se non sbaglio siamo dobbiamo eseguire edge impulse click mi ricordo restare lì pin edge impulse data forwarder dovrebbe essere questo quindi ciò che dobbiamo eseguire si trova o mairet.np global bin edge impulse data forwarder vediamo se è vero sì e questo è questo questo tool molto molto ben fatto perché si chiede what's your username or email address su edge impulse dot com e qui ci inserite chiaramente lo username che avete dato prima perché è il vostro account da me è la mia mail quindi emanuele punto l'attanzi anzi e poi ci chiede la password e tutto va bene vedete che cerca di collegarsi si si collega anche al e poi ci chiede la password dove noi abbiamo lasciato attaccato il nostro sp che sta sparando a temperatura periodicamente e poi siccome io nel mio account ho due progetti mi dice quale progetto a quale progetto vuoi connettere questo device devo connetterlo a iot quindi c'è quello sotto voi probabilmente ne avete uno solo vi sta funzionando in questo modo forse perché avete un progetto solo progetto a iot e poi vi dice detecting frequency da me ha fatto la detection di where e poi vi dice un sensor access detected il 17.2 what do you want to call them come lo vuoi chiamare? separati da virgola in realtà abbiamo solo un asse quindi lo chiameremo temp invio come vuoi chiamare questo device perché anche il device che è dal quale sta facendo la collezione potrebbe avere un nome io lo chiamerei esp 8266 underscore flattanzi è un nome semplicemente un tag che verrà associato ai dati provenienti da questo device adesso dice device is now connected to project iot e vai su acquisition per acquisire i dati adesso lo lasciate così e lui sta facendo il forward di tutto ciò che riceve dal seriale da questo device sta facendo tutto il forward in cloud quindi se è andato tutto bene se siete riusciti a fare login eccetera lui sta facendo questo però me l'ho dimenticato una cosa quindi buttiamolo un attimo con control c adesso quando lo rilanciate non vi richiede tutta la login eccetera perché ha salvato i suoi parametri ma dobbiamo lanciarlo con meno meno frequency 1 nel senso che fa un ricampionamento a un avete visto lui ha fatto la detection che era due a metri ci diamo meno meno frequency 1 rifà il campionamento a un ea su di rimandiamo un dato al secondo vedete non richiede più tutte le cose di prima perché è già configurato detecting data frequency quindi c'è un verrai di in frecchio c'è tu un'erro device questo è connetto aiut iot vai la sopra siete anche voi questa condizione come lo vuoi come lo vuoi chiamare noi abbiamo noi abbiamo chiamato temp o temperatura quello che vuoi dopo lo vedrai apparire sul cloud mentre il device manda 2 air circa lui riporta tutto a un air questo è utile perché magari fa già una media lui capito il locale prende due campioni di media di marco adesso andiamo in cloud quindi torniamo sul nostro browser perché allora abbiamo messo un di lei di 200 200 millisecondi sarebbe 5 airs il problema che perde del tempo perda del tempo nella lettura del dht il dht non ritorna immagliatamente il dato quindi se la del tempo del dht più 200 e viene fuori 2 airs con il dht no il dht 11 molto lento è fatto così perché ha un protocollo di comunicazione si chiama one wire usa un solo filo è lento perché su quel filo prima deve mandare pacchetti di sincronizzazione poi deve scaricare il dato e più di così non va ci vogliono dispositivi più veloci tipo quelli quadro c sono i quadro c non sono uguali del dht c'è di quel sensore blu di quella parte blu è lento però è un sensore di temperatura quindi nessuno chiede di solito temperature così era meno meno frequency meno meno frequency 1 cioè l'erro si si lui praticamente questo qui sta scrivendo sulla seriale l'interazione manda su l'unica cosa che ancora noi abbiamo detto di salvare quei dati quindi in realtà i dati non stanno davvero salvandosi sul cloud arrivano ma il cloud li sta semplicemente ignorando adesso andiamo sul cloud e diciamo di far partire la fase di acquisizione quindi se siamo basso è di un po vedete intanto se andiamo su devices adesso vedete che c'è un device scollegato vedete da me c'è sp8266 lattanzi con l'id il type data forward quindi è il software data forward c'è un sensor con un axis e l'ultima lettura è stata le 9.49 adesso andiamo su data acquisition perché ci serve acquisire dati data acquisition e vedete qua ci sono un po' di informazioni vedete sulla destra c'è il record new data il device abbiamo solo quello connesso e quindi già ce l'ha selezionato lì sensor with one axis temp perché il device si presenta in quel modo e qua c'è già la sua frequenza di un erzo sapiamo già tutto l'unica cosa che dobbiamo inserire è il nome di questa acquisizione possiamo chiamarla temperatura in aula e sample lente quanto vogliamo acquisire allora qui è espresso in millisecondi 10.000 millisecondi sono 10 secondi per addestrare un modello non è tanto di quindi dobbiamo campionare un po' di più adesso lo mettiamo a campionare almeno che ne sono 10 minuti 5 facciamo 5 minuti dai potremmo fare anche 10 poi facciamo andiamo a fare la caffè e poi torniamo dai facciamo 10 minuti 10 minuti sono 600.000 quindi 600.000 con 600 secondi che sono 10 minuti e poi facciamo start sampling e vedete lui comincia a fare il countdown 598 secondi eccetera e comincia a campionare mentre campione non li vediamo i dati li vedremo solo quando è finito di fare il sample l'ideale sarebbe che in questa finestra di acquisizione accadessero anche delle variazioni di temperatura perché deve dobbiamo addestrarci un modello su questo ok quindi è chiaro che se noi addestriamo un modello con 10 minuti che porta sempre 27 17 gradi e poi è facile dire quando ci sarà un'anomalia quindi mettiamo il dito ogni tanto su è molto comodo questo tool vedete in due passi siamo riusciti a caricare dati su cloud era già utilizzato e la cosa che vi dicevo molto utile è che in pochi passi riusciamo a inviare dati in cloud soprattutto senza dover modificare un codice dentro dentro le sp perché le sp basta che scriva sulla seriale poi c'è questo data forwarder quindi in realtà l'idea non è male no che hanno avuto questi del engine pools per facilitare le cose nella iot bene io direi che adesso possiamo davvero lasciarlo così magari passiamo la pausa un pochino prima e così quando torniamo dalla pausa avremo un po di dati per addestrare il modello e poi un'altra testato il modello premo il building del modello e lo caricheremo su arduino quindi lo lasciamo qua io adesso lo metto vicino alla giuntura del processore così di arriva al caldo il processore del mio portatile dovrebbe aumentare metto la registrazione in pausa quando avete praticamente affitto il campionamento vi mostra in anteprima vedete sotto la il grafico del dato che ha acquisito e lo trovate qua come tra i collect data chiaramente per addestrare il modello potete fare più sessioni di collect data quindi potete fare più file diciamo così non e potete mettere 4 5 quelli che volete che poi potranno essere usati nella fase di training ma volendo nella fase di testing allora adesso la cosa che dobbiamo fare però è creare un modello quindi andare a lavorare quello che chiamano un impulso quindi ci vedete sotto data acquisition cioè impulse design impulse design serve proprio a creare dei dei sistemi di processing di queste di questi dati e un modello da destrare quindi se noi andiamo su impulse design quello che vediamo è che lui ci propone da subito un blocco questo qui in rosso che è un blocco accetto a una serie data temporale del term serie data e lui ci dice che c'è un solo aste che si chiama temperatura e quello che ci sta proponendo è un sistema di window wing cioè di analisi a finestra del segnale no come come si fa normalmente normalmente come si fa a lavorare su una serie temporale si prende una finestra su quella finestra si calcolano delle feature con quelle feature poi si va ad addestrare un modello ok e quindi lui ci già si fa già una proposta ti dite il windows size mille millisecondi che sarebbe un secondo window increase mille millisecondi allora che cos'è il windows size banale è l'idea è la dimensione della finestra di processing sulla quale calcolare le feature il window increase invece è la percentuale di spostamento della finestra è la dimensione di spostamento quindi in questo caso abbiamo windows size un secondo windows increase un secondo quindi vuol dire che la seconda finestra è proprio di non overlappa per niente con la prima perché è subito successiva alla seconda e questo è lui aumenta di questo modo allora siccome abbiamo un campionamento ad un earth io non terrei la finestra di un secondo perché su un secondo abbiamo un dato solo è inutile quindi lavorare con una finestra così piccola allora io quanto meno metterei 5.000 millisecondi 5.000 millisecondi per così abbiamo almeno una finestra che copre cinque punti provenienti del nostro device window increase lo lascerei a un millisecondo per a un secondo perché almeno così abbiamo una grande overlapping delle finestre e abbiamo alla fine più più più più feature perché altrimenti abbiamo solo dieci minuti di campionamento e questo qui la quantità di di overlap ci aumenta il numero di feature che possiamo calcolare zero per data semplicemente se i dati non sono molti per delle finestre aggiunge gli zeri nell'ultima parte ecco questo vuol dire diciamo che così ci piace in così come l'abbiamo configurata però dobbiamo aggiungere un processing block vedete qui c'è ad processing block e poi c'è ad learning block il processing block è questo che vi ho appena detto per estrarre delle feature quindi chiaramente qui non lavoriamo con il deep learning perché l'idea di questa piattaforma di carriere i modelli abbastanza snelli da poter poi inserire sopra un device edge e quindi l'idea è calcolo delle feature su queste a destra il mio modello quindi andiamo a cliccare su ad processing block e ci appare un pop up che ci dice cosa possiamo fare vedete se i nostri dati sono immagini abbiamo pre process e normalize image data flatten che si usa proprio quello che dobbiamo usare noi per una serie temporale poi abbiamo audio spectrum analysis spec di cose noi andiamo ad aggiungere un flatten che questo che serve proprio per le serie temporali e l'input axis di flatten non può che essere la temperatura c'è solo quello il nome possiamo lasciare tranquillamente fatte nel non è che questo qui calcolerà le feature dopo l'ora va a essere ma andrà ad essere configurato perché ancora non possiamo configurarlo perché dobbiamo chiudere la catena vedete lui ci dice ancora di manca un learning block non possiamo ancora primi premere su save perché dobbiamo chiudere la catena benissimo quello dovrebbe ok è sempre più semplice di quello che uno pensa non lo diciamo a nessuno allora una volta fatto questo andiamo ad aggiungere il learning block allora learning block abbiamo anomali detection regression e classification e noi vogliamo proprio lavorare con l'anomali detection in questo caso che k means cluster quindi l'ultimo che abbiamo in fondo servirà appunto a definire il modello che ci permetta di identificare delle anomalie adesso la norma di detection l'abbiamo fatto possiamo fare save una volta fatto save allora la catena è stata acquisita e se vedete sulla sinistra l'unica cosa che crei crei di impulso nel senso che l'impulso è stato creato adesso dobbiamo lavorare su flatten cliccate su flatten sulla sinistra ecco flatten ci dice come calcolare le feature allora ci fa vedere intanto la finestra di campionamento vedete questa cosina bianca qua sopra che scorre no quella è la nostra finestra di 5000 millisecondi che poi verrà fatta scorrere chiaramente e sotto ci dice rossi precalcola le feature sotto quali sono le feature che lui ci ha dato di default ha messo l'aver age il minimo il massimo la ruman square standard deviation la schiuna e la portosi che sono alcune delle feature più usate in analisi appunto in processi delle serie temporali per machine learning allora io toglierei la curtosi e la schiù che sono delle fisiche non sarete mai sentito parlare queste queste qui vanno a valutare la simmetria di una serie temporale nella finestra quindi per capire se c'è simmetria verso il rispetto allo zero verso destra sinistra le togliamo anche perché sono un po complesse da calcolare quindi queste aumenteranno sicuramente il codice lasciamo quelle più semplici il lever il minimo il massimo la rudiment square standard deviation quindi abbiamo deselezionato le ultime due poi ciò facciamo un parametro vuoi scalare l'asse cioè quella tempo questo valore magari era in milligradi posso trasformarlo in gradi noi lasciamo la scala 1 perché vedete qua ci dice anche il picco di utilizzo della ram per calcolare le tifiche si dice che è tommasci ci basteranno 60 byte per calcolare queste feature come come partita di memoria di picco anche qui il chiamo 6 parameters una volta che il chiamo 6 parameters il questo blocco è pronto per generare le feature vedete ci dice che verranno generate 596 windows perché abbiamo detto appunto la finestra era da 5.000 ma scorreva di mille in volta clicchiamo su generate feature generate feature crea un job quindi lancia un lavoro diciamo così sul cloud e alla fine vi produce le vostre feature e fiche sono già state prodotte quindi ha già creato le 596 nel redd 596 feature dove ogni feature è sostituita da minimo massimo medio standard devi e rote man square questi cinque valori e di qua vi dà la possibilità di plottarli vedete su un sistema tridimensionale adesso lui ha plottato la media la minima e la massima si è un grafico 3d e se noi lo possiamo spostare ok adesso le fiche sono pronte per fare cosa per addestrare il modello di anomali detection vedete che c'è rimasto sempre sull'età nomi detection in grigio mentre ora creati impulse e flatten sono verbi giustamente processati andiamo su anomali detection e anomali detection deve essere configurato allora questo ricordiamoci che un sistema di machine learning masato su k min cluster quindi ci dice quali sono il numero di cluster che vuoi predisporre 32 allora è chiaro che più saranno il numero di cluster più il modello sarà grande più sarà possibile interpretare varia variazioni all'interno del della nostra linea temporale della nostra serie di dati adesso diciamo che 32 può tranquillamente bastare ma possiamo mettere anche 64 anche raddoppiare il numero di cluster e poi ci chiede quale feature vuoi usare e io le selezionerei tutte visto che non avrebbe senso visto che di là abbiamo definito delle feature le selezioniamo tutte per l'addestramento di questo modello la stella quindi che qui è consigliata fortemente ruth man square la consiglia fortemente quindi ti dico preferisco che tu la uvidi recommended base in your input ti sei raccomandata in base al tuo input e poi facciamo start training anche qui creiamo un job sul cloud che piano piano andrà ad addestrare il job completed ha già addestrato velocemente il modello e qua vi fa vedere appunto il grafico vedete con i cluster come si vanno a distribuire adesso chiaro p la serie temporale e mia era molto semplice perché c'era questa crescenza è chiaro che per funzionare bene un modello come questo deve avere tanti dati di l'idea è quella dobbiamo addestrarlo con un certo numero di cluster elevato in modo tale che la cosa ideale quale potrebbe essere uno lascia il sensore per un'intera giornata dentro la stanza campione all'intera giornata con quella destra e da lì in poi il modello individua le anomalie rispetto a quello che una giornata tipo è chiaro che adesso nel nostro caso questa cosa non sarà così veritiera ma una volta che abbiamo fatto il modello vedete il modello è fatto vedete questa matrice qua che viene spalmata sono tutti i pesi del modello no perché abbiamo appunto definito un modello come con 64 cluster di tipo k-means e questi questi pesi saranno quelli che poi dovranno essere convertiti come vi dicevo nella fase di riduzione della dimensione per poter stare dentro l'SP8266 ok però prima di fare il building del modello e trasportarlo sulle SPS8266 passiamo un test per vedere questo modello come lavora e se vedete qua abbiamo anche live classification live classification cosa vuol dire che se avete attivo il data forwarder di prima e noi adesso il modello lo possiamo direttamente testare con l'input che sta arrivando in questo momento con il live classification quindi clicchiamo sul live classification e lui ci dice guarda c'è connesso s più 82 66 di lattanti che a questa roba qua con la frequenza di un air quanto vuoi campionare per fare il testing allora adesso che ampegniamo qualcosa come 5 se come 6 secondi dei secondi sono 6 mila millisecondi e quindi facciamo start sampling adesso continua che campiona per 6 secondi in questo istante il valore e poi mi fa la classificazione in tempo reale dice classifying ok abbiamo fatto un campionamento un po breve visto che le finestre sono di 5.000 di 5 secondi però vedete ha la definita come anomalia vedete questa finestra per lui un'anomalia infatti dice anomalia 1 e questa è l'anomalia probabilmente sì perché rispetto al adesso io così ma intanto facciamo anche un campionamento un pochino più lungo la finestra 5 milisecone 5 secondi poi vi faccio vedere anche un'altra cosa che si può si può fare allora torniamo in live classification facciamo in piuttosto che 6 secondi facciamone 18 così bene abbiamo un po di finestre mi dispiace tu sei adesso lo ripetiamo costante si si e allora c'hanno molta inerzia questi sensori adesso vi faccio vedere anche a me si ecco adesso adesso si sta abbassando vedete con che inerzia si abbassa vedete perché l'ho spostato dalla dalla ventola si abbassa ma con un'inerzia insomma banale e anche da me sta individuando tutte anomalie vedete non ma lì è tutto tutto sopra vi dice anomali no anomali 14 e 0 e poi vi da anche il peso dell'anomalia vedete dove c'è scritto anomali il valore dell'anomalia 4 19 4 17 vedono sono tutti uguali nel senso che più è alto questo valore e più l'anomalia riconosciuta come tale chiaramente il nostro modello cosa ha imparato imparato di alto il valore medio di prima quindi se si discosta dal valore medio per lui darà sempre un'anomalia la cosa che possiamo fare però è anche settare adesso torniamo in anomali detection scusate in live classification no dove è che si fa ai model testing in model testing sotto live classificati c'è model testing model testing ha mantenuto le due tracce che abbiamo appena fatto quella da 18 secondi da 6 secondi e a fianco a classi fai all c'è un tastino e ti dice setta la la soglia di confidenza la soglia di confidenza normalmente si mette attorno a 0 8 qui era 0 3 questo vuol dire che per differenze fino a 0 8 l'anomalia non viene rilevata se supera 0 8 allora viene rilevata è chiaro noi prima vediamo un'anomalia da 4 quindi sarebbe non cambierebbe la classificazione assolutamente no 4 è un valore di simili distanza del cluster quindi se supera 0 per la distanza del cluster allora per noi non è un'anomalia 4 e molto supera di molto chiaramente dove devo andare ci sono questi tre puntini vicino a classificare per settare la soglia di confidenza 0 8 si di solito si tiene 0 8 come soglia di confidenza dei modelli di detection che è una distanza appunto dal cluster è un valore a dimensionale chiaro che prima quando abbiamo fatto la live classificazione veniva 4 quindi la rifaccio adesso una live classificazione andando a fare di un guru a un sample di 18 dico che l'ho spostato adesso non è più influenzato dalla ventola può darsi che vada un pochino meglio sì allora per questo esperimento diciamo il sensore di temperatura ha un po troppa inerzia e normalmente questi esperimenti si fanno con i sensori di co2 o con i sensori di idrocarburi perché i sensori di co2 di carburio variano più rapidamente la risposta ecco qui vedete stava sta calando ma sta calando in questo modo maledetto adesso però non mi dice mi dice tutti sono fuori dall'anomalia vedete no anomali no anomali sono tutti blu vedete 0 7 sopra 8 abbiamo messo la soglia 0 8 adesso vedete la soglia sempre più bassa si sta raffreddando ora è chiaro che come vi dicevo prima per avere un sistema è affidabile bisognerebbe fare un training su una molla di dati maggiore e via dicendo però passate mi insomma la catena delle cose che abbiamo sviluppato abbiamo acquisito da che abbiamo fatto il processing abbiamo fatto il training abbiamo fatto il testing adesso è ora di portare però l'inferenza sul dispositivo ok luca come si messo è riuscito a mettere i blocchi di data processing se vuoi lo riguardiamo un attimo fanno lo stesso però guarda che si si non ha fatto lo stesso guarda mai su impuls design e aggiungi un flatten l'hai aggiunto quindi ad process in blog poi ad learning blog di tipo anomaly detection k means e poi fai save impulse e fatto se il pool benissimo una volta che fatto 6 in plus clicca su flatten sulla sinistra e qui devi configurarlo per configurarlo ti si togliamo le ultime due e poi fai 6 parameter e poi fai gli fai generare le fiche ti lancia un job su un cloud e ti produce le fiche se va tutto buppine no a parte quello ma quanto era la finestra di campionamento di training un po corta forse è quelloicio è 那ca roast per questo storico si no però Grazie. Ok, andiamo a nuovo nel section. Allora qui fa il selezione. Se mettiamo tutto il video e poi fa il tabaccio. Sì, è un modello un po' più significativo perché sono tutte uguali però. Il modello è un modello. Ok, adesso puoi seguire. Nel senso che puoi chiudere comunque la catena, anche se appunto non è molto significativo perché i dati sono pochi e sono tutti uguali. Quindi quando vai a calcolare la direzione standard viene zero, la root-meansquat viene zero. Però adesso è l'ora, come vi dicevo, di portare il modello che abbiamo addestrato sull'SP. Quindi vedete in fondo c'è deployment. Plicchiamo su deployment. E deployment vi dice, come lo vuoi fare il tuo impulso? Puoi creare un C++ library, un Arduino library, un cube pack, un tensor library su Nvidia, eccetera. Noi chiaramente scegliamo Arduino. Cecchiamo Arduino. Una volta ceccato Arduino, sotto c'è build. Clicchiamo su build. E lui lancia un job dove crea un po' di cose e produce uno zip. Vedete? Ha prodotto una libreria in zip. Nella versione 1.01. La prima building che facciamo, poi lì man mano che facciamo i build cambierà anche la versione. Salviamola tranquillamente sul download. Diciamo ok e abbiamo la nostra libreria. Adesso la libreria per usarla serve che cosa? Serve uno sketch d'Arduino che linki a quella libreria. Ma soprattutto lo sketch deve usarla alla libreria. Perché questa qui è una libreria che contiene tutto l'SDK che implementa un modello di tipo K-Means e contiene i pesi da noi addestrati. Ok? Ma lo dobbiamo usare. Per usarlo ho predisposto uno sketch su Blendit che adesso andiamo a scaricare. Ci siete? Quindi su Blendit abbiamo Artificial Intelligence ESP8266 Temp senza logger. Perché il logger era quello di lo sketch di prima che ci serviva a salvare i dati. Questo invece è lo sketch che usa la libreria di inferenza. Quindi lo salviamo anche questo. L'ha salvato in download. Lo vado a spostare. Ctrl X. Lo metto dentro Home Arduino. Ctrl V. E poi lo apriamo. Ok. Ok. Ok. Adesso commentiamo un pochino questo sketch prima di fare le dovute modifiche per poter usare il modello che abbiamo appena generato. Perché questo è uno sketch che avevo prodotto io tempo fa che utilizzava un altro modello. Infatti vedete in cima c'è include, l'attanzi 76 project 1 inference. Questo va modificato in base al file di include che ci ha prodotto Arduino che dovremo andare a vedere come si chiama. Quindi questa riga, l'inclusione sarà sicuramente da modificare. E vabbè, questo super l'avevo commentato, non serve include Arduino.h. Quindi lo possiamo togliere. Vabbè, si presenta così. E qui, vi dicevo, dovremo andare a capire come si chiama questo file .h che ha prodotto nella libreria che abbiamo scaricato. Ma lo vediamo dopo. Cosa fa questo sketch? Chiaramente importa la libreria DHT perché deve classificare in tempo reale i dati dal DHT. Quindi, come prima, definiamo il D5 come il PIN, il DHT. E poi, vedete, sono stati definiti degli array qua sotto che sono inference future e future. Questi array serviranno per copiare i dati della temperatura e poi produrre le feature attraverso la libreria che ci ha prodotto, chiaramente, Edge Input. Poi, creo l'istanza di DHT, temperatura e umidità. Nel setup cosa faccio? Al solito, inizializzo la seriale. Vabbè, la stampa è ARC Quality Monitoring with Machine Learning, ma più possiamo metterci quello che ci pare. Inizializzo il DHT e poi stampo queste informazioni relative alla libreria. Cioè, DSP Input Frame Size, quanto è grande la finestra su cui dobbiamo campionare, e le label count, quali sono le feature, ma semplicemente è un debugger. Andiamo a vedere il loop. Allora, nel loop, qua dentro cosa faccio? Ogni tot intervalli in millisecondi espresso di sopra, calcolo, anche qui è temperatura e umidità, ma ci bastava semplicemente la temperatura, e li stampo. E poi, vedete, la temperatura la vado ad aggiungere nell'array dell'efficio, vedete? Assegno T, che è la mia temperatura, a feature in posizione feature a X e la incremento. Quindi nel loop vado a riempire il mio array. Visto che il mio modello l'ho addestrato su una finestra di 5 secondi, e qui dovrò mettere 5 valori. Quando l'array è pieno, e me ne accorgo da sotto, se l'indice è uguale a input frame size, vuol dire che l'array è pieno, allora faccio l'inferenza. Quindi l'inferenza la faccio solo al quinto secondo, quando l'array è pieno. E dico, running l'inference. Allora, per fare il running dell'inference, la libreria si usa così. Allora, devo copiare le mie feature su un nuovo array, che si chiamerà inference feature. Quindi memcopy fa quello, semplicemente copia il contenuto di feature su inference feature, e poi lancio questo signal from buffer su inference feature, che calcola le feature. Questo serve a calcolare le feature. Una volta calcolate le feature, vedete sotto, invoco run classifier. Run classifier su signal, che appunto sono le feature prodotte, esegue l'inferenza. E poi sottostampo la predizione. Prediction ti fa vedere anche i tempi che ci ha impiegato il DSP, che sarebbe praticamente la libreria per calcolo delle feature, a calcolare le feature, a fare la classificazione e a identificare l'anomalia. E poi sotto vedete se, oppla, se anomaly, se result.anomali maggiore di 08, questa soglia che vi dicevo, normalmente si usa 08, se il valore dell'anomalia è maggiore di 08, allora stampa anomaly e ti stampa lo score. Quindi se nella seriale leggiamo anomaly, vuol dire che ha fatto la detection di anomaly, se no non lo leggiamo, perché sotto if result.anomali maggiore di 08. Ok, allora adesso cosa dobbiamo fare? Dobbiamo capire come si chiama questo file h che include la libreria. Quindi per fare questo andiamo ad aprire il file zip che abbiamo scaricato prima, EI IoT Arduino 1.01, lo apriamo, IoT Inferencing, dobbiamo andare su Sources, ecco, da me si chiama IoT Inferencing.h. Non so da voi come si chiama, anche da voi? No. È in base al progetto, quindi dobbiamo copiarci quello. Quindi andiamo a copiare. IoT. Come hai detto, scusa? No, adesso vi faccio vedere, è la cosa comoda di Arlui. Quindi ci serve solo sapere come si chiama questo nome, questo file, ok? IoT. Dopo vi faccio vedere come si fa a linkare. IoT Inferencing.h. Vediamo se l'ho fatto bene. Eh, non mi ricordo, fatti vado a vedere. Mi sa che hai ragione te. Sì, trattino basso. Quindi IoT Inferencing.h. E facciamo un sale. Adesso però la libreria va linkata, perché sicuramente non c'è. Quindi andiamo su Sketch, Include Library, e Include Library ci può passare uno zip. Vedete? Add Zip Library. Facciamo Add Zip Library. Andiamo a risolvere lo zip dove era, era in download, si chiamava AI IoT Arduino 1.01, e lui lo spacchetta e lo allega al device. Adesso possiamo provare a fare compile. Se non abbiamo dimenticato nulla, tutte le volte che ho fatto questo esperimento, non ha mai dato pure di compilazione. Quindi voglio dire, Edge Impulse ha prodotto qualcosa di ben fatto, diciamo, bello solido. È un po' complicato da compilare, perché non è proprio piccolino, diciamo, questo strumento. E sta sull'SPG. Ricordiamoci di andare sul terminale intanto e terminare il data forwarder, se no ci blocca il dev SP1. L'SP0, scusate, se lo blocca. Ho terminato il data forwarder, perché adesso dovremo riflessare l'applicazione sul nostro ESPG. Come vedete ci impiega, insomma, del tempo. Tanto è un buon segno, vuol dire che l'inclusione della libreria è andata bene, perché altrimenti si sarebbe bloccato a pubblico. Eh sì, non è per niente leggero, perché alla fine il modello è il meno, nel senso che il modello è un file hack con tanti pesi al suo interno. Il problema è tutta l'architettura per poter usare quei pesi come modello. Poi c'è la parte DSP che produce le feature, anche quella è inclusa, non nel modello, è fuori dal modello, ma è inclusa nelle SDK. Tutta la parte per produrre le feature, un'altra prodotta le feature, si fa lanciare inferenza sul modello. Mi sta andando? Sì, poi possiamo anche fare subito la più, dovrebbe stare, insomma, di solito non è molto grande il modello che abbiamo generato. ecco qua. Io sto usando il 38% della memoria RAM e il 26% della memoria flash. C'è ancora spazio per fare modello anche un pochino più complicato. Avevamo usato 64 cluster. Chiaro, più aumenti i cluster, più diventa grosso il modello. E adesso cerchiamo di caricarlo sopra. sta facendo l'upload e poi vediamo se reagisce dandoci delle informazioni che hanno un senso. Ok, ha fatto il reset, andiamo ad aprire il serial monitor, vediamo cosa dice. Ecco, da me comincia a dire che c'è un'anomalia. Temperatura 18, umidità 32, anomalia. perché lo score è 1.12, la soglia 08 sta riscontrando sempre anomalie. Allora, vai sopra, su Sketch, include library, add zip library. E poi lì vai a cercare il file .zip. Eh no, ti conviene riprendere. Ecco, adesso non ci sono più anomalie perché l'ho avvicinato un po' al mio portatile, si è scaldato, è andato a 19 gradi, non dice che non ci sono più anomalie. infatti l'anomali score è negativo, meno 0,040. Niente, non si chiama niente. Vediamo se mi sono andato. sta salendo 20 gradi. Ecco, adesso comincia ad aranomali, lo score 0,9. Come vi dicevo, ecco, un sistema così ha senso se lo addestrate con tanti dati e quindi gli date diciamo così un andamento che non sia lineare come quello che gli abbiamo dato ma che possa in qualche modo codificare un segnale normale durante una giornata. Così affinché il vostro ESP semplicemente che cosa fa? Esegue questo modello e solo se c'è un'anomalia magari invia un messaggio con MQTT, vi manda una mail, qualcosa del genere. la cosa carina è che il modello è un modello non deterministico e lo vediamo che non è un modello a soglia perché vedete già adesso con 21 gradi dice che non ci sono anomalie benché prima uno dava delle anomalie con 20, qualcosa. Sì, non c'è alternatura. il modello è stato un modello uguale no, no, perché il modello sta nella flash avete visto quando si flasha il firmware va messo tutto non è che se ne mette avete visto che ogni volta lui flasha tutto il 100% della flash scusate. No, io lo provo di più, no, dico, col dispositivo dovresti tenere il modello se non la faremo allora sì. Sì, se il modello potrei collegarti con il modello e aggiornare il modello sì, sì, quel modo sì, il problema è che la cosa, normalmente cosa si fai? Ci metti una memoria EEPROM collegata perché c'è anche una porta per l'accomodizzazione sulla memoria e il modello lo lasci lì quindi over the air ti manda il modello lo scrivi sulla EEPROM e poi lo ricarichi da lì questo perché se ti riavvii altrimenti se il modello è solo in RAM lo perdi ora ti serve una copia nella EEPROM non lo puoi mettere nella flash perché devi cambiare tutto il firmware quando scrivi nella flash e lui lo carica e l'inferenza la rifà con quel modello nuovo allora vedete ecco sta funzionando insomma la cosa interessante è che in un dispositivo così piccolo siamo riusciti a caricare un modello di machine learning che abbiamo addestrato in cloud è chiaro che qui facciamo solo la fase di inferenza e la fase di addestramento e progettazione del modello la lasciamo invece a un sistema molto più potente giovedì vedremo i passaggi per portare dal punto di vista teorico vedremo cosa vuol dire portare un modello dal cloud dentro un dispositivo così piccolo con quelle che sono le fasi di compressione del modello di quantizzazione quella che chiama il pruning perché sono tutte fasi che vi permettono di togliere qualcosa perché se il modello il programma non ci sta togliere qualcosa ma toglielo con un criterio l'idea di dire tolgo qualcosa che mi riduca poco la sua accuratezza perché lo vado a togliere così brutalmente e questo lo vedremo nella teoria cioè cosa cosa ha fatto questa piattaforma Edge Impulse quando gli abbiamo detto di fare build del modello e vi dicevo la stessa cosa con questo dispositivo che ho comprato si può fare con il riconoscimento dei volti questo qui che ha la telecamera sempre su Edge Impulse potete campionare tante volte il vostro volto e metterci il modello di riconoscimento del volto e quindi lui lo esegue e magari vi dà un ok quando riconosce il vostro volto con questo dispositivo ripeto costa 8 euro è una cosa così c'è anche uno sketch che è un web server quindi ti fa preparare la webcam tranquillo in tempo reale si smette in wifi in tempo reale con questo qui mettendoci un web server dentro la mia moglie la metto in camera in casa così vedo cosa succede non troppo hanno un'inerzia troppo ah non va il tuo senso di temperatura allora sono lenti la stanza inerzia molto grande sempre meglio chiamare il brio allora adesso io blocco la registrazione perché abbiamo finito un po' di più che abbiamo finito il brio che abbiamo finito un po' di più un po' di più