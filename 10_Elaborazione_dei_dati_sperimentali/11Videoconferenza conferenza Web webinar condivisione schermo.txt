come come come come come come be Forsyric continuiamo con il test dell'ipotesi ok abbiamo visto l'altra volta come applicare il test dell'ipotesi a due casi abbiamo fatto due esempi un esempio in cui avevamo che la pdf era teta x la seta meno uno e le ipotesi erano su z cioè sul valore di z ok abbiamo visto che con il lemma in Neumann-Person potevamo definire qual era la x che divideva la regione critica da regione di mercettazione ok questo l'avevamo fatto con una sola osservazione cioè avevamo la direttata con una sola osservazione e vogliamo definire le due regioni l'incercitazione di H0 o di rifiuto di H0 e quindi di H1 rispetto all'H1 che è l'ipotesi alternativa e questo era un test che coinvolgeva appunto coinvolgeva una sola, cioè i valori definiti tali da definire la pdf perché appunto dando il valore di z, z, z, z, z, z, z, 1 la pdf veniva con z per questo è stato un esempio l'altro esempio è stato invece di più osservazioni tutte indipendenti l'una con l'altra ricordate? allora io volevo fare una cosa tutti indipendenti l'una con l'altra e abbiamo visto che il test era sulla possibilità che queste osservazioni fossero distribuite come una normale con una certa media la sigma con la sigma con la sitta o sempre la normale con un'altra media e sempre quella stessa quindi anche questo era un test in cui si conoscevano appunto le quindi potremmo sarebbe stato che al zero uguale due punti zero uguale 10 mi pare sigmo uguale 16 versus h1 tale che mi 1 uguale 15 e sigma sempre uguale a 16 il lemma in ambe due casi applicavano il lemma di norman pierson che si può scrivere come l di x h0 fratto l di x h1 maggiore di c dipende da alfa dove c'è una costante questo determina la regione di accettazione quindi ok dove l di x di l x h0 e l x h1 sono le punti di semiglianza secondo l'imposte di h3 con la proposta di h1 che è di legionamento maggiore di suono e una cosa importante che vi richiamo è che la funzione quindi l di x h0 non è altro che f di x h0 cioè la probabilità di ottenere i dati osservati se l'ipotesi è h0 quindi si chiama verosimilanza e una cosa importante è che se le x sono delle osservazioni dipendenti una dall'altra allora sappiamo che questa quindi se x sono l'avevo detto già l'altra volta ma lo richiamo perché è importante allora cosa si ha? si ha che l di x h0 o h1 adesso sono le importate è uguale al prodotto della probabilità di aver osservato sotto l'ipotesi h0 ogni osservazione perché? perché sappiamo che questo è proprio quello che poi corrisponde al teorema delle probabilità per eventi indipendenti va bene? cioè per eventi che in cui appunto non siamo una connessione diciamo del l'uno con l'altro va bene per questo lo richiamo perché avremo altri altri dati cioè riperà fuori altre volte e molto spesso invece di prendere questo si prende il logaritmo di questo prodotto perché? perché il logaritmo mantiene sempre la monotonia rispetto al valore della funzione in cui si fa il logaritmo che vuol dire che la monotonia vi ricordate la direte sempre y1 maggiore di y2 allora il logaritmo di y1 è maggiore di logaritmo di y2 questa è la monotonia che è quello che ci interessa quando facciamo delle disguaglianze e in più perché molto spesso si fa il logaritmo perché con il logaritmo il prodotto viene trasformato in una somma e le somme sono più facili da trattare se non è analita va bene questo è il ciclo nel caso dell'esercizio questo era esercizio 1 esercizio 2 nel caso del nel caso del esercizio 2 abbiamo visto che applicando appunto il problema di Norman Pearson quello che ci veniva fuori è che la statistica era proprio era la media aritmetica delle varie quindi per andare a distribuire subipotesi della media della popolazione si andava a vedere quanto era distribuita la media va bene stai seguendo avete riguardato partiamola qui avete riguardato la relazione per l'altra volta sinceramente si o no no per lui ha fatto così che vuol dire proprio no e neanche gli altri quindi va bene comunque questa faccio sempre un piccolo di caso per questo perché almeno ricominciamo da qualcosa da cui eravamo finito va bene però se non riuscite a riguardare la media qualcosa che non capite vi rimane lì è quello il problema non tanto non è che qui ci sono le interoperazioni però è chiaro che se uno non guarda non vede neanche quello che magari non capite dopo quando si vede le lezioni uno può venire a leggere i miei guardi però non rimane la stessa quindi cercate di di almeno di rileggere o di vedere se almeno più o meno avete capito non il passato ok allora queste erano delle dei test delle ipotesi semplici no quindi i composti invece sono i test dei riporti in cui abbiamo detto non si conosce cioè non si danno due alternative che determinano completamente la pdf dei gas pdf per esempio ne facciamo solo due poi dopo continueremo su questa cosa quindi facciamo questo esempio qui per esempio esercizio uno e due sono test semplici dei test composti per esempio può essere sempre un esempio sempre il test sulla media di una popolazione normale va bene allora l'abbiamo già fatto che è quello che abbiamo detto però come era un test semplice in cui ci chiedevamo la media può essere o 10 o 15 ci può essere anche un test in cui diciamo la media l'ipotesi nulla è che sia per esempio uguale a 10 l'ipotesi alternativa è che sia diversa dalla 10 quindi è un test sempre sulla popolazione però è un test composto non so avevo usato la parola composto l'altra volta semplice composto semplice e c'è un nome di diversi nomi composto l'ho detto ok allora questo test può essere questo che H0 sia quindi la media della popolazione sia proprio M0 e invece H1 che la media sia diversa da M0 va bene qui chiaramente sia non definiamo la media per H1 sia non diamo neanche la differenza di stano e quindi la Tdf non è definita in nessuno dei tuoi carri ok quindi non abbiamo la variazza ok allora in questo caso si può definire la statistica T T uguale l'altra parte ora come e in questo aspetta anche se lo metto qua a 9 ecco è questa t uguale x meno mi zero fratto s diviso radice di n ok questa si chiama la t di student cioè una variabile distribuita cioè questa variabile si distribuisce come proprio una distribuzione particolare che si chiama distribuzione della t t student allora prima di tutto vediamo un po' che cosa sono queste cose perché x per esempio prima in questo caso perché prima con x con il trattino veniva il vettore qui con x con il trattino indico la media aritmetica s invece è la stima una stima della varianza vedremo cioè la varianza vedremo che si può stimare se uno non la sa si può stimare dai dati così come noi stimiamo appunto la media tramite la mi tramite la media aritmetica e s visto che è una stima della varianza è uno fratto n meno uno sommatoria per i che va da uno a n di xi meno mi zero al quadrato n si chiamano i gradi di libertà della distribuzione di student allora nella distribuzione di student possiamo lo stesso salvo uno oggi è il il da nel 20 giusto la distribuzione di student è una distribuzione che assomiglia molto a una e in questa distribuzione utilizzando la t di student questa è la t quindi e questa è la distribuzione di student possiamo definire delle zone di accettazione allo stesso delle zone di rispetto allora se noi chiediamo di avere un'alpha quindi vogliamo un test con un certo valore di alfa alfa rappresenta la probabilità quindi di fare degli errori di un motivo e in questo caso questa probabilità è divisa in due parti perché appunto quando andiamo a fare a calcolarci la nostra t questa t può avere la stessa probabilità di essere una certa quantità a destra dello zero o a sinistra dello zero vedete se la guardate è zero proprio quando abbiamo che la nostra media aritmetica è uguale al valore della media che noi supponavamo è chiaro che quindi questa qui quando più questa è vicino alla media e tanto più appunto abbiamo la t piccola quindi siamo in una zona di accettazione va bene ed è pesata con che cosa? con la varianza perché è chiaro che più larga o più stretta è la zona di accettazione cambia perché la variante sappiamo che appunto misura dall'alghizza della nostra distribuzione quindi in questo caso se abbiamo un valore di alfa definito dobbiamo trovare i due limiti di io come l'ho chiamato comunque t1 vedete t1 e t2 ok tale che a sinistra di t1 che sia alfa metri e a destra di t2 che sia lo stesso alfa metri allora come si trovano beh la distribuzione t2 student non me la scrivo neanche è complicata però ugualmente ci sono o delle tabelle oppure adesso non si usano più le tabelle si usano appunto delle funzioni in byton sull'atribli student che chiaramente facilmente vi permettono di calcolare sia t1 che t2 dato alfa metri alfa metri ok quindi qui t1 sarà dato quando la cumulativa della distribuzione di student arriva ad alfa metri t2 sarà dato quando la cumulativa della distribuzione di student arriva a 1 meno alfa metri perché l'alfa metri deve essere di là come tutte 1 ok quindi in questo caso la zona di rigetto è t minore uguale di t1 o maggiore uguale di 2 ok quindi questo è l'esempio di un'altra statistica che utilizziamo perché è importante perché molto spesso si fanno cioè io ho delle osservazioni e mi dico ma la media di questa popolazione quant'è è quella che mi volevo cioè è quella che credevo è un'altra siccome la media è una quantità importante per definire una distribuzione chiaramente è importante avere una distribuzione e un test fatto proprio per la mia che dice qual è la probabilità di avere questa media o qual è la probabilità invece che sia un altro valore qualsiasi ok chiaramente tutto dipende anche dalla a cioè dal valore di a come noi appunto vogliamo fare se vogliamo un valore di 0.025 quindi un test con significatività dello 0.05 e dovremmo mettere 0.025 qua e 0.025 ok ok un'altra un'altra dopo o dopo oppure anche per casa non dopo degli esempi cioè due esercizietti sciocchi da fare su questo un'altra test importante quindi questi sono un test standard quindi che vengono utilizzati spesso e il test sulla varianza ok ok ok ok ok ok ok ok ok ok ok ok ok ok ok quindi una popolazione normale anzi più che di una popolazione normale popolazioni normali che mettiamo a confronto ok ok allora in questo caso la H0 è che le varianze siano uguali invece che sigma sigma 1 mettiamo va bene eh sì ma sì meglio meglio se non ci si confonde sigma uguale sigma b dove a e b sono la varianza delle due popolazioni H1 invece è che sigma sia diverso da sigma di che le varianze siano diverse allora in questo caso si utilizza un'altra statistica che è la statistica di Fisher non ricordo mai se c'è la C o no io qui ce l'ho messa però potrebbe anche solo essere C dovrebbe essere S A non ricordo allora la statistica di Fisher che invece che con T indichiamo con F è data da S1 al quadrato diviso S2 al quadrato ok e in questo caso abbiamo che questa quantità si distribuisce proprio come appunto la F di Fisher come diciamo la distribuzione che c'è una distribuzione proprio che si chiama distribuzione di Fisher ok allora S1 e S2 che cosa sono? Sono appunto anche qui la stima delle varianze della popolazione 1 e popolazione 2 quindi hanno questa stessa forma che riscriveremo con facciamo S allora qui veramente le abbiamo chiamate per non fare confusione no vi faccio solo confusione S A S B dove per esempio S A è uguale 1 fratto N A meno 1 la sommatoria per I che va da 1 a N A di XI A meno X A medio va bene al quadrato ok quindi sono due E la stessa quantità che abbiamo visto dall'altra parte S B va bene sarà la stessa cosa però quindi vedete che queste due popolazioni possono avere anche questa N A ci sarà N B anche dei valori diversi di numerosità dei campioni e qui vedete che rispetto che differenza c'è rispetto a questa che qui non conosciamo che qui conosciamo supponiamo di conoscere la nel valore di aspettazione mentre qua cioè questo è un valore dato perché io faccio il test sulla variazione sulla media quindi mi è uguale a 12 qui invece il valore non è dato perché io faccio un test vedete tra l'altro neanche su un valore su un uguale a due valori e quindi quella che doveva essere la media va calcolata secondo utilizzarla allora Fischer come è fatto la potete andare a vedere la distribuzione di Fischer vedete sempre positiva ed è una cosa di questo genere questa è la distribuzione e questa è la F di Fischer va bene chiaramente H0 ci dice che cosa H0 ci dice si verifica quando è F uguale 1 ok perché H0 è proprio che le due sigma siano uguali quelle sono le sigma stimate e queste sono le sigma che lo sono e qui lo stesso avremo la possibilità di utilizzare un test appunto con una certa significatività va bene quindi questo se nessuno altro poi le statistiche si possono trovare l'altra volta avevamo visto anche non so con i pesci di diverse cose le statistiche che si ottimizzano anche tramite le network eccetera eccetera per dei delle delle delle scritturei standard ci sono delle statistiche che sono già mostrate che sono le più famose diciamo non c'è sono altre comunque due che sono molto importanti va bene allora qui volevo vedere se ci arrivo non qua nulla qua anche qua blended Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. M0 e 1260. Ok? Allora, cosa si deve fare? Si va a calcolarsi da TD student secondo queste formule e poi si va, bisogna anche mettere i dati di libertà, e poi si va, se si vuole che la significasse a 0.05, utilizzando le funzioni di student, che sono anche i partiti, si può andare a calcolare questa probabilità. L'altro esercizio è una cosa del genere. Dati 2-7 misure di una stessa grandezza, si hanno i seguenti risultati già elaborati. Quindi abbiamo che S1 quadro, che era quello che vi avrei detto, che si calcolava con questa formula qua, quindi questo qua, ve l'ho già calcolato, deve essere abbastanza simile, ci sono degli sommatori così. Quindi, abbiamo già che 1 è uguale a questo, con 41 osservazioni, e nell'altro set di misure si ha 65.9 con 31 osservazioni. Per terminare, se l'ipotesi che le varianze siano uguali, è da accettare o da rigettare con una certa risultatuità. Anche qui, F è facile da fare, perché F è semplicemente 109, 63 fratto 65.99. Si va a vedere all'istituzione di Fischer, in cui bisogna sempre riportare i due gradi di libertà, quindi 41-31, va bene? e si va a vedere, appunto, se il valore che abbiamo trovato di F, quindi F, K, quindi sarà in questo stato, 109,63 diviso 65.99, che queste due rinzano nella zona di accettazione che vada alfamezi a 1-alfamezi. Va bene? Potete provare a casa a fare questo qui. Almeno andate a utilizzare, anche, appunto, in Python, le funzioni, che possiamo anche andare a vedere, in realtà, quali sono, perché dovrei averlo qua. Allora, А, in vain, la Lab Nav cadaccano, che possiamo amick�are, la Talia, come parla, intendo, casa addirittura del MacBookbook, ma parla, ui è per strictly vendetta. Grazie. Grazie. Ecco. Le funzioni sono in... Beh, c'è sempre in un pi. Le funzioni sono in sci-pi-stats. Ok. E... Questo è il primo... È il primo esercizio. E... Lì mi dice quanto vale la t. Ecco, vedete? La funzione è... Quindi sci-pi-stats.t.ppf Perché ppf sappiamo che è quella che ci dà. Dando la probabilità cumulativa, ci dà il maniore fino a quando bisogna integrare. Bene? E il secondo, ti. È stats.t.ppf perché è 0.975 perché è di 1-0.025. Bene? Questo è per quanto stats.ppf. Invece, invece, fischer. La vediamo qua, sulle varianze delle popolazioni normali. Si chiama... Stats.f.ppf. Vedete? 0.25. Allora, vedete che qui ci sono anche questi due parametri. 40 e 30. Come vi dicevo. Perché quelli sono i gradi di libertà. Quindi i gradi di libertà... Nell'esercizio... Allora, i gradi di libertà... Dove li scriviamo? Qua... Degree of freedom... Sono uguali... Sono uguali... Sono uguali a n-1. E infatti, se andiamo a vedere l'esercizio... Ci diceva che erano 41 e 31. Quindi i gradi di libertà sono i numeri di osservazioni meno 1. Ok? E allora... La funzione di Fisher... Dipende proprio anche dai gradi di libertà che bisogna andare a mettere. Quindi è sempre ppf... Però c'è la f invece la tifra di Fisher... E... Però devo metterci anche 40 e 30. Va bene? Quindi sono due... Due... Due... Due versetti molto semplici... Per esempio... In questo caso... F1 è 66... F1 è 05... F1 è 2... Quindi... Il calo... Cioè... Le due popolazioni avesse la stessa varianza... Era da accettare o da ricettare? Allora... Riendiamo qua... Quindi... F1 è questa... Questi altramezzi... Questi altramezzi... No? Quindi... Questo è F1... Questo è F1... La zona d'accettazione qual è? Questa... È la... Accettazione... Ok? Quindi... Se il mio valore di F... Sta... All'interno di questa zona... Io accetto... Con quella significatività... Ok? Allora... Se andiamo a vedere qua... No... Qua... Mi viene fuori... Questo è 1,6... Quindi... Stazza con i due valori... Sì... E quindi... Avrei accettato... L'ipotesi... Nulla... Sopra... Non mi ricordo... Possiamo andare a vedere... Eh... Ok? Sopra... Sopra... T veniva 1,8... Lo è A... Ero meno 3,1... 3,1... Quindi anche in questo caso... Veniva accettato... Dov'è? Dov'è? Dov'è? Dov'è? Perché anche in questo caso... Se ritorniamo qua... Avrei avuto che... Questa è una zona di accettazione... Ok... E quindi... Sarebbe stata accettata... Va bene? Ok... Ok... Bene... Allora... Quindi abbiamo visto... Questi esempi... In cui ci sono diverse statistiche... E allora... Una domanda... Che uno si pone... Quale sarà? Una domanda fondamentale... Qual è? Secondo voi... Una volta che uno c'è un pen per l'economia... E' quello... Secondo me... Di trovare... La statistica migliore localizzata... Va bene? Perché... Abbiamo visto l'altra volta... Abbiamo visto che... Per esempio... Per esempio... Ehm... Ehm... Ehm... Ehm... Ehm... Ho visto che... In questo esempio... In questo esempio... Questa statistica... Qual era la statistica? Che cosa sono queste... Queste linee nere? Da cosa sono determinate? Che cosa sono queste... Queste linee nere? Da cosa sono determinate? Che ne parlavo più forte... Perché non ci sembra... Dalla... Classification... Ah... Assoluto... Dalla classificazione... Sì... Ma... Cioè... Perché hanno diverse classificazioni? Perché la statistica... Dalla... Dalla... Dalla... Classification... Ah... Assoluto... Dalla classificazione... Sì... Cioè... Perché hanno diverse classificazioni? Perché la statistica è diversa... Cioè... Questa è una statistica... Lineare... Questa è una statistica... Un po' più... Intelligente... Quadrata... Questa è una statistica... Probabilmente non lineare... Però... Probabilmente... Poi... Ok... Perché... Appunto... La statistica... È proprio questo qua... Cioè... Una funzione dei dati... Che io pongo uguale... A un valore costante... No? Qui... È l'esempio di una stessa statistica... Per diversi valori... Però io devo trovare... Statistica migliore... E poi... Il valore che vi serve... Per avere un certo... Significabilità del test... Ok... Quindi... La statistica... Per esempio... Per student... È l'attivistudent... Per... Per... In generale... Gli esempi sono tantissimi... Tant'è vero... Come sapete benissimo... Si ricorre molto spesso... Con gli error networks... Per trovare la statistica migliore... Per ottimizzare... Il problema di classificazione... Esattamente... Allora... Per la statistica... Vabbè... Quindi queste sono tre statistiche diverse... Come facciamo a trovare la statistica? Allora... È... Appunto... Un problema... Generale... Quindi... Quindi... Quindi... Quindi... Unidore... Unidore... In un dato... Per... Il preche... Qui... un idone in un dato una cosa che si fa di grosso spesso sono chiaramente il neural networks in generale quindi machine learning no? che voi avete visto che è un problema di classificazione quindi che fa minimizzando farete anche vista con i reti neuronali eccetera eccetera minimizzando una funzione di errore ok? cerchiamo la statistica migliore un'altra possibilità è invece fare qualcosa di più analitico che chiaramente si applicherà su dei casi se volete più semplici o comunque avrà il successo migliore su dei casi abbastanza semplici questo approccio si chiama la statistica il Fisher e adesso ci andiamo a vedere la statistica com'è costruita in maniera abbastanza intuitiva ok? ma siete finiti ragazzi o cosa? avete lezione oggi? ah allora fine settimana allora eccoci con desideri ok adesso vi passo qua e non fa? ho avuto l'idea perché dopo un po' allora per chi ascolterà la registrazione abbiamo perso qualche minuto scusatemi c'è il slide ok siamo arrivati a definire cos'è Tau0 e Sigma0 V0 è la matrice di correlazione va bene? quindi Sigma1 al quadrato eccetera eccetera qui V12 qui V12 e poi ancora è chiaro che se le osservazioni sono tutte indipendenti come al solito qui avremo A per A1 per Sigma1 A1 al quadrato per Sigma1 al quadrato più A2 al quadrato per Sigma2 al quadrato quindi ci sono soffizioni ok scusa trasposta sì perché è vettura per la tigione che è mi sembra un po' risparmettino in perna ah dove l'ho messa io prima perché può darsi che anche era permesso a risponente sì infatti anche io l'ho messa risponente quindi ha fatto un libro ma dirvelo è attimo qua su trasformo ok allora prendendo questo si può fare la derivata di F rispetto ad A ok e metterla uguale a 0 senza fare tutto il conto quindi quindi deriviamo F rispetto A e massimizziamo quindi e quindi abbiamo che la soluzione è che A è proporzionale a V meno 1 V doppia meno 1 per mi 0 meno mi 1 dove V doppia è VJ per esempio è una matrice quindi è V0 più V1 VJ ok quindi mi viene fuori che i pesi sono proporzionali alla differenza tra le medie che è sotto l'ipotese a 0 e sotto l'ipotese a 1 e inversamenti proporzionali proprio alle matrici di covalentità rispetto a H0 e H1 quindi questa è la soluzione che si ha supponendo che T sia una combinazione lineare che è la scelta più semplice ok non è detta che sia ottimale questa scelta è la più semplice e se se si sceglie questa se si sceglie la la la combinazione lineare queste sono come si trovano le anie ok però non è detto che la combinazione lineare sia la scelta migliore allora si può dimostrare che la scelta migliore Fischer è la scelta ottimale per distribuzioni multigaussiane con la stessa varianza la stessa matrice di varianza va bene torno con questo caso vuol dimostrare che quella combinazione lineare con quelle scelte di a è la distribuzione in generale è una distribuzione si può proporare molto facilmente ma non è detto che sia migliore anzi abbiamo visto per esempio questi qua chiaramente che se era questo il problema non era sicuramente ragione migliore in questo caso sarebbe questo non lineare e questa è proprio lineare bene ok ok benissimo va bene gli altri metodi non lineari sono più in bacio lì si fa con il gradiente per vedere quale ha il minore eccetera eccetera sono più sofisticati però è importante sapere che c'è anche questa scelta ok allora a questo punto andiamo avanti sempre su questo tema delle scusate delle ipotesi su questo tema delle delle ipotesi allora fino a qui abbiamo parlato dei casi in cui abbiamo un'ipotesi è un'ipotesi alternativa va bene abbiamo fatto test dell'ipotesi con H0 e H1 allora molto spesso quando uno fa un esperimento poi se non è un esperimento comunque andrà in un'analisi statistica si può anche chiedere semplicemente se i dati osservati sono più o meno compatibili con un'ipotesi quindi non dice questa ipotesi rispetto a quest'altra dice solamente io ho questa ipotesi faccio delle misurazioni e voglio vedere quanto queste misurazioni mi convalidano la mia cosa che sarebbe come dire vediamo che se facessi quelle stesse misurazioni un sacco di volte mi dovrei avere una buona probabilità di trovare sempre una comprenza di volte di stessa allora questo quindi queste cose se invece facciamo quindi situazione in cui si vuole sta la validità di un'ipotesi H0 la chiamiamo sempre senza specificare ipotesi alternativa allora in questo caso in questo caso vogliamo una probabilità che misura in qualche modo questo che stiamo vedendo allora questa probabilità si chiama il problema cioè non la probabilità non è il problema comunque questo argomento diciamo è il problema della determinazione del P Maggi forse l'avete mai sentito quella d'aria il P allora adesso vediamo un po' ecco allora evalio siamo tutti un po' più in su ok allora facciamo ma qui mettiamo qui che è un altro argomento nuova situazione mettiamo se no non cambiamo esempio e si capisce meglio esempio facciamo tiriamo una moneta 20 volte ok e scelta testa oppure croce questa simmetrica la cosa 17 volte ok subito la nostra ipotesi è che la moneta non sia truccata truccata sapete cosa vuol dire truccata vuol dire che dà dei valori che non sono quelli veri un dado truccato è un dado che ti dà sempre 7 perché è fatto in modo tale da essere fatto male appunto per vicio o per per è un trucco che poi vedremo vuol dire che cosa vuol dire che la probabilità della testa uguale alla probabilità della cruce uguale se non è truccato vuol dire che noi ci aspettiamo che questa e questa e questa e questa e questa e questa e questa e questa e questa cioè 05 allora voi cosa direste che se avete un'uomo di questo genere il dado truccato la la la la la la moneta truccata non per poverizzare no per cosa lo sospendo c'era 16 20 però lo può dire solo con una certa probabilità quindi vi va in un misuro proprio qual è la probabilità di avere questo risultato o uno peggiore addirittura 18 20 ok chiaramente se la probabilità è molto bassa voi pensate perché si è toccato è sempre probabilistico però sono delle indicazioni va bene avete capito il problema ok quindi il p-value misura la probabilità di ottenere il risultato salvato secondo o uno peggiore secondo sotto sotto ipotesi hd ok vediamo un po' quindi il risultato osservato qual è sì nel nostro esempio che ne escono 17 studenti ok uno peggiore qual è che ne escono per esempio 18 studenti quindi la probabilità che ne escono 17 più la probabilità che ne escono 18 più la probabilità che ne escono 19 più la probabilità che ne escono 20 su 20 questa è il p-value la somma di tutte queste probabilità mi misura un po' la vera semiglianza di quello che sto vedendo siccome io qui posso qui non è sempre un libro qui posso anche non è che ho detto è testo è neve croce ho detto li posso uscire qual è la probabilità che riscano 17 della stessa specie quindi devo sommare la probabilità che escono 17 18 19 20 insieme alla probabilità che riscono 0 1 2 3 va bene perché in quel caso ne escono 17 dell'altro e insomma è poco provato di questo stesso ok questa è la definizione allora questo qui è importante il p-value perché si trova si trova molto molto spesso quando negli esperimenti anche nelle misurazioni statistiche perché le misure avrebbero semigliate della vostra ipotesi ok senza dire se ci sono ipotesi a terapia voi fate un'ipotesi fate delle misure e il p-value dice quando probabilisticamente queste misure supportano quello che voi avete ipotizzato allora nel nostro caso vediamo un po' quindi ecco qui o con facciamolo bene perché questo almeno facciamo un po' bene quindi nel mio caso nell'esempio mio è la probabilità che escono zero teste più la probabilità che esca una testa più la probabilità che escono due teste più la probabilità che escono tre teste più più la probabilità che escono più la probabilità che ne escono diciotto più la probabilità che ne escono dician 19 più la probabilità che ne escono 20 va bene questo è il mio più di questo di questo esempio ok ok adesso qui ho scritto p0 p1 questo è il numero di teste numero quindi questo numero teste curiosità in Aradol se è sempre testo cruce qualunque una moneta si dice fare testo cruce o non esiste è sempre testo cruce oppure qualcosa altro testo cruce perché da alcune parti si dice in maniera diversa non so se dice pesce l'almina o cosa però si dice testo cruce uguale ok allora queste qui cosa sono adesso in questo esempio qua sappiamo che quando noi abbiamo un esperimento con due uscite ognuna con una sua probabilità la distribuzione è una distribuzione binomiana va bene quando noi lanciamo una moneta è la distribuzione binomiana quindi quindi tiro della moneta distribuzione binomiana con p uguale 0,5 n uguale 20 n piccolo uguale numero di teste quindi per esempio p 17 20 0,5 è la probabilità che su 20 su 20 t rinescano 17 uguali e ognuno ha quella probabilità di 0,5 ok ok allora questo qui è quindi dobbiamo sommare queste vi ricordate com'è? è p di n n p è uguale a n grande su n per p alla n piccolo per 1 meno p alla n grande meno n piccolo questo l'abbiamo fatto un po' di tempo fa ok quindi dobbiamo utilizzare questo e se uno fa il conto in cui quindi questo qua abbiamo sempre p 0 20 0 5 p 1 20 0 5 p 2 30 0 5 eccetera eccetera prova che il p value risulta uguale a non mi ricordo ho calcolato a qualche parte è 0,025 credo non sono sicuro però vediamo se c'è la spesa la bassa è calcolata la bassa è calcolata la bassa è calcolata no po' non ho ben Title non è primero però no risultato ok? quindi sarebbe se volete lo 0,26% quindi diciamo che la probabilità di avere quel risultato o quello peggiore è molto bassa ok? quindi come si interpreta il p-value? è sempre una probabilità cioè vuol dire che facendo tante volte 20 tiri quella è la frazione di volte su 100 che voi trovate nei risultati uguali o peggiori di quello che avete trovato la prima volta vuol dire che quando non vi è tra qualcosa e per sempre è difficile di aver fruttato però sì quando non vi è tra l'altro il 9% la probabilità che sia vero è tutto allora quindi lo scriviamo il p-value è la frazione è una probabilità quindi è la frazione di volte che si ottene che si ottene libero tali dati cioè quelli che si sono osservati compatibili compatibili o meno compatibili con H0 se l'esperimento fosse ripetuto con H0 se l'esperimento fosse ripetuto con H0 molte volte nelle stesse condizioni l'esperimento l'esperimento in questo caso l'esperimento in questo caso sarebbe 20 in NASA 20 volumi ok ci fermiamo qua oggi e domani continuiamo a vedere questa cosa qua vediamo la lezione giovedì non c'è andato aspetti