Allora, l'ultima volta abbiamo iniziato a parlare di protocolli di identificazione, ok? Basati su password. Ne abbiamo visti un paio e abbiamo visto come questi possono essere sicuri rispetto alle prime due tipologie di avversario, di attacco, ovvero rispetto agli attacchi diretti, che sono quegli attacchi in cui l'attaccante cerca direttamente di indovinare la password, ok? Quindi abbiamo parlato dell'attacco basato sulla ricerca forza bruta, gli attacchi offline al dizionario e come cercare di mitigare o neutralizzare questo tipo di attacchi. E poi invece abbiamo parlato di attacchi da parte di avversari passivi che ascoltano il canale, quindi abbiamo parlato di waste dropping. In questo caso l'avversario ha la possibilità di ascoltare il traffico sul canale e quindi chiaramente diventa importante durante l'handshake tra prover e verifier evitare di trasmettere informazioni che l'avversario poi possa usare a sua volta per impersonare il prover e ingannare il verifier. Le tipologie di protocolli che abbiamo visto però non sono sufficienti a garantire la sicurezza contro la tipologia più espressiva di attacchi che è quella appunto degli attacchi attacchi attivi, cioè attacchi in cui l'avversario può fare diverse cose, ovvero può prima impersonare il verifier ingannando il prover e inducendolo a condividere informazioni riservate come ad esempio la password che serve per identificarsi e usare quindi queste informazioni in una seconda fase per impersonare il prover e ingannare il verifier. L'attac game basato sulla questa descrizione che ho appena fatto è questo quello di questo slide che abbiamo commentato la settimana scorsa e così come abbiamo commentato il fatto che nessuno dei protocolli che avevamo visto fino a questo momento poteva essere sicuro rispetto a questo tipo di attacchi e il motivo è che in tutti i protocolli che abbiamo visto finora c'è solo il prover che ha un ruolo attivo, il prover manda la password o qualche informazione che dipende dalla password, verifier, verifier, la verifica e basta. Per diventare robusti rispetto ad attacchi attivi dove l'avversario tenta di impersonare il verifier ingannare il prover abbiamo bisogno di protocolli dove non solo il prover ha un ruolo attivo in via delle informazioni ma anche il verifier ha un ruolo attivo che gli permetta di mandare delle informazioni. quindi protocolli dove ci sia un vero e proprio in via dove entrambi mandano delle informazioni e questo con lo scopo di impedire all'avversario di impersonare l'uno o l'altro questa idea. la prima versione di protocollo di identificazione basato su quest'idea che vi mostro è il protocollo di tipo challenge and response. si chiama così perché come vedremo tra poco il verifier non si limita banalmente a verificare informazioni che gli invia il prover ma gli propone una sfida, gli propone una challenge appunto alla quale il prover deve rispondere. se il prover risponde correttamente alla challenge significa che conosce la password, questa è un po' l'idea, cioè solo chi conosce la password per identificarsi è in grado di rispondere correttamente alla challenge. ok? questo renderà il protocollo robusto rispetto all'attacco attivo ma andiamo a vedere come funziona il protocollo così capiremo anche poi perché riesce ad essere sicuro rispetto ad attacchi attivi. la prima versione che vi faccio vedere è una versione in cui la password, adesso non la chiameremo password ma torniamo alla terminologia originale, la chiave segreta, quella che usa il prover coincide con la chiave di verifica, quella che usa il verifier. queste due chiave che coincidono rappresentano rappresentano la chiave randomica di un MAC, quindi di uno schema che viene utilizzato per l'integrità, potete usare qualunque tipo di MAC, non so, HMAC basato su SHA256 piuttosto che qualunque altro tipo di MAC. quindi questo protocollo presuppone che prover e verifier condividano a priori la chiave di un MAC, ok? che viene usata come chiave segreta dal prover come chiave di verifica dal verifier, ok? quindi assumiamo che a priori questa chiave sia stata scelta dal famoso algoritmo G di generazione delle due chiavi, quella sedete e quella di verifica. dopodiché come funziona il protocollo di identificazione? beh, il verifier sceglie un nonce randomico che appartiene al dominio del MAC e questo nonce randomico rappresenta la challenge, la challenge che viene inviata al prover, ok? il prover a questo punto cosa deve fare? deve rispondere alla challenge in che modo? segnando con il MAC la challenge, cioè firmandola usando il MAC, creando il tag, ok? quindi il prover prende la challenge che ha ricevuto dal verifier e ne calcola il tag usando il MAC e naturalmente la chiave che condivide con il verifier, ok? quindi il prover fa questa cosa, calcola il tag usando il MAC e usando la chiave K della challenge, dopodiché questo tag rappresenta la risposta, ok? che viene inviata al verifier, no? quindi un handshake estremamente banale abbiamo un prover, abbiamo un verifier prover e verifier condividono la chiave K di un MAC il verifier manda la challenge il prover risponde con il tag della challenge, ok? il prover, il verifier a questo punto non deve fare altro che verificare, usando la chiave K, che T sia il tag di C tutto qua, ok? quindi il verifier fa la verifica tramite il MAC del tag se la verifica ha successo cosa vuol dire? vuol dire che chi gli ha mandato il tag è effettivamente colui che condivide K col verifier ok? e quindi avrà dimostrato la sua identità no? questa è l'idea quindi un protocollo molto semplice il teorema dice che se il MAC è sicuro e la cardinalità del dominio del MAC è super poli allora questo protocollo è debolmente sicuro rispetto ad attacchi attivi cioè rispetto ad avversari che esibiscono il comportamento che abbiamo spiegato prima cioè avversari che possono impersonare a piacimento il prover o il verifier perché weekly secure e non secure? weekly secure perché? perché chiave segrete e chiave di verifica coincidono e quindi questo significa che la chiave di verifica non può essere pubblica ok? questa è la condizione ma perché questo protocollo è sicuro rispetto ad un attaccante che si comporta come abbiamo visto in questo attack game? immaginate un attaccante che che impersoni il verifier col prover e cerca di ottenere delle informazioni che successivamente può usare con il verifier originale no? quindi proviamo a vedere questo incrocio a che cosa da luogo quindi avete immaginiamo di avere il nostro il prover originale il verifier originale legittimo e abbiamo l'avversario ok? ora immaginiamo che in una prima fase l'avversario finga di essere il verifier con il prover ok? e interagendo con lui cerca di ottenere delle informazioni che possano poi aiutarlo a impersonare il prover col verifier legittimo ok? seguendo l'algoritmo il protocollo di challenge e response che abbiamo appena visto l'avversario cosa deve fare? deve mandare una challenge al prover ok? vedete la novità rispetto ai protocolli che abbiamo visto l'altra volta no? che sono tutti i protocolli in cui il verifier non partecipa attivamente sono protocolli dove il verifier che cosa fa? aspetta che il prover gli mandi delle informazioni utili per l'identificazione lui le riceve e poi le ricicla col verifier legittimo ed è il motivo per cui i protocolli che abbiamo visto settimana scorsa non funzionano non sono sicuri rispetto a questo tipo di attacco ok? in questo caso invece l'avversario non è che aspetta deve iniziare lui mandando la challenge al prover il prover risponde con il tag della challenge ok? ora l'avversario di questo tag cosa se ne fa? assolutamente niente perché immaginate che adesso il prover voglia identificarsi col verifier legittimo facendo finta di essere il prover ok? e come verrebbe il protocollo in questo caso? che il verifier legittimo manderebbe una sua challenge e l'avversario dovrebbe rispondere con il tag della challenge che gli ha mandato il verifier che sicuramente è diverso rispetto a questo a meno che sfortunatamente questo e questo non coincidano ok? ma la probabilità che coincidano è negligible se vale l'ipotesi del teorema che dice che la cardinalità dello spazio delle challenge è super poli ok? e quindi questo rende diciamo improbabile che l'avversario riesca riesca a identificarsi con il verifier per questo motivo qua ok? è chiaro? ora se vogliamo il limite di questo di questa soluzione qui è che prover e verifier devono condividere la chiave di un mac no? come possiamo fare per risolvere questo problema? ora il mac è lo strumento che abbiamo visto per taggare per firmare messaggi usando primitive a chiave simmetrica come facciamo a spezzare questa simmetria? quale altro strumento abbiamo a disposizione per fare un'operazione analoga ma senza usare primitive a chiave simmetrica? l'abbiamo visto poco tempo fa qual è l'analogo del del mac nell'ambito della criptografia a chiave pubblica? il film è digitale il corrispondente quell'ambito dei mac sono gli schemi di firma digitale lo schema di firma digitale fa la stessa cosa che fa un mac con la differenza che non si lavora su un'unica chiave k ma abbiamo la coppia la chiave segreta di firma e la chiave pubblica di verifica ed ecco che se al posto di un mac usiamo uno schema di firma digitale uno qualunque di quelli che conosciamo pkcs1 quello che vuoi basato su rsa piuttosto che altro benissimo e allora in quel caso chiave segreta chiave di verifica non coincidono più perché la chiave segreta sarà la chiave di firma la chiave di verifica sarà la chiave pubblica che quindi non ha più il vincolo di segretezza e quindi il risultato sarà che il nostro sistema non sarà debolmente sicuro ma sarà sicuro perché? perché la chiave di verifica può essere pubblica appunto e quindi l'idea appunto è quella di di sostituire il mac con uno schema di firma digitale il protocollo rimane lo stesso cioè il verifier manda la challenge al prover il prover che cosa dovrà fare? dovrà firmare la challenge con la chiave segreta dello schema di firma digitale dopodiché il verifier usando la chiave pubblica verificherà se la firma è corretta ok? e quindi in questo modo ecco che abbiamo ottenuto uno schema sicuro rispetto ad attacchi attivi ok? ora sempre su questo tipo di idea di usare schemi analoghi alle firme digitali vi faccio vedere un altro esempio di protocollo di identificazione che però usa come primitive non usa né il mac né gli schemi di firma digitale che abbiamo studiato fino ad oggi che si basano fondamentalmente su RSA ma usa come primitiva lo vediamo subito gli ingredienti del protocollo di Diffie-Hellman quindi un protocollo di identificazione che si basa sull'utilizzo dei gruppi ciclici no? con gli insiemi di valori in Z in un certo ZP che sono potenze di un generatore G ok? e questo schema è particolarmente interessante come vedremo perché non solo ci fornisce un protocollo di identificazione sicuro ma come vedremo ci dà lo spunto anche per creare lo schema di firma digitale basato su Diffie-Hellman cosa che ancora non avevamo visto ok? come funziona il protocollo di identificazione di Schnorr? allora qui dobbiamo rivedere un attimo i concetti di Diffie-Hellman che è da un po' che non vediamo si parte sempre da un gruppo ciclico generato da un generatore G ok? quindi il gruppo ciclico se vi ricordate contiene tutte le potenze di G nella sua cardinalità è Q ok? ciclico perché tutte quelle potenze sono diverse fra di loro e ciclico perché una volta arrivati a G alla Q si ricomincia da K queste sono le caratteristiche del nostro gruppo ciclico ognuno di quei valori appartiene a Zp le potenze invece appartengono a Zq ok? quindi sulla base di un gruppo ciclico scelto opportunamente a partire dai due numeri primi P e Q efficientemente grandi noi sappiamo che l'abbiamo visto anche in passato quando abbiamo studiato il Gamal sappiamo che possiamo scegliere randomicamente come chiave segreta un qualunque possibile esponente di G ok? quindi qualunque valore in Z in Zq quello lo useremo come chiave segreta e invece possiamo usare come chiave di verifica G alla alfa quindi G elevato a quel valore che abbiamo che abbiamo scelto dopodiché se vi ricordate c'è l'assunzione di Diffie ma anche ci dice che anche se io vi faccio vedere G alla alfa voi non siete in grado di risalire ad alfa ok? quindi questo è il modo in cui vengono scelte chiave segreta e chiave di verifica e quindi intanto vediamo che sono due valori diversi fra di loro e vediamo anche il fatto che non è necessario che la chiave di verifica sia mantenuta segreta ok? quindi un po' come nella soluzione precedente dopodiché come avviene il protocollo andiamo a vedere il protocollo tra prover e verifier dove ripeto il prover conosce la chiave segreta alfa il verifier invece sa qual è la chiave di verifica G alla alfa ma la chiave di verifica può essere ripeto che può essere pubblica il protocollo di identificazione di Schnorr funziona così P sceglie qualunque esponente beta per il nostro gruppo ciclico ok? assomiglia un po' a El Gamal questo questo protocollo eh? almeno in alcune parti e che cosa fa? chiaramente mantiene segreto beta ma trasmette G alla beta ok? a questo punto il verifier deve scegliere la challenge perché anche questo è un protocollo di challenge e response sceglie la challenge e la manda al prover ok? la challenge appartiene allo stesso dominio di alfa e di beta quindi siamo sempre in zq quindi tutti i possibili esponenti del generatore G all'interno del gruppo ciclico ok? o naturalmente sia beta che la challenge c sono scelti in maniera randomica a questo punto cosa fa P? calcola questa quantità che chiamiamo gamma cioè beta più alfa c ok? è una quantità che se ci pensate solo P è in grado di calcolare no? perché alfa è segreta la conosci solo P beta la scelta P e non la condivisa con nessuno l'unica informazione pubblica è la challenge del verifier ok? quindi gamma siamo certi del fatto che è nota solamente a P ok? e cioè solo P è in grado di calcolarla ecco dopodiché una volta che ha calcolato gamma lo trasmette al verifier ok? ora il verifier non può fare questo stesso calcolo per verificare la correttezza di gamma perché non conosce né alfa né beta ma cos'è che conosce? conosce G alla alfa e G alla beta ok? quindi può fare un altro calcolo e l'altro calcolo che può fare è questo ok? G è il generatore del gruppo ciclico informazione pubblica ed è nota a tutti ma perché perché ha senso fare questo calcolo? allora il verifier ripeto di tutte queste informazioni conosce solo gamma non conosce né alfa né beta conosce gamma e conosce la challenge sa che gamma deve essere stato calcolato in questo modo non conosce alfa e beta ma sa che gamma deve essere stato calcolato in quel modo ma se gamma è stato calcolato in questo modo allora deve valere questa uguaglianza no? se se gamma è uguale a se gamma è uguale a beta più alfa c allora necessariamente g alla gamma deve essere uguale a g alla beta più alfa c ok? ma g alla beta più alfa c sfruttando le proprietà dell'alumento a potenza si possono scrivere così ok? ora qual è la cosa interessante? la cosa interessante è che questa uguaglianza il verifier la può verificare non può verificare questa perché non conosce alfa e beta ma questa la può verificare perché la può verificare? devo vedere allora g alla gamma se la può calcolare perché perché gamma lo conosce g alla beta lo può calcolare perché perché l'ha ricevuto dal provere quindi anche g alla beta è noto g alla alfa per c che sarebbe g alla alfa alla c anche questo lo può calcolare perché? perché g alla alfa è la chiave di verifica c è la challenge quindi vedete che tutti gli ingredienti necessari per verificare questa uguaglianza il verifier li conosce e quindi può verificare l'uguaglianza ma se vale questa uguaglianza vuol dire che gamma è stato calcolato in questo modo ma chi è che può calcolare gamma in quel modo? chi è l'unico che può calcolare gamma in quel modo? è il possessore di alfa della chiave segreta alfa che dovrebbe essere colui che mi ha mandato g alla beta se uno che si manifesta come prover mi manda g alla beta con la base di un beta che ha scelto lui e poi mi dimostra che il gamma che mi manda poi è stato calcolato in quel modo allora mi sta dimostrando di essere il possessore di alfa e quindi mi sta dimostrando la sua identità senza farmi vedere alfa attenzione questa è la cosa interessante il prover mi sta dimostrando di conoscere alfa senza farmelo vedere che è un po' l'obiettivo della maggior parte degli schemi di identificazione verifier deve fare questo calcolo g all'alfa elevato alla c no perché perché perché g all'alfa c è uguale a g all'alfa elevato alla c g all'alfa è la chiave di verifica c è la challenge che ha scelto lui quindi e quindi è un calcolo che riesce a fare ok questa cosa di riuscire a dimostrare di conoscere un'informazione senza esibirla è una caratteristica di protocolli che adesso tra poco poi vedremo in maniera un po' più generale dettagliata e sono i cosiddetti protocolli in zero knowledge cioè quei protocolli che riescono a dimostrare qualcosa senza esibire la conoscenza di quel qualche cosa ma come in questo caso proposto da Schnorr attraverso un caso calcolo io ti faccio vedere che conosco una certa informazione ok il protocollo di Schnorr ripeto è un po' tosto interessante perché non solo offre un modo di fare identificazione senza usare schemi di firma digitale basati su RSA che sono più inefficienti ok ma offre anche un modo alternativo di fare firme digitali perché lo schema di Schnorr si può adattare e farlo diventare uno schema di firma digitale come poi vedremo quindi l'idea di Schnorr contemporaneamente in pratica la possiamo usare o per realizzare un protocollo di identificazione come questo o per realizzare uno schema di firma digitale chiaro come funziona ok il teorema dice come al solito che se l'assunzione di Diff-Hellman del logaritmo discreto vale che è la solita assunzione che ci dice che anche se voi vedete G alla alfa non riuscite a dedurre nessuna informazione sul quanto vale alfa e poi l'altra ipotesi è che la cardinalità di ZQ sia super poli questa è la solita assunzione perché se non fosse super poli è lo stesso esempio che vi ho fatto prima se la cardinalità di Z non fosse super poli la probabilità per un verifier di usare per un avversario di usare la stessa challenge che usa il verifier sarebbe non più trascurabile ok quindi lo stesso discorso che abbiamo fatto prima la probabilità per l'avversario che finge di usare un verifier di usare la stessa challenge che poi userà il verifier deve essere negligible e quindi la cardinalità di ZQ deve essere super poli sotto queste condizioni questo protocollo di identificazione è sicuro lo è dimostrabilmente rispetto ad attacchi diretti di tipo di voice dropping c'è una congettura non formalmente dimostrata ma empiricamente che legge e che dice che questo protocollo di identificazione è sicuro anche rispetto ad attacchi attivi ok come diventa il protocollo di Eugenor uno schema di firma digitale con pochissime diciamo pochissimi aggiustamenti che prevedono l'uso di una funzione di una funzione hash il cui compito è quello di generare la challenge in maniera pseudo casuale senza che questa debba essere scelta da una controparte ok per il resto il protocollo è lo stesso che vi ho appena presentato ovvero vediamo un po' come funziona la coppia di chiavi segreta e di verifica è esattamente quella che ci siamo appena detti prima quindi alfa scelto randomicamente è la chiave di firma g alla alfa è la chiave di verifica alfa è segreta g alla alfa è pubblica ok l'algoritmo di firma che questo schema utilizza che cosa fa i passi sono gli stessi che abbiamo visto prima ovvero ipotizziamo di dover firmare plaintext m usando la chiave segreta ok che cosa facciamo allora esattamente come nel protocollo di identificazione chi fa la firma scegli un beta calcola g alla beta e poi si calcola da solo senza chiederlo alla controparte la challenge nel protocollo di identificazione la challenge viene scelta dal verifier qui fa tutto il prover come calcola la challenge come digest di che cosa del messaggio che devo firmare concatenato con g alla meta ok quindi mi calcolo in questa la challenge è randomica perché perché se se la funzione esce è impredicibile quindi è una classica funzione hash non invertibile sicura allora sappiamo anche che il risultato del lashing è appunto impredicibile quindi tutti gli effetti la challenge è randomica come è giusto che debba essere dopo di che che cosa faccio fare gli stessi calcoli di prima ovvero calcolo gamma in questa maniera qua come beta più alfa c e la firma sarà la coppia g alla beta gamma perché la coppia g alla beta gamma beh perché chi deve verificare la firma del messaggio non deve far altro che verificare questa uguaglianza in maniera analoga come abbiamo visto prima ok quindi immaginate che io faccia la firma in questo modo no quindi io ho la chiave segreta alfa voi che volete verificare la mia firma conoscete g alla alfa che è la chiave di verifica ok quindi io che voglio firmare un messaggio a m da mandarvi che cosa faccio scelgo beta lo tengo per me calcolo g alla beta calcolo il hash di dei plain text combinato con g alla beta e questo digest c lo uso per calcolare gamma come l'espressione b più alfa c dopodiché io vi mando la firma vi mando la firma che è la coppia g alla beta gamma voi adesso dovete verificare la firma usando la chiave di verifica come fate? fate lo stesso calcolo che abbiamo visto prima ovvero prendete gamma e calcolate g alla gamma prendete g alla beta che lui fa parte della firma e lo moltiplicate per che cosa? per g alla alfa c g alla alfa la chiave di verifica c è la challenge che chiunque può calcolare no? perché la challenge è l'hash del plain text concatenato con g alla beta quindi chiunque può calcolare la challenge quindi voi potete verificare questa uguaglianza se l'uguaglianza è verificata allora avete la garanzia che quel messaggio è stato firmato da me e non da qualcun altro cioè da me che sono il possessore di questa chiave segreta ok? quindi questo è un modo alternativo di fare firme digitali usando gli ingredienti di Diffie Hellman e utilizzando il protocollo di Dichinor che è molto è molto efficiente perché i calcoli da fare sono estremamente diciamo non complessi soprattutto se fate il solito giochino di cui abbiamo parlato quando abbiamo raccontato di El Gamal soprattutto se al posto di un gruppo ciclico generato da un generatore g voi usate che cosa? un gruppo di punti di una curva ellittica quindi se voi sostituite il gruppo ciclico di ordine q generato da g con i punti scelti opportunamente una curva ellittica quindi usate la critografia ellittica ma lasciate tutto il resto così come è ecco che ottenete un algoritmo di firma digitale molto molto molto efficiente ok? perché tutte le operazioni di rilevamento a potenza diventano dei prodotti e tutti i prodotti diventano delle somme ricordate quando si passa dalla Diffie Hellman alla critografia ellittica ok? in Diffie Hellman avete g alla alfa in una critografia ellittica avete alfa moltiplicato per un punto P quindi non avete l'almente a potenza e il risultato il risultato pratico dell'implementazione di questo schema qui fatto però nell'ambito della critografia ellittica invece che in Diffie Hellman è è uno standard molto usato in letteratura che prende il nome di EC DSA EC sta per Liptic Cryptography tutti gli schemi che hanno l'acronimo EC davanti vuol dire che fanno riferimento all'uso della critografia ellittica quindi Diffie Hellman con le curve ellittiche DSA sta per Digital Signature Algorithm che è uno standard del NIST una delle varie organizzazioni che propongono standard ed è molto molto utilizzata in parecchi in parecchi contesti uno degli schemi di frame digitali più utilizzati in assoluto e che ormai ha soppiantato negli anni altri schemi come PKCS1 che invece è basato su RSA che è molto più molto più inefficiente qui alcuni elementi importanti necessari per garantire la sicurezza del dello schema di di Schnorr al di là delle ipotesi sul del teorema stanno nel fatto che le scelte randomiche che ci devono essere qua dentro siano effettivamente randomiche e quindi a parte la generazione della chiave segreta di verifica qui c'è un'altra componente randomica importante che è la scelta di beta ok tant'è che alcune implementazioni di CDSA che erano deboli nella scelta di beta o che addirittura usavano lo stesso beta più di una volta hanno dato luogo a delle vulnerabilità che poi sono state sfruttate in attacchi piuttosto famosi ok e qui ve ne cito due forse quella della Playstation non ve la ricordate è già vecchia di qualche anno ma ad un certo punto la Playstation 3 ha subito un attacco piuttosto massiccio che ha portato alla alla alla violazione di di diciamo di di di protocolli di identificazione che vengono utilizzati per l'autenticazione degli utenti che giocavano online ok e con la violazione di un sacco di utenze da questo punto di vista e è qualcosa di analogo è successo invece più recentemente a dei portafogli Bitcoin di cui parleremo tra qualche tra qualche lezione e che utilizzano all'interno firme digitali e Bitcoin usa al suo interno all'interno del proprio protocollo come schema di firma digitale CDSA ok le firme digitali all'interno del protocollo di Bitcoin sono molto importanti perché sono quelle che poi vengono utilizzate per no il il trasferimento di Bitcoin da da un utente all'altro e quindi questi i modi in cui vengono implementati gli schemi di firma digitale hanno un impatto estremamente importante sulla sicurezza di applicazioni reali e nel caso di CDSA questo è particolarmente critico insomma importante ma ci sono anche tanti altri esempi di situazioni di questo di questo genere che mettono in evidenza non tanto vulnerabilità del protocollo in sé per sé ma del modo in cui ho implementato che è un po' una criticità di cui abbiamo già parlato altre altre volte ora come detto volevo e questo chiude il discorso relativo ai protocolli di identificazione perché adesso invece volevo affrontare il tema che abbiamo anticipato ovvero il fatto che il protocollo di identificazione di Schnorr è un protocollo che in linea generale consente al prover di dimostrare di conoscere una certa informazione senza mostrare quell'informazione ok i protocolli che hanno questa caratteristica in letteratura prendono il nome di sigma protocols ok e che sono protocolli che soddisfano proprietà che vedremo tra cui come accendavo prima la proprietà della dimostrabilità in zero knowledge cioè il fatto che io riesco a dimostrare un qualcosa zero knowledge significa conoscenza zero cioè sono dimostrazioni che non rivelano a chi osserva la dimostrazione nessuna informazione critica al di là del risultato della dimostrazione stessa ok e sono protocolli che si usano in un sacco di di contesti diversi il classico esempio che si fa per attraverso una metafora dimostrare l'importanza dell'utilità del o anche il significato della delle prove in zero knowledge all'interno del sigma protocol è un esempio molto semplice voi immaginate di essere davanti all'ingresso di una grotta di un labirinto ok insieme al verifier voi siete il prover voi siete il verifier questo è l'ingresso e l'abirinto è fatto così ok e qua c'è una porta che sbarra il corridoio ok voi volete dimostrare al verifier di avere la chiave di quella porta senza fargliela vedere ok come fate entrate ad esempio da sinistra e uscite da destra in questo modo il verifier ha la dimostrazione del fatto che voi avete la chiave della porta perché senza la chiave della porta non sareste riusciti a fare giro ad anello però non avete bisogno di fargliela vedere e questa è un po' la stessa idea che sta dietro il protocollo di di Shnor che abbiamo descritto sia come schema di identificazione che come schema di firma digitale l'obiettivo di questo protocollo alla fine è permettere al prover di dimostrare al verifier di conoscere alfa che è la chiave del nostro esempietto senza farla vedere al verifier perché se gliela facessi vedere non mi servirebbe più a nulla a quel punto la dovrei buttare via ok questa è un po' l'idea dei protocolli sigma ora vi faccio vedere le caratteristiche generali dei protocolli sigma di cui questo è un'istanza particolare vi faccio vedere quelle che sono le proprietà che questi protocolli soddisfano e poi vi faccio vedere qualche esempio applicativo dei dei protocolli sigma andiamo a pescare le slide così così l'esempio che vi mostrerò alla fine sarà un esempio che prende spunto da protocolli di voto elettronico che sono una delle spine al fianco degli strumenti criptografici più dolorose i protocolli di voto elettronico sono quelli più problematici da realizzare e questo è uno dei motivi per cui effettivamente voto elettronico è un qualcosa che in ora non è mai riuscito a sfondare su larga scala si utilizza ma si utilizza nei contesti abbastanza particolari e ridotti e il motivo deriva dalla difficoltà di garantire tutta una serie di proprietà che vedremo allora veniamo ai protocolli ai sigma protocol di cui abbiamo già anticipato un po' un po' l'idea tra l'altro esattamente come nel caso di Shinor uno dei vantaggi evidenti di sigma protocol consiste nel fornire dei meccanismi per implementare sia protocolli di identificazione che schemi di firma digitale in maniera analoga a quello che abbiamo già visto appunto nel caso di di Shinor la definizione generale astratta di protocollo sigma è piuttosto semplice ed è facile vedere in questo schema generale come si cala in caso specifico come quello di Shinor allora intanto si parte da una relazione binaria che caratterizza che caratterizza il protocollo una relazione tra un dominio e un codominio una relazione che mette appunto che lega elementi di un certo dominio x a elementi di un certo dominio y il prover conosce entrambi gli elementi della coppia cioè conosce sia x l'elemento del dominio che y l'elemento del codominio mi sa che non sto condividendo un attimo eh sì sì allora sì sì mi sono dimenticato di condividere ecco qua eccoci qua allora dicevo l'elemento che caratterizza un protocollo sigma sono è innanzitutto una relazione tra un dominio x e un codominio y e vi faccio un esempio tanto per collegarci a qualcosa che abbiamo appena visto nel caso del protocollo di Schnorr eh il dominio x coincide con zq e e il codominio y coincide con zp e le coppie x y che appartengono a una relazione sono le coppie fatte così dove questa è x e questa è y ma questo è un esempio del caso del protocollo di Schnorr ovvero x è un'informazione entrambe sono note al prover sia x che y ok invece al verifier è nota solo y ok quindi il prover le conosce entrambe il verifier conosce solo y allora l'idea qual è l'idea è che il prover deve poter dimostrare al verifier di conoscere quella particolare x che è in relazione con la y che il verifier conosce senza naturalmente fargliela vedere no nel caso del protocollo di Schnorr le coppie della relazione che caratterizzano il protocollo sono coppie del tipo alfa g alla alfa alfa x g alla alfa y il verifier conosce y cioè conosce g alfa ma non conosce x cioè non conosce alfa il prover invece conosce anche x conosce alfa e come abbiamo visto in quel caso il compito del prover è dimostrare al verifier di conoscere alfa cioè di conoscere quel particolare x legato in relazione all'y che conosce il verifier ok ok dette in maniera generica io conosco una certa coppia che fa parte della relazione che caratterizza il protocollo sigma voi quella coppia non la conoscete ma conoscete solo y ok io vi devo dimostrare di conoscere chi è la x in relazione con quella particolare y però ve lo voglio dimostrare senza farvi vedere x ok questa è l'idea dei protocolli sigma generale di cui abbiamo visto un esempio nel caso di di Schnorr ok quindi ogni protocollo sigma ha la sua relazione binaria perché descrive delle coppie di elementi presi da un dominio e da un codominio di quelle coppie il prover conosce entrambi gli elementi il verifier invece conosce solo il secondo elemento della coppia ok come fa il prover a dimostrare quello che abbiamo appena detto al verifier senza esibire x esegue un protocollo di milkshake tra prover e verifier che è un challenge response protocol di cui abbiamo visto un esempio con Schnorr ma che nella sua versione più generale vi faccio vedere il milkshake e poi torniamo alla definizione si rappresenta così questo è lo schema generale di tutti i protocolli sigma compreso quello di Schnorr vedete a sinistra che cosa abbiamo a sinistra abbiamo il prover che conosce sia x che y entrambi gli elementi della coppia a destra che cosa abbiamo abbiamo il verifier che conosce solo y la sfida è la sfida che il verifier lancia il prover è dimostrami di conoscere l'x legato all'y che io conosco senza farmi vedere x come avviene lo scambio bene parte il prover che manda un commitment al verifier una stringa di qualche tipo ok poi cerchiamo di capire fra poco qual è l'analogia tra questo schema e il protocollo di Schnorr che abbiamo appena visto quindi parte il prover che manda un commitment il verifier sceglie in maniera randomica la challenge ci deve essere sempre una challenge e la manda al prover ok il prover calcola una risposta che dipende da che cosa dipende da tutte le informazioni che ha cioè dipende da x dipende da y dipende dal commitment dipende dalla challenge c calcola questa risposta che chiameremo z e la manda al verifier a questo punto il verifier analizzando z deve essere in grado di accettare o rifiutare la prova cioè deve essere in grado di stabilire se questa conversazione che ha avuto col prover e che è fatta di tre elementi t c e z è una conversazione valida valida nel senso che dimostra al verifier che il prover conosce x ok e quali sono gli ingredienti che usa Schnorr per implementare questo schema generale allora in parte l'abbiamo già detto prima perché x è alfa y è g alla alfa ok vi ricordate come comincia Schnorr l'abbiamo visto prima che il prover sceglie un beta e cos'è che manda al verifier manda g alla beta ok quindi g alla beta chi è qui dentro in questa conversazione è il commitment è t ok quindi nel caso di Schnorr questo è g alla beta no poi il verifier come risponde nel protocollo di Schnorr scegliendo radunicamente una challenge che manda al verifier ok a questo punto come calco chi è la risposta z che Schnorr manda al verifier ecco il famoso gamma no è quel famoso gamma che è beta più alfa c ok quindi la risposta che il prover manda è gamma a questo punto il verifier è in grado di accettare o rifiutare gamma sì perché abbiamo visto prima per accettare o rifiutare gamma che cosa deve verificare deve verificare che g alla gamma sia uguale a g alla beta per g all'alfa c quindi è in grado in maniera deterministica di eseguire un calcolo che gli permette di rispondere assert o reject se quella famosa uguaglianza torna allora il verifier accetterà la conversazione ovvero avrà la prova del fatto che il prover con cui ha parlato conosce effettivamente quel particolare x che è in legame con l'y se non a lui noto dove le coppie della relazione del protocollo di shinor sono queste ok questo è il modo in cui sono fatte le coppie quindi il verifier ha questo valore vuol sapere se il prover conosce questo ok quindi questo è lo schema generale di come sono fatti tutti i protocolli sigma no c'è una relazione binaria di cui il verifier conosce un solo elemento il prover li conosce entrambi attraverso questa conversazione fatta di un commitment che il prover manda una challenge che il verifier sceglie e una risposta finale che il prover genera attraverso questa conversazione il verifier deve essere in grado di accettare o rifiutare la prova di conoscenza questa è una prova di conoscenza alla fine che poi possa essere usata a scopi di identificazione o a scopi di firma digitale alla fine è sempre una prova di conoscenza ok quindi tornando indietro qui rivediamo tutti i passaggi che vengono eseguiti da prover e da verifier qui la cosa interessante è vedere al solito la proprietà di correttezza che dice che se il prover che ha in input la coppia XY esegue correttamente questo algoritmo e dall'altra parte abbiamo un verifier che lui altrettanto correttamente esegue il suo algoritmo conoscendo solo Y e se XY non sono effettivamente in relazione fra di loro allora il verifier deve accettare ok chiaramente l'idea è che un finto prover non deve essere in grado di farsi accettare una conversazione dal verifier quando non conosce quando in realtà non conosce X questo chiaramente è una delle proprietà che dobbiamo dobbiamo formalizzare ci sono tanti esempi in letteratura di protocolli sigma che funzionano in questa maniera qui e che hanno le loro relazioni nel caso di Shignor abbiamo visto che nel caso di Shignor le coppie sono queste alfa g alla alfa ok le coppie della relazione nel caso di altri schemi gli altri protocolli sigma che adesso non ci interessa approfondire le relazioni sono altre sono quelle che che vedete qui esiste un protocollo per curiosità esiste anche un protocollo sigma basato su RSA ad esempio dove le coppie sono sono fatte così ok ok cioè sono coppie del tipo x x alla e no cioè sono coppie di che tipo x alla e che cos'è x alla e è la cifratura di x perché è la chiave pubblica ok qui l'idea di un protocollo sigma basata su coppie di questo tipo se ci pensate è anche abbastanza semplice intuitiva cioè il verifier conosce x alla e voi dovete dimostrare di conoscere x quindi in pratica dovete poter dimostrare il verifier di conoscere la chiave di cifratura questa è un po' la cosa ed eseguendo una conversazione ispirata allo schema che abbiamo visto prima questa cosa è possibile e l'altra cosa interessante ripeto questi non li dettaglieremo però l'altra cosa interessante è che prendendo un qualunque protocollo sigma e l'abbiamo visto nel caso del protocollo di shinor esiste un modo per farlo diventare uno schema di firma digitale vi farò vedere un esempio che è quello di fiat e shamir perché è il più famoso ok ma tornando ai protocolli sigma vediamo quali sono le proprietà formali che li caratterizzano che sono due fondamentalmente intanto definiamo un po' da un punto di vista matematico alcuni elementi che caratterizzano i protocolli sigma a cominciare dalla famosa relazione che caratterizza ciascun protocollo ok e questa definizione ci dice ci definisce quello che viene chiamato linguaggio no della relazione il linguaggio della relazione sono tutti gli y tali per cui esiste un x con cui sono in relazione ok quindi il linguaggio della relazione sono tutti gli y per i quali esiste un x con cui sono in relazione perché a cosa ci serve questa definizione per caratterizzare la la proprietà più importante del dei protocolli sigma che è la la proof of knowledge la prova di conoscenza perché per quello che abbiamo visto l'obiettivo dei protocolli sigma di fatto se ci pensate è dimostrare questo senza svelare chi è x no questo è un po' lo scopo del protocollo sigma perché perché il verifier ha un certo y l'obiettivo del prover è dimostrare che esiste un x che lui conosce che è legato con quel particolare y senza svelare informazioni su x ok quindi il problema della proof of knowledge è questo fondamentalmente x in gergo viene chiamato witness no quel particolare x che si lega all'y che il verifier conosce è il witness e ripeto il verifier non deve sapere non dovrà mai sapere nulla su x deve sapere solo che esiste deve convincersi che esiste se il prover lo dimostra senza sapere qual è ok ora per caratterizzare questa proprietà cioè il fatto che il verifier deve sapere che questo x esiste senza sapere qual è utilizziamo come al solito un attack game no sulla base del quale definiamo formalmente quella proprietà che si chiama correttezza esistenziale esistenza al soundness ok in questo attack game che cosa succede succede che l'avversario intuitivamente l'avversario cerca di ingannare il verifier convincendolo ad accettare una falsa prova quindi convincendolo ad accettare il fatto che l'y che v conosce è legato a un certo x che l'avversario conosce quando in realtà non è vero ok è come se io mi spacciassi per nel protocollo di shinor per l'utente che conosce alfa il verifier ha un g all'alfa o peggio ancora il verifier ha un valore che gli do io e io riesco a convincere del fatto che quel valore è la potenza del generatore g quando magari non è vero e quindi lo convinco ad accettare una prova inesistente falsa infatti vedete nella taglia che cosa succede succede che l'avversario sceglie un certo y ok e fa finta di essere il prover no e interagisce con il verifier che conosce y però il verifier ripeto non sa se e qual è l'x associato a y l'avversario vince la tag game se riesce a convincere il verifier ad accettare la conversazione anche se quell'x non esiste anche se il witness di y non esiste quindi anche se y non appartiene al linguaggio della relazione esatto l'avversario non ha un x in relazione con quell'y ok il vantaggio dell'avversario come al solito è la probabilità di riuscire a convincere il verifier e noi quello che ci aspettiamo è che questa probabilità sia negligible per tutti gli avversari efficienti se così è allora si dice che vale la proprietà di existential soundness e qui capiamo anche il senso del nome di questa proprietà no correttezza esistenziale vuol dire che se un protocollo soddisfa l'existential soundness significa che le prove che vengono accettate dal verifier sono prove corrette di esistenza di x ok non sono prove falsificabili da un avversario ok poi c'è un teorema che è una diretta conseguenza di considerazioni che abbiamo già fatto negli esempi visti finora che dice che il vantaggio dell'avversario è pari alla di fatto alla probabilità di indovinare una challenge questo l'abbiamo visto già nel protocollo di di di di nei protocolli di challenge e response basati su firma digitale l'unica possibilità che l'avversario ha di ingannare è quella di usare di indovinare la challenge che userà il verifier che magari è la stessa che è già stata usata in passato dalla call prover ok ma è chiaro che dove ci dove questo è lo spazio delle delle challenge e questa quindi è la probabilità che succeda una cosa di questo genere e questo è il motivo per cui noi in tutti gli esempi che abbiamo visto abbiamo assunto che lo spazio delle challenge sia super poli perché se lo spazio delle challenge sia super poli questa è una quantità negligible e quindi vale l'existential soundness ok e questa è la prima proprietà importante quindi l'existential soundness se c'è mi garantisce che un avversario non possa falsificare una prova questa è l'idea intuitiva dell'existential soundness ok poi c'è l'altra l'altra proprietà infatti ovviamente ci posso proprietà importanti per il single protocol sono due e l'altra proprietà è la proprietà cosiddetta di zero knowledge ok e l'abbiamo già detta e ripetuta in tante salse la proprietà di zero knowledge ci dice fondamentalmente che quando il verifier accetta la conversazione come una prova valida non deve dedurre nessuna informazione non deve acquisire nessuna conoscenza relativa al witness relativa a x ok quindi se vogliamo mentre l'existential soundness è una proprietà a tutela del verifier perché se vale vuol dire che la probabilità di falsificare una prova è trascurabile e quindi chiaramente questa è una proprietà che tutela chi fa la verifica verifier la zero knowledge la zero knowledge invece è una proprietà che tutela chi? tutela il prover perché se vale la proprietà di zero knowledge significa che un verifier che accetta una prova corretta non impara nulla relativamente al valore del witness e quindi questo tutela il prover in cui interessa naturalmente quello di di non svelare nulla riguardo al valore di di x ok questo è un po' è l'idea l'idea che sta dietro la zero knowledge quindi questo è il motivo per cui abbiamo due proprietà interessanti per i protocolli di per il sigma protocol una che tutela verifier che è la resistential soundness l'altra che tutela approver che è la zero knowledge ok dimostrare la zero knowledge è la cosa più complicata perché non c'è un attack game semplice per la zero knowledge non mi farò vedere come sono le varianti degli attack game per la zero knowledge perché sono piuttosto complesse l'idea di base è che si muove da solo il marco si muove da solo vabbè abbiamo i fantasmi è lì la tastiera non so cosa sia successo vabbè l'idea degli degli degli attack game che stanno dietro le prove di zero knowledge sta nel dimostrare che l'esecuzione dal punto di vista dell'avversario l'esecuzione di una conversazione no di un shake tra prover e verifier dovrebbe essere indistinguibile rispetto ad una simulazione della stessa conversazione che non usa per niente x che non usa per niente il mix quindi voi da una parte avete una conversazione con commitment challenge e response basata sull'uso di x dall'altra avete una sua simulazione ok che non usa x queste due conversazioni se sono indispinguibili tra loro dal punto di vista di un avversario allora vuol dire esattamente che è male la zero knowledge perché se un avversario non riesce a distinguere una conversazione che usa x da una conversazione che non usa x chiaro che vuol dire che lui da qualunque conversazione non deduce nulla sul valore di x ok perché non riesce nemmeno a a capire qual è la differenza fra una conversazione che si basa su x e una che non si basa su x e le conversazioni per l'avversario che cosa sono sono le triple tcz commitment challenge e response ok lui vede queste no ok ripeto se dal punto di vista dell'avversario una conversazione fatta usando x rispetto a una che non lo usa sono indistinguibili allora vuol dire che è una simulazione quindi non è una conversazione reale ok io ti posso generare allora il protocollo sì siccome stiamo parlando dei protocolli probabilistici no quindi prendiamo un protocollo sigma reale ok dal punto di vista dell'avversario l'esecuzione del protocollo sigma reale genera delle conversazioni no e queste conversazioni avranno una distribuzione di probabilità che ci una distribuzione di probabilità che ci dice guarda la tripla tcz ha una certa probabilità di essere osservata un'altra tripla t' c' z' ha un'altra probabilità di essere osservata ok quindi quello che l'avversario vede è una distribuzione di probabilità su conversazioni che sono conversazioni reali del protocollo sigma e che quindi lavorano su x ok dall'altra parte prendiamo una simulazione in qualunque algoritmo il cui compito è quello di generare conversazioni ok quindi generare triple tcz no senza basarsi su x ok quindi un simulatore possiamo costruire un algoritmo se siamo in grado di costruire un algoritmo che genera queste triple un algoritmo probabilistico e anche questo algoritmo esibirà queste triple con una certa distribuzione di probabilità ok ora il simulatore lo deve costruire chi vuole dimostrare che il sigma protocol è soddito da zero knowledge ok quindi io ho il protocollo di sigma corretto e l'avversario vede la distribuzione di probabilità sulle conversazioni che genera dall'altra parte è un simulatore che genera in maniera pseudo casuale se vogliamo conversazioni che avranno la loro distribuzione di probabilità l'avversario cerca di capire mettiamole dentro una scatola nera da una parte del sigma protocol che lavora dall'altro simulatore che lavora se uno dentro una scatola nera l'avversario non sa in quale scatola c'è il simulatore in quale scatola c'è il sigma protocol ok lui vede le conversazioni che sparano ed essendo entrambi algoritmi probabilistici lui vede con che frequenza no escono certe conversazioni quindi vede osservando per parecchio tempo si costruisce una distribuzione di probabilità sulle conversazioni da una parte e dall'altra ok quindi magari vede che una certa conversazione da una parte esce con probabilità uno su mettiamo che siano anche probabili facciamo questa semplificazione quindi una certa conversazione esce con una certa probabilità magari nell'altra scatola la stessa conversazione non esce mai ok e allora se così è lui distingue subito la di simulatore dal dal dal protocollo sigma ok e se il simulatore mi inganna nel senso che le due distribuzioni di probabilità sulle conversazioni sono identiche allora vuol dire che l'avversario branco là nel buio non è in grado di distinguere il protocollo sigma da un simulatore che spara delle conversazioni senza usare x e se dal suo punto di vista queste due cose sono equivalenti vuol dire che lui in un contesto reale non è in grado di disumere nessun tipo di informazione riguardo a x perché se potesse farlo allora vorrebbe dire che sarebbe in grado di distinguere i due esperimenti questa è un po' l'idea ora se le due distribuzioni di probabilità sono identiche cosa che non succede quasi mai allora abbiamo la zero knowledge perfetta un po' come la differenza fra perfect security e semantic security no? in caso reale le due distribuzioni sono equivalenti la zero knowledge è perfetta e quindi si parla di perfect zero knowledge se le due le differenze fra le due distribuzioni di probabilità ci sono ma sono negligible ok? allora si parla in questo caso di zero knowledge statistica vi ricordate un po' i diversi tipi di DOOF quando abbiamo parlato delle o di UHF quando abbiamo parlato di funzioni universali quindi la classificazione era la stessa quindi abbiamo zero knowledge perfetta se le due distribuzioni sono identiche abbiamo zero knowledge statistica se le due distribuzioni non sono perfettamente uguali ma la differenza è negligible e poi abbiamo la zero knowledge computazionale se se le due distribuzioni sono statisticamente simili dal punto di vista non di qualunque avversario ma dal punto di vista degli avversari efficienti quindi quindi abbiamo zero knowledge statistica limitatamente agli avversari efficienti ecco tutto qua insomma quindi questo non vi farò vedere l'implementazione di quest'idea però questa è l'idea che si implementa si cerca di realizzare per dimostrare che un protocollo soddisfa la zero knowledge di qualche tipo perfetta statistica o computazionale quindi per dimostrare la bontà di un protocollo sigma bisogna da una parte dimostrare la existential soundness quindi la robustezza rispetto a questo tag game invece per dimostrare la zero knowledge di qualche tipo bisogna costruire un simulatore di conversazioni e fare il giochino che abbiamo appena mostrato questo è quello che che si fa il protocollo di schnor soddisfa la correttezza esistenziale e soddisfa anche la perfect zero knowledge quindi è stato dimostrato che valgono entrambe nel caso del protocollo di schnor ci sono tanti esempi in letteratura di utilizzo di protocolli sigma che siano corretti esistenzialmente e anche zero knowledge perfetti e questi sono tutti esempi che potrebbero essere approfonditi in un progetto tanto per fare ancora una volta un esempio di idee che possono emergere per da questo punto di vista questi così come altri e qui ne ho citati tre che sono abbastanza significativi questi sono tutti problemi che possono essere risolti in perfect zero knowledge e garantendo l'existential sadness attraverso dei protocolli sigma opportuni ok e se ci pensate non sono problemi banali ma che possono avere degli risvolti pratici ad esempio il problema degli equal plaintext è un problema in cui noi vogliamo dimostrare a un verifier che due ciphertext ottenuti con due chiavi diverse due chiavi pubbliche diverse ok cifrano lo stesso plaintext ma lo voglio fare senza mostrare il plaintext sarebbe falso ok o senza mostrare chiaramente le chiavi per fare la decifratura no immaginate un contesto in cui io usando un cifrario a chiave pubblica il gamal usando due chiavi diverse ho cifrato lo stesso messaggio ok ad esempio non so ho usato una chiave per mandare il messaggio cifrato a lui ho usato un'altra chiave per mandare lo stesso messaggio cifrato a lui loro due vogliono avere la garanzia anche se hanno ricevuto due cifrtex diversi vogliono avere la garanzia di aver ricevuto lo stesso o un osservatore esterno vuole avere la garanzia che loro due hanno ricevuto lo stesso messaggio senza conoscere il messaggio magari per questioni di equità questioni di legalità contesti in cui può essere utile in una cosa di questo genere possono essere tanti una terza parte vuole avere la garanzia che ciascuno di voi magari ha ricevuto lo stesso messaggio senza sapere quale perché magari c'è il dico della privacy però ognuno di voi ha avuto un cifrtex diverso e questa cosa si può dimostrare in Zero Knowledge con l'esistenza e il cellulare un altro è il problema delle encrypted bit voglio dimostrare un verifier che la cifratura di un bit è fatta con una certa chiave pubblica è stata fatta effettivamente usando quella chiave senza mostrare la corrispondente chiave segreta anche questo è dimostrabile in Zero Knowledge e in correttezza esistenziale io posso dimostrarvi che senza aprirlo posso dimostrarvi che un certo cifrtex di un bit è stato fatto usando una certa chiave pubblica l'ultimo è un esempio che può essere raccontato in tante salse diverse qui è bastato generare l'idea e dice che io voglio dimostrare al verifier che due cifrtex sono relativi a due plaintext tra cui esiste un certo tipo di legame ok è la generalizzazione del se vogliamo del del primo ad esempio non so magari mi interessa dimostrare che due cifrtex cifrano lo stesso plaintext ok oppure mi interessa dimostrare che due cifrtex cifrano un plaintext che può essere un numero e il successore di quel numero no questo può essere un altro tipo di o cose di questo genere ok lì si può addirittura andare a investigare sulla struttura del plaintext il plaintext che ne so potrebbe essere un testo piuttosto articolato mettete non so il plaintext potrebbe essere un bonifico ok e magari vi interessa dimostrare che due cifrtex rappresentano due bonifici fatti nei confronti dello stesso beneficiario quello è un tipo di legame tra i due plaintext però chiaramente non volete svelare il plaintext anche questa è una cosa che si può fare in zero knowledge garantendo la salva esistenziale ci sono protocolli sigma che permettono di fare questo si tratta sempre comunque in tutti i casi di cifrature fatte nell'ambito della crittografia chiave pubblica ok l'ultima cosa poi dopo ci fermiamo si oggi corretto le conversazioni questa è una cosa abbastanza banale le conversazioni dei protocolli sigma che abbiamo visto fino adesso sono tutte conversazioni interattive cosa vuol dire interattive sono conversazioni che prevedono uno scambio di messaggi che coinvolgono sia il prover che il verifier lato prover il contributo sono il commitment e la risposta lato verifier il contributo alla conversazione è la challenge quindi entrambi contribuiscono alla conversazione ok però modo per farlo l'abbiamo visto trasformando il protocollo di Schnorr in uno schema di firma digitale una conversazione che coinvolge entrambi si può trasformare facilmente in un protocollo non interattivo cioè in una conversazione che è generata solo ed esclusivamente a lato a lato prover senza coinvolgere l'interazione del verifier come si fa qual è l'idea allora per creare una conversazione non interattiva bisogna che uno dei due non partecipi allora la cosa più semplice è non far partecipare il verifier perché qual è il contributo del verifier alla conversazione la scelta randomica della challenge allora se vogliamo escludere il verifier dalla creazione della conversazione ma permettergli poi in un secondo tempo offline di prendere una conversazione e verificarla perché questo è importante come possiamo fare a lato prover per generare da solo una conversazione non interattiva che però venga accettata cioè una conversazione valida perché il dubbio quale può essere se io faccio fare la conversazione al prover che se la canta da solo ok senza interagire col verifier chi mi garantisce che quella conversazione è corretta oppure oppure in qualche modo è manipolata dal fatto che il prover ha potuto scegliere tutti quanti i suoi ingredienti allora qui l'unico ingrediente su cui dobbiamo giocare è la challenge perché tanto il commitment lo sceglie il prover la risposta la calcola il prover in maniera deterministica sulla base di tutti gli altri ingredienti l'unico che rimane è la challenge vogliamo togliere il verifier dall'inshake allora bisogna che sia il prover a generare randomicamente la challenge ci possiamo fidare del prover cioè ci possiamo fidare del fatto che il prover scelga effettivamente la challenge in maniera randomica e non la scelga come gli conviene a lui per farsificare una certa conversazione e ingannare come facciamo a imporre al prover di scegliere la challenge effettivamente in maniera randomica facciamo come abbiamo visto nello schema di firma digitale che usa il protocollo di schenor dove lì la challenge la calcolava direttamente chi faceva la firma non la calcolava il verifier e come la calcolava applicando la funzione hash il cui risultato è impredicibile quindi randomico su che cosa sugli altri ingredienti della conversazione in quel caso nel caso della firma digitale l'hash veniva calcolato su T e sul plaintext da firmare cioè sul commitment e sul test da firmare e quindi il digest era tutti gli effetti in maniera randomico che poteva essere usato come challenge e quindi in quel caso il protocollo si poteva eseguire tutto internamente al prover poi il risultato sarà una conversazione e quella conversazione offline la posso dare a chi me la chiede chi me la chiede la prende la verifica e dice sì va bene questa conversazione mi convince ho la prova del fatto che tu conosci il witness questa è l'idea e nei protocolli non interattivi succede esattamente esattamente questo ok quindi nei protocolli non interattivi si fa meno del verifier ok e il prover che cosa fa il prover che vuole dimostrare di conoscere questa coppia di cui è pubblica solo y deve creare una proof no e questa proof è una conversazione autogenerata dal prover cioè la sequenza commitment challenge e response che in cui fa tutto lui dopodiché il prover non deve far altro per convincere chiunque del fatto che lui conosce il witness x non deve far altro immaginiamo offline io voglio convincere un certo verifier di conoscere il witness beh non devo far altro che mandargli y perché y deve essere morto e poi gli mando la prova gli mando la conversazione che ho generato e gli do la possibilità di verificare se la verifica ha successo allora lui si convince ok e lo schema di firma basato sul protocollo di Shinorra segue questa idea qua quello che abbiamo visto quello che abbiamo visto prima ok naturalmente naturalmente anche per le versioni non interattive dei protocolli sigma abbiamo le stesse proprietà existential soundness e zero knowledge e valgono gli stessi risultati nel senso che se la proof cioè la conversazione che il prover genera autonomamente è corretta il verifier l'accetterà offline in un secondo tempo e non vale l'existential soundness nel senso che il prover se il protocollo si è ben sicuro non ha modo di falsificare una prova ok quindi existential soundness e questo a tutela del verifier e al tempo stesso se vale la zero knowledge improverà la garanzia che la prova che viene esibita al verifier non svela niente della natura di X del witness quindi stesse proprietà degli protocolli interattivi che abbiamo visto oggi pomeriggio vi faccio vedere come i protocolli non interattivi possono essere usati appunto per prendere un protocollo sigma e farlo diventare uno schema di firma digitale vi faccio vedere la trasformazione di piatti e shambier che abbiamo anticipato all'inizio e poi vi faccio vedere un esempio di come questi protocolli si usano negli schemi di voto elettronico il voto elettronico è un oceano di difficoltà ok ci si potrebbero fare dieci tesi sul voto elettronico io vi faccio vedere un piccolissimo esempio di come i protocolli sigma possono essere usati per soddisfare alcune proprietà degli schemi di voto ma ce ne sono tante quindi lì uno si potrebbe veramente divertire a farci una tesi sotto ok grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti grazie a tutti