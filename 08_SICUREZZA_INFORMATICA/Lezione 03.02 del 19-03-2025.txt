Bene, allora, una volta scorsa parlando di integrità abbiamo visto i MAC come strumento per garantire questa proprietà, il message authenticated code. Abbiamo visto come implementarli fondamentalmente usando come primitiva crittografica di riferimento i PRF, in particolare abbiamo visto che chiaramente non è sufficiente applicare una volta un PRF a un messaggio perché il problema fondamentale che abbiamo in questo senso è che il PRF lavora su domini piuttosto limitati, mentre invece i messaggi di cui vogliamo creare un tag a tutela dell'integrità magari sono lunghi a piacere, quindi occorre applicare in cascata il PRF a ogni blocco di messaggio, ogni blocco di plaintext in modo tale poi da generare un tag per l'intero messaggio che soddisfi la proprietà di sicurezza per il MAC. Abbiamo visto un paio di costruzioni che si possono utilizzare a questo scopo e che sono di fatto poi impiegate all'interno di standard in letteratura. Oggi vediamo un approccio più esteso alternativo di cui in realtà i casi che abbiamo visto la settimana scorsa possono essere interpretati come dei casi particolari. In particolare vediamo come costruire MAC usando funzioni hash. Le funzioni hash che si utilizzano in tanti diversi contesti, non solo nell'ambito della criptografia, sono funzioni che ad un certo diverso di astrazione fondamentalmente quello che fanno è mappare elementi di un dominio molto grande, nel nostro caso il dominio dei plaintext, in elementi di un codominio molto più piccolo. Nel nostro caso sarà il codominio dei possibili tag, visto che l'idea è quella di usare le funzioni hash come MAC per generare tag di un messaggio. L'unica differenza è che nel mondo delle funzioni hash l'output non viene chiamato di solito tag ma viene chiamato digest. Quindi l'applicazione di una funzione hash ad un certo messaggio ci restituisce un digest che noi in qualche modo utilizzeremo in forma di tag. Nel mondo della criptografia si distinguono due grandi famiglie di funzioni hash, quelle con chiave e quelle senza chiave. A seconda appunto che parte dell'input sia o meno una chiave segreta. In questa prima reazione vedremo in particolare come si definiscono le funzioni hash con chiave. Quindi funzioni hash che prendono in input il messaggio di cui vogliamo calcolare un tag, prendono in input una chiave segreta e restituiscono come output il digest, quello che chiamiamo appunto digest. Dopodiché vedremo che il tipo di costruzione che sfrutta le funzioni hash per definire un MAC è quello che vediamo qui in questo slide. Vedremo una costruttura in due passi, un primo passo in cui il plaintext M insieme alla chiave segreta K1 in questo caso, vengono dati in input la funzione hash che genera il digest, quindi denotato con T. Dopodiché ci sarà una seconda fase in cui il digest T combinato con una seconda chiave segreta K2 diversa da K1, vengono dati in input a un PRF per restituire quello che sarà il tag finale. Notate che questa costruzione è molto simile all'encrypted PRF che abbiamo visto la settimana scorsa. In cui c'era la prima fase in cui un certo tipo di costruzione basata su un PRF veniva applicata in cascata, ed erano gli esempi di F-Stelle ed F-CBC, a partire da una certa chiave K1. E poi c'era una seconda fase in cui il risultato finale di questa applicazione in cascata di PRF veniva cifrata una seconda volta usando una nuova chiave K2. e quella costruzione appunto prendeva il nome di encrypted PRF. Qui il discorso, vedete, è analogo. L'unica differenza è che nella prima fase non si usa F-CBC o F-Stelle, quindi non si usa un PRF in cascata, ma si usa la funzione hash. Con chiave. Poi vedremo che in realtà a livello implementativo ci sono veramente poche differenze tra le funzioni hash e funzioni come F-CBC ed F-Stella, tant'è che a tutti gli effetti, come vedremo tra poco, F-CBC e F-Stella hanno delle proprietà tali per cui possono essere considerati dei casi particolari di funzioni hash con chiave. Perché vedremo che appunto soddisfano alcune delle proprietà che le funzioni hash devono avere. Quindi noi adesso vediamo in generale quali sono le proprietà che devono caratterizzare le funzioni hash con chiave in maniera tale da poterle utilizzare in questa costruzione per generare dei maxi curi. Questa è un po' l'idea che vedremo. Come dicevo prima, caratteristica di tutte le funzioni hash, con chiave o senza chiave non è importanza, è che di solito il codominio è molto più piccolo rispetto al dominio. Dove per dominio appunto intendiamo l'insieme dei messaggi, dei plaintext, mentre invece il codominio rappresenta l'insieme dei digest, i risultati dell'applicazione della funzione hash. Questa cosa significa? Lavorando con un dominio molto grande, con un dominio molto piccolo, questo significa che... Vediamo se... Ok. No, questo è il dominio, sono i messaggi. Questo è il codominio, sono i digest, ho chiamato il T, diciamo dei digest, che è molto più piccolo rispetto al dominio, questo significa che necessariamente ci saranno diversi elementi del dominio che gioco forza verranno mappati nello stesso elemento del codominio, proprio per questa disparità di cardinalità. Questo problema prende il nome di collisione, il problema delle collisioni, che appunto si verifica quando due messaggi del dominio vengono mappati, chiaramente a partire dalla stessa chiave, nello stesso digest. Ok. Quindi vale questa condizione. Il digest generato dalla funzione hash, quando in input prende M0 la chiave K, è uguale al digest che la funzione hash genera, quando in input insieme alla chiave segreta K, abbiamo un altro messaggio M1 diverso da M0. Quindi vuol dire che M0 e M1 collidono rispetto alla funzione hash H e chiaramente rispetto alla specifica chiave K. Magari potrebbero collidere su K, ma non collidere su un'altra chiave K' o K. Ok. Ora, come detto, le collisioni sono chiaramente inevitabili, proprio per questo discorso legato alle cardinalità degli insiemi in ballo. Quindi bisogna tener conto di questo fattore. Naturalmente quello che ci aspettiamo se vogliamo usare le funzioni hash per costruire maxi curi è che sia difficile, sia inefficiente per un avversario riuscire a trovare le collisioni rispetto ad una determinata chiave. Perché è evidente che se l'avversario è in grado di trovare delle collisioni allora potrebbe vincere l'attack game dei MAC, la sicurezza dei MAC e quindi di fatto violare l'integrità. Questo è il problema di fondo. Quindi le funzioni hash che a noi interessano per la implementazione dei MAC sicuri sono quelle cosiddette resistenti alle collisioni. Ok? Ovvero funzioni hash per le quali un avversario efficiente non è in grado di trovare una collisione con probabilità non traspurabile. Ok? Le funzioni hash che soddisfano questa proprietà vengono chiamate funzioni hash universali UHF. Ok? Ok? Ok? Ok? Ok? Ok? Ok? Ok? Quindi per definire la sicurezza delle funzioni hash rispetto appunto a questa proprietà di resistenza alle collisioni abbiamo bisogno come lo solito di definire formalmente una tag game ok? Che appunto ci permette di stabilire poi cosa significa essere dal nostro punto di vista resistenti alle collisioni quindi riuscire a caratterizzare di fatto gli UHF la tag game è molto semplice quindi abbiamo una funzione hash con chiave definita su dominio dei plaintext e il codominio dei digest abbiamo al solito l'avversario e nella tag game la chiave usata per calcolare il digest viene scelta randomicamente dal challenger quindi è segreta rispetto all'avversario ok? quindi l'unica cosa è che l'avversario non conosce la chiave l'avversario quello che deve fare è trovare due messaggi che collidono rispetto a quella chiave ok? e il vantaggio che l'avversario ha appunto è la probabilità che di riuscire appunto a trovare due messaggi che collidono ok? ora rispetto a questo attack game si possono definire diverse classi di UHF a seconda del modo in cui noi poniamo condizioni su questa probabilità quindi sul vantaggio dell'avversario quindi ripetiamo il vantaggio dell'avversario è la probabilità di trovare una collisione rispetto alla chiave segreta che ha scelto il challenge ok? sulla base di questo attack game quindi sulla base del vantaggio dell'avversario che abbiamo definito si possono avere diverse classi di UHF ok? e sono queste tre che vediamo qui in particolare abbiamo la nozione di Epsilon UHF ovvero una funzione hash è un Epsilon UHF se il vantaggio dell'avversario è minore o uguale a Epsilon questo per tutti i possibili avversari faccio notare tutti quindi non solo quelli efficienti questa se vogliamo è la nozione più forte per un UHF ok? poi c'è la nozione di UHF statistico che ci dice che appunto una una funzione hash è un UHF statistico se esiste almeno un Epsilon trascurabile negligible quindi molto molto piccolo per cui l'H risulta essere Epsilon UHF ok? quindi in pratica una funzione hash è un UHF statistico se è un Epsilon UHF dove Epsilon è una quantità trascurabile molto molto piccola e questa è una definizione se vogliamo abbastanza ideale perché ci dice che qualunque avversario ha un vantaggio trascurabile rispetto all'identificazione di collisioni quindi ha una probabilità estremamente piccola di riuscire a trovare una collisione infine c'è l'ultima classe che è quella solita solita perché si riferisce agli avversari efficienti ed è la nozione di UHF computazionale ok? quindi una funzione hash è un UHF computazionale se il vantaggio dell'avversario è trascurabile per tutti gli avversari efficienti quindi di fatto rispetto alla definizione di UHF statistico stiamo restringendo il set di avversari di riferimento quindi non più tutti i possibili avversari ma solamente quelli efficienti cioè quelli che sono vincolati all'esecuzione di algoritmi che sono limitati polinomialmente ok? per come abbiamo definito l'attack game e la definizione di epsilon UHF vale questo lemma ovvero se una funzione hash è un epsilon UHF allora vale questa condizione qui cosa ci dice questa condizione qui? ci dice che se noi scegliamo randomicamente la chiave e questo k qui è la variabile casuale che rappresenta appunto la scelta della della chiave che seguirà come al solito una distribuzione di probabilità uniforme ok? quindi sotto questa condizione presi due qualunque messaggi M0 ed M1 ok? e questi nell'attack game da chi vengono scelti? vengono scelti dall'avversario la probabilità che quei due messaggi collidano è più piccola di epsilon quindi questo lemma è una conseguenza della definizione di epsilon UHF e del modo in cui abbiamo definito l'attack game ok? chiaramente se la nostra funzione hash H è statistica allora questo epsilon qui è negligible ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? ok? quindi abbiamo introdotto un po' di di definizioni per caratterizzare quella che è la sicurezza delle funzioni hash che è espressa in termini di resistenza alle collisioni questa è l'idea ok? bene cominciamo a vedere come costruire dei possibili UHF no? vedremo alcuni modi di costruire UHF e vedremo che a un certo punto i PRF sono primitive e crittografiche adeguate per costruire per costruire degli UHF ma partiamo da una definizione classica alternativa che si ispira molto alla analisi matematica fondamentalmente e che ci suggerisce un modo abbastanza efficiente per costruire un UHF che ha determinati requisiti di robustezza e quindi di resistenza alle collisioni l'idea è che possiamo costruire possiamo definire un polinomio che ci permette di costruire la nostra la nostra funzione l'interpretazione geometrica è abbastanza intuitiva infatti cosa dice questa definizione che ora andiamo a commentare ci dice che se noi dobbiamo calcolare il digest di un messaggio M la prima cosa che dobbiamo fare è dividere il messaggio in blocchi ok e per poi andare a definire una funzione hash su questo spazio delle chiavi ok ovvero lo spazio delle chiavi per la nostra funzione hash è l'insieme degli interi in zp quindi stiamo parlando di aritmetica modulare dove il modulo è p ok quindi interi minore uguali di p dove p che cos'è p è un numero primo grande a piacere ok quindi lo spazio delle chiavi è zp e i messaggi sono grandi a piacere non c'è non c'è chiaramente vincolo da questo punto di vista però quello che importa è che il messaggio possa essere spezzato in tanti blocchi dove ciascun blocco può essere visto come un elemento di zp ok quindi se questo qui se questo è il messaggio vuol dire che a 1 sta in zp a 2 sta in zp e così via quindi alla fine se abbiamo v diversi blocchi dove v è limitato in questo range da 0 l vuol dire che lo spazio dei messaggi è pari a zp con minore uguale a l ovvero una sequenza di al più elementi di zp ok dopodiché andiamo a definire la funzione hash in questo modo quindi vedete la funzione hash parametrizzata rispetto a p prende in input la chiave la sequenza di elementi di zp prende in input la sequenza di elementi di zp che formano il messaggio m e costruisce il digest in questa maniera qua come somma in aritmetica modulare quindi zp di tutti questi termini che vedete sono di grado diverso la somma di questi termini descrive un polinomio ok un polinomio i cui coefficienti che cosa sono da che cosa sono dati sono dati da dai blocchi del plaintext vedete questi sono i vari coefficienti del polinomio ma i coefficienti del polinomio non sono altro che i blocchi del plaintext ok il primo coefficiente qua è 1 quindi il coefficiente 1 è moltiplicato per la chiave elevata alla v il secondo coefficiente che è questo è moltiplicato per la chiave elevata alla v-1 e così via il terzo coefficiente che è questo è moltiplicato per la chiave elevata alla v-2 e così via fino ad arrivare all'ultimo coefficiente che è adv che è l'ultimo blocco del plaintext che di fatto è moltiplicato per k alla 0 no qui avevo k l'uomo non mi dico k la 0 ok ma questo non è altro che un polinomio ripeto questo non è altro questa espressione questa sommatoria non è altro che un polinomio no noi possiamo noi possiamo rappresentare anche graficamente no da un punto di vista geometrico questa sommatoria un polinomio che avrà una determinata sarà descritto da una determinata curva per esempio che non so adesso vado a caso questo potrebbe essere il nostro polinomio no che ha valori nel range che va da 0 a p no perché il polinomio è definito vedete solo tra 0 e p perché la somma dei termini è in aritmetica modulare in zp quindi da un punto di vista Giorgio mi chiede se p deve essere maggiore di l no non diciamo che entrambi sono limitati polinomialmente ma non c'è un legame tra di loro ok quindi p è un numero primo grande a piacere comunque limitato polinomialmente lo stesso vale per lo stesso vale per perché perché devono essere limitati polinomialmente perché questo calcolo qui dobbiamo poterlo fare in tempo polinomiale non so se ho risposto alla domanda ho fatto chiarezza su questo e se no dimmi pure quindi stavo dicendo il nostro il nostro polinomio lo possiamo appunto rappresentare come appena ho fatto vedere graficamente immaginiamo che questa sia la curva che descrive il nostro il nostro polinomio ok chiaramente la forma del polinomio dal punto di vista geometrico dipende dai coefficienti ma i coefficienti da chi dipendono dipendono dal dal plaintext no i coefficienti del polinomio sono di fatto il plaintext quindi questo cosa significa significa che ogni messaggio di cui vogliamo calcolare il digest è descritto da una diversa curva ok quindi ogni messaggio associato ad una curva che è la curva di un polinomio di un certo grado qual è il grado del polinomio? beh il grado del polinomio il grado massimo del polinomio è pare che cosa? av che è il numero di blocchi del messaggio cioè è proporzionale la lunghezza del messaggio quindi tanto più lungo è il messaggio tanto più alto sarà il grado del polinomio e quindi la curva avrà le sue belle caratteristiche no ok ci siamo fin qui è chiaro? ora in cosa consiste il digest che noi andiamo a calcolare? beh se andiamo a vedere l'espressione il digest non è altro che il valore del polinomio in un punto preciso quale punto? chi ha l'incognita qui del polinomio? è k cioè la chiave quindi questa definizione ci sta semplicemente dicendo che il digest di un messaggio non è altro che il valore del suo polinomio in un punto segreto perché la chiave è segreta no? ok quindi tornando alla rappresentazione grafica la curva che descrive il polinomio associato al messaggio è nota a tutti è nota a tutti perché? perché i coefficienti di questa curva sono derivano dal messaggio ok quindi come è fatta la curva associata ad un plaintext lo sa anche l'avversario ok ma cos'è che non sa l'avversario nell'andare nel calcolo del digest? non sa in quale punto il polinomio viene calcolato e il punto in cui il polinomio viene calcolato è k che è l'informazione segreta no? è la chiave quindi è come dire bene torniamo al disegno no? quella che ho disegnato è la curva associata al nostro m ok ora io mi chiedo quanto vale h di k m sapendo che questa è la curva associata a m beh k sarà un elemento compreso tra 0 e p ok e h di k m è esattamente andiamo a vedere il punto del polinomio corrispondente a k ok quindi il digest di m è un punto di quella curva quale lo so solo se conosco la chiave che ha ok quindi per calcolare il digest io devo calcolare il valore del polinomio in un punto segreto questa è questa è l'idea qui l'interpretazione geometrica è abbastanza semplice c'è un teorema che stabilisce che tipo di u hf è la nostra funzione hash costruita in questa maniera e il teorema dice che la nostra funzione hash hdp è un epsilon u hf dove epsilon è uguale a l fratto p ok non vi dimostro il teorema ma vorrei sottolineare il legame che c'è tra epsilon e il numeratore e il denominatore perché è chiaro che se vogliamo mantenere epsilon molto piccolo dobbiamo intervenire o su l o su p ok in particolare ci fa comodo avere un p grande no questo è abbastanza più grande p e più piccolo sarà epsilon ok infatti poi possiamo osservare subito il corollario che dice che se p è superpoli allora se p è superpoli cosa possiamo concludere beh se p è superpoli possiamo concludere che l fratto p è negligible quindi epsilon è negligible ma se epsilon è negligible allora vuol dire che la nostra funzione hash è un hf statistico no se p è superpoli quindi se questa se il denominatore è molto grande vuol dire che questa quantità è molto piccola è trascurabile quindi epsilon è trascurabile ok quindi vuol dire che la nostra funzione hash è un hf statistico no perché è un epsilon hf con epsilon trascurabile ok quindi che esattamente è anche meglio che di una funzione hash che sia un hf computazionale perché un hf statistico è robusto rispetto a qualunque categoria di avversario non solo rispetto a quelli computazionali quindi questa cosa ci piace molto ok intuitivamente qual è l'idea è che quanto più grande è p no maggiore sarà il numero di chiavi possibili le chiavi vanno da 0 a p quindi se p è super poli vuol dire che la probabilità per l'avversario di azzeccare la chiave è trascurabile no e questo è abbastanza ovvio dal punto di vista intuitivo forse meno ovvio il fatto che in questo teorema l compare al numeratore dove l noi sappiamo che rappresenta che cosa la la massima lunghezza di di relativa ai ai ai play text no ma al tempo stesso l è una misura di che cosa del grado del polinomio no perché torniamo alla definizione della nostra funzione hash il grado del polinomio è dato da v il massimo grado del polinomio è dato da v dove v è il numero di blocchi del plain text che è compreso fra 0 l quindi cresce l vuol dire che crescere può crescere la dimensione dei messaggi e quindi vuol dire che aumenta il grado del polinomio associato ai messaggi possibili messaggi molto lunghi sono descritti da polinomi di grado elevato ok e anche qui l'interpretazione grafica ci aiuta a capire perché avere un grado elevato nel polinomio non è bene ok rispetto alla robustezza ora più alto è il grado del polinomio maggiore il numero di massimi e minimi locali nella curva del polinomio quindi un polinomio di grado molto elevato ad esempio potrà avere vedete molti più minimi e massimi locali ok ma confrontate le due curve che abbiamo che abbiamo disegnato aumentando il numero di minimi e di massimi locali cos'è che aumenta secondo voi e che non fa bene alla funzione hash cos'è che la funzione hash deve evitare le collisioni le collisioni quindi è chiaro che se aumentano le collisioni non siamo contenti ora se aumenta il grado del polinomio aumentano le collisioni prendete ad esempio che ne so confrontiamo le due curve prendete questo elemento del codominio questo digest tracciate la riga e andate a vedere quanti sono i punti del polinomio che collidono sono questo questo questo questo e basta ok se prendete un polinomio che ha molti più minimi e massimi e quindi ha molti più fasi di crescita e decrescita quindi adesso devo fare un altro un altro disegno per fare il confronto con quello che abbiamo appena visto quindi se prendete che ne so prendete questa questo polinomio qui che sto disegnando le collisioni sono molte di più ok ma aumentando il numero delle collisioni aumenta la probabilità che l'avversario le possa individuare chiaramente quindi vedete anche da un punto di vista geometrico abbastanza intuitivo osservare che al crescere di L cresce il grado del polinomio e cresce il numero delle collisioni e quindi cresce la probabilità per l'avversario di individuarne naturalmente tutto questo è mitigato dal fatto di scegliere un P super poli cioè un denominatore che fa tendere a zero rapidamente il rapporto L su P e che quindi ci garantisce di lavorare con una funzione hash che sia un UHF statistico ok ora per come è definita la nostra funzione hash HP vedete che è anche efficiente da calcolare perché pensate all'implementazione in cui vi arriva un messaggio M molto lungo che ne so svariati mega un messaggio di svariati mega che quindi caricate in memoria un po' alla volta e di questo messaggio volete calcolare il digest ora il digest potete cominciare a calcolarlo man mano che caricate il messaggio in memoria senza che sia interamente presente in memoria perché perché vedete che il digest è la somma di tanti termini no allora per calcolare il primo termine non vi serve niente del del plain test lo potete già calcolare per calcolare il secondo termine vi serve il primo pezzo del messaggio quindi appena caricate il primo pezzo del messaggio in memoria potete già calcolare il secondo termine del digest e così via andare avanti in maniera incrementale voi questa sommatoria in maniera incrementale potete cominciare a calcolarla man mano che leggete il messaggio non avete bisogno di avere l'intero messaggio in memoria per iniziare a calcolare il digest ma è una cosa che potete fare man mano che caricate il messaggio che leggete il messaggio un pezzo alla volta e quindi questo naturalmente è un vantaggio anche dal punto di vista dell'efficienza ok quindi la funzione hash hp costruita in questa maniera è un UHF statistico sotto la condizione che il numero primo p che la parametriza sia superporto ora come detto all'inizio un altro modo di costruire completamente diverso di costruire un UHF consiste nell'usare una primitiva crittografica che già conosciamo almeno a livello teorico ovvero il PRF ok in che maniera la costruzione che vi propongo prende il nome di XOR hash molto semplice si chiama XOR hash perché come vedremo tra poco usa il PRF in combinazione con l'operatore di XOR e l'idea è un po' quella che abbiamo visto anche settimana scorsa ovvero siccome noi sappiamo che non possiamo applicare il PRF direttamente sul messaggio intero perché il messaggio può essere troppo lungo per il dominio del PRF pensate ad esempio se usate come PRF AS128 quindi l'input in questo caso per il PRF sono stringhe di 128 bit e i messaggi di cui vogliamo calcolare il digest sono molto più grandi di solito quindi stesso problema che abbiamo visto l'altra volta per i Mac quindi l'idea qual è? L'idea è di spezzare il messaggio e applicare il PRF a ogni porzione di messaggio infatti vedete che nella nostra definizione abbiamo che il messaggio viene suddiviso in tanti blocchi ciascuno dei quali viene dato in input al PRF insieme a un contatore lo osserviamo già qui vedete qua questo è l'input oltre chiaramente alla chiave K come al solito l'input del PRF è il blocco corrente del messaggio e vedete concatenato abbiamo il contatore del blocco perché insieme al blocco del messaggio si mette anche il contatore beh perché siccome nel prendendo un messaggio molto grande spezzandolo in tanti blocchi può capitare che ci siano blocchi uguali se in diverse zone del messaggio ad esempio ci sono sequenze di 128 bit uguali tra di loro io voglio evitare che al PRF venga dato due volte lo stesso input allora per risolvere questo problema il blocco viene concatenato con il contatore del blocco quello è sempre diverso e quindi in questo modo siamo sicuri che ogni volta che applichiamo il PRF lo applichiamo su un input diverso questo è importante perché perché la chiave che viene usata è sempre la stessa vedete è sempre K ok questo è il modo in cui si usa il PRF all'interno di un ciclo che come anticipato ha il compito di applicare il PRF alla sequenza di blocchi del messaggio e di costruire un po' la volta il tag come viene costruito il tag lo vediamo subito il tag cioè il digest scusate il digest della funzione hash viene inizializzato a una sequenza di zeri ok quindi inizialmente il tag è una sequenza di zeri dopodiché all'interno del nostro ciclo che verrà reiterato tante volte quanti sono i blocchi del messaggio circa che va da 1 a v dove v è il numero di blocchi del messaggio quello che succede lo vediamo è che a ogni step il tag corrente il digest corrente t viene legato in xor con l'output del prf applicato al blocco corrente quindi la la la la cascata di operazioni è questa si parte da questo digest iniziale dopo di che si prende il primo blocco insieme alla chiave k insieme all'indice del blocco che è 1 viene dato in pasto al prf usando la chiave k ok il risultato va in xor col valore iniziale del digest ok e questo diventerà il digest di riferimento per lo step successivo allo step successivo cosa succede succede questo si prende il blocco 2 e quindi ha indice 2 questo viene dato in pasto al prf usando la chiave k e il risultato va in xor con il tag precedente e così via questa cosa va avanti finché non ho già volito i blocchi di messaggio ok ok anche in questo caso come per la funzione hash hp abbiamo un teorema che ci dice sotto quali condizioni la nostra funzione hash è robusta alle collisioni in particolare c'è un teorema che dice che se f è un prf sicuro ad esempio as 128 ok e l'insieme dei tag è superpoli ovvero questa condizione qua allora questa costruzione xor hash è un uf computazionale quindi siamo leggermente peggio rispetto alla funzione hash hp che era un hf statistico qui invece xor hash è un hf computazionale quindi vuol dire che è robusto rispetto a tutti gli avversari efficienti non rispetto a tutti gli avversari o solo quelli efficienti ok questa costruzione qui è molto simile a fcbc fstella che abbiamo visto la settimana scorsa tant'è che c'è un corollario che dice che se invece di questa costruzione qui voi usate fcbc o fstella e sotto le stesse condizioni del teorema usate un prf sicuro e un dominio superposto holiday digest allora ciò che ottenete è un UHF computazionale quindi in pratica questo chiude il cerchio con quello che ho detto all'inizio della lezione quando gli ho detto che oggi vi avrei presentato un framework che generalizza i mac che abbiamo visto l'altra volta e questo è il risultato infatti questo risultato ci dice che le due costruzioni che abbiamo visto l'altra volta fcbc e fstella sono a tutti gli effetti degli UHF computazionali quindi abbiamo visto un esempio di UHF statistico che è la costruzione HP quella geometrica di prima e abbiamo già visto tre esempi di UHF computazionali che sono XORESH visto oggi e fcbc e fstella che abbiamo visto l'altra volta ok siamo ancora lontani da definire un MAC perché finora tornando alla prima slide stiamo parlando di che cosa finora stiamo parlando di questa operazione ovvero usare una chiave segreta per calcolare un digest relativo a un messaggio M quindi stiamo parlando delle proprietà di questa funzione qua se vogliamo sia un quanto meno UHF computazionale meglio ancora se statistico perché così vuol dire che è robusto alle collisioni rispetto a tutti i possibili avversari ok poi chiaramente c'è il secondo step che consiste nella cifratura del tramite PRF ma chiave diversa del digest per ottenere il tag finale che è un po' quello che abbiamo visto l'altra volta perché infatti anche l'altra volta cosa abbiamo detto abbiamo detto che FCBC e Fstella di per sé non bastano vanno cifrati il risultato va cifrato per ottenere l'encrypted PRF da usare come MAC ok e qui stiamo confermando questo tipo di discorso stiamo semplicemente dicendo che qui dobbiamo usare una funzione hash che sia quantomeno un UHF statistico ok per ottenere quindi un digest su cui non ci sia possibilità da parte dell'avversario di trovare delle collisioni per poi passare alla seconda fase e in questa fase cosa siamo arrivati a dire che possiamo usare Xoresh possiamo usare FCBC possiamo usare Fstella possiamo usare HP tutte le costruzioni che abbiamo di fatto visto finora ok questa un po' è l'idea che mette assieme le cose che abbiamo appena raccontato no poi come dicevamo come ho appena detto non basta applicare il nostro UHF ma bisogna cifrare cioè l'ultimo step no la cifratura del digest per ottenere il tag quindi fase 1 dal messaggio spariamo fuori un digest usando un UHF fase 2 cifriamo il digest per ottenere il tag come lo cifriamo lo cifriamo con un PRF ok quindi il paradigma che abbiamo anticipato e rivisto nella prima slide è quello dell'hash del PRF ovvero prima fai l'hash usando un UHF e poi usi un PRF quindi di fatto stiamo componendo due funzioni perché usiamo prima l'UHF e poi il PRF quindi prima l'UHF per calcolare il digest e poi il PRF per cifrare il digest e sparare il tag ok e le due operazioni devono usare due chiavi diverse questo lo avremmo messo in evidenza anche la volta scorsa quindi alla fine la composizione no che ci serve noi è quell'operazione che prende due chiavi K1 e K2 diverse tra di loro prende il messaggio e applica questa composizione qua ovvero usando K1 e una funzione hash universale calcoliamo il digest del messaggio il digest ottenuto in questa maniera lo diamo in input a un PRF usando una nuova chiave K2 per ottenere il tag finale ok questa composizione è sicura ce lo dice questo teorema che in pratica ci dice che le condizioni da rispettare sono che H sia quantomeno un UHF computazionale quindi probabilità per un avversario efficiente di individuare una collisione trascurabile ok poi il PRF deve essere sicuro questo è questo teorema è un po' il corrispondente del teorema che abbiamo visto l'altra volta per i MAC anzi per gli encrypted MAC cambia semplicemente il fatto che la prima operazione che facciamo è l'applicazione di una funzione hash ok quale H usare quale F usare potete comporre a piacimento qui c'è un esempio in cui si suggerisce che l'UHF può essere HP e il PRF può essere S128 ok il corollario che vedete qui è interessante per un motivo che vedremo tra poco e che giustificherà l'introduzione di un approccio nuovo diverso ed è un corollario che dice fondamentalmente cerca di quantificare qual è il vantaggio dell'avversario nei confronti di questa costruzione quindi della composizione PRF UHF in pratica il corollario ci dice che di base la robustezza di questa composizione dipende dalla robustezza di H e dalla robustezza di H e questo è ovvio infatti il corollario inizia dicendo che il vantaggio dell'avversario rispetto a questa costruzione ok è minore uguale del vantaggio dell'avversario nei confronti del PRF ok ok più più il vantaggio dell'avversario nei confronti di H che però è moltiplicato per una costante che è questa che adesso andremo a commentare cioè riassumendo il corollario ci sta dicendo che la probabilità che l'avversario ha di vincere l'attack game nei confronti della composizione è quindi la probabilità che l'avversario ha di vincere contro questa composizione è pari alla somma di due probabilità quella di vincere contro F e quella di vincere contro H moltiplicata per questa quantità qui ora è quel fattore moltiplicativo che ci sta un po' tra i piedi perché cosa dice quel fattore moltiplicativo intanto chi è Q Q è il numero di query che l'avversario fa nell'attack game contro H cioè quante coppie di messaggi su quante coppie di messaggi l'avversario prova a trovare la collisione e l'idea qual è? L'idea è che più tentativi l'avversario fa più aumenta la probabilità che lui riesca a trovare una collisione questo è obbio ma questa probabilità aumenta in maniera significativa oppure no questo chiaramente dipende dipende dal vantaggio che l'avversario ha nell'attack game vi faccio un esempio vediamo se c'è quello qui vi faccio un esempio quindi come come ho appena detto il vantaggio che l'avversario ha nei confronti della composizione dipenderà dal vantaggio che ha l'avversario nei confronti sia del prff che dell'uhfh e in entrambi i casi si presuppone che sia trascurabile ok però però immaginiamo che sia il nostro epsilon se usiamo un epsilon l'uhf però il corollario di prima ci dice che questo epsilon deve essere moltiplicato per qual quadrato fratto 2 ok dove q rappresenta il la quantità di tentativi che l'avversario fa di cercare collisione ok ora ci basta che epsilon sia trascurabile no noi vogliamo che questo sia trascurabile ok per la sicurezza del del mac a noi interessa che q al quadrato fratto 2 per epsilon sia trascurabile non solo che epsilon sia trascurabile ok questo cosa significa nella pratica allora immaginiamo che questo sia q dopo un po' di tempo che è una quantità ragionevole dopo un po' di tempo l'avversario è riuscito a fare 2 alla 32 tentativi di trovare delle collisioni ok ora se voi volete che il vantaggio dell'avversario nei confronti della robustezza del mac non superi questa quantità quindi sia trascurabile perché 1 su 2 alla 64 è trascurabile ok allora è necessario che epsilon siccome questa quantità è lui ma voi sapete che q vale questo allora bisogna che epsilon al massimo valga questo 1 su 2 alla 127 ok cioè dovete mantenere epsilon molto molto molto piccolo se volete che il vantaggio dell'avversario rimanga trascurabile al crescere di q cioè al crescere del numero di tentativi che l'avversario fa di trovare una collisione in altre parole se volete garantire che questa quantità sia davvero trascurabile al crescere di q bisogna che epsilon sia molto molto più piccolo e questo che ho mostrato ad esempio di quanto deve essere piccolo epsilon per questo valore di q se voi volete garantire questo livello di robustezza del mac ok ma chi è epsilon epsilon è quel valore che definisce il nostro epsilon u hf no quindi cosa ci sta dicendo tutto questo ci sta dicendo che l'u hf che voi usate nella composizione deve essere un epsilon u hf con un epsilon veramente piccolo ad esempio così piccolo se volete garantire una robustezza del mac che sia quantomeno 2 alla meno 64 che è una quantità negligibile ok e il problema qual è il problema è che trovare degli epsilon u hf con un epsilon così piccolo non è banale o quantomeno costa costa in termini di risorse prendete l'esempio di hp ok la prima funzione hash che abbiamo visto allora come facciamo a garantire che hp sia un epsilon u hf dove epsilon al più è 2 alla meno 127 bisogna che scegliamo un valore di p molto grande quantomeno un numero di 127 bit perché in quel caso appunto la cardinalità del insieme delle chiare 2 alla 127 e poi stiamo ragionando solo sul denominatore senza contare il numeratore quindi in realtà probabilmente non basta 2 alla 127 per il denominatore quindi probabilmente sarà 2 alla qualcosa di più di 127 dipende da quante grande l ok ma aumentare i p a dismisura in hp per garantire queste quantità in ballo significa puoi avere una funzione hash più lenta perché bisogna fare i più calcoli più complessi lo stesso discorso vale per f scusate per xor hash aumenta il numero di interazioni del ciclo for aumenta la difficoltà dei vari xor che l'hanno fatti perché poi involgono stringhe più lunghe ok quindi avere un uhf con un epsilon molto molto molto piccolo ha un costo in termini di efficienza questo è il motivo per cui esistono delle varianti rispetto alle costruzioni che abbiamo appena visto il cui esponente principale è il MAC di Carter Wegman che adesso andremo a commentare è l'unico che vi propongo perché è l'unico che rappresenta uno standard de facto e MAC come quelli di Carter Wegman hanno una peculiarità la prima è che sono probabilistici no e cosa vuol dire questo un po' come per la cifratura un po' come per i cifrari probabilistici quindi dato un messaggio e dato una chiave non avete un unico possibile tag per quel messaggio e quella chiave ma avete una distribuzione di probabilità su un insieme di tag quindi esattamente come per i cifrari probabilistici questa è la prima caratteristica la seconda caratteristica è che MAC come quelli di Carter Wegman riescono a garantire la robustezza del MAC che desiderate ad esempio 2 alla meno 64 senza dover lavorare con degli epsilon molto più piccoli cioè con lo stesso epsilon ottenete la stessa robustezza del MAC cioè Carter Wegman come vedremo è ci mette a disposizione un UHF un epsilon UHF dove l'epsilon è esattamente pari alla diciamo alla robustezza del MAC composto che andate costruirci sopra quindi in pratica è come dire che questo fattore qui non c'è più non pesa più quindi quindi un MAC come quello di carter e Wegman fa sparire questo per cui la robustezza del MAC dipenderà solo ed esclusivamente dalla robustezza del PRF e dalla robustezza del UHF solamente da questi due fattori e non dipenderà più da questo che col passare del tempo cresce ok ma come abbiamo appena visto ad esempio se questo col passare del tempo cresce e vogliamo mantenere costante la robustezza del MAC bisogna che questa quantità sia molto molto piccola invece no con carter Wegman vedete che la robustezza del MAC può coincidere con i valori di Epsilon perché questo fattore qui non ha più un peso e quindi recuperiamo in efficienza l'unico svantaggio è che MAC come quelli di carter e Wegman producono dei tag più lunghi rispetto a quelli associati alle costruzioni che abbiamo visto finora ora andiamo a vedere come funziona il MAC di carter Wegman che come tipo di costruzione è analogo a quella che abbiamo visto finora cioè si usa una funzione hash e poi in cascata si usa un PRF quindi l'approccio è sempre lo stesso con due chiavi diverse cioè la chiave che usa la funzione hash è diversa dalla chiave che usa il PRF infatti lo vediamo subito nella definizione dell'algoritmo di segnatura che utilizza due diverse chiavi una per l'UHF e una per il PRF ok e l'algoritmo di segnatura funziona in questo modo andiamo a vedere viene come per la cifratura probabilistica viene scelto un valore random un non r ok da un dominio dei dei non dopodiché l'UHF e il PRF vengono combinati in questa maniera da una parte vedete l'UHF si applica al messaggio con la prima chiave dall'altra vedete che si applica il PRF al valore random usando la seconda chiave i due output vengono semplicemente sommati in aritmetica modulare ok perché questa è sempre l'idea della composizione della cifratura di digest perché l'idea è sempre quella crea un digest e lo cifro i due step uso un UHF per creare un digest quel digest lo cifro usando un PRF ma qui l'idea è la stessa perché perché questa la potete vedere come la creazione del digest ok il resto la somma con l'output del PRF è la cifratura vi ricordate la primissima lezione che abbiamo fatto sui cifrari di Shannon e in particolare vi ricordate OTP additivo la versione additiva di OTP ovvero per fare la cifratura di un numero di plaintext interpretati come numeri si prende il numero si prendeva il numero e lo si sommava alla chiave in aritmetica modulare quello era l'OTP additivo ok uno dei primissimi cifrari di Shannon che abbiamo visto che era sicuro tanto era perfettamente sicuro quello ok ma qui vedete la stessa cosa perché perché quello che si fa è prendere il digest ok e cifrarlo in che maniera sommando il digest a qui è un po' più complicato non è semplicemente la chiave ma è questo serve per rendere probabilistico il MAC non è semplicemente la chiave ma è il PRF della chiave applicato a un valore random quindi in pratica la cifratura del digest viene fatta sommando il digest ad un valore randomico quindi qui stiamo mescolando hashing con il one time pad additivo perché perché il meccanismo di costruzione è sempre lo stesso hash then encrypt tramite il PRF tant'è che vi faccio vedere una definizione alternativa di Carter-Wegman ma assolutamente equivalente a questa dove si rende esplicito il fatto che si fa una cifratura e dove si rende esplicito il fatto che la cifratura è OTP additivo infatti questa è la definizione assolutamente equivalente di questa che abbiamo appena visto qua semplicemente esplicitando il ruolo della cifratura infatti vedete che nella definizione dell'algoritmo di disegnatura che cosa si fa? si fa prima l'applicazione dell'UHF quindi prima cosa si calcola il digest ok quindi questo è il digest del messaggio calcolato con la chiave K1 questo digest vedete viene cifrato usando K2 usando un un algoritmo di cifratura ma che cosa fa l'algoritmo di cifratura esattamente quello che abbiamo appena detto prima ovvero fa la somma tra il messaggio che viene dato in ingresso e un valore randomico dove il valore randomico piuttosto non è semplicemente l'R che è stato campionato ma è il PRF di R rispetto alla seconda chiave quindi non c'è di fatto nessuna novità in Carter Wegman rispetto significativa quantomeno rispetto a quanto abbiamo visto in questa idea qua che è un po' la stessa che abbiamo visto settimana scorsa perché anche in Carter Wegman l'idea è che in una prima fase si calcola il digest del messaggio e questa fase è deterministica in una seconda fase probabilistica il digest viene cifrato e la novità sta qui perché sta nel modo in cui il digest viene cifrato viene cifrato usando un cifrario probabilistico e la cifratura l'abbiamo appena vista la cifratura è questa quindi questo è il digest no? perché è questo ok questa è la seconda chiave K2 e la cifratura non è altro che la somma di digest e un valore randomico dove il valore randomico è il PR rispetto a K del non ok ok questo è il MAC proposto il primo MAC probabilistico così come proposto da Carter e Wehrman ora purtroppo questo MAC qui di Carter e Wehrman non è sicuro rispetto alle ipotesi che rendono sicuri gli altri MAC che abbiamo visto prima per gli altri MAC che abbiamo visto prima tornando ad esempio a questo era sufficiente che la funzione hash fosse un UHF computazionale e che il PR fosse sicuro addirittura nel caso di HP dove eccolo qui era sufficiente che il l'UHF fosse addirittura statistico nel caso di Carter e Wehrman anche se la cifratura che abbiamo appena visto è CPA sicura e anche se il l'UHF che usiamo è computazionale o addirittura statistico ebbene queste condizioni non sono sufficienti per rendere Carter e Wehrman un MAC sicuro ok la colpa non è del cifrario ma è dell'UHF quindi non basta ripeto per garantire che questa costruzione che abbiamo visto in questo slide sia un MAC sicuro non basta che H sia un UHF statistico o computazionale mentre invece basterebbe il fatto che la cifratura è CPA sicura perché questa è CPA sicura questa cifratura qua che di fatto è OTP additivo probabilistico è un cifrario CPA sicuro quindi su questo fronte nessun problema il problema c'è sul fronte della funzione H che viene usata vi farò vedere un esempio che ci dimostra per quale motivo anche se usassimo un UHF statistico il MAC non sarebbe sicuro sarebbe vulnerabile alle collisioni per rendere Carter Wegman sicuro dobbiamo aggiungere un'ulteriore proprietà agli UHF questa proprietà che dobbiamo aggiungere si chiama difference unpredictability cioè l'impredicibilità delle differenze che è una proprietà in più che la funzione di H deve avere intuitivamente che cosa rappresenta l'impredicibilità delle differenze allora l'idea è che non solo l'avversario non deve essere in grado di trovare una collisione ok ma non deve essere nemmeno in grado di trovare due messaggi che non collidono ma di cui è nota la differenza tra i digest quindi è una condizione ancora più forte quindi l'avversario non deve essere in grado di trovare due messaggi che collidono ma di cui però conosce la differenza tra i digest lo vediamo nella tag game la tag game è lo stesso di prima descriviamo questa tag game poi facciamo vedere perché questo qui è la tag game più forte rispetto a quello che avevamo visto prima andiamo a vedere cosa dice dice che vabbè il challenger sceglie la chiave randomicamente e vabbè nessuna novità l'avversario spara fuori due messaggi ok spara fuori due messaggi e un delta l'avversario vince il gioco se la differenza tra i due digest è uguale a delta cioè l'avversario vince se indovina la differenza tra i digest dei due messaggi ok ora la tag game che abbiamo visto all'inizio della lezione è il caso particolare in cui delta vale a zero no perché se voi ponete delta uguale a zero e l'avversario vince vuol dire che ha trovato una collisione perché vuol dire che i due digest coincidono quindi questa tag game è ancora più forte di quello che abbiamo visto all'inizio perché permette all'avversario di vincere in molti più casi magari l'avversario non è capace di trovare una collisione però magari l'avversario è capace di trovare due messaggi tali per cui lui è in grado di sapere qual è la differenza fra i loro digest senza conoscere due digest ma conoscere la loro differenza e conoscere la differenza tra i digest di due messaggi senza conoscere i digest vedremo che ci permette di montare un attacco contro la robustezza di Carter e Redman del Mac che abbiamo appena descritto e poi ve lo faccio vedere come un esempio ok anzi vi faccio vedere subito l'esempio e poi così capiamo per quale motivo dobbiamo usare funzioni hash robuste non solo rispetto alle collisioni ma robuste anche rispetto a questo tagging qua ok l'esempio l'esempio questo qui prendete HP no la prima funzione hash che abbiamo visto no e prendete questo messaggio fatto di un solo blocco dove A è un valore in ZP ok e prendete questo messaggio anche questo fatto di un solo blocco ed è il valore di M0 più 1 ok ora andate a riprendere la definizione di HP come funziona il famoso polinomio ok la differenza fra i due digest è questo meno questo che fa uno ok quindi questi due messaggi qui anche se l'avversario non conosce la chiave K gli fa vincere la tag game perché l'avversario pur non conoscendo la chiave sa che la differenza tra il digest di M0 e il digest di M1 è uguale a 1 questo è un esempio di situazioni in cui l'avversario senza conoscere la chiave può conoscere la differenza tra i digest di due messaggi voi direte va bene ma che cosa se ne fa della differenza del digest di due messaggi se non conosce la chiave in Carter Wegman andiamo avanti con l'esempio questa cosa gli permette di montare un attacco andiamo a vedere l'attacco l'abbiamo appena visto allora se vai a riprendere allora prendi prendi M0 che è un valore A ok allora andiamo a vedere HP no se tu hai un solo blocco quindi V è uguale a 1 quindi il digest è K alla 1 quindi è K K più l'unico blocco che è A moltiplicato per K alla 0 che fa 1 e quindi questo è il tuo digest se invece come blocco tu prendi A più 1 il calcolo da fare è lo stesso però il risultato è K più A più 1 ok quindi il digest di A è K più A il digest di A più 1 è K più A più 1 K non lo conosciamo l'avversario non lo conosce te fai la differenza fra questi due e la differenza fa 1 quindi anche se l'avversario non conosce la chiave non sa chi è questa sa benissimo che la differenza tra il digest di A e il digest di A più 1 è 1 ora cosa se ne fa di questa conoscenza adesso andiamo a vedere in Carter Wegman come questa conoscenza può essere sfruttata per violare la robustezza di Carter Wegman chiaro? ok ora tornando all'esempio ecco qua ora abbiamo detto che se usiamo un UHF vulnerabile a questo tipo di attack game come ad esempio HP quello che succede è che per l'avversario è possibile trovare due messaggi per cui anche se l'avversario non conosce la chiave Z1 lui sa qual è la differenza tra i due gli digest che è questo delta ok? ora andiamo a vedere come funziona Carter Wegman e calcoliamo il tag di M0 usando Carter Wegman la formula è questa cioè Carter Wegman che cosa fa? prima calcola il digest di M0 usando K1 poi fa la cifratura sommandogli che cosa? il valore randomico che è il PRF del valore random R usando K1 ok? e questo è il tag ci siamo no? che viene pubblicato anzi quello che viene pubblicato è la coppia RV perché dall'altra parte chi fa la verifica deve sapere quanto vale quanto vale no? quindi in rete viaggiano il messaggio immaginate Alice che manda un messaggio M0 a Bob in rete viaggiano il messaggio M0 e la coppia RV che consentirà a Bob conoscendo K1 e K2 di verificare che il tag sia no? coerente rispetto al messaggio che ha ricevuto ok? quindi l'avversario vede passare questi oggetti non conosce le chiavi ma vede passare questi oggetti ok? quindi in particolare vede r e vede v no? ora l'avversario può fare questa cosa prendere v e sommargli delta ok? chi è delta? delta è la differenza che l'avversario conosce tra il digest di M0 che è il messaggio che Alice ha mandato a Bob e un altro messaggio M1 che l'avversario è capace di calcolare perché abbiamo detto che stiamo usando una funzione hash vulnerabile al calcolo delle differenze quindi dobbiamo presupporre che l'avversario che vede passare M0 mandato da Alice a Bob sia in grado di calcolare un messaggio diverso M1 tale per cui la differenza tra i due hash tra i due digest è delta ci siamo fin qui? ok? quindi l'avversario conosce delta per un messaggio alternativo M1 a questo punto l'avversario deve semplicemente fare v più delta ok? ma v più delta che cos'è? v più delta è h di k1 M0 più f di k2 R delta no? ok? ok? ok? ma questo più questo è uguale a che cosa? è uguale a h di k1 m1 no? più f di k2 R giusto? no? ok? ma questa roba qui che cos'è? è un tag è un tag valido di m1 ok? è il tag di m1 quindi in altre parole l'avversario vedendo semplicemente passare m0 r e v e sapendo questo cioè sapendo conoscendo la differenza tra il digest di m0 e il digest di m1 senza conoscere i due digest ma conoscendo solo la loro differenza è in grado di costruire il tag corretto di m1 che è un messaggio scelto da lui quindi è in grado di violare la sicurezza del mac perché perché è riuscito a creare una una falsificazione esistenziale cioè è riuscito a creare il tag di un messaggio che non aveva mai visto prima passare taggato quindi a questo punto l'avversario può prendere m1 e insieme al tag spedirlo a bob e bob è convinto che quel messaggio arrivi da Alice chiaro chiaro quindi vi torno all'esempio del del di come la predicibilità delle differenze di cui ad esempio software HP può essere usata per violare l'integrità del del mac di Carter e Wegman quindi qual è la morale della favola la morale della favola è che non possiamo usare dentro Carter Wegman un UHF statistico qualunque come HP no ma dobbiamo usare un UHF che sia robusto rispetto a questo tagging cioè un UHF che sia robusto rispetto alla predicibilità delle differenze quindi un tagging più stringente rispetto a quello che avevamo visto prima ok ora usando questo tagging possiamo fare la stessa classificazione che avevamo visto prima con l'altro tagging prima avevamo definito il UHF UHF statistici UHF computazionali prima di questi di epsilon UHF ok la stessa classificazione la possiamo dare basandoci su questo tagging dove siamo robusti rispetto al calcolo delle differenze e ottenere quelli che vengono chiamati chiamate funzioni difference unpredictable quindi funzioni hash che sono robuste rispetto a questo tagging qui per cui l'attaccante non è in grado di predire le differenze ok e quindi abbiamo quelli che chiameremo DOOF quindi difference unpredictable functions cioè funzioni hash che sono robuste rispetto all'attac game che abbiamo appena descritto quindi abbiamo gli epsilon DOOF abbiamo i DOOF statistici abbiamo i DOOF computazionali ok c'è un modo per rendere UHF anche DOOF ok per trasformare un UHF in un DOOF ad esempio nel caso di HP abbiamo visto che non è un DOOF non è un DOOF perché abbiamo il controesempio che ci fa vedere che l'avversario è in grado di calcolare la differenza tra il digest di due messaggi scelti da lui come si fa a trasformare HP in un DOOF la trasformazione è molto semplice basta prendere la funzione HP ok e moltiplicare il risultato per la chiave quindi voi prendete il polinomio di HP e il risultato finale lo moltiplicate per la chiave questo trasforma HP in un DOOF il controesempio non funziona più con questa trasformazione perché non funziona più perché il digest di M0 diventa K per A ok scusate no ho detto una cavolata è questo allora il digest di M0 che era K più A diventa K per K più A no perché abbiamo detto che dobbiamo moltiplicare il digest per K ok mentre invece il digest di M1 che era K più A più 1 diventa K per K più A più 1 no tutto viene moltiplicato per K ok ora qual è la differenza tra questi due digest andiamo a fare un po' di calcoli abbiamo nella parte K al quadrato più K più K meno K al quadrato meno K giusto questo e questo vanno via questo e questo vanno via cosa mi rimane K quindi la differenza non è più 1 cioè è un valore che l'avversario conosce ma la differenza diventa K e l'avversario non la conosce quindi l'avversario non è in grado di perdire la differenza tra i due messaggi quindi con questa piccola modifica HP diventa un duffo cioè diventa robusto alla predicibilità delle differenze quindi dentro Carter Wegman invece di usare HP si usa si può usare questa variante ok se usate dei duff ecco che salta fuori il teorema e poi chiudiamo finale che stabilisce la sicurezza di Carter e Wegman in pratica ci dice che la cifratura deve essere sicura quindi il PRF visto che la cifratura il Carter Wegman viene fatta con un PRF torniamo alla definizione di Carter Wegman se non ce la siamo dimenticati ok Carter Wegman fa questo abbiamo detto fa applica la funzione hash per calcolare il digest ok e poi fa la cifratura no vedete fa la cifratura la cifratura è basata sul notipi additivo basato sul PRF ok ora il teorema che cosa dice ci dice che questo deve essere un do non semplicemente un UHF perché deve essere robusto alla tag game che abbiamo appena descritto e il PRF deve essere sicuro andiamo a rivedere il teorema finale quindi PRF sicuro H deve essere un do computazionale la terza condizione ma vale sempre per i meccanismi probabilistici ovvero quella che dice che il dominio dei non deve essere superfogli ok cioè la probabilità che lo stesso R venga usato due volte deve essere trascurato sotto queste tre condizioni il MAC di Carter e Wegman è sicuro non solo è sicuro ma è più efficiente della rispetto ai MAC che avevamo descritto prima perché scompare torniamo un attimo alla descrizione del corollario dei MAC che avevamo descritto prima allora prima avevamo detto che per la composizione PRF o HF classica no la robustezza dipendeva da quella di H quella di F però quella di H veniva moltiplicata per quel fattore quadrato quadrato 2 che era quello che ci faceva un po' sparigliare le carte perché Q può crescere tanto e quindi vuol dire che Epsilon dobbiamo ottenerlo molto molto piccolo nel teorema legato a Carter e Wegman quel fattore sparisce il fattore Q al quadrato fratto 2 sparisce e viene sostituito da questo fattore voi direte ma è cambiato poco prima c'era il fattore Q al quadrato fratto 2 ok adesso invece c'è questo Q al quadrato fratto 2 però vedete cosa c'è al 2 illuminatore insieme al 2 la cardinalità dell'insieme dei non che se il Mac di Carter e il Wegman soddisfa il teorema vuol dire che questa quantità qui diventa visto che è la cardinalità di Are Super Poli diventa trascurabile diventa negligible quindi sparisce ed ecco che abbiamo dimostrato abbiamo fatto vedere che usando un Mac probabilistico come Carter e Wegman complicando leggermente la funzione hash che non basta più che sia un HF deve essere un DOOF e abbiamo fatto vedere per quale motivo otteniamo un un Mac che è sicuro sotto più o meno le stesse condizioni del caso precedente però in maniera più efficiente perché Corollario ci dice che quel fattore qualquadrato sparisce ok Carter Wegman è l'unico Mac probabilistico che vedremo quindi come in tutti i cifrari probabilistici è un Mac dove il valore randomico diventa parte dell'input del del Mac stesso quindi quel famoso Nose diventa vedete un elemento importante per la segnatura no quindi l'algoritmo di segnatura si basa sulla chiave sul messaggio e sul valore randomico chiaramente chi fa la verifica deve usare lo stesso valore randomico e questo è il motivo per cui viene trasmesso in chiaro insieme al tag ok chiudo dicendo che Carter e Wegman è anche questo uno standard de facto che viene usato molto in letteratura ma vi dirò poi altro oggi pomeriggio non ci vediamo l'ho annullato l'elezione di segnatura e ci vediamo direttamente domani ok va bene se non c'è altro se non ci sono domande dalle moto sì per oggi ci fermiamo qua domani Grazie a tutti.