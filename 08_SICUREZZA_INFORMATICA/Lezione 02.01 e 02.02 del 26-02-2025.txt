ok allora riprendiamo un attimo il punto dalla volta scorsa relativo al concetto di sicurezza semantica come avevamo messo in evidenza la sicurezza semantica si basa su quello che abbiamo chiamato atta game perché ispirato alla teoria alla teoria dei giochi e nella definizione della tag game abbiamo visto che la nozione di sicurezza fa riferimento a avversari e algoritmi che sono efficienti abbiamo iniziato a capire da un punto di vista matematico cosa vuol dire essere efficiente oggi porteremo avanti questo discorso e fa riferimento anche a probabilità più espressa come vantaggio dell'avversario nel gioco che devono essere trascurabili che è negligible efficient sono i due termini particolari su cui ci siamo basati e che naturalmente richiedono di essere di essere formalizzati la volta scorsa abbiamo visto da un punto di vista matematico intanto cosa vuol dire per una funzione essere trascurabile attraverso questa definizione una rappresentazione anche geometrica abbiamo visto che fondamentalmente l'intuizione è che una funzione trascurabile se converge a zero molto molto rapidamente abbiamo detto che l'inversa di una funzione trascurabile è detta super super super poli ok quindi una funzione che cresce molto molto rapidamente e infine abbiamo detto che è una funzione invece limitata polinomialmente se passatevi l'intuizione dal punto di vista grafico la curva di questa funzione rimane sempre sotto la curva di un certo polinomio non ha importanza di quale di quale grado ora perché richiamare queste definizioni perché il concetto di algoritmo efficiente che compare nella definizione di sicurezza semantica si appoggia proprio a queste idee cosa vuol dire affermare che l'algoritmo che l'avversario segue per cercare di vincere la tag game è efficiente ok e quindi è vincolato a determinate risorse che l'avversario può può usare perché il concetto di sicurezza semantica non è un concetto assoluto come abbiamo visto non possiamo non potremmo dire che certo cifrario è in assoluto semantica secure ok dipende appunto da quali sono le risorse cui facciamo riferimento nell'andare a definire l'avversario in termini di un algoritmo efficiente quindi i due concetti sono molto legati tra di loro da questo da questo punto di vista quindi ripeto non potremo mai dire che un certo cifrario è sicuro punto e basta è sicuro rispetto a determinate risorse che l'avversario mette in campo per cercare di vincere la tag game tant'è che in letteratura la definizione dei teoremi che stabiliscono la sicurezza semantica dei vari cifrari è sempre parametrizzata rispetto a dei valori che vanno a stabilire a determinare qual è appunto l'efficienza degli avversari che vengono presi in considerazione l'attributo più importante che viene usato questo scopo prende il nome di parametro di sicurezza di solito rappresentato dalla lettera lambda e questo parametro misura in qualche modo il livello di efficienza cui facciamo riferimento nella definizione della sicurezza semantica è un parametro che va a stabilire alcuni valori che in particolare determinano che cosa significa fare riferimento ad avversari quindi algoritmi efficienti cioè in che senso efficienti ora questo parametro di sicurezza questo valore lambda è di solito un intero positivo che è direttamente proporzionale alla robustezza del cifrario rispetto ad avversari efficienti e quindi tanto più grande lambda tanto più tranquilli noi siamo rispetto alla sicurezza del cifrario e questo parametro influenza anche alcuni degli attributi che caratterizzano il cifrario ad esempio la lunghezza della chiave ok quando andiamo a scegliere la lunghezza della chiave sappiamo che questo valore influenza la robustezza del cifrario perché lo stesso cifrario può essere molto sicuro se usiamo chiavi molto lunghe ma può diventare banalmente vulnerabile se usiamo una chiave troppo corta ok perché motivo è ovvio se usiamo una chiave troppo corta allora per un avversario sufficientemente efficiente adesso vedremo cosa significa può diventare fattibile implementare un attacco in cui si vanno a provare tutte le chiavi possibili e se queste sono un numero relativamente basso l'operazione si può fare in tempo polinomiale e quindi per quanto robusto possa essere il cifrario se l'avversario però ha possibilità di provare un'altra chiave troppo corta ok tutte le chiave possibili questo viene chiamato in gerda attacco a forza brutta brutto forza attacchi è chiaro che se questo attacco diventa fattibile per le risorse che ha l'avversario il cifrario è vulnerabile non sarà mai sicuro quindi per questo motivo è importante stabilire sempre rispetto a quale parametro di sicurezza noi stabiliamo che un certo cifrario è semanticamente sicuro e questo parametro appunto è il parametro di sicurezza lambda ora come dicevo prima di solito quanto più alto questo parametro maggiore è la robustezza del cifrario quindi ad esempio se l'ambda è molto grande questo significa che vengono usate chiavi molto lunghe poi vedremo di quantificare questo anche man mano che studieremo nel dettaglio i cifrari pratici qual è il prezzo da pagare è che se voi volete aumentare la robustezza del vostro cifrario dovete pagare un prezzo in termini di efficienza perché è chiaro che se noi vogliamo complicare le cose per l'avversario quindi obbligarlo a usare algoritmi sempre più efficienti quindi sempre più dispendiosi come risorse ok per cercare di violare il cifrario al tempo stesso il cifrario dovrà usare gli algoritmi di cifratura e di cifratura altrettanto efficienti e quindi costosi in termini di tempi di esecuzione quindi questo cosa significa? Significa che di solito alzando il livello del parametro lambda è vero che aumentiamo la robustezza ma diminuiamo le performance del cifrario quindi aumentiamo i tempi di esecuzione degli algoritmi di cifratura e di cifratura perché così come l'avversario usa algoritmi efficienti rispetto al parametro lambda anche il cifrario usa algoritmi efficienti per cifrare e di cifrare quindi vale lo stesso discorso quindi c'è un trade off tra livello di robustezza del cifrario e performance intesa come tempi di esecuzione per il cifrario necessari per cifrare e di cifrare le informazioni in certi contesti questi tempi di esecuzione sono importanti ok? anzi in certi contesti non ci possiamo permettere di usare cifrari troppo pesanti da un punto di vista computazionale perché ad esempio non ci sono le risorse di esposizione pensate al contesto dei dispositivi IoT in quel caso le risorse sono sempre piuttosto limitate e quindi lì diciamo che la soglia si abbassa dal punto di vista del parametro di sicurezza lambda quindi nell'andare a stabilire la sicurezza semantica di un cifrario bisogna sempre partire dal parametro di sicurezza lambda qual è il parametro che ci interessa quindi a seconda di come lo scegliamo potremmo andare a stabilire qual è il livello di sicurezza del cifrario perché lavorando su lambda cambia la classe di avversari efficienti e di conseguenza cambia la nozione di sicurezza perché la nozione di sicurezza dice che il cifrario è sicuro se il vantaggio dell'avversario è trascurabile per tutti gli avversari efficienti ma chi sono gli avversari efficienti? dipendono dal parametro lambda più alto è lambda e maggiore sono le risorse computazionali che gli avversari devono mettere in campo per poter attaccare il cifrario da un punto di vista matematico come abbiamo visto l'altra volta è possibile stabilire ve lo accenno oggi poi non ne parleremo più perché l'importante per me è che sia chiaro il concetto, l'idea si può stabilire matematicamente che cosa significa essere un algoritmo efficiente ok? quindi possiamo stabilire quali sono i limiti degli avversari rispetto ai quali noi ci confrontiamo nell'andare a stabilire la sicurezza dei nostri cifrari questa è l'idea e la definizione matematica di algoritmo efficiente e quindi si applica agli avversari ma anche ai cifrari quindi anche gli algoritmi di cifratura e di cifratura è questa che vedete qua la definizione dice che fissato il famoso parametro di sicurezza lambda che vogliamo noi e ripeto lo scegliamo in base al trade off che ci interessa tra robustezza e performance se vogliamo privilegiare la robustezza sceglieremo un lambda grande se ci interessano le performance abbasseremo il valore di lambda ok? l'esempietto per capire l'effetto del parametro lambda è sempre quello delle chiavi lambda grande significa chiavi lunghe yeah if you have a lot of computational resources we can raise up lambda exactly and higher lambda means more computational resources for the cipher but also for the adversity ok la definizione dice che fissato il parametro lambda un algoritmo efficiente è un qualunque qui dice sistema reattivo c'è un qualunque algoritmo che interagisce con l'environment con l'ambiente che deve essere limitato in che modo? vediamo cosa dice la definizione deve esistere in realtà deve esistere due funzioni una funzione t limitata polinomialmente quindi una funzione che non cresce troppo in fretta deve essere sempre bounded da un certo polinomio e un'altra funzione trascurabile quindi una funzione che converge molto rapidamente a zero quindi t è una funzione limitata polinomialmente e epsilon è una funzione trascurabile e cosa mi stabiliscono queste due funzioni? queste funzioni vedremo adesso che servono per stabilire i limiti dell'algoritmo efficiente cosa può fare e cosa non può fare l'algoritmo efficiente infatti vedete che dice che rispetto a queste due funzioni per tutti gli ambienti quindi ovunque noi andiamo a eseguire l'algoritmo qualunque sia l'input che noi diamo in pasto al nostro algoritmo quindi per tutti gli ambienti la probabilità che il tempo di esecuzione dell'algoritmo efficiente ecceda la funzione polinomialmente limitata che è una funzione che in input prende il parametro lambda quindi vuol dire la probabilità che l'algoritmo efficiente superi il tetto imposto dal polinomio quindi che esegua per più tempo quindi che abbia più risorse fondamentalmente a disposizione quindi la probabilità che si vada oltre è trascurabile perché questa probabilità deve essere limitata dalla funzione epsilon che è una funzione trascurabile quindi in pratica queste due funzioni ci stanno dicendo che l'algoritmo efficiente ha dei tempi di esecuzione che dipendono da un polinomio da una funzione polinomiale quindi non sono dei tempi di esecuzione illimitati che si impendono e crescono come un esponenziale quindi vuol dire che sono tempi di esecuzione vincolati da risorse limitate ok? perché la probabilità che ci sia un'impennata che l'algoritmo efficiente abbia delle performance che superano i limiti del polinomio è una probabilità trascurabile non possiamo mai assumere che sia zero perché in teoria della probabilità ogni evento deve essere preso in considerazione ma è trascurabile ok? ora chi è che stabilisce qual è il polinomio di riferimento? è lambda ok? quindi graficamente parlando non si, bisogna qui se ci rimane la registrazione graficamente parlando avete la vostra perché non va? vediamo questo non funziona allora vediamo un po' se riesco a farlo andare niente niente così è lo stesso allora da un punto di vista grafico no? siete voi a scegliere in base a lambda il polinomio che rappresenta il tetto ok? l'upper bound quindi che ne so magari questo no? e la definizione che vedete qui cosa ci dice? ci dice che il tempo di esecuzione dell'algoritmo efficiente sta sotto il polinomio e lo può superare solo con una probabilità trascurabile è chiaro che se voi aumentate lambda magari potete usare un polinomio più alto quindi vuol dire che l'algoritmo può essere più efficiente ok? e quindi cosa vuol dire? vuol dire che se voi crescete a fare aumentare lambda e riuscite a dimostrare che il vostro cifrario è sicuro rispetto a quel particolare valore di lambda vuol dire che un avversario che ha a disposizione tutte le risorse computazionali che si può permettere nei limiti di quel parametro le può usare ma non gli serviranno per rompere il cifrario perché se il cifrario è semanticamente sicuro allora abbiamo la garanzia che un avversario con quella quantità di risorse non è in grado di vincere l'attack game ok? quindi è chiaro che maggiore il livello di sicurezza che volete più alto lambda dovete dovete scegliere ok? sì sì sì sì quindi è chiaro che se voi dimostrate che rispetto a un certo lambda il vostro cifrario è sicuro voi avete la garanzia che un avversario con risorse limitate da quel lambda non ce la fa a vincere l'attack game se esiste un avversario che ha più risorse non avete nessuna garanzia ok? quindi bisogna sempre fare i conti col fatto che là fuori ci possono essere degli avversari con delle risorse importanti è in base a quello che voi stabilite quanto volete che sia sicuro il vostro il vostro cifrario quindi per esempio scegliere chiavi di una certa di una certa lunghezza ok? è chiaro? ora ci sono valori di lambda che ci permettano in maniera ragionevole di ipotizzare che nessun avversario reale sia in grado di vincere l'attack game per cifrare i semanticamente sicuri adesso vi faccio vedere un esempio con un paio di cifre che ci dicono che questa ragionevole sicurezza la possiamo avere sono andato ad aggiungere a fare un po' di conti l'altro giorno questa slide l'ho aggiunta da pochi giorni se ne avevate già scaricate più tardi della settimana scorsa non c'è perché sono andato a vedere un po' di valori aggiornati per capire qual è lo sforzo computazionale che un avversario dovrebbe fare per rompere i cifrari semanticamente sicuri che usano chiavi di una certa lunghezza il riferimento come dicevamo prima è l'attacco del brute force attack che è l'attacco più semplice che un avversario può implementare nell'attack game ok ovvero provare tutte le chiavi possibili no allora va bene ma quante chiavi può provare in un tempo ragionevole un avversario in base alle risorse computazionali che potrebbe avere a disposizione allora qui ho preso un esempio dalla letteratura che ci aiuta un po' a capire l'ordine delle cose sono andato a vedere qual è l'hash rate globale attuale per la blockchain di bitcoin cosa significa questo conoscete bitcoin non i dettagli a livello generale ok tanto è un argomento che più avanti probabilmente avremo il tempo di fare ora se non lo sapete ora per validarmi transazioni che rappresentano scambi di bitcoin e coniare nuovi bitcoin bisogna effettuare delle operazioni criptografiche piuttosto costose questo è con l'obiettivo appunto di un gergo minare quindi coniare nuovi nuovi bitcoin adesso non vi voglio dare i dettagli ma perché comunque vi farò vedere specificatamente una volta che avremo tutti gli ingredienti quali sono le operazioni che si fanno ok per adesso la cosa che vale la pena ricordare è che fondamentalmente per cercare di coniare bitcoin ok io ho bisogno di risorse di calcolo perché ho bisogno di risorse di calcolo perché devo risolvere un puzzle criptografico che richiede di utilizzare una specifica primitiva criptografica che sono le funzioni hash che studieremo adesso non ci interessa sapere che cosa fanno li studieremo ciò che conta è che se voglio coniare bitcoin io devo far lavorare massivamente il calcolatore per eseguire un maggior numero possibile di operazioni hash perché questo aumenta la probabilità che io sia in grado appunto di coniare bitcoin ora a livello mondiale e questi sono dati statistici reali potete andare a verificarli c'è un sito che vi fa vedere l'andamento di tutto quello che succede sulla blockchain di bitcoin in tempo reale quindi a livello mondiale si svolgono si eseguono di solito 2 alla 70 operazioni criptografiche quindi invocazioni delle funzioni hash per ogni secondo adesso in questo momento in un secondo spasso per il mondo ci sono tutti quanti i calcolatori impegnati nel tentativo di poniare bitcoin che stanno facendo 2 alla 70 è un numero molto grande molto molto grande 2 alla 70 operazioni al secondo ok immaginate un avversario che voglia fare un brute force attack sulla chiave di una qualunque primitiva criptografica possiamo ipotizzare che se avesse a disposizione tutte le risorse di calcolo che in questo momento al mondo sono impegnate per coniare bitcoin potrebbe fare anche lui circa 2 alla 70 operazioni in un secondo ipotizzando che ci sia questo fantomatico avversario in grado di sequestrare tutta la potenza di calcolo che in questo momento si sta usando per coniare bitcoin e non è una potenza di calcolo trascurabile perché pensate che il consumo di energia dedicato a questo tipo di operazioni è annualmente paragonabile al consumo di energia di un paese di medio grande dimensione adesso non sono aggiornato ma fino a qualche tempo fa facendo la classifica dei consumi energetici delle azioni del mondo il consumo dedicato a bitcoin occupava attorno alla trentesima posizione davanti alla Danimarca e dietro non mi ricordo quale altro paese a livello di quindi stiamo parlando di risorse computazionali importanti ora immaginate che ci sia un avversario che ha a disposizione queste risorse per fare un brute force attack su un cifrario semanticamente sicuro quindi potremmo ipotizzare che è in grado di fare due alla di provare due alla 70 diverse chiavi in un secondo ok ogni chiave richiede di fare un tentativo sul cifrario questo significa due alla 95 in un anno che significa due alla 105 in mille anni ok attualmente la lunghezza tipica delle chiavi in cifrari considerate semanticamente sicuri in cifratura chiave simmetrica vi cito questo perché è uno di quelli che studieremo che è A e S che è un cifrario considerato semanticamente sicuro attualmente una lunghezza ragionevole per le chiavi di A e S è 128 bit quindi vuol dire che esistono due alla 128 diverse chiavi che ha un numero molto molto molto più grande di due alla 105 che è il numero di chiavi che il nostro avversario molto potente sarebbe in grado di verificare in mille anni ok quindi siamo ancora parecchio lontani no da da da questo vi dà un'idea di come vengono scelte le lunghezze delle chiavi ok quindi 128 bit è una lunghezza associata a un certo valore di lambda che ci permette molto tranquillamente di stabilire che se consideriamo un avversario efficiente le cui risorse computazionali sono limitate polinonialmente rispetto a una funzione T che è quella della differenzione che abbiamo visto prima parametrizzata rispetto a un lambda che è associato appunto ai 128 bit per chiave ebbene sappiamo quali sono le risorse computazionali di un tale avversario ci sembrano ragionevoli da un punto di vista se vogliamo rimanere tranquilli rispetto al discorso della robustezza e quindi un cifrario semanticamente sicuro rispetto a un tale valore di lambda ci fa stare relativamente tranquilli ok se abbassiamo troppo lambda e che ne so prendiamo chiavi di 32 bit allora anche un cifrario come AS diventa vulnerabile ok perché è vero è vero che AS con chiavi di 32 bit è ancora semanticamente sicuro ma lo è rispetto ad una classe di avversari efficienti molto piccola con risorse molto limitate che non rispecchia le risorse del mondo reale ok cioè se usassimo se usassimo AS con chiave 32 bit è come dire che il nostro cifrario è sicuro rispetto ad un avversario che ha a disposizione un laptop per vincere la tag game che ha determinate caratteristiche piuttosto limitate ci basta dipende dipende dal contesto cioè in certi contesti magari ci basta avere quel livello di sicurezza perché perché riteniamo di che la robustezza del nostro sistema non sia di interesse per avversari molto efficienti e quindi ci accontentiamo spesso volentieri per la sicurezza di dispositivi mobili come i sensori si fa questo tipo di ragionamento ok ci si accontenta i valori bassi però in altri contesti se pensiamo a un sistema bancario è chiaro che un valore di lambda così basso non è assolutamente ragionevole ok perché perché vogliamo essere robusti rispetto ad avversari più espressivi più potenti quindi dobbiamo ammazzare lambda per poter comprendere nella classe di avversari efficienti rispetto a cui siamo sicuri anche tutti quelli che riteniamo essere realistici al mondo d'oggi mi sono spiegato? ok questo se ho cercato di sicure i miei personal data over my laptop with no side effect my money or what else I could deal with short keys a small class of adversaries but for a bank system it's different ok non tornerò più sul discorso del parametro di sicurezza sul discorso del degli algoritmi efficienti limitati polinormalmente rispetto a questo discorso che abbiamo appena fatto però vorrei che sia chiaro l'intuizione che ci sta dietro quindi d'ora in avanti quando parliamo di definizioni di sicurezza rispetto ad avversari efficienti sappiamo cosa vuol dire in questo senso qua ok tutto chiaro chiudo chiudo questo primo set di slide generali sui cifrari sui cifrari proponendo un esempio di solito alla fine di ogni gruppo di slide metto sempre un esempio reale di domini applicativi dove si usano gli strumenti che abbiamo appena visto ok finora abbiamo visto poco e niente nel senso che ancora non siamo entrati nel dettaglio delle della cifratura chiave simmetrica abbiamo parlato genericamente di cifrari e abbiamo parlato di semantic security ok ora il concetto di sicurezza semantica è già sufficiente per realizzare applicazioni del mondo reale che utilizzano appunto cifrari che sono semanticamente sicuri l'esempietto che vi propongo è abbastanza tipico noto magari vi è capitato di usare o quantomeno di conoscere applicazioni come Tor che servono fondamentalmente per garantire l'anonimato nelle connessioni al web che voi attivate che si basa Tor in particolare si basa su un protocollo che è una diciamo una versione estesa di quello che prende il nome di onion routing che vi mostro qui nella versione sulla versione più più semplice che però si basa appunto sull'uso di cifrari semanticamente sicuri ok qui il problema qual è il problema è che Alice vuole mandare un messaggio a Bob preservando la propria identità quindi garantendo l'anonimato non vuole che si sappia che è lei il mittente di un messaggio che arriva che arriva a Bob ok quindi nessuno lungo la rete deve essere in grado di stabilire osservando i pacchetti che viaggiano che Alice sta mandando un messaggio a Bob questo è il problema ok l'idea qual è l'idea di utilizzare una serie di proxy di router lungo il tragitto da Alice a Bob l'obiettivo di questi chiamiamoli proxy è quello di fornire un servizio di mixaggio un mixing service che serve fondamentalmente per raccogliere messaggi in ingresso mescolarli in che senso mescolarli significa fondamentalmente accumulare messaggi che arrivano in ingresso e poi spararli fuori in un ordine diverso rispetto a quello di ingresso ok in modo tale da rendere difficoltosa l'analisi dei percorsi che un certo messaggio segue nell'andare da Alice a Bob è chiaro che questo servizio ha senso se i messaggi viaggiano cifrati perché se Alice manda un messaggio in chiaro un plain text a Bob basta seguire il tragitto ed ecco che quando il messaggio arriva a Bob io so che è partito da Alice anche se non c'è scritto Alice nel mittente del messaggio mi basta seguire il percorso quindi i messaggi vanno cifrati e non basta cifrarli vanno cifrati più volte no perché di nuovo se Alice cifra il messaggio e lo trasmette e il messaggio cifrato in quella maniera arriva a Bob di nuovo io che osservo mi basta vedere il tragitto che il messaggio cifrato fa da Alice a Bob ecco che quando arriva Bob so che quel messaggio arriva da Alice quindi il messaggio deve cambiare cifratura più volte e questo avviene dentro i proxy in che maniera vi faccio vedere due esempietti guardate il primo esempio dobbiamo assumere che Alice condivida una chiave che è una delle soluzioni che mi ha fatto l'altra volta condivida già una chiave segreta con ciascun proxy Phil è un proxy ok quindi Alice e Phil condividono una chiave supponiamo che questa chiave sia K1 ok Alice che cosa fa cifra il plaintext M che vuole mandare a M insieme al destinatario che è Bob quindi la tupla Bob M viene cifrata usando K1 da Alice Alice trasmette il messaggio e chi osserva il canale vede passare un ciphertext e se questo ciphertext è stato cifrato usando un cifrario semanticamente sicuro l'osservatore non è in grado di dedurre nessuna informazione sul suo contenuto quindi né su M né su Bob destinatario il ciphertext arriva a Phil Phil accumula tanti ciphertext perché è chiaro che se Phil trasmettesse in uscita i messaggi che gli arrivano nello stesso ordine in cui gli arrivano allora è chiaro che l'osservatore sarebbe in grado di ricostruire le traiettorie mentre invece Phil che cosa fa? raccoglie tanti messaggi li tiene in pancia un po' e poi li spara fuori in ordine diverso rispetto a quello di entrata chiaramente che cosa fa Phil? decifra il ciphertext e spara fuori il plaintext ok? quindi voi che osservate la rete vedete entrare nel proxy tanti ciphertext quello di Alice e quello di altri poi dopo un po' vedete uscire dal proxy in ordine sparso dei plaintext quindi non siete più in grado di accoppiare un certo ciphertext che è entrato nel proxy con un certo plaintext che esce dal proxy nel caso di Alice dal proxy uscirà il plaintext m che Phil ha decifrato e che verrà inviato a Bob come fa a sapere che è Bob e l'informazione era presente dentro il ciphertext in questo modo preserviamo l'anonimato di Alice ok? qui vedete l'esempio con due proxy no no no no no no no no in questo caso no perché nel caso di più proxy vale il secondo esempio no tutte le cifrature vengono fatte prima ok in questo caso cioè Alice che cosa fa se sa che deve attraversare due proxy Fib e Phil crea C1 come abbiamo visto prima poi C1 lo cifra ulteriormente usando la chiave che condivide con Fib quindi in pratica è come se Alice creasse una matrioska di ciphertext che ha tanti strati quanti sono i proxy che verranno coinvolti in questo caso Alice sa il percorso viene lo stabilisce a priori ok magari fa fa una query per capire qual è il percorso che può seguire e quindi raccoglie le informazioni sui vari proxy anche perché dobbiamo assumere che condivida una chiave con i vari proxy dopodiché crea in questo caso crea C2 C2 arriva Fib C2 è cifrato con K2 che è la chiave condivisa tra Alice e Fib quindi Fib riesce a recuperare il contenuto di C2 che è la tupla Phil C1 quindi sa che deve inviare C1 a Phil a Phil arriva C1 e a questo punto Phil fa la stessa cosa che aveva fatto prima di cifra C1 e spacchetta M lo manda Bob gli arriva comunque M ok e la catena può essere lunga piacere e non arriva il messaggio se un router salta non arriva il messaggio però avere più proxy coinvolti aumenta il livello di sicurezza perché supponendo che ci sia un proxy malevolo non è in grado di violare l'anonimato di Alice per violare l'anonimato di Alice tutti i proxy dovrebbero essere collusi quindi tutti malevoli d'accordo per di loro allora in quel caso è chiaro che riuscirai a ricostruire il percorso del VM ok però se i proxy sono tanti la probabilità che siano tutti sotto il controllo dell'avversario è più bassa ok bene questa struttura regge funziona se il cifrario che si usa no per cifrare i vari messaggi è semanticamente sicuro assumendo che ogni chiave viene usata una volta solo ok questo è un esempio bene ora siccome vi ho promesso di alternare le parti relative a teoria e pratica adesso stamattina continuiamo con la teoria invece oggi pomeriggio poi faremo il salto alla parte più più applicativa quindi questo significa che adesso cominceremo a parlare della prima famiglia di cifrari a chiave simmetrica che studieremo ne studieremo due di famiglie la prima è quella di cifrari di chi afflusso che adesso iniziamo a vedere Ah ok ok ok Yeah If we won't guarantee the anonymity of Alice obviously we have to use a way to allow Alice and each proxy to share a key without imposing to Alice to reveal her identity to the proxies The idea is that if Alice has to share K1 with Phil and K2 with Phoebe We have to guarantee this sharing without revealing the identity of Alice to the proxy Ok so the proxy knows that someone I don't know who is sharing with him a certain key Ok And when I receive a certain ciphertext there will be some metadata specifying not the specific key but an information that allows the proxy to recover the key I mean assume that this proxy has a table a key table Ok Maybe the metadata associated to the cipher may say that the key necessary needed to to recover the message is the health of the table Ok So the proxy doesn't know who who is the owner of the key otherwise the anonymity would be violated So that's the meaning of key sharing does not require identification identification of Alice Ok who is the The Unisan perfettamente sicuro che abbiamo visto. OTP. Tutti gli altri che abbiamo visto non sono perfettamente sicuri. Quindi l'idea che è venuta in mente poi a chi ha studiato i proposti di string cipher è questa. Siccome sappiamo che OTP è perfettamente sicuro, possiamo provare a approssimare OTP, a usare un cifrario che assomigli a OTP e che quindi ci garantisca non la perfect security ma quantomeno la semantic security. Questa è l'idea che sta dietro agli string cipher, ai cifrari a flusso. L'idea in realtà è molto semplice, ovvero qual è il problema di OTP? Che lo rende impraticabile. Ho bisogno di una chiave che ha la stessa lunghezza del plaintext, perché OTP mi dice di fare l'oxor tra plaintext e chiave. Se il plaintext è molto lungo, io una chiave altrettanto lunga probabilmente non ce l'ho. Ok? Questo è il problema di OTP. Allora, come viene risolto questo problema negli string cipher? L'idea è di usare una chiave relativamente piccola. Ok? E in gergo viene chiamata seme, seed. Ok? E usare questa chiave in combinazione con un certo algoritmo che vedremo, che vedremo, per creare chiamiamola una pseudo chiave molto lunga da combinare in XOR col plaintext come se usassimo OTP. Quindi l'idea è di usare comunque OTP, però di non avere una chiave lunga tanto quanto il plaintext, ma di generarla a partire da un seme. È chiaro che questa generazione della chiave a partire dal seme deve essere una generazione il più possibile casuale, perché la chiave non può essere prevedibile. Ok? Io devo avere la garanzia che se prendo il seme e lo do in pasto, seme segreto, e lo do in pasto a questo algoritmo, l'algoritmo mi deve restituire una stringa lunga piacere che dal punto di vista di un osservatore esterno è puramente casuale, perché questa stringa per me sarà effettivamente la chiave da usare seguendo OTP per cifrare il plaintext. Questa è l'idea. Ok? Andiamo a vedere formalmente come funziona. Quindi, siccome ci speriamo a OTP, plaintext e ciphertext hanno sempre la stessa lunghezza, no? Perché dovremmo fare lo XOR. Le chiavi, invece, sono molto più corte. Ok? Quindi, le chiavi hanno una lunghezza L piccolo che ha un valore molto, molto, molto più piccolo rispetto alla dimensione massima dei plaintext. Ok? La chiave in questo caso, appunto, viene chiamata SID, o SEME, e l'idea è quella di usare il SEME come input di un algoritmo il cui obiettivo. Il cui obiettivo è quello di creare una stringa lunga quanto il plaintext puramente casuale. ok? Quindi non predicibile. Questo algoritmo, G grande, prende il nome di pseudo-random generator, PRG, generatore pseudo-casuale. No? Perché pseudo-casuale? Perché puramente casuale non lo possiamo ottenere. No? Cioè, un algoritmo puramente casuale per generare una stringa sarebbe un algoritmo che per ogni bit della stringa lancia una moneta se test metto zero, se uno metto, se croce metto uno. Quello sarebbe un algoritmo truly-random, puramente casuale. Non è realizzabile un algoritmo puramente casuale. Quindi ci dobbiamo accontentare di un algoritmo pseudo-casuale, quindi quasi-casuale. Ok? E la cifratura poi avviene come in OTP. Quindi come funziona? Partite dal seme, dal seed, lo date in input al PRG, al pseudo-random generator, questo genera una stringa, la prendete lunga quanto il plaintext e la usate come chiave di OTP, cioè fate lo XOR tra la stringa e il plaintext. La decifratura funziona nello stesso modo. Quindi se Alice e Bob condividono il seme, entrambi sono in grado di generare la stringa pseudo-casuale e quindi Alice sarà in grado di fare la cifratura e Bob sarà in grado di fare la decifratura. Ok? Ci siamo? Ora, chiaramente, come vedremo adesso, la sicurezza semantica di uno stream cipher che funziona in questo modo dipende in qualche modo dalla sicurezza, dalla robustezza del PRG. Ok? Pratica. Qui l'unico segreto che abbiamo è il seme. Quindi solamente chi conosce il seme dovrebbe sapere qual è la stringa pseudo-casuale che il PRG spara in output rispetto a quel seme. Ok? Questa è l'idea. E per stabilire la sicurezza del PRG si usa una definizione che è simile a quella della sicurezza semantica sempre basata su un attack game e che si basa su un'intuizione molto molto semplice. Ora da un punto di vista intuitivo quando è che un PRG possiamo dire che è sicuro? Perché mettetevi nei panni dell'avversario. Ok? No? Allora facciamo questo gioco. No? Io sono l'avversario. Voi mi fate vedere da una parte una stringa trulli random. Quindi generata lanciando la monetina per ciascun bit. Ok? Dall'altra mi fate vedere invece una stringa generata dal PRG usando un certo seme. Ok? Non mi dite quale delle due è trulli random e quale pseudo random. io le confronto se non riesco in qualche modo confrontandole a dedurre qualcosa qualche informazione che mi faccia propendere verso una verso l'altra che mi faccia dire ma forse questa è quella puramente casuale questa magari non lo è perché è fatta in un modo che non mi sembra del tutto casuale. Ok? se questo non è possibile cioè se le due stringhe sono dal mio punto di vista si dice indistinguibili indistinguishable cioè io non ho un criterio per stabilire che una stringa è stata generata in maniera trulli random e l'altra in maniera pseudo random non ho nessuna informazione analizzando le due stringhe non ho nessuna informazione che mi faccia dire quale è trulli random e quale è pseudo random quindi le due stringhe sono indistinguibili se le cose stanno così se le due stringhe sono indistinguibili allora vuol dire che il PRG è sicuro perché l'avversario non è in grado di prevedere come si comporta e se non è in grado di prevedere come si comporta il PRG rispetto a un certo seme allora il lavoro che lo string cipher fa è un lavoro sicuro perché l'avversario non ha modo di prevedere non conoscendo il seme l'avversario non avrà modo di capire quale sarà la stringa generata dal PRG che andrà in XOR con il plaintext ok questa è l'idea la tag game è questo qua è molto semplice è molto anche simile a quelli che abbiamo già visto la settimana scorsa il challenger fa esattamente quello che ci siamo appena detti ovvero a seconda dell'esperimento in cui ci troviamo scelto in ogni anno deterministica il challenger decide se creare una stringa Tully random o se creare una stringa pseudo random a partire dal seme e usando il PRG ok dopodiché fa vedere il risultato all'avversario l'avversario deve esaminando la stringa e usando l'algoritmo efficiente che ha a disposizione cercare di capire se la stringa che sta osservando è true random o pseudo random cioè è stata generata veramente in maniera casuale o se invece è stata generata dal PRG si calcola il vantaggio dell'avversario esattamente come abbiamo visto settimana scorsa c'è il vantaggio dell'avversario al solito ha la differenza tra la probabilità di due eventi ovvero l'evento in cui l'avversario spara uno e la stringa era true random meno la probabilità che l'avversario spari sempre uno ma la stringa era pseudo random se le due probabilità sono molto vicine è chiaro che l'avversario non è in grado di distinguere un esperimento dall'altro quindi la definizione di sicurezza è esattamente simile a quella che abbiamo già visto cioè il PRG è sicuro se il vantaggio dell'avversario è trascurabile ok quindi questo è il concetto di sicurezza per un PRG cioè il fatto di produrre stringhe che io non riesco a distinguere rispetto a stringhe che siano completamente casuali generate in maniera veramente casuale poi c'è un teorema che dice che se il PRG è sicuro allora lo string cipher è semanticamente sicuro quindi vedete la sicurezza che interessa a noi per lo string cipher dipende esclusivamente da che cosa? dalla sicurezza del PRG ok? perché tanto sappiamo già che il TP è sicuro quindi eventuali problemi possono derivare solo dal PRG ma se il PRG è sicuro allora possiamo dire che lo string cipher è semanticamente sicuro ok? ok? tutto chiaro? ora gli string cipher hanno un po' di problemini ve ne faccio vedere due che vanno oltre le assoluzioni che abbiamo fatto la settimana scorsa però è ben anticipati perché nel mondo reale questi problemi possono essere importanti e il primo problema per cui abbiamo fatto la soluzione l'altra volta ogni chiave la usiamo una volta sola e qui capiamo perché è importante che ogni chiave l'hanno usata una volta sola immaginate di usare lo stesso seme per cifrare due diversi messaggi m m' ok? quindi general ciphertext c in questa maniera qui come abbiamo visto ok? e poi general ciphertext c primo in quest'altra maniera qua e poi immaginiamo di pubblicare trasmettere in rete prima c e poi c primo quindi l'avversario li vede passare entrambi e sa che sono due ciphertext di due messaggi m m' primo ottenuti a partire dallo stesso seme ok? ora l'avversario che cosa può fare? guardate questa sequenza di operazioni algebriche può fare lo xor dei due ciphertext ok? però noi sappiamo che i due ciphertext sono stati generati no? facendo lo xor per definizione tra l'output del prg e il plaintext l'output del prg è sempre quello perché abbiamo detto che i due messaggi sono cifrati a partire dallo stesso seme ok? quindi vuol dire che entrambi i plaintext sono combinati con la stessa stringa pseudo casuale ora se voi sfruttate un po' di proprietà dello xor simile a quelle che abbiamo visto settimana scorsa quando abbiamo dimostrato la correttezza di di otp vi salta fuori che questa espressione cioè di fatto lo xor tra i due ciphertext è uguale a che cosa? è uguale all'oxor dei due plaintext guardate da dove siamo partiti e dove siamo arrivati noi partiamo dall'oxor dei ciphertext e otteniamo che il risultato di questa operazione è uguale all'oxor di due plaintext quindi cosa vuol dire questo? vuol dire che l'avversario anche se non sa chi sono M e M primo sa che hanno certe proprietà perché conosce il risultato del loro xor ok? sembra un'informazione di poco conto ma è sufficiente per l'avversario per recuperare almeno alcuni bit di M e M primo con uno sforzo computazionale relativamente basso perché come abbiamo intuitivamente l'altra volta se vi ricordate abbiamo detto che un cifrario è semanticamente sicuro se non svela nessuna proprietà del plaintext era una delle condizioni che abbiamo visto ok? qui invece stiamo vedendo che il cifrario svela delle proprietà dei plaintext perché ci dice quanto fa M xor M primo ok? quindi viene violato il teorema che abbiamo visto l'altra volta sui cifrari semanticamente sicuri e questa vulnerabilità è sufficiente per costruire degli attacchi che consentono all'avversario di recuperare i plaintext e quindi nel momento in cui l'avversario recupera i plaintext automaticamente viene a conoscere GDS cioè la stringa pseudorambra e quindi di fatto violare la robustezza del seme ok? quindi per gli string cipher in particolare vale quello che abbiamo detto l'altra volta ogni chiave in questo caso di seme va usato una volta sola questo problema si chiama to time pad cioè il fatto che la stessa chiave viene usata per almeno due messaggi diversi e diverse vulnerabilità di sistemi crittografici reali sono dovute a questo problema qua poi le incontreremo ve le citerò man mano che andremo avanti ok? quindi quando vi ricorderò in to time pad no le il problema è questo l'altro problema riguarda un'altra condizione che viene violata e che ha a che fare con l'integrità dell'accenno perché di integrità comunque parleremo più avanti e questa vulnerabilità degli string cipher ha a che vedere con quella condizione che viene chiamata malleabilità malleability cioè la possibilità da parte del dell'avversario di di manipolare per questo motivo si dice malleabile manipolare il ciphertext e quindi il plaintext senza che Alice e Bob se ne accorgano come può fare anche qui basta osservare le proprietà del dell'oxor perché vedete un po' allora di nuovo noi sappiamo che il ciphertext è l'oxor del plaintext con la stringa pseudo casuale generata dal dal PRG ok ora immaginate che l'avversario in questo caso l'avversario sta sul canale si comporta come il cosiddetto man in the middle quindi vede passare il ciphertext lo prende lo manipola e lo rimette sul canale ok ci siamo come lo manipola immaginiamo che l'attaccante lo manipoli in questa maniera qua cioè prende il ciphertext che passa sul canale sceglie una una stringa chiamiamola delta a suo piacere e la combina in xor con il ciphertext il risultato lo chiamiamo cprimo cprimo viene inoltrato a bob ok quindi alice ha cifrato m creato c trasmesso c sul canale l'avversario lo intercetta lo cambia in cprimo e lo fa arrivare a bob adesso bob che cosa fa bob decifra cprimo e come lo decifra in questa maniera qua combinando vincsor con la stringa pseudo casuale ok ma spacchettando i vari elementi che trovate qui nell'espressione quindi sapendo che cprimo è uguale a questa roba qua in xor con la stringa pseudo casuale che cosa salta fuori salta fuori che il risultato della decifratura da parte di bob è mxor delta non è più m quindi bob riceve mxor bob se ne accorge che è successo qualcosa di strano nel merdo non ha modo di accorgersene riceve un messaggio riceve un ciphertext riesce a decifrarlo per lui il plaintext è mxor delta ok quindi lui non ha modo di accorgersi che il messaggio è cambiato non è m ma è m più delta quindi lo string cipher è malleabile per questo motivo qua l'avversario può modificare il plaintext il plaintext attraverso una modifica fatta sul ciphertext perché vedete la stessa modifica che l'avversario fa sul ciphertext è propagata sul plaintext questa condizione di malleabilità è critica in un contesto reale in certi casi sì vi faccio un esempio perché la domanda che uno si fa è vabbè ma che ne sa l'avversario di quale delta deve usare affinché m più delta sia un messaggio ancora significativo per bob no perché m non lo conosce non conoscendo m vabbè viene il ciphertext e delta lo scegne lui ma non conoscendo m come fa l'avversario a sapere che m più delta ha senso è un messaggio che può avere senso apparentemente non è possibile però in certi casi l'avversario ha delle informazioni a sua disposizione che gli permettono di capire anche se non sa m qual è la sua struttura e quindi capire dove intervenire con le modifiche e quindi come definire delta prendete il caso delle mail cifrate ok c'è modo di cifrare una mail no perché volete che il contenuto della mail che viene spedito sia confidenziale una volta si usava si usavano dei cifrati PGP è uno dei primi esempi di cifrare il cui obiettivo era proprio quello di cifrare le email ok ora molto spesso la struttura delle email è standard no ad esempio nelle in certi byte specifici del del plaintext è contenuto il nome del mittente l'email del mittente ok anche se voi cifrate la mail e usate uno string cypher i byte del cypher che contengono l'identità del mittente sono sempre gli stessi non cambia la posizione ok quindi l'avversario sa quale porzione del cypher text contiene l'informazione sul mittente ok ipotizziamo che l'obiettivo dell'avversario sia cambiare il mittente quindi far credere a bob che il mittente non è alice ma è lui ok dovrebbe creare un delta una maschera praticamente delta è una maschera con un contenuto significativo solo in corrispondenza dei byte occupati dall'indirizzo dell'immittente e applicare questa maschera in maniera tale è che il risultato sia trasformare l'indirizzo dell'immittente nell'indirizzo suo ok è chiaro che questa cosa qui si può fare solo se io conosco se l'avversario conosce l'indirizzo dell'immittente no perché delta lo sceglie lui va in xor con l'indirizzo dell'immittente io se conosco l'indirizzo dell'immittente posso scegliere opportunamente un delta che trasformi quell'indirizzo lì in un altro a mio piacere perché facendo l'oxor io ho la possibilità di trasformare a seconda di come definisco delta qualunque bit come mi pare a me però devo sapere quali sono questi bit perché altrimenti se scelgo delta a caso perché non so qual è l'indirizzo dell'immittente il risultato magari sarà una stringa inesistente e quindi Bob se ne accorge che gli è arrivato un messaggio alterato ora purtroppo quello che succede è che spesso alcuni metadati viaggiano in chiaro ok quindi magari l'avversario è in grado di sapere chi è il mittente del messaggio anche se nel ciphertext non lo vede lo vede da altri metadati che non fanno parte del plaintext ma sono parte del pay off del pacchetto che viene trasmesso ok quindi esaminando il pacchetto vedi chi è il mittente sa che dentro il ciphertext in una posizione ben precisa c'è l'indicazione di quel mittente ok quindi conosce parte del plaintext cioè il mittente sai che posizione si trova a questo punto scegli decide qual è il delta che trasforma quella sequenza di bit associata all'indirizzo del mittente nella suo indirizzo fa quest'operazione direttamente sul ciphertext dunque nel modo che abbiamo visto qua e quando il messaggio alterato arriva a Bob Bob lo decifra il risultato è m più delta cioè è lo stesso messaggio che Alice ha confessionato tranne in un punto ovvero in quella sequenza di byte che contiene l'indirizzo del mittente quindi Bob riterrà che quel messaggio non arriva dalla Alice ma dall'identità che l'avversario ha scelto ok chiaro l'esempio ora in maniera più complessa questo attacco potrebbe essere messo in piedi per che ne so faccio un esempio immaginate all'home banking per cambiare il mittente o il destinatario di un bonifico ok elaborandolo in maniera un pochino più più sofisticata ok ci siamo quindi la malleabilità è un problema che in certi contesti è serio in altri no perché in altri non c'è modo di sapere qual è la struttura di M e quindi io non ho nessuna informazione che mi permetta di stabilire come calcolare delta in una maniera che a me fa comodo per realizzare un certo attacco però il contesto dove questa cosa funziona ce ne sono ce ne sono diversi questo è il modo in cui a livello teorico funzionano gli string cipher quindi la definizione che abbiamo visto in questa slide è quella di base per tutti gli string cipher poi ci sono delle evoluzioni ad esempio i PRG ad esempio che riguardano i PRG cioè ad esempio ci sono dei modi per estendere un PRG cioè voi immaginate di avere un PRG faccio un esempio pratico immaginate un PRG che lavora su dei semi di 128 bit e il PRG vi spara fuori una stringa pseudo casuale lunga 5k ok? magari quei 5k vi bastano perché il plaintext è lungo al massimo 5k e quindi riuscite a fare loxor ma se il plaintext è più lungo e quindi quella stringa lì non vi basta come fate? non potete replicarla perché indebolite il PRG quindi esistono delle operazioni che senza cambiare il seme vi permettono di estendere la lunghezza della stringa pseudo casuale e quindi creare una sequenza lunga piacere adattandola al plaintext che volete cifrare tramite ATP adesso non entrerò nei dettagli vi menziono solamente il fatto che esistono due in letteratura estensioni dei PRG in questo senso che sono entrambe semanticamente sicure cioè se partite da un PRG sicuro queste estensioni sono a loro volta sicure e quindi gli string cipher basati su queste estensioni saranno semanticamente sicuri vi do solo l'intuizione la prima estensione vi dice semplicemente che potete usando diversi semi potete concatenare il risultato del PRG per ciascun seme e ottenere una stringa che sarà sicura questa è meno interessante perché richiede di usare tanti semi diversi io magari ne condivido solo uno con Alice e Bob condividono solo un seme e quindi questa estensione non è interessante la più interessante è la seconda perché lavora con un seme solo ok e l'idea è abbastanza interessante perché come faccio a generare una stringa pseudo casuale più lunga di quella che il PRG mi dà senza cambiare il seme allora si basa su un trucco e qual è questo trucco allora io uso il seme per generare la stringa pseudo casuale che avrà una certa lunghezza poi che cosa faccio con questa stringa pseudo casuale un pezzettino lo tolgo ok e il resto lo tengo come chiave OTP il pezzettino che tolgo lo uso come nuovo seme per generare un'altra sequenza pseudo casuale dalla quale toglierò di nuovo un pezzettino che funzionerà come nuovo seme e la parte resuida invece la vado a mettere nel risultato della concatenazione finale e in questa maniera partendo da un unico seme voi avete modo di generare tanti semi ogni volta che applicate il PRG ottenete una stringa un pezzettino lo prendete come nuovo seme e andate avanti così e poi concatenate tutti i risultati ed ecco che in questa maniera avete una sequenza lunga a piacere dipende da quante volte voi replicate questa questa operazione lo potete fare senza limiti e i PRG sicuri sono anche impredicibili cosa significa questo ve lo spiego attraverso un altro tag game che vi dà idea di che cosa vuol dire impredicibilità immaginate un tag game dove l'avversario sa che il challenger sta creando sta usando il PRG però non conosce il seme ok e l'avversario dice al challenger fammi vedere i primi i bit della stringa pseudo casuale io lo sceglie lui fammi vedere i primi 100 bit i primi 200 bit della stringa che il PRG genera a partire dal seme che tu sai io non so ok e fammela vedere quindi fammi vedere i primi bit della stringa l'avversario si guarda il risultato esegui sull'algoritmo efficiente fa tutto quello che deve fare e cerca di indovinare quale potrebbe essere il successivo il bit successivo ok quindi in pratica come dire faccio un esempio pratico il challenger crea la la stringa pseudo casuale l'avversario vuole vedere i primi 100 bit il challenger prende i primi 100 bit della stringa pseudo casuale li fa vedere all'avversario l'avversario deve indovinare quale è il 101 quello successivo ok ora se veramente la stringa pseudo casuale è indistinguibile da una stringa veramente casuale truly random l'avversario non è in grado di indovinare quale sarà il prossimo bit se non a caso quindi con una probabilità pari al 50% perché è esattamente quello che succederebbe con la stringa casuale se io faccio 100 volte il lancio di una moneta e vi faccio vedere il risultato voi avete delle informazioni significative che vi permettono di stabilire quale sarà il risultato del lancio successivo no e qui è la stessa cosa se il PRG è sicuro anche se io vi faccio vedere i primi 100 bit della stringa pseudo casuale voi osservando questa stringa non dovreste avere modo di sapere con una probabilità maggiore al 50% qual è il valore del bit successivo ok e se le cose stanno così allora vuol dire che il PRG è impredicibile no e c'è un teorema che dice che la sicurezza dei PRG come l'abbiamo definita prima è equivalente al concetto di impredicibilità quindi i PRG sicuri sono anche unpredictable ok è un se solo se quindi sono due nozioni assolutamente equivalenti ok i PRG mi fanno venire in mente qualcosa che avete mai visto in passato o studiato in altri corsi esatto esatto esatto esatto magari non vi è mai capitato però in programmazione con il visito appunto si usano i generatori di numeri casuali spesso spesso e volentieri quindi la domanda che ci possiamo fare è un generatore di numeri casuali come quello che mette a disposizione che ne so la libreria del Borland C piuttosto che qualunque altro tipo di compilatore o di ambiente gli stessi sistemi operativi prendete Linux ha una funzione di libreria sua interna che genera numeri casuali si chiama random mi sembra ok allora quelli sono generatori di numeri casuali allora la domanda che ci possiamo fare è ma i generatori di numeri casuali come la funzione run di Linux è un PRG cioè lo posso usare come PRG di uno string cipher la risposta è no perché sono predicibili sono predictable molto spesso i generatori di numeri casuali usati all'interno di sistemi operativi che infatti non vengono usati per la criptografia vengono usati là dove serve generare un numero casuale ad esempio per un algoritmo probabilistico ok nella maggior parte dei casi sono predictable cioè non sono sicuri rispetto a questo tag game qui cioè se voi osservate una sequenza di bit generata dalla funzione run avete una probabilità significativamente maggiore del 50% di nominare quale sarà il bit successivo ok due parole su su questa cosa tornerò a propone due parole sulla storia degli string cipher e della loro robustezza il primo string cipher diffuso in letteratura risale agli anni 80 ed è RC4 sviluppato da Rivest che è un criptografo piuttosto famoso che ricorrerà spesso Rivest è la R di RSA ad esempio che è uno degli algoritmi che studieremo più avanti e RC4 è uno string cipher è stato usato per parecchi anni in parecchie applicazioni SSL TLS web sono tutti protocolli criptografici che vedremo adesso non vi sto a raccontare dove come venivano e vengono utilizzati tuttora in versioni aggiornate ad esempio TLS è il protocollo criptografico che sta alla base di HTTPS ok c'è la versione sicura di protocollo HTTPS RC4 ormai è deprecato non si usa più perché sono stati trovati definiti attacchi significativi che lo rendono vulnerabile quindi RC4 di fatto non è più uno standard di fatto non si usa non si usa più ad esempio intanto per citare un attacco significativo RC4 veniva usato per implementare la cifratura all'interno del protocollo pptp in Windows MT che è un protocollo che appunto serviva per creare una VPN point to point l'equivalente delle VPN di adesso fondamentalmente e veniva usato RC4 per fare cifratura dei messaggi peccato che il protocollo usasse all'interno usasse lo RC4 per cifrare con lo stesso seme diversi messaggi quindi soffriva del to time pad e questo per questo motivo è stato appunto traccato ci sono svariati tentativi di successo di criptanalisi di questo cifrato come dicevo prima la maggior parte dei generatori di numeri casuali in particolare quelli che in statistica vengono chiamati linear congruential generators generatori congruenziali lineari che sono degli algoritmi per la generazione di numeri casuali che appunto vengono usati in statistica per fare le campionature e vengono molto utilizzati ad esempio all'interno dei simulatori ok i generatori di numeri casuali sono fondamentali nell'ambito della simulazione proprio per dare quel elemento randomico che serve per stabilire ad esempio che input generare per testare il sistema piuttosto che quali traccia seguire e via dicendo la tra grande maggioranza di questi appunto generatori di numeri pseudo casuali e lì vi cito alcuni sistemi che li utilizzano compreso la libreria standard Glibc sono predicibili ok quindi non soddisfano il teorema che abbiamo appena visto sulla predicibilità e quindi non devono essere utilizzati per nell'ambito della critografia ed è uno dei motivi per cui su questo calcherò sempre la mano è sempre sbagliato cercare pensare di svilupparsi in casa da un algoritmo di cifratura si usano quelli standard punto non è che si è sbagliato anche prendere un algoritmo standard e reimplementarlo magari perché pensiamo di renderlo più efficiente lo vogliamo adattare a che ne so al nostro sistema per qualche motivo no non va mai fatto uno dei motivi è questo poi ce ne sono tanti altri di cui parleremo però una cosa che non va fatta mai è implementare una propria versione personale di un cifrario si prendono le librerie standard disponibili in letteratura poi forse di questo riusciremo a parlare più avanti per darvi un altro esempio saprete che ad un certo punto nella storia dei DVD anzi abbastanza presto nella storia dei DVD si è trovato un modo per copiarli sebbene fossero protetti uno dei sistemi maggiormente diffuso che è stato craccato in questo senso è lo standard CSS il content scrambling system che era il sistema che si usava appunto per cifrare le informazioni sui film tanto per fare un esempio pratico si usava nello standard CSS uno string cipher vulnerabile e quindi quello è uno dei motivi per cui predicibile in particolare è uno degli svariati motivi per cui lo standard CSS poi è stato abbandonato non l'unico vi darò altri esempi delle sue vulnerabilità ma una delle tante era dovuta all'uso di uno string cipher basato su un prg predicibile ok qual è invece lo stato dell'arte oggi si usano ancora gli string cipher si naturalmente esistono string cipher che usano prg sicuri unpredictable e in letteratura esistono fondamentalmente due famiglie di string cipher robusti da questo punto di vista che sono la famiglia salsa e la famiglia cia cia non sono buffi però i sono sempre molto originali nella scelta dei nomi dei loro algoritmi anche se sono due famiglie diverse si basano entrambe sullo stesso principio per diciamo per definire il prg perché la differenza fondamentale tra le due famiglie consiste nel modo in cui il prg è definito perché tanto poi la cipher si fa con otp e adesso non ci interessa entrare nei dettagli di come questo funziona però è interessante menzionare quantomeno il modus operandi cioè quali sono e in che modo vengono usate certe operazioni per realizzare il prg perché poi sono le stesse modalità che ritroveremo anche in altre famiglie di cifrari basati su approcci completamente diversi le operazioni primitive che si usano in questo caso sono sempre due sono sempre le stesse una è l'oxor proprio per le sue caratteristiche estremamente simmetriche la tabella di verità dell'oxor si presta a questo tipo di uso e l'altra è l'uso di permutazioni permutazioni nel senso vi ricordate i cifrari per sostituzione che abbiamo visto la settimana scorsa quindi permutazioni definite come operazioni che prendono una sequenza di bit e la permutano cioè la scambiano l'ordine dei bit all'interno della sequenza cioè la fanno diventare una sequenza alternativa ok permutazioni exor sono le due operazioni tipiche che stanno alla base non solo di sars e caccia ma più avanti come vedremo anche alla base di cifrari di tipo completamente diverso qui anche se noi entriamo in dettagli dell'algoritmo l'idea è che per la generazione della stringa pseudo casuale si esegue un ciclo ecco il ciclo for più esterno all'interno del ciclo si combinano le informazioni che abbiamo e all'inizio all'inizio l'unica informazione che abbiamo è il seme il seme a partire da quello si innescono una serie di operazioni basate appunto su permutazioni exor le permutazioni sono note non sono segrete ok cioè le funzioni di permutazione che si utilizzano sono sono note in particolare sia salsa che caccia usano ciascuno la sua sono diverse una funzione di permutazione che lavora sempre su sequenze di 512 bit quella funzione pi che vedete lì è la funzione di permutazione prende una sequenza di 512 bit e la permuta scambia le posizioni dei bit in un modo predefinito le trovate in letteratura nella pubblicazione delle tabelle di permutazione e come vedete quello che succede all'interno dell'algoritmo appunto è di permutare blocchi di 512 bit ed eseguire gli exor in maniera reiterata perché il 5 viene eseguito più e più più volte ok qui in particolare si lavora su appunto blocchi di 512 bit parte dei quali sono dedicati al al seme che è l'unica forzione segreta delle informazioni che vengono utilizzate e da lì si genera una sequenza di blocchi lunga piacere fino ad arrivare ad ottenere appunto una sequenza pseudo random che è il risultato del PRG ok quindi quel ciclo for che vedete è la definizione in pseudocodice del PRG del nostro pseudo random generator e l'output è la sequenza pseudo random che verrà legata in exor col plaintext usando l'idea di ATP questo è il modo in cui esistono esistono a tutt'oggi implementazioni sia di salsa che di ciacia in molti protocolli crittografici anche all'interno di HTTPS ad esempio si usano queste diverse famiglie di di stream cipher va bene due cose ma poi le riprenderemo la prossima volta poi ci fermiamo volevo farvi un confronto secondo me abbiamo parlato di generatori di numeri casuali e abbiamo detto che non sono adeguati per rappresentare PRG perché non sono non sono impredicibili quindi vale la pena spendere due parole su come sul sui generatori di numeri casuali e su come si determina la la la la predicibilità nell'ambito dei generatori di numeri di numeri casuali intanto come funzionano al loro interno i generatori di numeri noi avete un'idea di come funzionano i generatori di numeri casuali perché per un calcolatore non c'è cosa più difficile che generare un numero casuale perché per definizione i calcolatori sono deterministici gli datano input e gli spara sempre lo stesso output e quindi sviluppare un algoritmo che abbia un elemento di casualità che gli consenta di generare una sequenza appunto pseudo casuale non è una cosa banale tant'è che si usano diversi trucchi in genere per inserire iniettare un elemento di casualità all'interno di questi algoritmi sotto forma di input che dovrebbero essere imprendicibili e che poi l'algoritmo va a manipolare fino a sparare fuori la nostra stringa pseudo casuale ad esempio sotto linux l'elemento l'elemento di casualità che viene usato come input per il random number generator sono le latenze associate a determinati eventi quanto tempo passa prima di osservare un certo spostamento del mouse o quanto tempo passa tra l'utilizzo due utilizzi consecutivi dello stesso tasto dalla tastiera quindi eventi che non dipendono dal calcolatore dipendono dall'ambiente esterno e quindi dovrebbero essere impredicibili i dati associati a questi eventi casuali vengono combinati con lo stato interno del generatore di numeri casuali che fa i suoi calcoli e spara fuori l'outfit nonostante questo i generatori di numeri casuali sono comunque predicibili quindi come vedete è estremamente complicato sviluppare un PRG secondo i canoni di sicurezza che abbiamo visto prima essere indispensabili per poter realizzare uno string cipher semanticamente sicuro quindi le cose sono estremamente complesse da questo punto di vista va bene io direi che ci possiamo fermare qui perché poi invece la prossima volta continueremo vedendo nel dettaglio come si valuta la impredicibilità rispetto a questo tipo di meccanismi ci sono domande sì sì sì esatto l'opseudo codice che seguono le due famiglie è lo stesso cambia solo come fatta la funzione di permutazione cambia qualche dettaglio su come funziona la funzione di padding che è quella funzione che serve per creare il blocco che poi va manipolato per ottenere la string a presenza del casuale però sono dettagli tecnici che non ho commentato prima perché c'è un dettaglio tecnico è quella funzione pad che serve appunto per creare una sequenza di 512 bit e che sarà quella che viene manipolata per generare il mio blocco pseudo casuale sono dettagli che cambiano leggermente tra salsa e chacha ma la struttura del pseudocodice è sempre la stessa quindi al netto di pad e pi i due sono equivalenti noi ci vediamo le due che invece parliamo d'altro di applicazioni pratiche cicli prodig Super