Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Ciao a tutti. Buongiorno. Buongiorno. Buongiorno. Buongiorno. Ciao a tutti. Ciao a tutti. Buongiorno. Ciao a tree. Ciao a colleague. Ciao a Bernardo. adesso arriva anche il professor Luca Rossi spero che vi sia stato utile intanto questa prima lezione se avete dei suggerimenti di aggiustamento è il momento giusto per farli presente altrimenti continuiamo con questo andamento oggi immagino che ci avvicineremo di più alle applicazioni di studio sui social media però vediamo che cosa ci ha preparato Luca intanto io posso dire che ho modificato i due file di lezione, l'HTML dei due file di lezione perché adesso i commenti non sono più nascosti il che significa che vedete anche le librerie che è il package come li chiama AR che servono però un secondo solo che Luca mi dice che sta arrivando allora a Ok, ci siamo. Ok, ci siamo. Qui, essendo in un'aula un pochino rimbomba. Mi puoi abilitare a condividere lo schermo? Ok, eccoci. Mi puoi abilitare a condividere lo schermo? Va bene, dai, proprio perché sei tu. Allora. Ok, sei co-host. Non ho co-host. Fammi vedere un po' che cosa può fare un co-host. Oggi avevamo una riunione con il rettore. A un certo punto credo ci sia stato uno zoom bombing perché è partita una voce meccanica che raccontava cose. Non ho ben capito. Ma contro l'ITU? Ah, non lo sai perché giustamente era in una lingua attenta. No, no, no, era in inglese, però non si capiva, era un gran casino. Sembrava tipo un bot di assistenza per prodotti Microsoft, ma non era chiarissimo cosa stesse parlando. Non capita. Allora, mi rivolgo a Luca Cinti. Aspettiamo ancora qualche minuto. Partiamo. Mi sentite? Sì. Ok, bene. A volte le cuffie vi danno problemi. Che io sappia, siamo tutti, adesso mi manca l'appello Luca... Non mi ricordo, siamo un altro Luca. Un altro Luca. Sì, però... Non so, non vado a sapere. Magari mi hanno contestato. Facciamo una cosa. No, va bene, non volevo stalkerarlo fino a questo punto, era solo una curiosità. Ecco. Dicevo, prima che entrassi Luca avevo già chiesto ai presenti se c'erano dei suggerimenti su... quello che era stato fatto fino a questo momento, mi è sembrato di capire che il ritmo fosse adatto a quello che loro si aspettavano e quindi direi che possiamo procedere come previsto. Sì, voi eventualmente... Sì, scusa, scusa, mi ho dato anche del tutto. Ho fatto bene. Eventualmente se abbiamo problemi, interrompiamo nel mentre, facendoci aspettare. Assolutamente sì, ma se avevate proprio un suggerimento dicendo andiamo più piano, andiamo più veloce, allora ci si adattava. Però se il ritmo è ok, poi dopo ovviamente potete interrompere quando volete per qualunque tipo di dubbio che vi venga in mente. Se siamo pronti, io darei la parola al professor Luca Rossi e sono curioso anch'io di vedere che cosa ha preparato per noi. Voi vedete la mia schermata di RStudio, giusto? Sì. Ok. Allora, oggi l'idea è di fare un passo più nella pratica del social network analysis applicata ai dati da social media, che, ci tengo a precisarlo, è una cosa, non dico una disciplina, ma comunque un sottoambito che ha alcune cose, alcune particolarità, un po' dovute alla natura dei dati, e che si è sviluppato più di recente rispetto ad altre applicazioni della social network analysis o della network analysis in generale. La network analysis viene continuamente usata in contesti diversi, adesso se dovessi dire dove sarà il grosso sviluppo nei prossimi mesi, se non anni è probabilmente legato a dinamiche di life science, social network analysis e medicina, ci sono molti, molta ricerca in questi ambiti, promettente, non promettente, non sono in grado di dirlo, però sicuramente c'è molta attenzione. E, ad esempio, in quel caso si ha a che fare con tipi di dati di reti strutturalmente diverse, ad esempio la densità di quelle reti è diversa, le distribuzioni del grado sono diverse. Quando parliamo di reti applicate ai social network, normalmente non abbiamo a che fare con reti che sono enormemente diverse, perché si comportano più o meno come reti normali, reti sociali che abbiamo osservato offline. Ci troviamo di fronte a reti che sono molto più larghe, molto più grandi, spesso con molti più nodi, quindi anche con molti più archi. E questo, portato all'estremo, ha degli aspetti, diciamo, problematici da un punto di vista computazionale, perché non tutte le cose si possono fare con la stessa agilità, pensate alcuni metodi sono stati sviluppati quando le reti potevano avere, non so, 60-100 nodi, quando hai 4 miliardi di nodi, quindi alcune cose non scalano così bene. Altre cose sostanzialmente ha più a che fare con l'interpretazione che diamo dei risultati e non con, né con la struttura della rete, né con, diciamo, la pratica computazionale sottostante. Comunque, non volevo usare troppo tempo sull'aspetto di raccolta dei dati. Oggi lavoriamo con dei dati di Twitter, perché credo che poi Fabio imposterà il corso molto su dati di Facebook, quindi giusto per farvi vedere una diversità, ma cercando anche di capire i tratti comuni o comunque come possiamo pensare alcune cose in comune. Non vorrei farvi raccogliere a voi i dati, giusto per saltare una parte, per cui se passate, dovreste avere un nuovo file HTML dove si vedono tutti i package che vengono lanciati questa volta. Dovreste avere ricevuto anche un file che si chiama lezione2.rdata. I file rdata sono uno dei vari modi in cui potete salvare e condividere dati di R. Questo sostanzialmente salva tutti i dati che trovate nell'environment qua. È il file che ottenete se quando siete in RStudio cliccate salva e salvate. E in questo file rdata che potete o caricare manualmente da qua o caricare con load e il nome del file, ammesso che siate nella working directory giusta, dovreste trovare sostanzialmente un oggetto che si chiama tweets, che è un data frame che contiene 4000 errori e osservazioni e 90 variabili. Lo vedete da qua. Se volete provare a raccogliere dati tweet da soli, vi lascio qui commentato, ma che potete scommentare agevolmente il codice. Questo codice qui è basato su un package che è rtweet, che carichiamo qua all'inizio, e in questo caso fa una ricerca di tweet live, usando gli streaming API. Adesso prende dei tweet sostanzialmente mentre vengono prodotti. Quando ho preparato questa lezione ho guardato cosa c'era in trending topic in Italia e non c'era granché, e quindi i dati per la lezione di oggi sono l'hashtag tweetamibeautiful, che stava andando in onda in quel momento, e quindi il contesto è gente che twitta guardando beautiful in televisione. è un esempio come tanti. È un esempio utile perché non sono troppi tweet, e quindi non abbiamo problemi da un punto di vista delle dimensioni dei grafi che creeremo. Comunque, se volete provare, una volta che vi siete creati un account su Twitter, ammesso che non l'abbiate, potete semplicemente vi utilizzare questo codice così com'è, semplicemente cambiando qui l'hashtag che volete cercare, e senza aver bisogno di API eccetera, fare un'autenticazione tramite il vostro browser, quindi vi aprirà una finestra del browser che vi chiede di fare il login su Twitter. Una volta che avete fatto questo, vi scarica i dati, è molto semplice e non ci sono grossi inghippi. Però, diciamo, noi partiamo dall'idea che i dati li abbiamo già scaricati, così saltiamo una parte della complessità. Vediamo però, e questo è utile, come ci arrivano i dati, perché noi abbiamo Twitter che ha delle API, adesso Twitter ha un sacco di, un paio di versioni diverse di API. In questi dati qui, come vedete, hanno 90 colonne, quindi sono dati che contengono un sacco di informazioni. Potete vederli, però sostanzialmente sono un data frame, una grande tabella con alcune informazioni che ci interessano, molto importanti, non so, lo user ID, lo status ID, che sono ID sia dell'utente che del tweet, una data, uno screen name, il test effettivo del tweet, la source del tweet, un sacco di informazioni. Se volete vedere l'elenco completo delle colonne, in R potete scrivere names e il nome dell'oggetto, nel caso sia un data frame, vi dà l'elenco di tutte le colonne. Come vedete, c'è l'imbarazzo della scelta. Alcune di queste sono molto interessanti, altre sono meno, ma diciamo, l'interesse poi dipende un po' da quello che ci volete fare. e noi quello che ci vogliamo fare è essenzialmente costruire delle reti. Perché, se ci pensate, il problema è quello che abbiamo detto l'altra volta. La rete la costruiamo un po' come ci pare a noi. Una volta che siamo noi che decidiamo quali sono i nostri attori, quali sono i nostri archi, la rete la costruiamo come vogliamo. Quando lavoravamo con l'esempio della rete costruita dal trono di spade, vi ho detto due personaggi sono collegati se hanno interagito nel libro l'uno con l'altro. Quindi, in un qualche modo, il processo, il pre-processing dietro a quella rete è stato sostanzialmente creare uno script che andava attraverso tutto il testo e se i nomi dei due personaggi apparivano all'interno della stessa frase, mi pare che forse, non l'ho fatto io, mi pare che fosse così, venivano collegati. O qualcosa del genere, diciamo. Comunque, il punto è che dobbiamo creare o decidere noi che cos'è che costruisce i nodi, che cos'è che costruisce gli archi di questa rete. Perché i dati Twitter, che avete visto, non ci arrivano come una rete, ci arrivano come un data frame, ci arrivano come una tabella. Per cui è un po' un problema. Il punto è che noi possiamo fare un sacco di reti. Perché non abbiamo un tipo solo di reti, abbiamo un sacco di reti che volendo possiamo costruire. Possiamo costruire un sacco di reti nel senso che possiamo costruire reti partendo da un sacco di dati o possiamo anche costruire tipi diversi di rete. Cerchiamo di raccontare un attimo. La rete più semplice che possiamo immaginare è quella che si chiama tecnicamente un simple graph. E noi chiamiamo simple graph un grafo che ha dei nodi, degli archi, ovviamente, ma non ha self loop e gli archi sostanzialmente rappresentano un unico tipo di relazione. Quindi un simple graph è normalmente il grafico in quale abbiamo lavorato l'altro giorno. Abbiamo un tipo solo di attori, un tipo solo di relazioni e non permettiamo che un attore sia collegato con se stesso. Abbiamo una serie di vincoli per poter chiamare una cosa un simple graph e questo è, siamo alla cosa più semplice. Poi però possiamo avere, e spesso capita, l'esigenza di lavorare con grafi un po' diversi perché magari la cosa che vogliamo rappresentare come una rete non ci basta avere un solo tipo di attori. Vogliamo avere due attori o tre tipi di attori o quattro tipi di attori. Allora queste reti qui sono un'altra famiglia, se volete, di reti e si chiamano reti n partite, diciamo. Sono reti bipartite se abbiamo a che fare con due tipi di attori, sono reti tripartite se abbiamo a che fare con tre tipi di attori e non so, immagino che ci siano anche delle reti quadripartite anche se non ho mai vista una, ma tecnicamente è possibile. Aspetto, la regola, se volete, di una rete bipartita, per potersi chiamare tale, è che abbiamo due tipi di attori e quindi abbiamo, non lo so, persone e film, pensate alle reti di raccomandazioni con le quali può lavorare una cosa tipo Netflix che collega utenti a prodotti. Quindi tu sei collegato a una serie tv nel momento in cui hai guardato quella serie tv. Però è una rete bipartita perché abbiamo due tipi di attori diversi. da un lato utenti e dall'altro prodotti serie tv o film o quello che vi pare. La regola delle reti bipartite, siccome le reti bipartite, è che le connessioni possano avvenire solo tra attori di tipo diverso. Quindi se ho una rete bipartita, nella mia rete bipartita, ci saranno solo connessioni che vanno da attori a prodotti mediali, se è Netflix a quello che vi pare. Quindi questo è come gestiamo la moltiplicità di attori e poi vediamo perché facciamo così. Però l'importante è ricordarsi che in una rete bipartita, per essere tale, non ci sono solo due tipi di attori, ma ci sono anche relazioni che possono andare solo dal tipo di attore A al tipo di attore B. Altrimenti non è una rete bipartita. Un'altra cosa che possiamo avere è avere il bisogno di gestire tipi diversi di relazione. Ad esempio, non ci va bene avere una rete dove c'è solo un tipo di relazione. Mettiamo il caso c'è solo la relazione amicizia, ma vogliamo avere una rete dove abbiamo la gente che va d'accordo e la gente che si odia e vogliamo avere le due relazioni nella stessa rete. Non vogliamo costruire due reti diverse. Potremmo costruire due reti diverse, ma invece diciamo proviamo a lavorare con queste reti come se fossero in una stessa rete e quindi creiamo quella che si chiama una rete multiplex, dove multiplex significa che gli archi hanno un valore diverso. Le reti multiplex sono una gigantesca famiglia che va dalle versioni più semplici delle reti multiplex che si chiamano signed network dove sostanzialmente attribuisci un valore positivo o negativo all'arco, quindi gli archi sono sì di tipi diversi ma sono solo di due tipi, uno è positivo e uno è negativo e gestisci con questa diciamo polarità alcune dinamiche interessanti. Una volta che hai una signed network puoi cominciare a modellare situazioni tipo beh, il nemico del mio nemico è mio amico o situazioni simili sono molto usate in ambiti anche di simulazione di natura economica per transazioni debiti eccetera. Ma potete anche pensare di avere multiplex con n relazioni, n tipologie di relazioni. Potete avere delle multiplex dove ad esempio questa è una tesi che sto supervisionando adesso utilizzando del machine learning ogni tweet tra due autori è stato ricondotto a un sentiment di qualche tipo su una scala di dieci sentimenti diversi e quindi si crea una multiplex con dieci possibili relazioni dove i tweet possono essere tweet di odio tweet di amore tweet di supporto tweet di knowledge exchange e così via. È chiaro che la capacità che hai di rappresentare meccanismi complessi aumenta ma aumenta anche la complessità del modello sottostante quindi poi è una cosa che va un attimo un attimo valutata. Non lavoreremo con reti multiplex oggi perché iGraph non le supporta di fatto e quindi non ci facciamo molto ma lavoreremo con reti bipartite a un certo punto. Però torniamo indietro cerchiamo di costruire una rete normale tanto per iniziare cioè cerchiamo di fare il primo passaggio che è quello che va dal nostro dal nostro file di tweet diciamo dal nostro data frame che contiene i nostri 4000 tweet su beautiful a un qualche tipo di rete. Allora io adesso vi faccio vedere un pezzo di codice mi sono reso conto che questo codice qui è un codice R un po' particolare perché è scritto utilizzando delle pipes che sono queste queste cose qua che sono introdotte da un package particolare di R quindi non appartengono diciamo al modo tradizionale di scrivere di scrivere codice codice in R comunque quello che fa una pipe è semplicemente prendere l'output di una prima funzione e buttarlo come input della riga successiva quindi è giusto per rendere il codice secondo me più leggibile quindi quello che quello che facciamo adesso è prima partendo dal nostro data frame che ha 90 colonne e sono decisamente troppe non ce ne facciamo niente ne prendiamo solo alcune quindi prendiamo innanzitutto vogliamo costruire il nostro obiettivo è di costruire una rete di retweet ok quindi prendiamo prima solo le colonne che sono retweet quindi quelle che hanno un retweet count maggiore di zero poi prendiamo scusate le righe che sono retweet cioè prendiamo solo i tweet che hanno un retweet count maggiore di zero poi prendiamo solo le colonne che ci interessano per costruire questa rete cioè lo screen name e il mention screen name siccome il mention screen name è una lista quindi può contenere molti mention screen name noi la annestiamo la esplodiamo e poi dopo togliamo diciamo quelli dove il mention screen name è uguale a zero perché lì non sapremo cosa ci mette metterci quindi se guardiamo dopo la nostra parte filtering prima di fare il graph data frame il nostro output è sostanzialmente questo qua uno screen name che è da dove parte il tweet e un un mention screen name che è il personaggio menzionato nel nel retweet a questo punto abbiamo sostanzialmente tutti gli elementi come abbiamo visto ieri che ci servono per fare una per costruire una rete cioè abbiamo una edge list con due due un from e un to a questo punto abbiamo l'ultimo nostro comando che questo viene da da igraph che dice graph from data frame cioè costruisce un grafo a partire da una struttura di data frame dove directed è vero e quindi noi lo rifacciamo e l'abbiamo chiamato questo grafo rtg per retweet graph se Luca ti interrompo un secondo perché volevo introdurre una riflessione molto veloce su la scelta che è stata fatta di fare una rete sulla base degli screen name allora una delle cose che dovete sapere è che di solito gli screen name tendono a essere modificabili nel tempo quindi supponiamo supponendo di avere di voler costruire una rete con dati che durano per con tweet reperiti nell'arco di mesi settimane o anche eventualmente tempi più brevi esiste il rischio che un utente abbia nel frattempo cambiato lo screen name e quindi ci può falsare la relazione per evitare questo noi non lo facciamo in questo caso perché ovviamente rende tutto solo più complicato si può utilizzare l'id del user id da una parte e l'id della persona menzionata dall'altra in modo tale di avere dei riferimenti stabili nel tempo chiaramente quando poi hai una rete con user id è meno leggibile lì per lì quindi a te dopo diciamo per noi oggi è più semplice avere una rete dove c'è tipo freaking silence invece che una rete dove c'è 12345 diciamo semplicemente più friendly da un certo punto di vista però se guardiamo soprattutto in certi contesti lo screen name non è non è stabile quindi quello è un problema a questo punto voi avete una volta che il grafo il codice contiene anche la parte graph from data frame possiamo vedere questo rtg e vediamo che iGraph ce lo riconosce come un grafo come ci aspetteremo vediamo che è un grafo diretto che contiene 330 330 nodi e 1809 archi un altro grafo che possiamo fare e che invece in questo caso è un grafo bipartito che si può fare che si fa a volte quando si lavora con i dati di twitter è un grafo che collega gli utenti agli hashtag cioè noi vogliamo sapere quali utenti hanno usato quali hashtag chiaramente tolto l'hashtag che è stato usato in questo caso per raccogliere i tweet perché quello diciamo l'hanno usato tutti per definizione abbiamo usato quell'hashtag per raccogliere i tweet quindi lo togliamo se guardiamo il codice che è molto simile in realtà selezioniamo gli screen name e gli hashtag perché in questo caso non abbiamo bisogno di filtrare perché non abbiamo più la dinamica dei retweet togliamo facciamo l'annest degli hashtag perché anche qui gli hashtag appaiono come una lista e filtriamo l'hashtag dopo averlo messo tutto in caratteri minuscoli in modo da togliere sia tweetami beautiful collati grande tweetami beautiful collati piccola eccetera però il processo è concettualmente molto simile se lo guardiamo fino a qui dove abbiamo una rete dove abbiamo screen name e hashtag scusi scusi un attimo mi dà errore quando provo lanciare il comando quello lì la pipe sul comando unnest tu unnest hai immagino anche un eh immagino anche un pacchetto hai caricato tidyverse no dove lo devo allora unnest è di un library di una library che si chiama tidy r che però ti dovrebbe caricare se tu fai library tidyverse ti dovrebbe caricare eh tutti i package diciamo di questo mega coso che si chiama tidyverse che sono una serie di pacchetti eh tra questi ci dovrebbe essere anche eh eh quello che contiene a unnest ok comunque se ce l'avete lo dovreste vedere perché nel momento in cui iniziate a scrivere eh unnest vi dovrebbe apparire unnest e vi dovrebbe far vedere a quale a quale package appartiene ok adesso devo cercare questo tidy eh sì grazie questa questa questo qui è la nostra è sostanzialmente la nostra ehm la nostra edge list che quindi possiamo usare in in iGraph per costruire un grafo e adesso il nostro eh H che sta per hashtag e G che sta per un grafo ce l'abbiamo e abbiamo 355 ehm 355 utenti non è vero 355 tra utenti e hashtag che sono collegati da eh 714 eh archi allora mh normalmente a questo punto se volete possiamo fare un piccolo esercizio se la cosa diciamo quanto tempo abbiamo diciamo un attimo può essere anche senza che lo facciamo col codice ma lo facciamo concettualmente possiamo chiedereci ok abbiamo due reti una degli hashtag una hashtag utenti e una utenti utenti che si sono retweetate come le descriviamo ieri abbiamo visto un po' di modi per descrivere delle reti riusciamo a pensare come descrivere queste reti per descrivere intendi così per dare dei un po' di metriche che ci facciano capire che cosa come sono fatte queste reti internamente ieri abbiamo visto un po' di modi un po' di di metriche beh sì possiamo usare le varie metriche quelle ad esempio il numero di comunicazioni per nodi la closeness between una cosa del genere possiamo usare possiamo usare la degree ad esempio possiamo fare diciamo vedere le nostre densità che abbiamo visto ieri come anche oggi come ieri vediamo che abbiamo delle densità molto basse che sono reti sparse possiamo calcolare la degree di tutte le due reti cioè di tutti gli attori perché la degree è una misura dell'attore e quindi calcolarla per gli attori delle nostre reti possiamo fare vedere la distribuzione della degree di una delle due ad esempio in questo caso la distribuzione della degree di quella dei retweet e vedete che è estremamente schiuto è un po' schifo questa visualizzazione adesso ve la fate andare bene però è molto molto molto schifo abbiamo sostanzialmente tutti gli attori verso verso zero e molti pochissimi con una degree molto alta quindi però abbiamo un po' di abbiamo un po' di elementi che ci possono aiutare a capire come sono come sono fatte queste queste queste queste reti possiamo anche provare a esplorarle così visivamente queste sono reti di dimensioni piccole quindi non ci sono grossi problemi link più edge punto answering 백 client al adesso vedere sign con dire dire non par dire sorry dire note police Andrew Ok, ad esempio, giusto per... Vediamo qualcosa che ci dice, o forse non ci dice molto, però... Questa è una cosa un po' strana, scusate. Ok, perché... Dovete sapere che ggplot è, diciamo, una delle cose più potenti e più difficili di... Ecco, questa è meglio, visualizzazione, diciamo, è sbagliato semplicemente comando. Ad esempio, così, a occhio, guardandola, vediamo ad esempio alcuni dei discorsi che abbiamo fatto ieri sul numero di componenti. Vediamo che, sì, questa è una rete che abbiamo raccolto con dei tweet usando un hashtag solo, ma è chiaramente, ad esempio, divisa in componenti. C'è un componente più grande, abbastanza connesso con vari scambi, c'è un componente più piccolo che essenzialmente si tratta di persone che hanno retweetato un personaggio, o un personaggio che ha retweetato una serie di altre persone, e poi abbiamo una serie di diadi, diciamo, micro componenti con due nodi e una componente con tre nodi. Quindi, comunque, abbiamo già un'idea di questa... alcune delle dinamiche qua. Se vogliamo fare la parte con gli hashtag, ecco, un po' diversa. Questa è molto più semplice capire perché è visualizzata così, che d'altra parte abbiamo due tipologie diverse, e comunque abbiamo tutti utenti e tutti archi. In questo caso non ci dice molto, se non che vediamo anche qui un qualche tipo di struttura a componenti, anche se è un po' più difficile da vedere. Ok, ora cerchiamo di... Quello che volevo ragionare oggi, invece, era l'aspetto di community detection, per prima cosa. Perché community detection se ne parla molto, è una cosa che tutti vogliono fare quando hanno a che fare con le reti, è trovare le comunità, e quindi giusto per dare un'idea di che cosa parliamo quando parliamo di community detection. iGraph? Aspetta, aggiungo solamente una cosa. Ovviamente, una delle altre possibilità è quella di pensare a modellare una relazione fra utente e URL che ha twittato. Vi dico questo perché, diciamo, questo poi alla fine, in un certo senso, è il cuore di Cornet, e lo vedremo meglio in seguito. Concettualmente non cambia niente, cioè nel senso uno modella la relazione tra un utente e un link, modella la relazione tra un utente e un hashtag, modella la relazione tra un utente e un altro utente. Cominciamo prima, a un certo punto, molto inizialmente, inizialmente siete voi a decidere che cos'è che costituisce questa rete, voi o, insomma, qualcuno a un certo punto. E quindi, poi la rete è quella cosa lì, qualcuno modella la relazione tra utente e link, modella la relazione tra utente e golf club, modella la relazione tra utente e hashtag, o tra utente e altro utente. Alcune sono più dirette, altre sono dirette. Se modelliamo la relazione tra entità della stessa natura, abbiamo a che fare con una rete normale, con un grafo normale, se modelliamo la relazione tra entità che non sono della stessa natura, ma sono una persona, un account e un link, abbiamo a che fare con una rete bipartita. Ed è bipartita perché concettualmente il link non può linkare un altro link. Cioè, non esiste, non troverete mai nei vostri dati se avete utenti che hanno condiviso qualcosa, un qualcosa che ha condiviso un utente. Quindi è una rete bipartita, o un link che ha condiviso un altro link, chiaramente. Tornando sull'aspetto community detection, tutti hanno una buona idea di stomaco, di che cos'è una community, ma in realtà che cos'è una community è una questione piuttosto complicata. È complicata, diciamo, dal punto di vista della teoria sociologica, se volete, ma è abbastanza complicata anche dal punto di vista della teoria delle reti. perché un po' come con centralità, bisogna capire che cos'è che costituisce effettivamente una comunità, come lo possiamo misurare e come vogliamo, e qual è l'idea di comunità che abbiamo in qualche modo iscritto in una metrica piuttosto che in un'altra metrica. Allora, tendenzialmente c'è una qualche forma di consenso, dico qualche forma perché ci sono chiaramente dei metodi che si basano su altre idee, che una comunità, quando osservata sulla rete, mostri delle caratteristiche strutturali in modo tale che abbia più connessioni all'interno della comunità che connessioni tra l'interno della comunità e il resto della rete. Questa è l'intuizione. Se io ho a che fare con una comunità e osservo una comunità sulla rete, questa comunità, per essere tale, deve avere più connessioni al proprio interno rispetto, tra i membri della comunità, rispetto alle connessioni che i membri della comunità hanno con il resto della rete. I membri della comunità non sono completamente isolati dalla rete, perché altrimenti abbiamo a che fare con un componente e non con una comunità, ma ci deve essere una densità, se volete, interna a questo gruppo, a questo subset di nodi, maggiore di quella che posso osservare tra il subset di nodi e l'esterno della rete, e il resto della rete. Questa idea è catturata da una metrica che si chiama modularità, modularity. immagino che in italiano sia modularità. E quello che la modularity misura è essenzialmente, dato un set di nodi, i nodi che questi, gli archi che questi nodi condividono all'interno di questo set, rispetto agli archi che ti puoi aspettare che condividano per condivisioni random all'interno dello stesso set di nodi. Cioè, più la mia divisione in set crea più nodi, più condivisioni, più connessioni interne rispetto a quelle che mi posso aspettare casualmente, allora più il mio punteggio di modularità, il mio score di modularità sarà alto. Molti degli algoritmi di community detection con i quali abbiamo a che fare oggigiorno, quello che fanno sono di fatto algoritmi che cercano di ottimizzare la modularità. Cioè, provano in maniera più o meno smart, diverse configurazioni di set di nodi, misurano la modularità e si muovono sempre verso un punteggio più alto possibile di modularità. Una volta che non riescono a produrre una modularità più alta, dicono, ok, questo clustering, questi diversi set di nodi, è il risultato della mia community detection. E te lo do associato a un punteggio di modularità che sostanzialmente ti dice quanto quei nodi lì sono connessi internamente più che essere connessi con il resto della rete. Quindi potete usare la modularità come una metrica di qualità rispetto al risultato della community detection. Community detection vi dà sempre un risultato, ma poi ve lo dà magari con una modularità molto bassa perché quella rete non è riuscita a trovare a trovare niente, cioè trovare un valore maggiore. Ci sono altri altri metodi, alcuni come un metodo che usiamo oggi che si chiama edge betweenness che è basato sull'idea se vi ricordiate la betweenness centrality cioè che è il numero di shortest path che passano attraverso un nodo beh, concettualmente ci potete pensare facilmente quella metrica lì si può calcolare anche per gli archi cioè il numero di shortest path che passano attraverso un arco invece che passare attraverso un nodo. Con l'edge betweenness puoi pensare a un meccanismo per cui dici ok se questo questo arco qui ha un'elevatissima edge betweenness come dicevamo ieri a proposito della betweenness centrality se un arco ha un edge betweenness molto elevata cosa significa? Significa che terrà insieme parti della rete che non che altrimenti sarebbero staccate se quelle parti della rete altrimenti sarebbero staccate e invece devono passare da questo edge per essere collegate significa concettualmente pensateci un attimo che quelle parti della rete tra di loro hanno molti archi in comune ma una parte con l'altra hanno poche connessioni perché altrimenti l'edge betweenness non sarebbe così alta e quindi quello che fa l'algoritmo di edge betweenness è tagliare sostanzialmente questi archi con l'edge betweenness più alta fino a che non arriva a una decomposizione della rete poi c'è un metodo per cui sceglie qual è la decomposizione ottimale e dice questo è il mio risultato ci sono vari altri metodi se avete voglia nella documentazione di iGraph trovate la lunga lista di community detection algorithms che include alcuni sono più interessanti altri sono sostanzialmente molto di nicchia se avete voglia potete leggere le descrizioni di infomap che è un algoritmo molto recente che è anche molto bello per come è pensato però diciamo più o meno l'idea di quello che cercano di modellare è sempre la stessa allora se noi vogliamo applicare un algoritmo di community detection quello che facciamo è sostanzialmente chiamare la funzione in iGraph in questo caso allora se io lo faccio senza assegnare il risultato a niente vedrete che ottengo varie cose out è un punteggio di modularità ottengo un numero di gruppi di comunità che vengono identificate e ottengo una lunga una lista un oggetto lista che contiene l'elenco di tutti di tutti i cose in realtà l'output di community detection di iGraph è un output complesso che è composto da tanti sotto oggetti di noi lo non così mi incasina tutto lo assegniamo a un oggetto così lo possiamo esplorare con comodità e possiamo vedere non so gli archi rimossi perché questo qui che abbiamo lanciato era l'edge betweenness l'unione delle varie comunità eccetera eccetera possiamo vedere anche membership che è quello che ci interessa particolarmente perché membership ci dà per ogni nodo nella nostra rete il numero l'ID della comunità espresso con un numero al quale il nome il nodo appartiene quindi sappiamo che il nodo numero 1 appartiene alla comunità 1 il numero 1 appartiene al numero 2 appartiene alla comunità 1 il nodo numero 3 appartiene alla comunità 2 e così via per tutti i nostri nodi della rete ora se vi ricordate quello che abbiamo detto rispetto a come iGraph indicizza i gli attori della della nostra rete beh noi possiamo prendere questo risultato qui che è quello che abbiamo nell'oggetto con membership e metterlo come un attributo sui nostri nodi a questo punto se noi guardiamo il nostro RTG vediamo che il nostro grafo che prima aveva solo name e degree adesso contiene anche com e b che è il risultato della community detection ottenuto con l'age betweenness che abbiamo messo noi possiamo fare la stessa cosa con un altro con un altro algoritmo in questo caso l'algoritmo si chiama l'uven ed è un algoritmo di ottimizzazione della modularity lo mettiamo in un oggetto che chiamiamo com low e poi mettiamo membership lo mettiamo dentro il nostro attributo che chiamiamo com low così adesso il nostro grafo di g avrà due attributi nuovi uno che contiene il risultato della edge betweenness e uno che contiene il risultato del l'uven della community detection ottenuta con l'uven a questo punto la domanda sorge spontanea chi ha ragione e guarda ottengono lo stesso risultato perché l'uven mi dà un risultato e se guardiamo il nostro com l'uven sappiamo che ad esempio ottiene 13 gruppi e una modularità di 0.37 se guardiamo il nostro risultato di com e b otteniamo 14 gruppi e una modularità di 0.2 chi ha ragione? chi è che è meglio? uno dice da un punto di vista della modularità è meglio l'uven però chiaramente l'uven è un algoritmo che quello fa ottimizzare la modularità se proprio tira fuori anche la modularità più bassa sarebbe un algoritmo proprio fatto male allora il punto è questo una cosa che possiamo fare è comparare questi due questi due algoritmi ora non so se siete familiari con una metrica che si chiama normalized mutual information si usa in machine learning a volte comunque la normalized mutual information è un modo per misurare la similarità tra due due clustering cioè tu prendi x elementi li dividi in due clustering diversi e poi vuoi sapere quanto sono simili questi due clustering è un metodo che è implementato in iGraph e che possiamo usare con questa funzione compare compare dove vuole come argomenti i risultati gli output di due community detection quindi com eb e com lù e come metodo ne vede parecchi ma adesso noi usiamo nmi che è questa normalized mutual information e ci dà uno score è facile da leggere perché ci dà uno score tra 0 e 1 e ci dice che i due i due le due community le due community structure i due i due modi di dividere la rete in comunità si assomigliano 0.64 si assomigliano ma neanche troppo ecco quindi da una parte abbiamo un risultato e dall'altra parte abbiamo un risultato che è significativamente diverso non è uguale sono proprio diversi cioè non è solo che abbiamo una comunità in più e quindi magari non so l'UVN che crea 14 comunità invece di crearne 13 ha staccato due nodi che erano poco poco collegati e li ha messi da parte li ha messi in una comunità da sola mentre tutto il resto è lo stesso qui siamo di fronte a due algoritmi che ci offrono due risultati di community detection sostanzialmente diversi a questo punto il punto è chi ha ragione e chi ha ragione non ve lo dico io perché non lo so e non ve lo dice nessun algoritmo perché non lo sa neanche lui cioè il problema è questo noi in certi casi quando facciamo community detection di solito abbiamo un'opzione che in realtà non si verifica mai che è da un lato abbiamo un ground truth cioè un'informazione su qual è la verità della community structure che stiamo cercando di di studiare se io faccio community detection su dei dati twitter di politici italiani posso pensare che l'affiliazione dei politici ai vari partiti sia un qualche tipo di ground per vedere se però non è esattamente quella cosa lì quando faccio community detection su twitter dati che non conosco di fatto non ho nessuna informazione per sapere qual è la vera comunità ho un risultato non ho una vera comunità possiamo anche visualizzarle giusto per capire di cosa stiamo parlando questa visualizzazione adesso non ci va troppo però giusto per vederla ah fatta da qua non me la fa vedere scusate la vedete qua adesso ci sono delle cose che chiaramente la comunità chiaramente gli algoritmi hanno identificato nella stessa maniera cioè le i componenti sono stati presi come comunità a sé stanti ma ci sono altre differenze all'interno del major component che sono sostanzialmente diverse e questo diciamo in un qualche modo non abbiamo una risposta a qual è la cosa migliore non sappiamo che non sappiamo se l'edge betweenness ha più senso o se ha più senso l'uven quello che possiamo fare è sono due cose una è una valutazione manuale che adesso vi vorrei provare a far fare e l'altra è una una valutazione di natura concettuale cioè pensando rispetto al tipo di dati che abbiamo ha più senso un algoritmo che funziona tagliando gli edge betweenness sulla base dell'edge betweenness del grafo o ha più senso un algoritmo che funziona aggregando sostanzialmente dal basso verso l'alto aggregando nodi assieme puntando a ottimizzare la modularità poi ci sono altre considerazioni pratiche che possiamo fare l'edge betweenness siccome si basa sul calcolare l'edge betweenness ad ogni step è un algoritmo che è enormemente time consuming perché scala veramente molto male che tutte le volte che deve farlo deve ricalcolare l'edge betweenness per il grafo intero e questo va fatto tutte le volte la modularità viene fatta in maniera un po' più smart e quindi ad esempio è molto più veloce ora io diciamo da usare anche come attività durante la pausa vorrei che voi scriveste salvaste i due grafi come dei file excel cioè dei file gefi quindi questo per retweet e che non ha fatto diciamo questo scusate cosa che non mi piace ok vabbè insomma non mi capisco un attimo perché vai te lo ti allora grafi file format ok e quest'altro per niente sostanzialmente questo qui esattamente quando lo salvate lo trovate come rtgraf nella vostra cartella e lo potete aprire adesso vi condivido lo schermo di gefi se me lo fa vedere qua a questo punto vedete gefi vero ok a questo punto potete usare la visualizzazione di gefi potete scegliere un layout qualunque questa è una rete piccola non ci dovrebbero essere problemi tranne il mio gefi che ha problemi di suo ma quello che potete fare è andando qua dove c'è l'appearance del grafico la parte di visualizzazione del grafo scegliere partition scegliere uno dei due attributi di comunità magari prendete una palette un po' più lunga di questa questa e vederlo visualizzato vediamo un po' se un altro algoritmo è più veloce ok e vederlo visualizzato una volta che l'avete visualizzato potete cercare di esplorare prima la parte partition offerta da eb edge between e poi la partition offerta da l'uven e cercare di capire qual è la differenza facciamo 10 minuti di pausa e mi sembra un ottimo modo per usare questo tempo ricordate che per vedere chi è chi selezionate questa parte qui con il punto interrogativo e cliccate e cliccate sopra poi probabilmente immagino dopo scondo immagino magari mi sbaglio che non siate familiari con twittami beautiful come hashtag su twitter quindi quello che potete fare è copiare incollare questi nomi e cercare di capire chi sono quali oppure farvi ispirare dai nomi diciamo dalla cosa però la cosa interessante è cercare di capire perché il risultato del community detection è così diverso perché pensate adesso giusto poi dopo sto zitto che ho bisogno di bere un attimo ma se vi dico fatemi una community detection voi avete n algoritmi là fuori che vi fanno la community detection a questo punto la domanda quale scegliete è una domanda a cui secondo me qualcuno a un certo punto deve rispondere perché poi la valutazione di queste cose di fatto è un po' è fatta manualmente e quindi non è non è così semplice poi potete anche dire tutti usano l'uven cosa che tendenzialmente è vera usiamo l'uven anche noi però l'importante è sapere o almeno capire che cosa c'è sotto facciamo dieci minuti di pausa e poi riprendiamo ok anche io vado a prendere una bottiglia d'acqua e ritorno a dopo tra Co di Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Cintanto ci facciamo un po' di fatti di Luca Rossi leggendo i suoi messaggi su Slack. Posso fare una domanda nel caso? Peraltro ci sono una serie di esperti in questo Slack, che riconosco dei nuovi di social network analysis, poi anche questo collega che si chiama Mille Koscia, che è uno dei più riconosciuti esperti di Slack. Grazie. Mi sono perso una cosa, ti l'hai auto usato per vedere il grafico? Su Gefi? Sì. Credo forse Atlas 2. Di solito usiamo quasi sempre quello. Anche se è parecchio veloce non so esattamente che cosa abbia usato, ma penso forse Atlas 2. Perché ci sta impiegando un po'. Non so allora se era quello, perché è un certo punto, o forse Atlas normale. Perché ho visto che anche da lui all'inizio, il primo che aveva scelto, mi sembrava poco reattivo. Però di solito non è così, Gefi riesce a posizionare con forza Atlas 2 reti da decine di migliaia di nodi tranquillamente. È molto potente l'idea, diciamo, di utilizzare, di visualizzare queste strutture a nodi e archi. Perché sì, è molto flessibile anche, si può utilizzare per un'infinità di possibilità. Quello che fa Cornet nello specifico è di creare una rete tra account pubblici Facebook, quindi pagine, gruppi pubblici, e link condivisi. Quello che siamo passati a un paper, Policing Post Promotes Political Polarization. Sembra interessante. Adesso siamo tornati a RStudio. Non è che il mio Slack sia particolarmente entusiasmante. Ah, avevo letto tutto comunque. A un certo punto ci eravamo anche attassionati e volevamo andare a vedere gli altri messaggi, ma non potevamo. No, però, potrei vedere un bellissimo articolo che stiamo per sottomettere, che ha questo bellissimo titolo, Contante P, che è stato scelto apposta perché la prima versione aveva un titolo Contante F, e il revisore numero due aveva detto togliete questo titolo che è un inutile scioglilingua, l'autore adesso l'ha passato sulla P, ha delle figure bellissime, un articolo definitivo sulla polarizzazione online, bellissimo, bellissimo. Passacelo dopo. Ah, sì, sì, è tutto finto, eh? Cioè, tutto finto, però è molto bello. Allora, torniamo di qua e condividiamo a RStudio. Ok. Allora, avete guardato con Gefi qualcosa? Avete cliccato in giro? Avete pensato perché, qual è l'algoritmo che vi soddisfa di più? Mi hanno chiesto qual è l'algoritmo di posizionamento che avevi utilizzato, perché l'hai fatto rapidamente. Ah, per il layout, ok. Sì. Allora, mi condividete Gefi, ok. Allora, non mi ricordo, Forza Atlas 2. Allora, giusto, adesso non volevo perdere troppo tempo sui layout, ma allora, i layout, quasi tutti i layout che trovate implementati su Gefi sono layout di tipo fisico, cioè in un qualche modo cercano di simulare, come se ci fossero delle forze fisiche che producono un'attrazione rispetto ai nodi che sono strettamente connessi e una repulsione rispetto a quando i nodi non sono connessi. Poi ci possono essere vari modi. Se vedete, ad esempio, Forza Atlas, che è abbastanza chiaro rispetto a questa dinamica qui, con i parametri che vi permette di settare, avete un parametro che si chiama gravità, se lo mettete tipo a 300 anziché a 30, fa come se ci sia una gravità più forte rispetto ai nodi. Quindi noi la mettiamo un po' a meno, sempre un po' troppo. Poi c'è un parametro che è repulsione, quindi c'è una repulsione tra i nodi. Poi possiamo mettere, quindi i nodi, nonostante ci sia una gravità che li porta tutti verso lo stesso punto, tendono a respingersi quando non sono connessi. C'è una forza di attrazione tra i nodi invece quando sono connessi, quindi possiamo anche quella mettere più o meno forte. e poi ci sono varie funzioni che servono a stabilizzare la questione e poi c'è invece una forma di attraction distribution, che invece di avere la gravità tutta in un centro, mette la gravità un po' come se venisse dall'esterno. e poi basta, sostanzialmente il modo è quello. Cercano essenzialmente tutti gli algoritmi con strategie leggermente diverse, però cercano di mostrare qualche tipo di struttura di comunità o comunque di tenere vicini i nodi che sono fortemente connessi e spingere lontani i nodi che non sono fortemente connessi. A seconda della loro efficienza, a seconda della dimensione della rete, a seconda anche del numero di componenti della rete, un algoritmo funziona meglio di un altro. In generale, quello che ci interessava in questo caso qui era il comportamento di due algoritmi di community detection, community detection e layout sono due cose diverse, anche se hanno in comune questo aspetto di tenere vicini sostanzialmente i nodi che sono connessi, era vedere come due algoritmi di community detection quando hanno a che fare con lo stesso grafo, cioè con la stessa parte del grafo, quindi con lo stesso componente, perché gli altri componenti li hanno tutti e due, tutti identificati come comunità a se stanti, producevano dei risultati diversi. Questo è Louven e questo è l'Age Betweenness. Vedete Louven, produce molte più comunità qui all'interno, sicuramente produce questa comunità nera e mi pare che probabilmente poi ne produca anche e attribuisce a degli altri nodi a un'altra comunità. Quindi, anche noi possiamo fare che andiamo nodo per nodo e cerchiamo di capire se questi nodi effettivamente ha senso che stiano assieme o non ha senso che stiano assieme, oppure possiamo renderla come viene, cercando di capire però qual è la logica sottostante nei singoli algoritmi. Valutare le comunità è molto difficile, è oggettivamente molto difficile, perché voi potete avere delle valutazioni di massima. Non so, se fate community detection su reti politiche potete sicuramente vedere che le comunità che vengono ritrovate in linea di massima hanno, esistono attorno a, non so, posizioni politiche. Più è semplice il sistema politico, più è semplice il risultato. Se guardate le elezioni americane, ritrovate queste bellissime cose a due blocchi e sono tutti molto felici. Se guardate le elezioni italiane, ad esempio dove il sistema è molto più complesso, a livello di polarizzazioni, vicinanze, lontananze, vi trovate una dinamica che non è così semplice. Quindi anche andare a capire, è giusto o sbagliato che il nodo X sia nella comunità Y, non è così semplice. È chiaro che i risultati delle community detection vanno prese per quello che sono, cioè per un algoritmo applicato a una struttura di una rete che però non necessariamente vi dice la verità. Ecco, mettiamola così, se non altro perché algoritmi diversi, come vediamo anche in un esempio così semplice, vi danno risultati a volte anche molto diversi. Poi possiamo ragionare sui singoli algoritmi, ma magari dopo è fuori dagli scopi, diciamo, di oggi. Qual è la risposta alla domanda? No, nel senso, la risposta alla mia domanda è che non c'è una risposta. Non c'è una risposta. Secondo me, tendenzialmente, se uno ci perde un po' di tempo, la mia sensazione quando ho provato a farlo era che Louven avesse un po' più senso rispetto alla Edge Betweenness, ma questo avesse un po' più senso, si basa anche sulla mia non particolare familiarità con Treat Me Beautiful e il contesto. Adesso è un discorso un po' più serio. È molto difficile valutare una struttura di comunità se non si conosce il contesto. Per le reti sociali. Probabilmente anche per ogni altra rete, nel senso, anche se fate una rete metabolica, è molto difficile valutare il risultato di un community detection se non conoscete il contesto. perché non abbiamo una verità con la quale confrontarla e dire ok, è giusto all'80%, è giusto al 90%. Qui abbiamo dei risultati, alcuni ci sembrano più verosibili di altri, però dipende. Ad esempio, in un paper fatto ormai tanti tanti anni fa con un ragazzo che faceva il dottorato con me all'epoca, giocavamo cercando, facendo community detection su dati Twitter, su dati politici di Twitter ed era interessante perché la community detection fatta con i dati di retweet funzionava molto bene sulle party line, cioè sostanzialmente ci si retweetava all'interno dei partiti, al massimo all'interno delle coalizioni, noi lavoravamo sul sistema politico danese, ma è più o meno come quello italiano, mentre se introducevamo la dimensione delle reply, cioè dell'utente che fa reply e quindi risponde a un altro utente, tutto si complessificava perché le reply non seguivano più le linee all'interno dei partiti, ma venivano usate tra i candidati di vari partiti per litigare uno con l'altro. e quindi la comunità che veniva individuata era una comunità che non seguiva più le linee di partito, non erano più connessi i membri degli stessi partiti, ma erano connessi membri di partiti diversi. Quindi in qualche modo, se non si capisce la semantica della rete, se non si capisce la semantica degli archi, è molto difficile fare una valutazione dei risultati della community detection. Detto questo, la chiudiamo e torniamo a RStudio. Allora, avevamo inizialmente creato due reti, una utenti che rituitano utenti e l'altra utenti che utilizzano hashtag. La nostra rete che abbiamo fatto era quest'altra qua, era hgb, utenti hashtag, che è una rete piccolina, con 355 tra utenti e hashtag e 714 nodi. Allora, è possibile in linea di massima lavorare con reti bipartite, però se pensate un attimo a cosa significa una rete bipartita e che ha questa caratteristica di avere archi, di non avere tutte le connessioni possibili, perché per reti sono connessioni tra nodi di un tipo e nodi dell'altro, vi rendete conto che le metriche normali che usiamo per le reti non possono essere applicate quasi tutte così come sono per le reti bipartite. Questo fa sì che, nonostante spesso i dati che abbiamo abbiano forme di reti bipartite, tipo utenti che condividono un link o anche persone che frequentano, che guardano film o persone che frequentano un club o un'associazione o sono nel CDA di una particolare azienda, spesso quello che facciamo per lavorare con questo tipo di reti è fare quello che si chiama proiezione, cioè trasformiamo una rete bipartita in una rete normale. Sostanzialmente una proiezione quello che fa è se A è connesso a B se A ha guardato il film B e C ha guardato il film B noi toglieremo queste due connessioni bipartite e costruiremo una connessione nuova tra A e C. È abbastanza è abbastanza semplice, cioè se io guardo la casa di carta e Fabio guarda la casa di carta togliamo le connessioni tra me e tra Fabio e la casa di carta e facciamo una connessione tra me e Fabio. Questa diciamo è l'essenza della proiezione. Poi si può fare in alcuni modi diversi però essenzialmente questa è la proiezione. Ora, noi chiamiamo la rete che abbiamo fatto tra hashtag e utenti l'abbiamo chiamata bipartita ma iGraph non lo sa che è una rete bipartita cioè per noi lo è perché sappiamo che da una parte ci abbiamo messo degli hashtag e dall'altra ci abbiamo messo degli utenti. Però se chiediamo a iGraph di controllare se la rete è bipartita e gli chiediamo is bipartite come che è la funzione che controlla questa cosa iGraph risponde falso perché noi dobbiamo in qualche modo dirglielo ad iGraph che questa è una rete bipartita. Allora, iGraph considera si rende conto di avere a che fare con reti bipartite quando i nodi della rete contengono un attributo type che l'attributo type può avere il valore che vuole ma quello che faremo dopo è più comodo se è un valore binario vero o falso quindi type 1 vero type 2 falso e se poi controllando quando gli chiediamo di is bipartite si verifica che non ci siano connessioni tra type 1 con type 1 e type 2 con type 2 quindi noi possiamo fargli adesso vi dopo vi spiego perché l'abbiamo fatto così giustamente questo non l'abbiamo fatto un attimo se no non funziona ok una volta che abbiamo fornito ad iGraph le informazioni di cui ha bisogno per vedere per verificare la bipartite se gli richiediamo se la nostra rete is bipartite la risposta diventa true cosa abbiamo fatto qua se pensate a come abbiamo costruito questa rete noi abbiamo costruito questa rete mettendo tutti i nostri utenti da una parte e tutti i nostri hashtag dall'altra poi abbiamo detto ad iGraph di costruire la rete e di farla diretta di farla direzionata possiamo tornare su a vedere il codice che l'ha costruito che è questo qua questa parte qui del codice subito prima che crei