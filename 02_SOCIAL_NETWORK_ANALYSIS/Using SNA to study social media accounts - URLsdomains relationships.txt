Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Ciao, ciao. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie. Bene. Dunque, direi che probabilmente possiamo iniziare. Mi sentite intanto? Sì, sentiamo. Cosa facciamo, prof? Teniamo il microfono o preferisci che scriviamo? Se potete intervenire direttamente in audio tranquillamente. Va bene, grazie. Allora, intanto vi chiedo se avete avuto modo di riprovare con calma quella breve introduzione con codice alla social network analysis che abbiamo fatto insieme nelle ultime due lezioni. Se non l'avete fatto, oppure se tutto era sufficientemente chiaro, quindi non avete sentito questa necessità, va ovviamente bene lo stesso. E sappiate che, come avrete visto, i file delle due lezioni sono state rese disponibili, quindi avete la possibilità di rivederle quando ritenete opportuno. Io avevo due persone prenotate, ma sicuramente per l'aula, sicuramente Luca lo vedo collegato, quindi non verrà in aula. Non so, ecco, dicevo non so paride, ma è arrivato adesso. E quindi adesso, un secondo che lo metto presente nel nostro sistema. Ciao, scusami. Allora, dunque, un secondo solo. Allora. Allora. Allora. Ah, ok. Ti sei registrato da solo all'ingresso? Ti vedo già presente, dico... Mi sono registrato prima. All'ingresso. Adesso non so riparli alla prima. No, no, no, ma va benissimo perché ti vedo già registrato, cioè non devo fare niente io praticamente. Ok. Allora, torniamo un attimo qui. e devo però, dovete darmi un secondo perché a questo punto devo apprezzarmi per rapproiettare, in modo tale che anche chi è in aula possa vedere quello che... No, guardo la computer. Vedete il computer? Ok. Va bene, allora. No, abbiamo sempre fatto che... Ok, diamo un secondo intanto. Allora. E appunto stavo dicendo, non so se avete avuto occasione di dare un'occhiata a quella introduzione o se avete avuto curiosità di approfondire alcune delle cose che siamo state toccate, diciamo, in modo necessariamente breve durante le ultime due lezioni. Quello che faremo oggi insieme è iniziare un progressivo avvicinamento a un utilizzo della SNA più specifico, cioè avete visto che la potenza del metodo deriva anche dal fatto che è estremamente flessibile e consente di rappresentare relazioni di varia natura e di domini completamente diversi, tant'è vero che la stessa tecnica, le stesse tecniche, le stesse metriche vengono utilizzate in discipline completamente diverse che vanno dalle scienze sociali e quindi anche dal fatto che la biologia fino alla fisica per lo studio dei rapporti tra le particelle e via discorrendo. Quindi, diciamo, da una parte noi abbiamo un metodo che è estremamente flessibile, è estremamente adatto a descrivere situazioni e contesti molto diversi, dall'altra abbiamo invece un taglio che noi daremo in questo corso che rende tutto questo metodo applicato a uno specifico campo di analisi che fondamentalmente è il campo, che vedete anche descritto con un titolo qui, di studio di applicazione della SNA a uno specifico campo di analisi che sono stati e colori che sono stati fisici. Quindi, per esempio, è un concetto di relazioni che possono esistere fra account di social media e notizie o fonti di notizie, intese come un complesso di notizie che provengono da una stessa fonte di informazione. Ora, capite bene che questo tema è diventato negli ultimi anni sempre più importante, poiché immagino lo sapete bene, anche se non siete degli studenti con un background sulla comunicazione, che gran parte del traffico verso le fonti di informazione nel corso degli ultimi anni arriva dai social media. Quindi applicare la SNA a studiare il rapporto fra account di social media e storie o notizie che circolano su queste piattaforme è fondamentale per capire come queste storie circolano, chi le fa circolare, quanto popolari esse siano attraverso i social media e quali sono le fonti che in qualche modo riscuotono maggiore successo attraverso queste piattaforme e quindi sfruttano meglio l'ecosistema dell'informazione contemporaneo per ottenere il massimo del risultato possibile. Bene, come potete immaginare il fatto che stiamo usando un metodo che è basato su nodi e relazioni fra questi nodi, quindi archi diciamo, per usare un po' il linguaggio della SNA, si presta particolarmente bene a raccontare alcune cose che avvengono su internet. E non è un caso che il primo studio che ha utilizzato la social network analysis è diventato una specie di icona di questi studi. E' uno studio fatto sulla blogosfera, quindi stiamo parlando del 2004, delle elezioni politiche americane del 2004. E' una collega che si chiama Lada Adamic, insieme a altri coautori, ha avuto questa idea di andare a studiare la relazione, di andare a descrivere l'ecosistema dell'informazione dei blog di quell'epoca attraverso la social network analysis e in particolare l'analisi dei link che collegavano un blog ad un altro. Lo sapete che vi ricorderete sicuramente l'epoca in cui il dibattito pubblico passava anche attraverso i blog, prima che tutto ciò fosse in qualche modo assorbito dei social media. Uno dei risultati che poi sono rimasti nella storia dell'applicazione di questi metodi a le scienze politiche anche, e sintetizzato dal grafico che vedete qui. In pratica, lada amici e colleghi hanno analizzato i post di qualche migliaio di blog politici americani, in parte vicini ai democratici e in parte vicini ai repubblicani. Vedete che i colori che sono stati scelti per rappresentare questo grafico sono quelli del blu e del rosso, tipici il primo del Partito Democratico e il secondo del Partito Repubblicano. ha tracciato fondamentalmente le relazioni fra tutti questi post, andando a vedere quando il link andava da uno schieramento all'altro, o piuttosto rimaneva all'interno dello stesso schieramento. Quello che si vede molto chiaramente da questa immagine, che appunto come dicevo è diventata un pochino iconica e rappresenta tuttora l'idea della polarizzazione nel dibattito pubblico americano, dove sapete ci sono solamente due poli, e quindi la tendenza alla polarizzazione è in qualche modo forse più spinta anche di quella che abbiamo noi nel nostro sistema multipartitico. Vedete che si creano due cluster piuttosto chiaramente identificabili, e alcune relazioni all'interno, diciamo, fra questi cluster, ma molto molto deboli. E soprattutto nel paper viene messo in evidenza come di fatto ci fosse una tendenza ad avere queste relazioni in uscita dalla comunità, più sul lato dei blog vicini al Partito Democratico, che sul lato dei blog vicini al Partito Repubblicano. cioè, come dire, i blog più vicini ai democratici, pur riferendosi quasi esclusivamente a loro stessi, ogni tanto si riferivano anche ai blog del Partito Repubblicano, e il viceversa invece avveniva molto molto poco di frequente. Assolutamente sì, sì, sì. Non so, io l'ho aperto o l'ho lasciato aperto? No, no, no, perché se non è una notizia, non si riferiva. Non so, io l'ho aperto o l'ho aperto? Non so, io l'ho aperto o l'ho aperto. Ok, stiamo... Abbiamo intanto chiuso la finestra. Ok, questo è per un po' raccontarvi la storia di questo metodo, che non vi farò nel dettaglio, perché non è questo l'oggetto, diciamo, del corso. Facciamo un salto nel tempo e arriviamo a uno studio molto più recente. nel 2016 un gruppo di colleghi al Bergman Center di Harvard studia, decide di mappare l'ecosistema informativo nei mesi che hanno preceduto le elezioni presidenziali del 2016. non è un caso, diciamo, che si vada da un'elezione presidenziale americana all'altra, perché spesso, diciamo, l'innovazione nell'ambito degli studi sulla comunicazione politica è molto trainata da questi eventi di grande interesse. Cosa hanno fatto questi colleghi? Hanno fatto un lavoro piuttosto interessante. Allora, vedete che in questa mappa ci sono anche qui dei nodi che sono caratterizzati da un colore più verso il blu e dei nodi che sono caratterizzati più da un colore verso il rosso. Le relazioni fra questi nodi sono abbastanza facili da comprendere perché di fatto sono i link che provenivano da una certa fonte di informazione verso l'altra. Ora, capite, bisogna un attimo calarsi dentro il sistema, dentro il tipo di giornalismo che fanno negli Stati Uniti, anche online, dove l'uso del link è molto più frequente rispetto a quello che viene fatto nei quotidiani italiani e anche l'uso del link verso un'altra fonte, talvolta anche un competitor. Ora, noi in Italia lo vediamo molto raramente questo utilizzo, per cui una mappa del genere sarebbe difficile da poter riprodurre, ma questo solo per dirvi come sono state costruite le relazioni fra questi nodi. Ma voi potreste chiedersi, ok, ma come hanno fatto a decidere se una fonte era più vicina, doveva essere più rossa o più sul blu? E lì, diciamo, hanno utilizzato un metodo che è al tempo stesso molto semplice, ma contemporaneamente è un'altra fonte di un'altra fonte. Lo vedremo meglio fra un attimo, ma vi posso dire in generale che si basa sull'analisi di come queste notizie sono circolate nel social network Twitter. Grazie a questo metodo, che vi descriverò fra un attimo, sono riusciti a categorizzare il cosiddetto leaning politico di ciascuna di queste fonti e appunto poi a mapparne il colore in questo grafico. L'ultimo aspetto rilevante riguarda la dimensione di questi nodi e su questo loro hanno utilizzato metodi diversi. In questo specifico grafico la dimensione è legata al numero di citazioni che quella fonte ha avuto su Twitter. Ovviamente si potrebbe fare la stessa cosa con le citazioni che quella fonte, cioè che gli articoli di quella fonte hanno avuto su un altro social network come Facebook e si potrebbe fare anche semplicemente guardando ai link cioè agli articoli che contengono i link che vanno da una fonte all'altra attribuendo, usando per esempio la degree banalmente come metrica che mostra quanti link in ingresso una fonte ha e quanti link in uscita ha. Poi uno potrebbe dire ma potremmo usare l'indegree perché l'indegree in qualche modo ti dà più l'idea di quanto quella fonte sia stata utilizzata come punto di riferimento mentre l'indegree è quanto le altre fonti hanno utilizzato quanto quella fonte lì ha utilizzato altre fonti come punti di riferimento per cui ovviamente l'indegree in questo caso potrebbe essere una buona metrica. di fatto in realtà l'attributo della dimensione qui non viene fuori da specifici analisi della rete stessa ma è stato attribuito come un elemento in qualche modo esterno. Cosa abbiamo fatto noi? Nel 2018 abbiamo avuto un piccolo finanziamento da Open Society Foundation per studiare, per mappare le notizie politiche nei sei mesi che hanno preceduto le elezioni politiche del 2018 e poi abbiamo replicato questo studio per le elezioni politiche del 2019 e per farlo ci siamo basati su e abbiamo sviluppato il metodo che i colleghi americani avevano in qualche modo definito. Allora cosa abbiamo fatto? Abbiamo costruito, io adesso entrerò un pochino più nel dettaglio rispetto a quanto faccio di solito sull'aspetto metodologico perché credo possa essere di vostro interesse abbiamo costruito, abbiamo raccolto 84 mila notizie politiche pubblicate nei sei mesi che hanno preceduto le elezioni del 2018 come abbiamo fatto a farlo? Fondamentalmente abbiamo utilizzato un software open source che si chiama Eugene e ve lo scrivo nella chat così dovreste poterlo guardare che cosa è Eugene? Eugene di suo è un sistema ad agenti e da casa rivedete le slide a parte che me lo puoi confermare anche tu si rivedono le slide giusto? Un sistema ad agenti che fondamentalmente consente di interagire con servizi internet di filtrare i contenuti raccolti attraverso per esempio dei servizi web e di andare a salvare questi contenuti dentro un database quindi quello che noi abbiamo fatto fondamentalmente è sfruttare i feed di Google News relativi ai politici e ai partiti politici italiani allora ma tuttora vi dirò Google News supportava i feed RSS oggi non li supporta più in modo ufficiale ma se voi avete per caso la struttura del link usata in precedenza scoprirete che di fatto li supporta ancora semplicemente non lo racconta più in giro facendo questo abbiamo bypassato una serie di problemi legati al fatto che quando tu raccogli notizie su certi temi usando come parole chiave per esempio i nomi dei politici ovviamente non tutti i nomi funzionano nello stesso modo cioè può capitare che sia un partito politico sia un personaggio politico abbiano un nome comune che per esempio corrisponde anche a una parola di uso comune quindi in questo caso è necessario disambiguare questo termine il che crea una serie di complicazioni invece Google News aveva una sorta di diciamo sfruttavamo l'intelligenza artificiale di Google News che già è in grado di raccogliere notizie riguardanti o un personaggio politico o un tema e consente all'utente finale proprio di abbonarsi a questi contenuti per esempio io posso seguire tutte le notizie su Matteo Renzi piuttosto che sul partito Italia Viva raccoglievamo tutto questo e per ciascuna notizia andavamo ad interrogare le API di Facebook periodicamente per misurare quante e quali tipi di interazioni quella notizia stava avendo su Facebook anche qui c'è una storia abbastanza interessante che racconta come questi metodi tendano a cambiare nel tempo molto rapidamente a causa dei cambiamenti dell'ecosistema perché fra le elezioni del 2018 e le elezioni del 2019 Facebook ha pensato bene di modificare il rate limit di richieste che potevano essere fatte a questa API rendendo praticamente impossibile replicare esattamente quello che avevamo fatto la prima volta e quello che avevamo fatto la prima volta era questo una volta che avevamo identificato una URL andavamo a interrogare le API di Facebook una volta all'ora per sette giorni dopo la rilevazione quindi avevamo le interazioni divise in commenti, condivisioni e reazioni come insieme di like e le nuove reazioni per ciascuna delle nostre notizie anche nel tempo si potevano fare tante cose diverse alcune di quelle che abbiamo fatto adesso ve le racconto quindi sette di notizie più relativo a engagement diciamo a una settimana dalla pubblicazione come massimo ma anche con tutte le liste intermedie ora per ora poi cosa abbiamo fatto? volevamo replicare il metodo che hanno usato i colleghi americani vi dicevo che si basa sulla circolazione su Twitter di queste notizie e l'idea è semplice ma interessante loro cosa hanno pensato? hanno detto beh, intanto acquisiamo i retweet per un certo periodo di tempo dei politici americani in questo caso era molto semplice perché loro immaginatevi un sistema bipartitico quindi i retweet dell'account di Hillary Clinton e i retweet dell'account di Donald Trump ok? noi, il nostro caso era molto più complesso infatti diciamo il nostro contributo da questo punto di vista, dal punto di vista metodologico è stato quello di estendere il metodo da un sistema bipartitico a un sistema multipartitico quando tu hai raccolto i retweet dei partiti politici tu sei dei due candidati politici adesso dico due per semplificare giusto per chiarire come funziona il metodo tu ti trovi in una situazione per cui ciascun singolo utente può aver retweetato o un solo candidato o l'altro oppure aver fatto un po' di retweet diciamo per l'uno e per l'altro quindi supponiamo che un utente abbia fatto 100 retweet può averne fatto 100 tutti per Hillary Clinton 100 tutti per Donald Trump o un qualche tipo di distribuzione diversa da questa intermedia grazie a questo io posso fare una sorta di seppur super semplificata identificazione del leaning politico di quell'utente cioè io posso dire se tu hai retweetato tu utente hai retweetato solo Hillary Clinton io ti ritengo un supporter di Hillary Clinton se hai fatto il contrario ti ritengo di Trump e in base a come ti sei comportato ti assegno diciamo in una distribuzione ideologica che va dalla Clinton a Trump quindi diciamo dalla sinistra alla destra vedete come negli Stati Uniti è tutto molto più semplice una volta che tu hai attribuito a ciascun utente un leaning politico e da casa ragazzi se volete interrompetemi pure così come anche da qui io purtroppo non vedo quello che scrivete in questo momento per cui ok grazie grazie prof per ora è tutto chiaro bene bene grazie allora una volta che abbiamo identificato il leaning politico di tutti gli utenti che hanno retweetato i nostri politici possiamo fare una cosa ulteriore cioè andare a raccogliere tutti i tweet che questi utenti hanno fatto in un certo periodo di tempo nel nostro caso ci siamo limitati a prendere i 5000 retweetter più attivi e a raccogliere tutto ciò che loro avevano pubblicato in un mese di tempo ora fra queste cose che loro avevano pubblicato ovviamente c'erano anche dei tweet che contenevano link verso fonti di informazione e lì inizia diciamo il gioco questo metodo si chiama multiparty media partisanship attention score e appunto è ispirato al metodo che hanno sviluppato i colleghi americani che si chiama media partisanship attention score e fondamentalmente lavora su due fasi la prima consiste nel stimare la partisanship cioè quanto la partigianeria di ciascun utente in base alla proporzione dei suoi retweet per ciascun partito politico e nella seconda fase si stima l'attenzione partigiana verso una fonte di informazione condivisa da questi utenti nella loro timeline cioè una volta che io ho raccolto i tweet di questi utenti posso fare un ragionamento del tipo ah, gli utenti che sono vicini a Hillary Clinton tendono a postare tweet con link verso il New York Times allora il New York Times è vicino a Hillary Clinton cioè faccio un'inferenza di questo genere che passa attraverso il comportamento degli utenti con lo scopo in realtà di identificare diciamo il political leaning delle fonti di informazione ora ovviamente bisogna stare molto attenti a quello che si dice come si usano i termini infatti i colleghi americani sono stati molto attenti da questo punto di vista vedete che loro non parlano di political leaning delle fonti perché è una cosa molto complessa cioè dire il New York Times di sinistra in teoria prevederebbe che tu fai un'analisi degli articoli del New York Times e identifichi questo political leaning attraverso i contenuti di fatto noi con questo metodo tu non stai stimando precisamente se il New York Times è una fonte partigiana ma stai dicendo che la sua audience è partigiana quindi l'attenzione è partigiana poi dopo probabilmente si può anche estendere il ragionamento ma quello che stai studiando in questo caso è quanto l'attenzione verso una fonte di informazione sia partigiana quindi una fonte può avere un'attenzione solo dai supporter della Clinton solo dai supporter di Trump o diciamo da un mix di questi gruppi e ovviamente in base a questo io posso attribuire quei colori che voi avete visto dentro il grafico si possono fare poi tante cose ovviamente si può creare una mappa dell'ecosistema dell'informazione simile a quello che hanno fatto i colleghi americani anche in questo caso come se vi ricordate la mappa che avete visto per gli Stati Uniti di fatto non si evidenziano dei veri e propri cluster autonomi è molto diverso dal caso della blogosfera anche se ovviamente si identificano abbastanza chiaramente delle zone dove ci sono delle fonti che appaiono essere diciamo aver avuto un'attenzione più partigiana di altre e qui ci è venuta in mente un'idea cioè noi abbiamo detto quindi ci sono delle fonti che fondamentalmente ricevono attenzione solo da i supporter di un certo partito e ci sono delle fonti che invece ricevono attenzione da supporter di vari partiti quindi in qualche modo noi possiamo misurare questa cosa chiamandola noi l'abbiamo chiamata insularità cioè quanto è insulare quanto è come dire utilizzato solo da un'audience partigiana una fonte rispetto al suo contrario ovvero una fonte cross partisan cioè che la cui attenzione diciamo è distribuita fra i supporter di vari partiti quindi l'insularità è l'opposto di essere cross partisan e di fatto è un indice diciamo di quanto quella fonte sia più spostata è utilizzata solo da una singola comunità partigiana oppure da più comunità questo ovviamente è importantissimo dal punto di vista della comunicazione adesso ve la faccio breve perché forse non è diciamo il vostro interesse specifico però è chiaro che una fonte che viene utilizzata solo da una singola comunità tende a essere a raccontare un certo punto di vista in modo molto chiaro mentre una che viene utilizzata da più fonti tende a essere un pochino più rispettosa dei punti di vista degli altri per cui per esempio in media per i quali noi abbiamo calcolato l'insularità le fonti per le quali noi abbiamo calcolato l'insularità che avevano valori più alti tendevano a essere le fonti politiche di partito per obbie ragioni quindi o il blog del partito o il blog per esempio il blog delle stelle o il sito ufficiale del partito che poi a loro volta già allora erano in forma di blog anch'essi per cui avevano degli elementi come fossero sui singoli partiti e nello studio che abbiamo fatto quando poi vai a mappare queste relazioni di fatto ritrovi le coalizioni con qualche eccezione abbastanza interessante però tendenzialmente ritrovi la coalizione di centrodestra la coalizione di centrosinistra e il movimento 5 terzo che allora era un terzo polo proprio nel 2018 questo era molto molto chiaro perché vi ricordate qua stiamo parlando di prima del governo giallo-verde di prima del governo Conte due e via dicendo ok questa quindi è l'insularità e a un certo punto abbiamo detto beh con questa insularità noi possiamo fare delle cose ad esempio possiamo costruire quattro categorie di fonti da quelle che hanno praticamente non hanno nessuna insularità a quelle che hanno un'insularità bassa moderata o alta utilizzando diciamo le proprietà della distribuzione di questa misura quindi la media e la diciamo la deviazione standard rispetto a questa media abbiamo costruito queste quattro categorie per cui per esempio la categoria nulla era tutto ciò che era una deviazione standard sotto la media la media faceva la distinzione fra il basso e il moderato e una deviazione standard sopra la media creava la categoria fra moderato e alto una volta che abbiamo classificato in questo modo le nostre fonti di informazione abbiamo proceduto a un processo di aggiudicazione cioè noi abbiamo detto di quelle che hanno un qualche tipo di insularità noi le possiamo in qualche modo aggiudicare a un singolo partito di quelle che invece non ce l'hanno ovviamente no le metteremo in un'altra categoria ed è l'unica fuori questa qui c'è la spiegazione quindi tutto ciò che non ha insularità 121 fonti li abbiamo messi nella categoria cross partisan e abbiamo aggiudicato ad un partito le restanti 513 fonti il risultato è quello che vedete qui quando siamo andati a fare questa aggiudicazione ci siamo resi conto che c'erano due partiti che sicuramente avevano in qualche modo grazie all'attivismo dei loro supporter acquisito in qualche modo un certo numero di fonti e adesso consiglio sempre da fare questi ragionamenti però il dato in sé si presta a questo ragionamento ovvero se vi ricordate quali sono i due partiti che sono usciti i vincitori da quelle elezioni effettivamente furono il Movimento 5 Stelle e la Lega la Lega passò dal 4 17% il Movimento 5 Stelle ebbero il suo successo massimo della storia quindi diffido sempre dalla perché ci sono tanti tanti studi che sono andati in questa direzione cioè l'idea di guardare a quello che avviene nei social media come un possibile modello un possibile fonte di dati per un modello previsionale di quello che succederà nella realtà è facilmente alterabile questo è diventato evidentissimo diciamo negli ultimi anni ma all'inizio molti si sono lanciati in questa idea di dire ma guardiamo nei social media e vediamo se riusciamo a prevedere quello che succederà ad esempio nelle elezioni questo è stato un grande classico per alcuni anni una volta che abbiamo aggiudicato le fonti ai partiti abbiamo iniziato a chiederci delle cose tipo è possibile che i partiti cosiddetti populisti tendano a usare più fonti insulari cioè sapete che i partiti populisti tendono ad avere una visione del mondo molto ben definita e molto vicina diciamo molto estrema in qualche modo quindi ci si poteva aspettare che effettivamente i partiti populisti utilizzassero fonti più insulari quando siamo andati a vedere effettivamente abbiamo scoperto che la Lega e il Movimento 5 Stelle cioè i partiti che tendenzialmente vengono definiti populisti adesso non entro ovviamente nel dibattito se lo siano o meno hanno usato diciamo facevano un uso di fonti più come dire partigiane più insulari rispetto a quanto non facessero l'EU e il Partito Democratico vedete in particolare il Movimento 5 Stelle ha un valore fra quelle ad alta insularità molto più elevato degli altri e invece la Lega ha un valore più alto in quelle di moderata insularità ma nel complesso se andiamo a sommare quelle due barre abbiamo una differenza statisticamente significativa rispetto a quanto non non vediamo fra l'EU e il Partito Democratico un'altra domanda di ricerca che siamo posti è siccome vi ricordate noi abbiamo raccolto anche l'engagement cioè le interazioni su Facebook di queste notizie e quindi una volta che tu hai l'engagement a livello di notizia sommando quell'engagement puoi arrivare all'engagement della fonte nel suo complesso e l'idea è ci siamo chiesti ma è possibile che le fonti insulari rispetto a quelle invece cross parties tendano ad avere delle interazioni di tipo diverso e ci siamo concentrati sulle condivisioni rispetto ai commenti che di fatto sono due interazioni diverse perché uno spesso commenta quando in qualche modo vuole esprimere un certo tipo di critica non sempre però a grandissime linee e condivide invece quando vuole diciamo far sì che il mondo sappia di quella notizia quando siamo andati a vedere i risultati effettivamente abbiamo scoperto che tendenzialmente le fonti cross partisan quindi quelle a nessuna insularità quelle sulla colonna sulla quarta colonna tendevano a ricevere più commenti e condivisioni e questo è esattamente l'opposto di quello che avveniva per le fonti più insulari e qual è la logica? La logica è che probabilmente queste comunità diciamo in qualche modo direi omofili che condividono gli stessi valori diventavano anche degli attivisti nella condivisione di questi contenuti per cui quelle notizie tendevano ad avere un numero relativamente basso di commenti ma un numero molto alto di condivisioni perché questi attivisti in qualche modo facevano cercavano di condividere il più possibile questi contenuti e viceversa avveniva invece sulle fonti cross partisan il che era anche abbastanza interessante perché proprio guardando anche al diciamo ai dati che avevamo in nostro possesso era piuttosto chiaro che si trovava spesso notizie pubblicate da fonti cross partisan che ricevevano un numero molto elevato di commenti e questi commenti tendevano a essere di tipo critico quindi queste comunità probabilmente erano attive non solo nel diffondere il più possibile il loro messaggio ma anche nel far pensare la loro opinione in queste arene dove varie comunità si andavano a incontrare cioè quelle messe a disposizione dai commenti delle fonti cosiddette cross partisan che ovviamente tendenzialmente da noi erano quasi tutti i media mainstream per cui Corriere.it Repubblica tutte queste fonti che in qualche modo per quanto poi possano essere accusati di partigianeria anch'essi ma a guardare questo indicatore venivano comunque utilizzate da fonti da da gruppi partigiani da comunità partigiane diverse quindi abbiamo iniziato a riflettere su questa distinzione fra commenti e condivisioni e abbiamo posto la nostra attenzione sulle forme di manipolazione cioè un po' come dicevi tu Paride ponendosi la prospettiva esattamente opposta a quella che dice i social media sono uno specchio della società noi ci siamo posti il problema di vedere c'è qualcuno che sta manipolando quei numeri allo scopo di diciamo indurre chi crede che i social media sia uno specchio della società a farsi un'idea diciamo di un certo genere di quello che gli italiani ad esempio pensano questo è molto importante perché purtroppo per quanto ciascuno di noi che conosce un po' come funzionano i media sociali è perfettamente consapevole che esistano delle forme di manipolazione e che quindi quei numeri che noi vediamo i numeri dell'engagement che in qualche modo diventano degli indicatori di status per cui se uno ha tanti follower allora è tanto popolare oppure se quel contenuto ha avuto tantissime interazioni allora magari un contenuto vero per quanto noi sappiamo che non sia così in qualche modo la maggior parte degli utenti tendono invece a fare questa semplice equazione e lo fanno molto anche i giornalisti il che significa immaginate un giornalista che è su Twitter sapete che Twitter diciamo la gran parte dell'utenza di Twitter è composta da giornalisti politici e sapete che Twitter ha una funzione che si chiama trending topics dove vengono mostrati diciamo i temi di cui più si dibatte sulla piattaforma ora se io riesco a in qualche modo mandare alcuni miei temi in trending topic ottengo un risultato che va ben oltre il social media perché posso indurre un giornalista a dire ah guarda le persone gli italiani sono interessati a questo tema allora io che sono un giornalista ne prendo atto e ne parlo anch'io innescando un feedback che appunto fa sì che il risultato di questa operazione non si fermi semplicemente all'interno del media sociale ma che travasi sui media mainstream e quindi vado a toccare un certo tipo di pubblico che magari con i media sociali solamente non sarebbero mai stati raggiunti allora abbiamo iniziato a cercare di riflettere un po' più da vicino su chi o chi fa queste operazioni che vengono definite di media manipulation e nel frattempo di quelle gli americani hanno coniato questo termine che è un termine interessante perché diciamo quando voi pensate a media manipulation se andassimo a chiederlo in giro per la strada che cosa significa la manipolazione dei media tutti ci saprebbero dare una risposta e direbbero probabilmente è il processo attraverso il quale i media influenzano le persone l'opinione pubblica l'audience quello che è di fatto in questa nuova accezione media manipulation si riferisce invece a come i media possano diventare oggetto di manipolazione cioè come dicevo prima fare delle operazioni che avvengono online ma con lo scopo di influenzare i giornalisti chi racconta l'opinione pubblica attraverso i media mainstream a raccontarla in un certo modo piuttosto che un altro vi faccio un esempio se io sono un giornalista di quelli magari che va nei talk show politici a esprimere le sue opinioni diciamo con il ruolo dell'opinionista e mi accorgo che tutte le volte che tocco certi temi ricevo tanti insulti di persone apparentemente arrabbiate beh nella mia mente scatta automaticamente quel meccanismo che dice beh se io tocco il tema per esempio immigrazione non come problema e dopo mi ritrovo 10-15 messaggi di gente arrabbiata che mi insulta e mostra odio nei miei confronti mi faccio l'idea che il clima di opinione pubblica vada in una certa direzione e di conseguenza la volta successiva ci penso due volte a esprimere la mia opinione in quel senso perché ricevere gli insulti non piace a nessuno e perché i giornalisti diciamo se c'è una cosa che sanno fare bene e cercare di capire qual è l'andamento dell'opinione pubblica e in qualche modo riuscire a seguirlo perché il loro obiettivo è quello di raccontare cosa che interessano alle persone quindi capire dove sta andando l'interesse delle persone fa parte proprio del loro mestiere allora negli ultimi anni abbiamo concentrato la nostra attenzione su una specifica forma di manipolazione che noi abbiamo chiamato coordinated in authentic link sharing behavior ma in particolare il coordinamento condiviso di link sui social media allora che cosa significa questo questo strano nome lo strano nome deriva da un termine che è stato reso popolare da facebook che negli anni negli ultimi anni diciamo dal 2018 in poi ha iniziato a utilizzare di frequente la frase coordinated in authentic behavior per giustificare alcune azioni compiute da facebook che sono risultate in cancellazioni di intere reti di utenti allora cosa c'è di interessante su questo termine che a un certo punto diciamo emerge l'interesse verso questo termine deriva dal fatto che per la prima volta non si prova ad affrontare il problema della disinformazione attraverso i contenuti ma attraverso i comportamenti cioè questo metodo è in qualche modo agnostico rispetto ai contenuti l'idea è che ci possono essere degli utenti in rete che hanno dei comportamenti sospetti che fanno sì che io diciamo ponga attenzione a ciò che loro producono e lì arrivo sul livello dei contenuti ma approccio attraverso il livello del comportamento questo è fondamentale perché approcciare dal livello dei contenuti è ovviamente diciamo il modo più logico è il primo che viene in mente cioè quando io voglio combattere la disinformazione vado a cercare le notizie false il resto non è un caso che tutto il dibattito sulla disinformazione e sulla misinformazione ruoti intorno al termine fake news che già dà l'idea di come l'approccio iniziale sia stato un approccio basato sui contenuti e il che ha totalmente senso se non fosse che uno i contenuti sono tantissimi per cui è un metodo che non scala bene di quante persone abbiamo bisogno per controllare tutti i contenuti pensate che facebook non direttamente loro ma tramite aziende che fanno da intermediario gestisce 25.000 alcuni dicono 30.000 persone che vanno a verificare se le segnalazioni fatte dagli utenti per la violazione degli standard della comunità violino o meno gli standard della comunità 30.000 persone in tutto il mondo per avere un servizio che va avanti 24 ore su 24 in contesti locali più disparati per cui è un lavoro estremamente difficile per quanto riguarda lo specifico delle notizie false facebook ha sempre approcciato al problema dicendo facebook non deve essere l'arbitro della verità cioè non siamo noi a dover decidere cosa è vero e cosa è falso questo perché per vari motivi uno è molto difficile decidere cosa è vero e cosa è falso due ci sono delle dei giornalisti che sono specializzati in questo tipo di lavoro e quindi facebook ha deciso di affidarsi a questi giornalisti in tutto il mondo per esempio in italia c'è una sola organizzazione che fa questo lavoro per facebook che si chiama pagella politica e di recente ha lanciato il brand facta che ritroverete quando su facebook viene mostrato un contenuto che è stato considerato falso e che viene da qualche mese accompagnato dal link al debunking fatto da pagella politica o fatta quindi praticamente in qualche modo facebook subappalta questa parte sulle notizie false a soggetti di terze parti ma poi c'è un altro problema ulteriore cioè anche supponendo che si riesca a distinguere fra notizie vere e notizie false in un modo abbastanza agevole quello che si osserva è che molto spesso gli attori che desiderano manipolare l'opinione pubblica fanno circolare talvolta delle notizie che sono del tutto vere ma sono notizie che raccontano bene il loro punto di vista pensate a le comunità antivacciniste e come fanno circolare i singoli casi in cui il vaccino ha dato un qualche tipo di effetto collaterale è chiaro che se io ho una comunità che si nutre dal punto di vista informativo solo dei contenuti che io produco si fa un'idea di quanto i vaccini siano dannosi molto più forte di quello che in realtà sia perché queste comunità sanno che devono amplificare il più possibile quel messaggio allo scopo di ottenere un cambiamento nelle opinioni che fa ritenere i vaccini più pericolosi di quello che di fatto non siano dal punto di vista strettamente statistico e del resto sappiamo che in questi mesi l'abbiamo visto molto molto bene che diciamo l'esperienza raccontata di una singola persona spesso vale più di tante statistiche e quindi quando uno legge una notizia e dice ah c'è questo caso questa cosa la colpisce molto di più rispetto a dire ah ma è solo lo 0,0000x per cento quindi l'approccio sui contenuti in qualche modo è un approccio che pur essendo ancora utilizzato è in qualche modo limitato allora voi siete ovviamente tra l'altro studenti di informatica e probabilmente vi starete chiedendo ah ma perché ancora qualcuno non ha fatto un sistema di detection delle notizie false più o meno automatizzato oppure addirittura perché facebook non crea un sistema di machine learning sfruttando tutti i dati che queste 25.000 persone producono andando a flaggare i vari contenuti come rispettosi o meno dello standard allora io la risposta non la so ma suppongo che se né facebook né google né youtube né twitter abbiano ancora un sistema di questo genere evidentemente le difficoltà che costruire un sistema automatizzato di questo genere pone sono tali che neanche queste piattaforme che sicuramente non mancano né delle competenze né dei dati che potrebbero essere necessari per alimentare questi sistemi riescono a fare quindi diciamo l'approccio sugli attori ok lo stiamo continuando a fare ma probabilmente non è da lì che riusciamo a risolvere la questione da qualcuno e questo è stato fatto molto da anche dei ricercatori accademici ma anche da facebook stessa ha proposto un approccio basato sugli attori cioè qual è l'idea l'idea è che se io ho un account di social media o una fonte di informazione che ripetutamente ha pubblicato notizie false io a un certo punto non ho più bisogno di analizzare i singoli contenuti di questa fonte di informazione ma posso ritenere l'intera fonte come falsa e questo semplifica notevolmente il problema per esempio se io come ricercatore mi pongo la domanda di ricerca di stimare quanto quanta informazione intorno a un tema sia di tipo problematico piuttosto che no posso semplicemente vedere tutto quello che è prodotto dalle fonti che sono per esempio nelle black list nelle liste nere dei fact checker e vedere quello che invece non è in queste liste nere e vado a fare il confronto e dico ah ma alla fine molti di questi studi finiscono dicendo alla fine questi contenuti di fatto rappresentano una piccola minoranza rispetto al complesso delle notizie che circolano in rete bene solo che c'è un piccolo problema le black list per quanto ovviamente vengano aggiornate da tutti non riescono a stare al passo con i tempi dei cambiamenti di strategia che questi gruppi continuano a fare nel loro tentativo di manipolare l'opinione pubblica perché? perché questi attori è dimostrato e lo vedremo anche fra un attimo tendono a cambiare per esempio il dominio di riferimento a abbandonare account di social media che sono stati in qualche modo scoperti come parte di certe operazioni le stesse platform in qualche modo danno un loro contributo a questa evoluzione quando bloccano certi account e quindi di conseguenza fanno spostare queste operazioni su altri account quindi se io uso una blacklist fatta sei mesi fa e poi nell'accademia non è mai così perché fino a quando un articolo viene pubblicato è passato almeno un anno da quando è stato scritto se vado a riutilizzare quella blacklist sicuramente scopro che molte di quelle fonti non esistono più e se il mio obiettivo è andare a misurare quanto l'informazione sia problematica intorno a un certo tema probabilmente sto sottostimando in modo molto importante quello che voglio che voglio osservare adesso da quel punto di vista sia qui perché stanno andando sui copani stanno andando perché io poi ma non ci hanno la prima cioè non ti vanno la carne faccio vedere che non hai il punto di vista esatto esatto è chiaro che è praticamente un continuo gioco del gatto con il topo perché di fronte a nuove strategie ci sono nuovi modi per cercare di fronteggiarle e poi nuove strategie e si continua così allora l'idea del coordinating di dire ok non guardiamo più ai contenuti o agli attori ma guardiamo al loro comportamento quando io mi accorgo che ci sono 10-15 pagine facebook che postano gli stessi contenuti continuamente posso supporre che dietro ci sia un'operazione coordinata e questa operazione può essere talvolta diciamo alla luce del sole pensate per esempio a che ne so il mattino e tutte le sue versioni locali che possono ripostare i contenuti della pagina principale in modo automatico lì c'è una forma di autenticità cioè tu pagina ti presenti come parte di un network di cui sei il branch locale e riproponi oltre ai tuoi contenuti anche quelli che ti arrivano diciamo dalla casa madre talvolta invece questa forma di autenticità è completamente assente cioè pagine e gruppi collaborano senza né dire qual è il loro punto di riferimento né specificare nessun tipo di affiliazione fra di loro e lì allora facebook parla di inautenticità fondamentalmente tutte le volte che qualcuno si spaccia per qualcos'altro sulla piattaforma nella linea autenticità facebook per dirla tutta include anche gli account fake che sono una componente importante del coordinated inauthentic behavior ma gli account fake loro li possono vedere o meglio hanno dei sistemi di detection noi a ricercatori esterni alla piattaforma non abbiamo nessunissima possibilità di identificare account di singoli utenti che sono fake ma perché è così importante diciamo porre attenzione all'inautenticità beh se noi guardiamo a la storia della ricerca sull'influenza dei media dovete sapere ve la faccio veramente brevissima che la storia degli effetti della ricerca sugli effetti dei media nasce dopo la seconda guerra mondiale nasce negli Stati Uniti e per ovvie ragioni cioè a un certo punto questi ricercatori alcuni dei quali tra l'altro scappati dalla guerra in Europa si iniziano a porsi dei problemi e a chiedersi ma com'è possibile che una popolazione come quella tedesca abbia seguito senza battere il ciglio le diciamo le regole imposte da un dittatore e com'è possibile che in Italia sia successo la stessa cosa non è che il fatto che ci fossero dei nuovi media quelli che allora erano i nuovi media quindi la radio e in particolare la radio il cinema anche hanno giocato un ruolo nel creare questo consenso e quindi hanno iniziato a studiare come i media hanno possono influenzare l'opinione pubblica ci sono tante teorie di cui non vi parlo ma quelle un pochino più evolute parlano di una influenza che non avviene direttamente da i media a diciamo le menti dei singoli delle singole persone nell'audience ma che questa influenza tende a essere mediata da quelli che nella ricerca in questa teoria vengono chiamati opinion leader ma che potete immaginarvi come delle persone che sono dei vostri pari con i quali voi parlate e talvolta parlate anche di contenuti che provengono dai media ma per il fatto che quel messaggio non viene da un soggetto diciamo molto lontano da voi come può essere un giornalista o appunto un mezzo di comunicazione ma viene da una persona che voi conoscete in un contesto dove in qualche modo voi non vi aspettate che ci sia qualcuno che possa essere interessato a farvi cambiare idea in un contesto di intrattenimento quando uno sta parlando con i suoi amici è proprio lì che è più facile che le idee cambino perché diciamo quando noi siamo di fronte pensate al mondo della pubblicità cioè quando noi siamo di fronte a una pubblicità noi sappiamo cioè abbiamo tutte le nostre difese diciamo contro l'influenza ben attive perché sappiamo che di fronte abbiamo qualcuno il cui scopo principale è quello di cercare di farci cambiare idea quando invece siamo in una chiacchierata informale con i nostri amici è possibile è più facile che si cambi idea pensate a proprio alle idee politiche pensate al ai talk show politici i talk show politici sono l'audience dei talk show politici tende a essere formato da persone che hanno interesse verso la politica e queste persone tendono anche a essere prevalentemente quelle che hanno delle opinioni politiche già ben strutturate il risultato è che i talk show politici in sé incidono pochissimo rispetto al cambiamento delle opinioni politiche perché quelli che li guardano hanno già delle opinioni politiche consolidate allora diventa interessante il meccanismo perché uno si chiede ma io allora se sono un politico e se voglio raggiungere persone a cui posso far cambiare idea dove le devo andare a cercare e come allora sicuramente le devo andare a cercare non in delle arene dove si parla specificamente di politica perché lì trovo probabilmente solo persone che hanno già delle idee chiare quindi non gliele faccio cambiare due devo andare in un ambiente dove le persone non si aspettano di essere influenzate dove sono lì per l'intrattenimento per sono rilassate stanno pensando ad altro e quindi cosa succede che se noi trasliamo questa idea dentro le piattaforme di social media vedete quanto può essere importante provare a costruire delle degli account che hanno una ampia base di follower di una diciamo estrazione politica incerta e talvolta totalmente disinteressate alla politica e usare poi quegli spazi per mandare i messaggi politici perché è così che si raggiungono persone che sono indecise e persone che non sono interessate alla politica in quanto tali potrebbero essere più facilmente influenzabili rispetto a quanto lo possono essere persone che hanno già delle idee politiche consolidate quelle quello che noi abbiamo fatto è passare dal coordinated inauthentic behavior a quello che noi chiamiamo coordinated link sharing behavior che è di fatto un sottoinsieme del coordinated inauthentic behavior non guarda in modo automatizzato alla parte della inautenticità che ovviamente è un aspetto estremamente complicato che di solito facciamo con delle analisi qualitative su queste su queste pagine allora qual è la logica del coordinated link sharing behavior fondamentalmente ci sono due aspetti importanti uno è che più account di social media siano essi facebook o instagram nel nostro sistema ma in teoria il metodo è facilmente applicabile a altri social media condividono lo stesso link in uno spazio di tempo molto breve e lo fanno ripetutamente per link diversi qual è la logica la logica è che certo può capitare che per caso due account facebook diversi due pagine diverse postino lo stesso link in uno spazio di tempo molto breve ma quando lo fanno continuamente e ripetutamente allora è legittimo porsi il dubbio che esse stiano agendo in modo strategicamente coordinato che siano automatizzate probabilmente a livello software e che appunto lavorino come se se fossero un unico gruppo pur non spesso non dicendolo allora qual è la logica dietro il coordinator di un sharing behavior e perché è una forma di manipolazione beh immaginatevi un secondo cioè riflettete un secondo su come funziona l'algoritmo di queste piattaforme l'algoritmo di queste piattaforme come sapete presiede anche alla distribuzione di questi contenuti cioè decide se un contenuto deve essere più o meno spinto diciamo dall'algoritmo e come decide quali sono i contenuti che devono essere più spinti dall'algoritmo andando ad analizzare le performance iniziali di quel contenuto cioè l'idea adesso ovviamente questi algoritmi sono molto più complessi di come lo sto descrivendo adesso però l'idea generale è che se un contenuto sta performando bene nelle sue prime ore di vita anzi addirittura nei suoi primi minuti di vita nei suoi primi momenti di vita allora Facebook conclude che quel contenuto sta interessando e lo fa circolare ulteriormente quindi se io riesco a ingannare l'algoritmo di Facebook facendo collaborare 10 15 pagine che ciascuna ha un'ampia audience che condivide nello stesso istante lo stesso contenuto quello che Facebook vede è che quel contenuto sta performando particolarmente bene in uno spazio di tempo molto molto limitato e quindi potrebbe innescare quel feedback che fa sì che poi l'algoritmo faccia il resto del lavoro nella diffusione quindi lo scopo secondo noi di questa tecnica è appunto quella di ingannare l'algoritmo di Facebook facendoli percepire che questi contenuti sono più popolari di quanto essi siano allora abbiamo fatto uno studio vi ricordate usando lo stesso dataset di notizie delle elezioni del 2018 delle elezioni del 2019 quindi ricordatevi sempre che stiamo parlando di notizie politiche pubblicate nei sei mesi che hanno preceduto le elezioni del 2018 e nei sei mesi che hanno preceduto le elezioni del 2019 ci siamo chiesti ma questo comportamento coordinato effettivamente lo troviamo su queste notizie politiche ci sono delle pagine e dei gruppi Facebook che condividono in modo strategico contenuti politici e poi dopo ci siamo chiesti ma questi questi network si caratterizzano per una forma di autenticità dicono noi siamo un network e stiamo facendo un'operazione come un gruppo o invece non è così e poi abbiamo guardato all'efficacia cioè questo modo di condividere queste notizie effettivamente va poi a incidere su il numero di interazioni che queste notizie producono cioè quelle condivise in modo coordinato hanno ricevuto effettivamente più interazioni di quelle condivise in modo non coordinato e qui abbiamo sviluppato il metodo che poi è quello che in qualche modo andremo a vedere insieme quando entreremo a partire da domani proprio nel nel codice di corenet il metodo si basa su questo questo threshold che noi abbiamo definito qui a very short period of time cioè cosa significa un periodo di tempo molto breve allora noi eravamo di fronte a due possibilità noi potevamo diciamo in qualche modo definire questa soglia in modo rigido dicendo che ne so che 30 secondi 15 secondi un minuto può essere una soglia ragionevole ma siccome ci siamo accorti che in dataset diversi in qualche modo questa soglia era diversa abbiamo cercato di costruire un sistema che in base al dataset che tu stai analizzando stimi questa soglia per cui ci sono dei dataset di condivisioni facebook di notizie che tendono ad avere questa soglia molto bassa e altre che invece hanno una soglia più alta quindi in core net vedrete che l'utente si può specificare un suo threshold ma c'è anche un algoritmo che gli stima in base al dataset che tu gli dai in pasto qual è secondo noi il threshold più adatto abbiamo utilizzato questi questi dataset di notizie che noi avevamo già raccolto durante gli sei mesi che hanno appresciuto le elezioni politiche del 2018 quelle europee del 2019 e abbiamo usato per raccogliere le condivisioni CrowdTangle allora CrowdTangle CrowdTangle è una piattaforma che è di proprietà di Facebook è una piattaforma di social media analytics nel tempo diciamo sono diventato un grande appassionato forse esperto di CrowdTangle tant'è vero che se cercate core net vedrete che viene spesso citato da CrowdTangle stesso come diciamo una delle best practice del che gli utenti hanno prodotto intorno a questa piattaforma e CrowdTangle fondamentalmente è un software che nasce per misurare le performance dei contenuti su i social media non specificamente su Facebook ma a un certo punto viene acquistato da Facebook e pensate questo perché è interessante cioè CrowdTangle come è avvenuto anche per altre aziende ha intuito che raccogliere periodicamente i dati dell'engagement di una piattaforma di social media poteva diventare un business un qualcosa di interesse questo perché perché le piattaforme di social media e io ho avuto modo di verificare questa cosa proprio collaborando con loro noi pensiamo che in qualche modo di essere di fronte delle aziende che sono talmente potenti e ben organizzate che di fronte a una richiesta tirami fuori questo dato siano in grado di eseguirlo diciamo in tempi ragionevolmente brevi ma questo in realtà non è così perché bisogna immaginare che queste aziende producono una mole pazzesca di dati e analizzano solo lo stretto indispensabile che gli è utile per il loro core business cioè per esempio Facebook ha come obiettivo quello di aumentare la permanenza degli utenti sulla piattaforma misura con grandissima attenzione quel dato lì ma se tu gli chiedi quali sono le notizie che più circolano su Facebook loro non lo sanno cioè non hanno o per saperlo devono mettere delle persone a lavorare su quello laddove quel dato a loro non gli interessava prima e fare questo gli costa del tempo e della fatica quindi quando delle piattaforme esterne a un certo punto hanno detto ma se io mi attacco alle loro API e raccolgo un po' come abbiamo fatto noi nelle elezioni del 2018 questi dati sistematicamente a un certo punto mi trovo con una specie di tesoro nelle mani e questo è successo sia per Twitter che per Facebook in entrambi i casi le aziende che hanno iniziato a fare questo sono state acquisite a un certo punto dalla piattaforma perché hanno detto ah effettivamente sono state facendo una cosa che noi non ci avevamo pensato ma ha senso quindi Crowdangle adesso ha il pregio di essere un'azienda posseduta da Facebook e quindi che garantisce che i dati diciamo prodotti rispetto a Facebook siano del tutto coerenti con quelli che puoi vedere sulla piattaforma e offre anche la possibilità di utilizzare Instagram Twitter Reddit non traccia tutto quello che c'è su Facebook perché Crowdangle si limita alla parte pubblica di Facebook quindi ad esempio non traccia i gruppi privati i profili ovviamente delle singole persone e non traccia i gruppi privati traccia le pagine pubbliche i gruppi pubblici i profili i cosiddetti verificati pubblici cioè ci sono alcuni profili che sono profili diciamo utenti di Facebook normali ma che per esempio hanno raggiunto i 5000 follower che possono applicare per diventare una specie di cosa intermedia fra il profilo personale e la pagina non sono tantissimi sono tendenzialmente personaggi pubblici e non tracciano le performance dei post sponsorizzati Facebook adesso ha una cosa che si chiama Ads Library dove ci sono tutti i dati che riguardano invece la pubblicità non tracciano i post che sono mostrati solo a uno specifico gruppo di follower sapete che nelle pagine uno può dire non farlo vedere a tutti ma farlo vedere solo a quelli che hanno come provenienza un certo luogo geografico questi post non vengono tracciati da CrowdTangle e ovviamente purtroppo non traccia i commenti non abbiamo nessuna informazione rispetto ai commenti se non il numero dei commenti CrowdTangle quando spiega questa cosa fa vedere che loro arrivano fino ai numerini che ci sono sotto il post sotto non vanno e questo è un accordo che hanno con Facebook anche legato al fatto che il commento a differenza del dato numerico è molto più difficile da come dire anonimizzare cioè anche se io tolgo il nome dell'utente non ci vuole molto a fare delle ricerche inverse del testo e scoprire qual è l'utente che ha postato e quindi ci sono tutta una serie di problemi poi se volete un giorno vi racconto anche diciamo dell'esperienza che ho avuto con Facebook nel creare un dataset di notizie che hanno restato disponibile ai ricercatori diciamo non senza aver passato tutta una serie di problematiche riguardanti la privacy cioè vi dico solamente questa cosa quando hanno progettato questo dataset che è un dataset apparentemente il più innocuo possibile cioè un dataset che aggrega tutte le interazioni su una URL pubblicata su Facebook in più hanno detto beh togliamo tutte le URL che sono state condivise in pubblico meno di credo che sia cento volte questo perché perché il loro timore è che tu guardando quanto e come è stata condivisa una certa URL possa provare a risalire a un singolo utente e quindi infrangendo la privacy capite bene che Facebook oggi ha come problema principale anche quando si apre ai ricercatori esterni quello di non essere loro i protagonisti di una Cambridge Analytica 2 cioè di un altro scandalo dei dati quindi l'ultima cosa che vogliono è che attraverso un programma gestito direttamente da loro in collaborazione con i ricercatori qualche ricercatore scopra qualche metodo magico per fare esatto esatto loro però questa lezione l'hanno imparato cioè loro hanno capito che se tu lasci un sistema potente in mano al mondo qualcuno che cerca di farne un uso imprevisto diciamo così c'è quindi adesso vanno con i piedi di piombo qui c'è questa soglia ma non solo hanno applicato una cosa che loro chiamano differential privacy cioè non che loro lo chiamano che si chiama differential privacy cioè a tutti i dati delle interazioni su queste notizie è stato applicato un rumore di fondo un rumore distribuito secondo una distribuzione gaussiana che significa che tu hai a che fare con dati che talvolta sono anche dati negativi perché il rumore è talmente ampio che a un dato basso ti può far diventare il dato negativo implicando tutta una serie di problematiche dal punto di vista della costruzione dei modelli statistici eccetera vabbè non ve la faccio tanto lunga comunque quando io sono stato con i miei collaboratori a fare la formazione su questo sistema ho capito che diciamo non sarebbe stato il giorno dopo che avremmo avuto i dati disponibili ma sarebbe stato dopo forse più di un anno e infatti così è stato e quindi ho detto ai miei collaboratori ragazzi c'è CrowdTangle questa cosa qui è interessante approfondiamo questa perché secondo me possiamo farci delle cose delle cose utili e ci siamo concentrati su una un endpoint dell'API di CrowdTangle che si chiama il links endpoint allora come funziona questo links endpoint è molto molto banale cioè accetta come input una URL e come output ti restituisce una serie di informazioni sulla circolazione di quella URL qui in questo caso vedete come è composta la la richiesta per cui tu puoi chiedere di restituire da 1 a 100 post in realtà adesso hanno aumentato fino a 1000 post entro quando la condivisione la condivisione deve essere fatta il link ovviamente che è obbligatorio che vuoi andare a tracciare se avere o no una summary statistic di queste informazioni l'offset vabbè lo tralascio perché riguarda solo la diciamo la paginazione se uno vuole fare più più richieste su quale piattaforma fare questa questa analisi noi abbiamo come ricercatori accesso solamente a Facebook e Instagram in realtà quindi non abbiamo né Reddit né Twitter purtroppo e da quando deve iniziare noi di solito praticamente Cornet funziona così richiede come input una lista di URL e data di pubblicazione quindi usa la data di pubblicazione come start date e aggiunge sette giorni per cui va a studiare la circolazione delle notizie su Facebook e Instagram da una settimana dalla pubblicazione questo perché perché praticamente queste operazioni di manipolazione legate al coordinamento come vi dicevo hanno senso solo se avvengono nei primi momenti di vita della della notizia in più studiando le curve dell'engagement sulle notizie che avevamo abbiamo visto che in pratica nell'arco di massimo due giorni l'engagement intorno a una notizia praticamente arriva a zero e quindi si stabilizza diciamo immaginate una curva che fa così e poi si stabilizza ma nell'arco certe volte di poche ore quindi brucia tutta la sua attività in ben meno di una settimana quindi prendendo una settimana in qualche modo hai dei dati che sono abbastanza stabili quindi tutte le condivisioni fatte su facebook di un certo link in una settimana con questi dati in pratica tu parti da una lista di url con le loro date e ottieni un dataset di condivisioni di quelle url vedremo meglio nei prossimi giorni come è costruito questa data perché come poi dopo noi l'abbiamo utilizzato però la logica fondamentalmente è questa vi dico invece un po' di risultati perché oggi la logica della lezione di oggi è di dire queste sono le cose che si possono fare e poi arrivare diciamo sull'aspetto più puramente metodologico e tecnico allora quando noi abbiamo applicato questo metodo sul set di notizie politiche vi ricordo dai quali siamo partiti abbiamo individuato dieci reti organizzate nel 2018 composta nel complesso da 28 fra pagine e gruppi pubblici e 50 nel 2019 composte fra da nel complesso da 143 fra pagine e gruppi pubblici ora già in diciamo i titoli delle ah vi dico una cosa questa rappresentazione che viene prodotta direttamente da core net e appunto sfrutta la social network analysis come vedremo bene domani e fondamentalmente mappa le relazioni fra le pagine in base al numero di condivisioni coordinate che hanno fatto quindi due pagine o due gruppi sono più vicini nella rappresentazione grafica se hanno condiviso in modo coordinato più volte il numero assoluto di condivisioni coordinate o talvolta anche i follower della pagina o del gruppo vengono utilizzati invece per rappresentare la grandezza del nodo già guardando questi nomi una cosa che si capisce abbastanza chiaramente è che nessuna di queste pagine è una pagina politica vi ricordo che noi siamo partiti da due dataset di notizie politiche quindi già questi due network sono due network che nulla hanno a che fare all'apparenza con la politica e infatti la cosa che è saltata subito all'occhio è che noi avevamo a che fare con tre almeno tipi di network diversi quelli politici e questo ce l'aspettavamo che ci fossero delle pagine che erano coordinate allora ad esempio la stessa pagina ufficiale di Matteo Salvini era parte di un network oggi non è più così e così ce ne erano vicini alla Lega ce ne erano vicini al Movimento 5 Stelle ma quelli ce li aspettavamo e di fatto come dicevo fino a quando non si pone il problema dell'autenticità dell'inaautenticità il fatto che ci sia coordinamento di per sé non è un qualcosa di negativo cioè ognuno fa il marketing online come ritiene opportuno cioè non c'è nessuna legge che dice tu non ti puoi coordinare e e poi abbiamo trovato invece dei network misti che vedete come quello mostrato in questo esempio contiene pagine gruppi dai titoli chiaramente vicini a un certo una certa posizione ideologica nero dentro Italia patriamia quindi ovviamente il nazionalismo Italia uguale dittatura prima aiutiamo gli italiani poi si vede movimento adesso Italia riprendiamoci la patria quindi diciamo quel mix di nazionalismo anti-immigrazione che ha caratterizzato insomma molto gli ultimi anni della storia italiana solo che vicino a queste pagine chiaramente identificate come ideologiche c'erano pagine come dislessia portami via screenshot divertenti corriere della notizia che finge di essere una una notizia un sito di notizie rimandando diciamo al nome del corriere e quindi veniva spontaneo chiedersi ma come mai dentro come mai dislessia portami via condivideva gli stessi link di Italia uguale dittatura o Italia patria mia c'è qualcosa che non torna se non fosse che poi abbiamo scoperto i letter completamente non politici cioè network che non avevano proprio nessun riferimento in nessuna delle loro pagine a account politici ma che di fatto avevano condiviso in modo coordinato contenuti politici ricordatevi sempre che noi siamo partiti da due data sette di notizie politiche e tenete presente quel link attivi che c'è al centro perché lo ritroveremo nella storia che sto per raccontarvi allora quando racconto la questione dell'inautenticità di solito uso sempre questo caso la pagina professione il cui nome completo è professione mantenuto ovvero questa pagina che vedete qui professione mantenuto ha come diciamo core business di produzione dei suoi contenuti queste foto di ragazze più o meno svestite ma non solo ragazze talvolta anche ragazzi con legata in qualche modo allo sport non so questo è il taglio diciamo che chi riusisce la pagina ha deciso di dare vedete che si tratta di una pagina che già allora quando noi l'abbiamo osservata aveva raggiunto un certo grado di popolarità perché stiamo parlando dei 150.000 follower e che posta appunto tendenzialmente notizie di soggetti seminudi in pose più o meno provocative legate allo sport ma ogni tanto posta anche contenuti di questo genere riposta i video di Salvini direttamente dalla pagina ufficiale di Matteo Salvini posta propaganda anti-europea posta notizie diciamo di supporto a Putin provenienti da fonti notoriamente inserite in blacklist di notizie false questa tg-news24.com ricordatevi anche questo perché ritornerà a breve quindi chiaramente una pagina e network costruiti per raggiungere un pubblico disinteressato alla politica al quale puoi andare a inviare notizie politiche ora qualcuno qui c'è sempre il problema di dire ok ma queste pagine siamo sicuri che lo facciano per uno scopo ideologico o potrebbero anche farlo semplicemente perché hanno venduto in qualche modo i loro follower a un content provider di terze parti cioè tu quando hai una pagina grande può capitare di essere approcciato da qualcuno che dice ma se ti do qualche soldo tu mi fai circolare i miei contenuti quindi questo noi non lo sappiamo ma comunque sia il problema rimane perché anche se fossero delle pagine che sono semplicemente pagate per far circolare questi contenuti rimaneva il problema di chi paga per far circolare questi contenuti e non altri evidentemente qualcuno ha del denaro da spendere per provare a influenzare l'opinione pubblica attraverso questi network e queste pagine quando siamo andati a vedere l'efficacia anche essa diciamo rispecchiava le nostre aspettative se guardate sia nel 2018 sia nel 2019 le notizie condivise in modo coordinato hanno ricevuto un engagement superiore rispetto a quelle condivise in modo non coordinato e l'altra cosa interessante è che abbiamo fatto un lavoro di questo genere cioè noi abbiamo detto il nostro metodo non parte dai contenuti parte dal comportamento ma potrebbe essere che guardando il comportamento poi noi andiamo in qualche modo a far emergere i contenuti problematici e come abbiamo fatto a dimostrarlo siamo andati a vedere i domini condivisi in modo coordinato che erano presenti anche nelle blacklist dei fact checker italiani quindi abbiamo preso queste blacklist abbiamo visto questi sono i domini coordinati questi sono i domini non coordinati in che percentuale questi domini appartengono a queste blacklist e abbiamo scoperto che sistematicamente vedete in 4 dataset diversi la percentuale di domini inclusi nelle blacklist era sistematicamente superiore in quelli condivisi in modo coordinato rispetto a quelli condivisi in modo non coordinato e vabbè abbiamo stimato un valore che si chiama risk ratio che dimostra che diciamo c'è una differenza statisticamente significativa tra questi due gruppi il che non dico che porta a concludere che il nostro sistema trova le notizie false perché ovviamente non è così ma ti fa concentrare su un sotto insieme di notizie dove ce ne sono molte che sono problematiche più che diciamo se andassi a cercarle con altri metodi crowdtangle consente di fare delle dashboard anche pubbliche che noi usiamo per monitorare quello che fanno i network coordinati che abbiamo identificato in questo caso c'è un esempio delle entità coordinate che abbiamo trovato con questo studio ma quello che è importante diciamo al di là dello specifico caso è il fatto che queste questi network possono essere monitorati nel tempo tenete presente questa idea cioè una volta che tu li hai identificati puoi monitorare cosa fanno nel tempo c'è una collega francese che poi in realtà non è una collega accademica ma è una collega che lavora grafica che è una diciamo delle società che si occupano di combattere la disinformazione proprio come il loro core business un'azienda privata che ha tirato fuori questo questo nome carino per definire questo approccio che appunto non si limita a guardare i contenuti non si limita a guardare gli attori ma in qualche modo ottiene insieme tutte queste tre prospettive e guarda caso diciamo il nome viene anche fuori come ABC framework quindi manipolative actors deceptive behavior e harmful content adesso per oggi mi fermo qua ma abbiamo quasi finito diciamo questa parte sul diciamo sui risultati che abbiamo ottenuto applicando questo metodo e domani vedremo proprio quello che abbiamo fatto sullo specifico del coronavirus e dei network coordinati nell'ambito della disinformazione sul coronavirus occuperemo non tanto tempo della lezione di domani e poi seguendo un metodo simile a quello che avete usato con i markdown di DR andremo a fare una sorta di percorso guidato nel codice di Cornet per imparare a conoscerlo un pochino meglio perché appunto l'idea che ho è che come progetto diciamo del corso possiate identificare dei delle possibilità diciamo di miglioramento personalizzazione di Cornet e possiate effettivamente agire sul codice per modificarlo a vostro piacimento vedremo che ci sono alcune idee su come migliorarlo noi ce le abbiamo già e ve le proporremo altre emergeranno diciamo anche dai vostri suggerimenti ognuno di voi ne potrà scegliere una o anche la stessa può essere scelta la più persone e come diciamo nel proseguio delle lezioni ci dedicheremo proprio a questi progetti nello specifico quindi sarà diventerà un corso molto operativo legato a questi a questi obiettivi ok allora io mi fermo qui a casa ci siete ancora siete sopravvissuti ci siete annoiati sì sì tutto bene tutto bene ok ci siamo ci siamo bene bene bene allora ragazzi ci vediamo domani alle 4 perfetto domani arrivederci a domani ciao ciao ciao